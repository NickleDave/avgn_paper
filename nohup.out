[I 14:29:35.984 LabApp] [nb_conda_kernels] enabled, 14 kernels found
[I 14:29:38.885 LabApp] The port 8186 is already in use, trying another port.
[I 14:29:39.107 LabApp] [jupyter_nbextensions_configurator] enabled 0.4.0
[I 14:29:39.441 LabApp] JupyterLab extension loaded from /mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/jupyterlab
[I 14:29:39.441 LabApp] JupyterLab application directory is /mnt/cube/tsainbur/conda_envs/tpy3/share/jupyter/lab
[I 14:29:39.499 LabApp] Serving notebooks from local directory: /home/AD/tsainbur/github_repos
[I 14:29:39.499 LabApp] The Jupyter Notebook is running at:
[I 14:29:39.499 LabApp] http://localhost:8187/?token=3a7357890b53acb133dd7c2150e37137b6c1e71b6c8b2c43
[I 14:29:39.499 LabApp]  or http://127.0.0.1:8187/?token=3a7357890b53acb133dd7c2150e37137b6c1e71b6c8b2c43
[I 14:29:39.499 LabApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[C 14:29:39.514 LabApp] 
    
    To access the notebook, open this file in a browser:
        file:///run/user/18000/jupyter/nbserver-20419-open.html
    Or copy and paste one of these URLs:
        http://localhost:8187/?token=3a7357890b53acb133dd7c2150e37137b6c1e71b6c8b2c43
     or http://127.0.0.1:8187/?token=3a7357890b53acb133dd7c2150e37137b6c1e71b6c8b2c43
[I 14:30:45.967 LabApp] 302 GET /tree (::1) 2.52ms
[I 14:31:18.809 LabApp] 302 GET /?token=3a7357890b53acb133dd7c2150e37137b6c1e71b6c8b2c43 (::1) 0.60ms
[W 14:32:26.598 LabApp] delete /avgn_paper/cudf=0.9
[W 15:08:40.608 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/5.0-human-phones-umap.ipynb is not trusted
[I 15:08:41.876 LabApp] Kernel started: 17f20f81-e059-49a8-864c-62e7ddd683cb
[I 15:08:44.568 LabApp] Adapting from protocol version 5.1 (kernel 17f20f81-e059-49a8-864c-62e7ddd683cb) to 5.3 (client).
[I 15:10:46.584 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/5.0-human-phones-umap.ipynb
[W 15:10:46.586 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/5.0-human-phones-umap.ipynb is not trusted
[I 15:10:55.256 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/5.0-human-phones-umap.ipynb
[W 15:10:55.258 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/5.0-human-phones-umap.ipynb is not trusted
[I 15:12:53.055 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/5.0-human-phones-umap.ipynb
[W 15:12:53.058 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/5.0-human-phones-umap.ipynb is not trusted
[I 15:14:06.540 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/5.0-human-phones-umap.ipynb
[W 15:14:06.543 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/5.0-human-phones-umap.ipynb is not trusted
[I 15:14:11.381 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/5.0-human-phones-umap.ipynb
[W 15:14:11.383 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/5.0-human-phones-umap.ipynb is not trusted
[I 15:17:28.540 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/5.0-human-phones-umap.ipynb
[W 15:17:28.543 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/5.0-human-phones-umap.ipynb is not trusted
[I 15:20:11.902 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/5.0-human-phones-umap.ipynb
[I 15:20:37.342 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/5.0-human-phones-umap.ipynb
[I 15:23:47.208 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/5.0-human-phones-umap.ipynb
[I 15:24:11.619 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/5.0-human-phones-umap.ipynb
[I 15:24:13.978 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/5.0-human-phones-umap.ipynb
[I 15:25:12.817 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/5.0-human-phones-umap.ipynb
[I 15:27:46.105 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/5.0-human-phones-umap.ipynb
[I 15:28:06.835 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/5.0-human-phones-umap.ipynb
[I 15:29:13.468 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/5.0-human-phones-umap.ipynb
[I 15:29:46.772 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/5.0-human-phones-umap.ipynb
[I 15:30:11.873 LabApp] KernelRestarter: restarting kernel (1/5), keep random ports
kernel 17f20f81-e059-49a8-864c-62e7ddd683cb restarted
[I 15:31:06.007 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/5.0-human-phones-umap.ipynb
[I 15:32:00.468 LabApp] Starting buffering for 17f20f81-e059-49a8-864c-62e7ddd683cb:7c2a3a9ad202425682347e70bfabc91f
[I 15:32:00.493 LabApp] Adapting from protocol version 5.1 (kernel 17f20f81-e059-49a8-864c-62e7ddd683cb) to 5.3 (client).
[I 15:32:00.494 LabApp] Restoring connection for 17f20f81-e059-49a8-864c-62e7ddd683cb:7c2a3a9ad202425682347e70bfabc91f
[I 15:32:04.070 LabApp] Starting buffering for 17f20f81-e059-49a8-864c-62e7ddd683cb:7c2a3a9ad202425682347e70bfabc91f
[I 15:32:04.505 LabApp] Kernel restarted: 17f20f81-e059-49a8-864c-62e7ddd683cb
[I 15:32:06.909 LabApp] Adapting from protocol version 5.1 (kernel 17f20f81-e059-49a8-864c-62e7ddd683cb) to 5.3 (client).
[I 15:32:06.910 LabApp] Restoring connection for 17f20f81-e059-49a8-864c-62e7ddd683cb:7c2a3a9ad202425682347e70bfabc91f
[I 15:32:06.910 LabApp] Replaying 6 buffered messages
[I 15:34:24.873 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/5.0-human-phones-umap.ipynb
[I 15:37:44.911 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/5.0-human-phones-umap.ipynb
[I 15:41:06.044 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/5.0-human-phones-umap.ipynb
[I 15:58:29.605 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/5.0-human-phones-umap.ipynb
[I 16:01:06.981 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/5.0-human-phones-umap.ipynb
[I 16:02:33.083 LabApp] Kernel started: 92cb25a9-c440-4c23-ae86-6dde85b2a48d
[I 16:02:34.712 LabApp] Adapting from protocol version 5.1 (kernel 92cb25a9-c440-4c23-ae86-6dde85b2a48d) to 5.3 (client).
[I 16:03:53.801 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/5.0-human-words-umap.ipynb
[I 16:04:03.683 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/5.0-human-words-umap.ipynb
[I 16:04:28.729 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/5.0-human-phones-umap.ipynb
[I 16:07:37.309 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/5.0-human-words-umap.ipynb
[I 16:07:37.681 LabApp] Kernel interrupted: 92cb25a9-c440-4c23-ae86-6dde85b2a48d
[I 16:08:36.119 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/5.0-human-words-umap.ipynb
[I 16:10:37.408 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/5.0-human-words-umap.ipynb
[I 16:12:37.612 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/5.0-human-words-umap.ipynb
[W 16:13:45.666 LabApp] Blocking request with no referer
[W 16:13:45.666 LabApp] 403 GET /files/github_repos/avgn_paper/figures/phonemes.jpg (::1): Blocking request from unknown origin
[W 16:13:45.742 LabApp] 403 GET /files/github_repos/avgn_paper/figures/phonemes.jpg (::1) 77.66ms referer=None
[W 16:13:50.366 LabApp] 404 GET /tree/github_repos/avgn_paper/figures/phonemes.jpg (::1) 7.16ms referer=None
[I 16:13:57.591 LabApp] 302 GET /tree/avgn_paper/figures/phonemes.jpg (::1) 2.39ms
[W 16:13:57.626 LabApp] Blocking request with no referer
[W 16:13:57.626 LabApp] 403 GET /files/avgn_paper/figures/phonemes.jpg (::1): Blocking request from unknown origin
[W 16:13:57.629 LabApp] 403 GET /files/avgn_paper/figures/phonemes.jpg (::1) 3.85ms referer=None
[W 16:14:01.417 LabApp] Blocking request with no referer
[W 16:14:01.417 LabApp] 403 GET /files/avgn_paper/figures/ (::1): Blocking request from unknown origin
[W 16:14:01.419 LabApp] 403 GET /files/avgn_paper/figures/ (::1) 3.97ms referer=None
[I 16:14:04.530 LabApp] 302 GET /tree/avgn_paper/figures/ (::1) 0.94ms
[W 16:15:50.737 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/cassins-syllable-umap.ipynb is not trusted
[I 16:15:51.812 LabApp] Kernel started: 20fcd187-6aa4-4789-8c98-137c26058989
[I 16:15:53.570 LabApp] Adapting from protocol version 5.1 (kernel 20fcd187-6aa4-4789-8c98-137c26058989) to 5.3 (client).
[I 16:16:51.317 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/cassins-syllable-umap.ipynb
[W 16:16:51.319 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/cassins-syllable-umap.ipynb is not trusted
[I 16:17:52.834 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/cassins-syllable-umap.ipynb
[W 16:17:52.836 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/cassins-syllable-umap.ipynb is not trusted
[I 16:23:52.673 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/cassins-syllable-umap.ipynb
[W 16:23:52.675 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/cassins-syllable-umap.ipynb is not trusted
[I 16:24:47.664 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/cassins-syllable-umap.ipynb
[W 16:24:47.666 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/cassins-syllable-umap.ipynb is not trusted
[I 16:25:03.722 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/cassins-syllable-umap.ipynb
[W 16:25:03.724 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/cassins-syllable-umap.ipynb is not trusted
[I 16:25:52.163 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/cassins-syllable-umap.ipynb
[I 16:27:53.246 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/cassins-syllable-umap.ipynb
[W 16:31:04.023 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/starling-umap.ipynb is not trusted
[I 16:31:05.471 LabApp] Kernel started: 40d7b582-1c06-4c11-8d0c-0326bbfe2dc2
[I 16:31:06.934 LabApp] Adapting from protocol version 5.1 (kernel 40d7b582-1c06-4c11-8d0c-0326bbfe2dc2) to 5.3 (client).
[I 16:33:08.960 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/starling-umap.ipynb
[W 16:33:08.962 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/starling-umap.ipynb is not trusted
[W 16:45:23.573 LabApp] WebSocket ping timeout after 119965 ms.
[I 16:45:28.577 LabApp] Starting buffering for 20fcd187-6aa4-4789-8c98-137c26058989:bb43777ae11d46f3812c8973405370c3
[W 16:45:34.715 LabApp] WebSocket ping timeout after 119975 ms.
[W 16:45:36.911 LabApp] WebSocket ping timeout after 119977 ms.
[W 16:45:36.936 LabApp] WebSocket ping timeout after 119977 ms.
[I 16:45:39.717 LabApp] Starting buffering for 92cb25a9-c440-4c23-ae86-6dde85b2a48d:cbf21590e2f14b1a8ade281efbcea0cd
[I 16:45:41.913 LabApp] Starting buffering for 17f20f81-e059-49a8-864c-62e7ddd683cb:7c2a3a9ad202425682347e70bfabc91f
[I 16:45:41.938 LabApp] Starting buffering for 40d7b582-1c06-4c11-8d0c-0326bbfe2dc2:bd4138dc4f5b462a853512b2e0ed92a0
[W 11:52:21.906 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/starling-umap.ipynb is not trusted
[W 11:52:22.571 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/4.0-marmoset-dataset-umap.ipynb is not trusted
[I 11:52:23.619 LabApp] Kernel started: 699e13d6-2df5-4be6-91af-7ed3ede3331a
[I 11:52:24.054 LabApp] Adapting from protocol version 5.1 (kernel 40d7b582-1c06-4c11-8d0c-0326bbfe2dc2) to 5.3 (client).
[I 11:52:32.761 LabApp] Adapting from protocol version 5.1 (kernel 699e13d6-2df5-4be6-91af-7ed3ede3331a) to 5.3 (client).
[I 11:54:24.689 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/4.0-marmoset-dataset-umap.ipynb
[W 11:54:24.692 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/4.0-marmoset-dataset-umap.ipynb is not trusted
[I 11:54:28.170 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/starling-umap.ipynb
[W 11:54:28.174 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/starling-umap.ipynb is not trusted
[I 11:56:01.138 LabApp] Adapting from protocol version 5.1 (kernel 17f20f81-e059-49a8-864c-62e7ddd683cb) to 5.3 (client).
[I 11:56:23.628 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/4.0-marmoset-dataset-umap.ipynb
[W 11:56:23.630 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/4.0-marmoset-dataset-umap.ipynb is not trusted
[I 11:57:18.399 LabApp] Kernel interrupted: 699e13d6-2df5-4be6-91af-7ed3ede3331a
Got CUSOLVER error 7 at /conda/conda-bld/libcuml_1566588242169/work/cpp/src/common/cumlHandle.cpp:267
CUSOLVER_STATUS_INTERNAL_ERROR
[I 11:57:50.354 LabApp] KernelRestarter: restarting kernel (1/5), keep random ports
kernel 699e13d6-2df5-4be6-91af-7ed3ede3331a restarted
[I 11:58:13.734 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/5.0-human-phones-umap.ipynb
[I 11:58:23.767 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/4.0-marmoset-dataset-umap.ipynb
[W 11:58:23.769 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/4.0-marmoset-dataset-umap.ipynb is not trusted
[I 11:58:58.506 LabApp] KernelRestarter: restarting kernel (1/5), keep random ports
kernel 17f20f81-e059-49a8-864c-62e7ddd683cb restarted
[I 12:16:23.773 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/4.0-marmoset-dataset-umap.ipynb
[W 12:16:23.774 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/4.0-marmoset-dataset-umap.ipynb is not trusted
[I 12:18:23.853 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/4.0-marmoset-dataset-umap.ipynb
[W 12:18:23.854 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/4.0-marmoset-dataset-umap.ipynb is not trusted
[I 12:18:26.780 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/starling-umap.ipynb
[W 12:18:26.783 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/starling-umap.ipynb is not trusted
[I 12:19:21.520 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/4.0-marmoset-dataset-umap.ipynb
[W 12:19:21.521 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/4.0-marmoset-dataset-umap.ipynb is not trusted
[I 12:19:33.627 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/4.0-marmoset-dataset-umap.ipynb
[W 12:19:33.629 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/4.0-marmoset-dataset-umap.ipynb is not trusted
[I 12:19:44.234 LabApp] Kernel interrupted: 699e13d6-2df5-4be6-91af-7ed3ede3331a
[I 12:20:24.166 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/4.0-marmoset-dataset-umap.ipynb
[W 12:20:24.168 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/4.0-marmoset-dataset-umap.ipynb is not trusted
[I 12:20:28.830 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/starling-umap.ipynb
[W 12:20:28.832 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/starling-umap.ipynb is not trusted
[I 12:21:10.339 LabApp] Kernel interrupted: 699e13d6-2df5-4be6-91af-7ed3ede3331a
[I 12:21:28.635 LabApp] Kernel interrupted: 699e13d6-2df5-4be6-91af-7ed3ede3331a
[I 12:22:24.153 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/4.0-marmoset-dataset-umap.ipynb
[W 12:22:24.155 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/4.0-marmoset-dataset-umap.ipynb is not trusted
[I 12:23:00.217 LabApp] Starting buffering for 17f20f81-e059-49a8-864c-62e7ddd683cb:b4aae02a35124e0e8b49b3afd218752c
[I 12:23:10.225 LabApp] Kernel started: 6fcc572e-3831-4ae8-95cb-225536608467
[I 12:23:13.081 LabApp] Adapting from protocol version 5.1 (kernel 6fcc572e-3831-4ae8-95cb-225536608467) to 5.3 (client).
[I 12:23:25.241 LabApp] Starting buffering for 6fcc572e-3831-4ae8-95cb-225536608467:4b495aed26094d8da15b029e0eac1785
[I 12:23:37.986 LabApp] Kernel shutdown: 6fcc572e-3831-4ae8-95cb-225536608467
[W 12:23:38.642 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/fruitbat-isolation-umap.ipynb is not trusted
[I 12:23:39.662 LabApp] Kernel started: 3cd6a1dc-880a-4e21-92b5-3118b29a9780
[I 12:23:43.517 LabApp] Kernel shutdown: 40d7b582-1c06-4c11-8d0c-0326bbfe2dc2
[I 12:23:45.224 LabApp] Kernel shutdown: 699e13d6-2df5-4be6-91af-7ed3ede3331a
[I 12:23:45.230 LabApp] Adapting from protocol version 5.1 (kernel 3cd6a1dc-880a-4e21-92b5-3118b29a9780) to 5.3 (client).
[I 12:23:45.749 LabApp] Kernel shutdown: 17f20f81-e059-49a8-864c-62e7ddd683cb
[I 12:23:47.968 LabApp] Kernel shutdown: 20fcd187-6aa4-4789-8c98-137c26058989
[I 12:23:53.861 LabApp] Kernel shutdown: 92cb25a9-c440-4c23-ae86-6dde85b2a48d
[W 12:23:58.028 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/canary-syllable-umap.ipynb is not trusted
[I 12:23:59.861 LabApp] Kernel started: 66f2f873-47e1-418f-a61c-25b4a6627eb9
[I 12:24:02.908 LabApp] Adapting from protocol version 5.1 (kernel 66f2f873-47e1-418f-a61c-25b4a6627eb9) to 5.3 (client).
[W 12:24:21.799 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/5.0-swamp-sparrow-dataset-umap.ipynb is not trusted
[I 12:24:22.658 LabApp] Kernel started: 2d3054ae-066c-4998-bf0a-040fd272b76e
[I 12:24:25.207 LabApp] Adapting from protocol version 5.1 (kernel 2d3054ae-066c-4998-bf0a-040fd272b76e) to 5.3 (client).
[W 12:24:33.808 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/zf-lib-syllable-umap.ipynb is not trusted
[I 12:24:34.600 LabApp] Kernel started: 98fc4fd3-9c54-4da9-9a34-065514d41017
[I 12:24:37.390 LabApp] Adapting from protocol version 5.1 (kernel 98fc4fd3-9c54-4da9-9a34-065514d41017) to 5.3 (client).
[W 12:24:52.869 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/zf-syllable-umap.ipynb is not trusted
[I 12:24:54.572 LabApp] Kernel started: 3bcbaa8f-8279-4b6f-955a-6537a82c1757
[I 12:24:56.810 LabApp] Adapting from protocol version 5.1 (kernel 3bcbaa8f-8279-4b6f-955a-6537a82c1757) to 5.3 (client).
[W 12:25:01.347 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/munia-syllable-umap.ipynb is not trusted
[W 12:25:06.966 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/humpback-syllable-umap.ipynb is not trusted
[I 12:25:07.748 LabApp] Kernel started: fc0b22f0-149f-483f-a3a3-005c25c53225
[I 12:25:09.089 LabApp] Adapting from protocol version 5.1 (kernel fc0b22f0-149f-483f-a3a3-005c25c53225) to 5.3 (client).
[I 12:25:11.041 LabApp] Kernel started: 9ae0acb6-5a70-4fdf-8547-1d760390b51c
[I 12:25:12.459 LabApp] Adapting from protocol version 5.1 (kernel 9ae0acb6-5a70-4fdf-8547-1d760390b51c) to 5.3 (client).
[W 12:25:19.594 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/5.0-mouse-umap.ipynb is not trusted
[W 12:25:19.842 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/mouse-usv-syllable-umap.ipynb is not trusted
[I 12:25:20.155 LabApp] Kernel started: 27404533-ce8e-4b49-93ff-0132477e97a7
[I 12:25:21.186 LabApp] Adapting from protocol version 5.1 (kernel 27404533-ce8e-4b49-93ff-0132477e97a7) to 5.3 (client).
[I 12:25:21.345 LabApp] Kernel started: 9eb35b93-8ad3-4ee2-bf16-4ff16ea2ff79
[I 12:25:22.368 LabApp] Adapting from protocol version 5.1 (kernel 9eb35b93-8ad3-4ee2-bf16-4ff16ea2ff79) to 5.3 (client).
[W 12:25:32.571 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/thrasher-syllable-umap.ipynb is not trusted
[I 12:25:34.197 LabApp] Kernel started: 80a69b0b-000f-4d9f-807c-9b8537c8b97d
[W 12:25:35.686 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/bf-sober-umap.ipynb is not trusted
[I 12:25:35.880 LabApp] Adapting from protocol version 5.1 (kernel 80a69b0b-000f-4d9f-807c-9b8537c8b97d) to 5.3 (client).
[I 12:25:36.652 LabApp] Kernel started: f57a99d2-2a3d-4982-b869-a0a4ec8bcc1e
[I 12:25:37.871 LabApp] Adapting from protocol version 5.1 (kernel f57a99d2-2a3d-4982-b869-a0a4ec8bcc1e) to 5.3 (client).
[I 12:25:42.288 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/fruitbat-isolation-umap.ipynb
[W 12:25:42.293 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/fruitbat-isolation-umap.ipynb is not trusted
[W 12:25:48.455 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/macaque-syllable-umap.ipynb is not trusted
[I 12:25:49.101 LabApp] Kernel started: f6663d4f-f39f-43bf-846a-18ff976a5eaf
[I 12:25:50.673 LabApp] Adapting from protocol version 5.1 (kernel f6663d4f-f39f-43bf-846a-18ff976a5eaf) to 5.3 (client).
[I 12:26:10.336 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/canary-syllable-umap.ipynb
[W 12:26:10.339 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/canary-syllable-umap.ipynb is not trusted
[I 12:26:24.647 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/5.0-swamp-sparrow-dataset-umap.ipynb
[W 12:26:24.648 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/5.0-swamp-sparrow-dataset-umap.ipynb is not trusted
[I 12:26:36.455 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/zf-lib-syllable-umap.ipynb
[W 12:26:36.457 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/zf-lib-syllable-umap.ipynb is not trusted
[I 12:27:05.074 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/zf-syllable-umap.ipynb
[W 12:27:05.076 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/zf-syllable-umap.ipynb is not trusted
[I 12:27:08.640 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/humpback-syllable-umap.ipynb
[W 12:27:08.641 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/humpback-syllable-umap.ipynb is not trusted
[I 12:27:21.360 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/5.0-mouse-umap.ipynb
[W 12:27:21.362 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/5.0-mouse-umap.ipynb is not trusted
[I 12:27:37.781 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/thrasher-syllable-umap.ipynb
[W 12:27:37.782 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/thrasher-syllable-umap.ipynb is not trusted
[I 12:27:39.509 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/mouse-usv-syllable-umap.ipynb
[W 12:27:39.511 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/mouse-usv-syllable-umap.ipynb is not trusted
[I 12:27:48.740 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/bf-sober-umap.ipynb
[W 12:27:48.741 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/bf-sober-umap.ipynb is not trusted
[I 12:27:51.158 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/macaque-syllable-umap.ipynb
[W 12:27:51.160 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/macaque-syllable-umap.ipynb is not trusted
[I 12:28:42.895 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/munia-syllable-umap.ipynb
[W 12:28:42.901 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/munia-syllable-umap.ipynb is not trusted
[I 12:29:34.896 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/thrasher-syllable-umap.ipynb
[W 12:29:34.898 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/thrasher-syllable-umap.ipynb is not trusted
[I 12:31:35.080 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/thrasher-syllable-umap.ipynb
[W 12:31:35.082 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/thrasher-syllable-umap.ipynb is not trusted
[I 12:33:34.911 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/thrasher-syllable-umap.ipynb
[W 12:33:34.913 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/thrasher-syllable-umap.ipynb is not trusted
[I 12:34:27.169 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/thrasher-syllable-umap.ipynb
[W 12:34:27.170 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/thrasher-syllable-umap.ipynb is not trusted
[I 12:34:49.847 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/thrasher-syllable-umap.ipynb
[W 12:34:49.849 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/thrasher-syllable-umap.ipynb is not trusted
[I 12:34:55.400 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/thrasher-syllable-umap.ipynb
[W 12:34:55.401 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/thrasher-syllable-umap.ipynb is not trusted
[I 12:35:34.655 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/thrasher-syllable-umap.ipynb
[W 12:35:34.656 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/thrasher-syllable-umap.ipynb is not trusted
[I 12:37:34.590 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/thrasher-syllable-umap.ipynb
[W 12:37:34.592 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/thrasher-syllable-umap.ipynb is not trusted
[I 12:39:34.445 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/thrasher-syllable-umap.ipynb
[W 12:39:34.445 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/thrasher-syllable-umap.ipynb is not trusted
[I 12:41:34.895 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/thrasher-syllable-umap.ipynb
[W 12:41:34.896 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/thrasher-syllable-umap.ipynb is not trusted
[I 12:41:43.591 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/thrasher-syllable-umap.ipynb
[W 12:41:43.592 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/thrasher-syllable-umap.ipynb is not trusted
[I 12:42:42.468 LabApp] Starting buffering for 80a69b0b-000f-4d9f-807c-9b8537c8b97d:eaed47f9c0cc4996aec674395203191a
[I 12:42:44.077 LabApp] Kernel shutdown: 80a69b0b-000f-4d9f-807c-9b8537c8b97d
[I 12:43:41.936 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/bf-sober-umap.ipynb
[W 12:43:41.937 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/bf-sober-umap.ipynb is not trusted
[I 12:45:23.551 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/bf-sober-umap.ipynb
[I 12:45:36.751 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/bf-sober-umap.ipynb
[I 12:46:57.919 LabApp] Kernel interrupted: f6663d4f-f39f-43bf-846a-18ff976a5eaf
[I 12:47:38.309 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/bf-sober-umap.ipynb
[I 12:47:49.880 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/macaque-syllable-umap.ipynb
[I 12:49:50.578 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/macaque-syllable-umap.ipynb
[I 12:50:19.423 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/bf-sober-umap.ipynb
[I 12:50:22.912 LabApp] Starting buffering for f6663d4f-f39f-43bf-846a-18ff976a5eaf:881825cad030414ebda941ca072c11f4
[I 12:50:24.018 LabApp] Kernel shutdown: f6663d4f-f39f-43bf-846a-18ff976a5eaf
[I 12:51:39.445 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/bf-sober-umap.ipynb
[I 12:52:24.747 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/5.0-swamp-sparrow-dataset-umap.ipynb
[W 12:52:24.748 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/5.0-swamp-sparrow-dataset-umap.ipynb is not trusted
[W 12:54:02.765 LabApp] WebSocket ping timeout after 119982 ms.
[W 12:54:02.911 LabApp] WebSocket ping timeout after 119981 ms.
[W 12:54:07.394 LabApp] WebSocket ping timeout after 119982 ms.
[W 12:54:08.768 LabApp] WebSocket ping timeout after 120877 ms.
[I 12:54:08.769 LabApp] Starting buffering for 66f2f873-47e1-418f-a61c-25b4a6627eb9:73e2d75ea0d744a685edd2a91813b537
[W 12:54:09.092 LabApp] WebSocket ping timeout after 119936 ms.
[I 12:54:12.395 LabApp] Starting buffering for 98fc4fd3-9c54-4da9-9a34-065514d41017:bde34a9e9d8e472e890ff8bb16fc955d
[W 12:54:12.462 LabApp] WebSocket ping timeout after 119870 ms.
[I 12:54:13.770 LabApp] Starting buffering for f57a99d2-2a3d-4982-b869-a0a4ec8bcc1e:09af5c3f38f6486f9c621fd275d4469c
[I 12:54:14.094 LabApp] Starting buffering for fc0b22f0-149f-483f-a3a3-005c25c53225:a71c6c2cbb9545a1b4681e4311498c65
[I 12:54:17.463 LabApp] Starting buffering for 9ae0acb6-5a70-4fdf-8547-1d760390b51c:7bba80b33bb443b486796db682d52483
[W 12:54:21.190 LabApp] WebSocket ping timeout after 119979 ms.
[W 12:54:22.370 LabApp] WebSocket ping timeout after 119977 ms.
[W 12:54:23.864 LabApp] WebSocket ping timeout after 119620 ms.
[W 12:54:24.056 LabApp] WebSocket ping timeout after 119714 ms.
[W 12:54:25.210 LabApp] WebSocket ping timeout after 119981 ms.
[I 12:54:26.192 LabApp] Starting buffering for 27404533-ce8e-4b49-93ff-0132477e97a7:049c5f83af99425f9e0e141ca6ab5918
[W 12:54:26.813 LabApp] WebSocket ping timeout after 119939 ms.
[I 12:54:27.372 LabApp] Starting buffering for 9eb35b93-8ad3-4ee2-bf16-4ff16ea2ff79:44b1f9c2ced64077a6edce0ca0e1b7e4
[I 12:54:28.866 LabApp] Starting buffering for 3cd6a1dc-880a-4e21-92b5-3118b29a9780:29ef092561ed48dd8d59e70bacdedc2e
[I 12:54:30.212 LabApp] Starting buffering for 2d3054ae-066c-4998-bf0a-040fd272b76e:01b6e061d2ef4b4f90ff1976b4098815
[I 12:54:31.815 LabApp] Starting buffering for 3bcbaa8f-8279-4b6f-955a-6537a82c1757:2082e68d668a49bd9dfd8c2678383585
[I 13:24:34.508 LabApp] Adapting from protocol version 5.1 (kernel 2d3054ae-066c-4998-bf0a-040fd272b76e) to 5.3 (client).
[I 13:24:34.511 LabApp] Restoring connection for 2d3054ae-066c-4998-bf0a-040fd272b76e:01b6e061d2ef4b4f90ff1976b4098815
[I 13:24:55.477 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/bf-sober-umap.ipynb
[I 13:25:41.835 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/5.0-swamp-sparrow-dataset-umap.ipynb
[W 13:25:41.836 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/5.0-swamp-sparrow-dataset-umap.ipynb is not trusted
[W 13:30:34.512 LabApp] WebSocket ping timeout after 119995 ms.
[I 13:30:39.514 LabApp] Starting buffering for 2d3054ae-066c-4998-bf0a-040fd272b76e:01b6e061d2ef4b4f90ff1976b4098815
[I 15:44:07.040 LabApp] Kernel started: 33b45f22-5576-43e2-97b7-a32613fce2a4
[I 15:44:08.630 LabApp] Adapting from protocol version 5.1 (kernel f57a99d2-2a3d-4982-b869-a0a4ec8bcc1e) to 5.3 (client).
[I 15:44:09.248 LabApp] Adapting from protocol version 5.1 (kernel 33b45f22-5576-43e2-97b7-a32613fce2a4) to 5.3 (client).
[I 15:44:49.272 LabApp] Starting buffering for 33b45f22-5576-43e2-97b7-a32613fce2a4:581b1622d5d24c9a8b0002ff56a830e0
[W 15:45:59.270 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/4.0-marmoset-dataset-umap.ipynb is not trusted
[I 15:46:00.333 LabApp] Kernel started: 08e58ea1-c381-41d5-80c8-1b513b7c28b6
[I 15:46:02.505 LabApp] Adapting from protocol version 5.1 (kernel 08e58ea1-c381-41d5-80c8-1b513b7c28b6) to 5.3 (client).
[I 15:46:08.254 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/bf-sober-umap.ipynb
[I 15:47:01.085 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/bf-sober-umap.ipynb
[I 15:47:11.108 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/bf-sober-umap.ipynb
[I 15:47:36.591 LabApp] Kernel started: b1475146-df01-419d-ab38-cc741375fc46
[I 15:47:38.012 LabApp] Adapting from protocol version 5.1 (kernel b1475146-df01-419d-ab38-cc741375fc46) to 5.3 (client).
[I 15:48:00.379 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/4.0-marmoset-dataset-umap.ipynb
[W 15:48:00.381 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/4.0-marmoset-dataset-umap.ipynb is not trusted
[I 15:48:08.230 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/bf-sober-umap.ipynb
[I 15:49:34.067 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/bf-sober-umap.ipynb
[I 15:49:44.308 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/bf-sober-umap.ipynb
[I 15:50:03.582 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/bf-sober-umap.ipynb
[I 15:52:08.192 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/bf-sober-umap.ipynb
[I 15:52:15.199 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/bf-sober-umap.ipynb
[I 15:52:21.561 LabApp] Kernel interrupted: f57a99d2-2a3d-4982-b869-a0a4ec8bcc1e
[I 15:54:08.157 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/bf-sober-umap.ipynb
[I 15:56:09.046 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/bf-sober-umap.ipynb
[I 15:57:03.748 LabApp] Starting buffering for b1475146-df01-419d-ab38-cc741375fc46:2ac9921d1e37450dbc087dbed71ebee9
[W 15:57:04.896 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/5.0-swamp-sparrow-dataset-umap.ipynb is not trusted
[I 15:57:05.822 LabApp] Adapting from protocol version 5.1 (kernel 2d3054ae-066c-4998-bf0a-040fd272b76e) to 5.3 (client).
[I 15:57:10.311 LabApp] Adapting from protocol version 5.1 (kernel 3bcbaa8f-8279-4b6f-955a-6537a82c1757) to 5.3 (client).
[I 15:58:00.287 LabApp] Kernel interrupted: f57a99d2-2a3d-4982-b869-a0a4ec8bcc1e
[I 15:58:00.431 LabApp] Kernel interrupted: f57a99d2-2a3d-4982-b869-a0a4ec8bcc1e
[I 15:58:08.220 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/bf-sober-umap.ipynb
[I 15:59:10.707 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/zf-syllable-umap.ipynb
[I 16:00:08.213 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/bf-sober-umap.ipynb
[W 16:00:12.133 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/mouse-usv-syllable-umap.ipynb is not trusted
[I 16:00:13.542 LabApp] Adapting from protocol version 5.1 (kernel 9eb35b93-8ad3-4ee2-bf16-4ff16ea2ff79) to 5.3 (client).
[I 16:01:04.962 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/zf-syllable-umap.ipynb
[I 16:01:05.962 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/zf-syllable-umap.ipynb
[I 16:01:11.690 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/zf-syllable-umap.ipynb
[I 16:01:32.049 LabApp] Kernel shutdown: f57a99d2-2a3d-4982-b869-a0a4ec8bcc1e
[I 16:02:08.758 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/bf-sober-umap.ipynb
[I 16:02:13.834 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/mouse-usv-syllable-umap.ipynb
[W 16:02:13.835 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/mouse-usv-syllable-umap.ipynb is not trusted
[I 16:02:20.593 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/mouse-usv-syllable-umap.ipynb
[W 16:02:20.594 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/mouse-usv-syllable-umap.ipynb is not trusted
[I 16:02:23.232 LabApp] Kernel interrupted: 9eb35b93-8ad3-4ee2-bf16-4ff16ea2ff79
[I 16:02:27.808 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/mouse-usv-syllable-umap.ipynb
[W 16:02:27.810 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/mouse-usv-syllable-umap.ipynb is not trusted
[I 16:03:07.235 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/zf-syllable-umap.ipynb
[I 16:03:10.455 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/zf-syllable-umap.ipynb
[I 16:03:12.890 LabApp] Kernel interrupted: 3bcbaa8f-8279-4b6f-955a-6537a82c1757
[I 16:03:16.269 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/bf-sober-umap.ipynb
[I 16:04:13.773 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/mouse-usv-syllable-umap.ipynb
[W 16:04:13.774 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/mouse-usv-syllable-umap.ipynb is not trusted
[I 16:05:10.397 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/zf-syllable-umap.ipynb
[W 16:18:40.313 LabApp] WebSocket ping timeout after 119992 ms.
[W 16:18:43.544 LabApp] WebSocket ping timeout after 119960 ms.
[I 16:18:45.315 LabApp] Starting buffering for 3bcbaa8f-8279-4b6f-955a-6537a82c1757:ce83cdadc3d54b05a3daa3e942bc1199
[I 16:18:48.546 LabApp] Starting buffering for 9eb35b93-8ad3-4ee2-bf16-4ff16ea2ff79:4d0b6403f167479089b2511d0be1ddd4
[W 16:19:02.508 LabApp] WebSocket ping timeout after 119995 ms.
[W 16:19:05.824 LabApp] WebSocket ping timeout after 119918 ms.
[I 16:19:07.510 LabApp] Starting buffering for 08e58ea1-c381-41d5-80c8-1b513b7c28b6:88dad83bce6f46678bb332087de290e0
[I 16:19:10.826 LabApp] Starting buffering for 2d3054ae-066c-4998-bf0a-040fd272b76e:36d84ae61d614f9e9b368ed0635e4435
[I 16:25:22.557 LabApp] Adapting from protocol version 5.1 (kernel 9eb35b93-8ad3-4ee2-bf16-4ff16ea2ff79) to 5.3 (client).
[I 16:25:22.559 LabApp] Restoring connection for 9eb35b93-8ad3-4ee2-bf16-4ff16ea2ff79:4d0b6403f167479089b2511d0be1ddd4
[I 16:25:22.584 LabApp] Adapting from protocol version 5.1 (kernel 3bcbaa8f-8279-4b6f-955a-6537a82c1757) to 5.3 (client).
[I 16:25:22.592 LabApp] Restoring connection for 3bcbaa8f-8279-4b6f-955a-6537a82c1757:ce83cdadc3d54b05a3daa3e942bc1199
[I 16:25:25.942 LabApp] Adapting from protocol version 5.1 (kernel 08e58ea1-c381-41d5-80c8-1b513b7c28b6) to 5.3 (client).
[I 16:25:25.943 LabApp] Restoring connection for 08e58ea1-c381-41d5-80c8-1b513b7c28b6:88dad83bce6f46678bb332087de290e0
[I 16:25:25.968 LabApp] Adapting from protocol version 5.1 (kernel 2d3054ae-066c-4998-bf0a-040fd272b76e) to 5.3 (client).
[I 16:25:25.970 LabApp] Restoring connection for 2d3054ae-066c-4998-bf0a-040fd272b76e:36d84ae61d614f9e9b368ed0635e4435
[I 16:25:41.684 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/mouse-usv-syllable-umap.ipynb
[W 16:25:41.686 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/mouse-usv-syllable-umap.ipynb is not trusted
[I 16:26:38.569 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/zf-syllable-umap.ipynb
[I 16:27:42.091 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/mouse-usv-syllable-umap.ipynb
[W 16:27:42.093 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/mouse-usv-syllable-umap.ipynb is not trusted
[I 16:28:00.621 LabApp] Adapting from protocol version 5.1 (kernel 27404533-ce8e-4b49-93ff-0132477e97a7) to 5.3 (client).
[I 16:28:09.990 LabApp] Starting buffering for 27404533-ce8e-4b49-93ff-0132477e97a7:acb724a00d8c4fd0885c2a14370afb0d
[W 16:28:10.624 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/humpback-syllable-umap.ipynb is not trusted
[I 16:28:11.160 LabApp] Adapting from protocol version 5.1 (kernel fc0b22f0-149f-483f-a3a3-005c25c53225) to 5.3 (client).
[I 16:28:39.198 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/zf-syllable-umap.ipynb
[I 16:30:11.128 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/humpback-syllable-umap.ipynb
[I 16:30:39.518 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/zf-syllable-umap.ipynb
[I 16:32:11.148 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/humpback-syllable-umap.ipynb
[I 16:33:22.658 LabApp] Starting buffering for fc0b22f0-149f-483f-a3a3-005c25c53225:e2c25428859b483ea25e0bed3a4cd731
[W 16:33:24.180 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/zf-lib-syllable-umap.ipynb is not trusted
[I 16:33:25.109 LabApp] Adapting from protocol version 5.1 (kernel 98fc4fd3-9c54-4da9-9a34-065514d41017) to 5.3 (client).
[I 16:35:00.346 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/zf-lib-syllable-umap.ipynb
[W 16:35:00.348 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/zf-lib-syllable-umap.ipynb is not trusted
[I 16:35:25.136 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/zf-lib-syllable-umap.ipynb
[W 16:35:25.139 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/zf-lib-syllable-umap.ipynb is not trusted
[I 16:35:29.138 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/4.0-marmoset-dataset-umap.ipynb
[W 16:35:29.139 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/4.0-marmoset-dataset-umap.ipynb is not trusted
[I 16:37:25.714 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/zf-lib-syllable-umap.ipynb
[W 16:37:25.717 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/zf-lib-syllable-umap.ipynb is not trusted
[I 16:38:04.855 LabApp] Starting buffering for 9eb35b93-8ad3-4ee2-bf16-4ff16ea2ff79:4d0b6403f167479089b2511d0be1ddd4
[W 16:38:07.466 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/munia-syllable-umap.ipynb is not trusted
[W 16:38:09.335 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/canary-syllable-umap.ipynb is not trusted
[W 16:38:10.100 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/starling-umap.ipynb is not trusted
[I 16:38:11.194 LabApp] Adapting from protocol version 5.1 (kernel 66f2f873-47e1-418f-a61c-25b4a6627eb9) to 5.3 (client).
[I 16:38:11.375 LabApp] Kernel started: 6897d04b-f64d-44cd-b06b-40949ab61d16
[I 16:38:13.314 LabApp] Adapting from protocol version 5.1 (kernel 6897d04b-f64d-44cd-b06b-40949ab61d16) to 5.3 (client).
[I 16:38:14.480 LabApp] Adapting from protocol version 5.1 (kernel 9ae0acb6-5a70-4fdf-8547-1d760390b51c) to 5.3 (client).
[I 16:39:12.462 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/munia-syllable-umap.ipynb
[W 16:39:12.466 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/munia-syllable-umap.ipynb is not trusted
[I 16:39:34.652 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/munia-syllable-umap.ipynb
[W 16:39:34.658 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/munia-syllable-umap.ipynb is not trusted
[I 16:40:12.054 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/starling-umap.ipynb
[W 16:40:12.057 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/starling-umap.ipynb is not trusted
[I 16:40:12.603 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/canary-syllable-umap.ipynb
[W 16:40:12.605 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/canary-syllable-umap.ipynb is not trusted
[I 16:40:14.548 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/munia-syllable-umap.ipynb
[I 16:42:16.100 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/munia-syllable-umap.ipynb
[I 16:44:21.262 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/munia-syllable-umap.ipynb
[I 16:46:18.599 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/munia-syllable-umap.ipynb
[W 17:11:13.317 LabApp] WebSocket ping timeout after 119890 ms.
[W 17:11:14.482 LabApp] WebSocket ping timeout after 119994 ms.
[I 17:11:18.320 LabApp] Starting buffering for 6897d04b-f64d-44cd-b06b-40949ab61d16:9522ceef8b564ca7b29b902376a626ae
[I 17:11:19.484 LabApp] Starting buffering for 9ae0acb6-5a70-4fdf-8547-1d760390b51c:db70bb7633484c4684bf016f00bfe4cc
[W 17:11:22.593 LabApp] WebSocket ping timeout after 119951 ms.
[W 17:11:25.112 LabApp] WebSocket ping timeout after 119911 ms.
[W 17:11:25.945 LabApp] WebSocket ping timeout after 119820 ms.
[W 17:11:25.970 LabApp] WebSocket ping timeout after 119841 ms.
[I 17:11:27.594 LabApp] Starting buffering for 3bcbaa8f-8279-4b6f-955a-6537a82c1757:ce83cdadc3d54b05a3daa3e942bc1199
[I 17:11:30.114 LabApp] Starting buffering for 98fc4fd3-9c54-4da9-9a34-065514d41017:4aa57af1b49a48ea9c6af3bb0ec5edb8
[I 17:11:30.947 LabApp] Starting buffering for 08e58ea1-c381-41d5-80c8-1b513b7c28b6:88dad83bce6f46678bb332087de290e0
[I 17:11:30.972 LabApp] Starting buffering for 2d3054ae-066c-4998-bf0a-040fd272b76e:36d84ae61d614f9e9b368ed0635e4435
[W 17:11:41.201 LabApp] WebSocket ping timeout after 119924 ms.
[I 17:11:46.203 LabApp] Starting buffering for 66f2f873-47e1-418f-a61c-25b4a6627eb9:9c940072363b43ae87e03776abaaab34
[I 17:32:57.956 LabApp] Adapting from protocol version 5.1 (kernel 66f2f873-47e1-418f-a61c-25b4a6627eb9) to 5.3 (client).
[I 17:32:57.958 LabApp] Restoring connection for 66f2f873-47e1-418f-a61c-25b4a6627eb9:9c940072363b43ae87e03776abaaab34
[I 17:34:47.397 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/canary-syllable-umap.ipynb
[W 17:34:47.400 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/canary-syllable-umap.ipynb is not trusted
2019-10-15 17:36:36.123047: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-15 17:36:36.151516: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-10-15 17:36:36.151598: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: txori
2019-10-15 17:36:36.151623: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: txori
2019-10-15 17:36:36.151755: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.79.0
2019-10-15 17:36:36.151826: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 410.79.0
2019-10-15 17:36:36.151851: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 410.79.0
2019-10-15 17:36:36.204146: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2600090000 Hz
2019-10-15 17:36:36.205860: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5571fdbd4d20 executing computations on platform Host. Devices:
2019-10-15 17:36:36.205924: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
[I 17:36:48.198 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/canary-syllable-umap.ipynb
[I 17:38:47.054 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/canary-syllable-umap.ipynb
[I 17:39:26.299 LabApp] Adapting from protocol version 5.1 (kernel 2d3054ae-066c-4998-bf0a-040fd272b76e) to 5.3 (client).
[I 17:39:26.300 LabApp] Restoring connection for 2d3054ae-066c-4998-bf0a-040fd272b76e:36d84ae61d614f9e9b368ed0635e4435
2019-10-15 17:40:08.160184: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-15 17:40:08.181688: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-10-15 17:40:08.181820: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: txori
2019-10-15 17:40:08.181836: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: txori
2019-10-15 17:40:08.181988: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.79.0
2019-10-15 17:40:08.182068: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 410.79.0
2019-10-15 17:40:08.182085: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 410.79.0
2019-10-15 17:40:08.309202: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2600090000 Hz
2019-10-15 17:40:08.310635: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56171321bc90 executing computations on platform Host. Devices:
2019-10-15 17:40:08.310681: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
[I 17:41:06.978 LabApp] Kernel interrupted: 66f2f873-47e1-418f-a61c-25b4a6627eb9
[I 17:41:11.238 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/5.0-swamp-sparrow-dataset-umap.ipynb
[W 17:41:11.241 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/5.0-swamp-sparrow-dataset-umap.ipynb is not trusted
[I 17:41:45.355 LabApp] Kernel interrupted: 66f2f873-47e1-418f-a61c-25b4a6627eb9
[I 17:41:55.329 LabApp] Kernel interrupted: 66f2f873-47e1-418f-a61c-25b4a6627eb9
[I 17:42:47.065 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/canary-syllable-umap.ipynb
[I 17:44:20.392 LabApp] Kernel interrupted: 66f2f873-47e1-418f-a61c-25b4a6627eb9
[I 17:44:47.055 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/canary-syllable-umap.ipynb
[I 17:45:05.041 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/canary-syllable-umap.ipynb
[I 17:45:13.627 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/canary-syllable-umap.ipynb
[I 17:46:39.282 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/canary-syllable-umap.ipynb
[I 17:46:53.255 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/canary-syllable-umap.ipynb
[W 17:47:13.097 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/starling-umap.ipynb is not trusted
[I 17:47:17.603 LabApp] Adapting from protocol version 5.1 (kernel 6897d04b-f64d-44cd-b06b-40949ab61d16) to 5.3 (client).
[W 17:47:18.466 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/4.0-marmoset-dataset-umap.ipynb is not trusted
[I 17:47:18.653 LabApp] Adapting from protocol version 5.1 (kernel b1475146-df01-419d-ab38-cc741375fc46) to 5.3 (client).
[W 17:47:19.133 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/zf-lib-syllable-umap.ipynb is not trusted
[W 17:47:22.977 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/mouse-usv-syllable-umap.ipynb is not trusted
[I 17:47:23.120 LabApp] Adapting from protocol version 5.1 (kernel 08e58ea1-c381-41d5-80c8-1b513b7c28b6) to 5.3 (client).
[I 17:47:23.127 LabApp] Starting buffering for 6897d04b-f64d-44cd-b06b-40949ab61d16:d1a2de18a95241c786ea66ec9b119150
[I 17:47:23.364 LabApp] Adapting from protocol version 5.1 (kernel 33b45f22-5576-43e2-97b7-a32613fce2a4) to 5.3 (client).
[I 17:47:23.843 LabApp] Kernel shutdown: 6897d04b-f64d-44cd-b06b-40949ab61d16
[I 17:47:23.858 LabApp] Adapting from protocol version 5.1 (kernel 27404533-ce8e-4b49-93ff-0132477e97a7) to 5.3 (client).
[I 17:47:23.858 LabApp] Adapting from protocol version 5.1 (kernel 98fc4fd3-9c54-4da9-9a34-065514d41017) to 5.3 (client).
[I 17:47:24.348 LabApp] Adapting from protocol version 5.1 (kernel fc0b22f0-149f-483f-a3a3-005c25c53225) to 5.3 (client).
[I 17:47:24.603 LabApp] Adapting from protocol version 5.1 (kernel 3bcbaa8f-8279-4b6f-955a-6537a82c1757) to 5.3 (client).
[I 17:47:25.012 LabApp] Adapting from protocol version 5.1 (kernel 9eb35b93-8ad3-4ee2-bf16-4ff16ea2ff79) to 5.3 (client).
[I 17:47:28.548 LabApp] Starting buffering for b1475146-df01-419d-ab38-cc741375fc46:10c10bfd5dc9461197cf7d6403c73df8
[I 17:47:28.954 LabApp] Kernel shutdown: b1475146-df01-419d-ab38-cc741375fc46
[I 17:47:29.421 LabApp] Adapting from protocol version 5.1 (kernel 9ae0acb6-5a70-4fdf-8547-1d760390b51c) to 5.3 (client).
[I 17:47:33.737 LabApp] Starting buffering for 08e58ea1-c381-41d5-80c8-1b513b7c28b6:d18954efce1c4492a444f99256b2dcdd
[I 17:47:34.144 LabApp] Kernel shutdown: 08e58ea1-c381-41d5-80c8-1b513b7c28b6
[I 17:47:36.760 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/4.0-marmoset-dataset-umap.ipynb
[W 17:47:36.761 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/4.0-marmoset-dataset-umap.ipynb is not trusted
[I 17:47:37.690 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/4.0-marmoset-dataset-umap.ipynb
[W 17:47:37.691 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/4.0-marmoset-dataset-umap.ipynb is not trusted
[I 17:47:41.734 LabApp] Kernel shutdown: 33b45f22-5576-43e2-97b7-a32613fce2a4
[I 17:47:48.181 LabApp] Starting buffering for 9eb35b93-8ad3-4ee2-bf16-4ff16ea2ff79:2f8bbeaeea364deb81d11f403dcdca52
[I 17:47:49.390 LabApp] Kernel shutdown: 9eb35b93-8ad3-4ee2-bf16-4ff16ea2ff79
[I 17:47:54.156 LabApp] Starting buffering for 27404533-ce8e-4b49-93ff-0132477e97a7:aa4e531717ea427184f83ece3ad5770a
[I 17:47:54.563 LabApp] Kernel shutdown: 27404533-ce8e-4b49-93ff-0132477e97a7
[I 17:47:59.133 LabApp] Starting buffering for 9ae0acb6-5a70-4fdf-8547-1d760390b51c:d42ccfcd968243a894d732387b3d08b9
[I 17:48:01.042 LabApp] Kernel shutdown: 9ae0acb6-5a70-4fdf-8547-1d760390b51c
[I 17:48:04.462 LabApp] Starting buffering for fc0b22f0-149f-483f-a3a3-005c25c53225:5087b6f0f71b4a018161520db6064317
[I 17:48:05.369 LabApp] Kernel shutdown: fc0b22f0-149f-483f-a3a3-005c25c53225
[I 17:48:08.587 LabApp] Starting buffering for 3bcbaa8f-8279-4b6f-955a-6537a82c1757:4e6634d8cca7490384229ae807998a0d
[I 17:48:10.397 LabApp] Kernel shutdown: 3bcbaa8f-8279-4b6f-955a-6537a82c1757
[I 17:48:14.660 LabApp] Starting buffering for 98fc4fd3-9c54-4da9-9a34-065514d41017:fc08b2bbaf934b4885c641e898c6c9ea
[I 17:48:16.068 LabApp] Kernel shutdown: 98fc4fd3-9c54-4da9-9a34-065514d41017
[I 17:48:22.790 LabApp] Starting buffering for 2d3054ae-066c-4998-bf0a-040fd272b76e:36d84ae61d614f9e9b368ed0635e4435
[I 17:48:25.413 LabApp] Kernel restarted: 2d3054ae-066c-4998-bf0a-040fd272b76e
[I 17:48:27.012 LabApp] Adapting from protocol version 5.1 (kernel 2d3054ae-066c-4998-bf0a-040fd272b76e) to 5.3 (client).
[I 17:48:27.013 LabApp] Restoring connection for 2d3054ae-066c-4998-bf0a-040fd272b76e:36d84ae61d614f9e9b368ed0635e4435
[I 17:48:27.013 LabApp] Replaying 6 buffered messages
[I 17:48:47.050 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/canary-syllable-umap.ipynb
2019-10-15 17:49:04.675150: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-15 17:49:09.374470: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-10-15 17:49:09.374575: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: txori
2019-10-15 17:49:09.374594: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: txori
2019-10-15 17:49:09.374814: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.79.0
2019-10-15 17:49:09.374874: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 410.79.0
2019-10-15 17:49:09.374890: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 410.79.0
2019-10-15 17:49:09.454014: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2600090000 Hz
2019-10-15 17:49:09.455828: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x557b8e40ab00 executing computations on platform Host. Devices:
2019-10-15 17:49:09.455877: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
[I 17:49:10.932 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/5.0-swamp-sparrow-dataset-umap.ipynb
[I 17:50:00.838 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/canary-syllable-umap.ipynb
[I 17:50:26.571 LabApp] Starting buffering for 2d3054ae-066c-4998-bf0a-040fd272b76e:36d84ae61d614f9e9b368ed0635e4435
[I 17:50:28.900 LabApp] Kernel restarted: 2d3054ae-066c-4998-bf0a-040fd272b76e
[I 17:50:28.977 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/5.0-swamp-sparrow-dataset-umap.ipynb
[I 17:50:30.673 LabApp] Adapting from protocol version 5.1 (kernel 2d3054ae-066c-4998-bf0a-040fd272b76e) to 5.3 (client).
[I 17:50:30.674 LabApp] Restoring connection for 2d3054ae-066c-4998-bf0a-040fd272b76e:36d84ae61d614f9e9b368ed0635e4435
[I 17:50:30.674 LabApp] Replaying 6 buffered messages
[I 17:50:49.951 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/5.0-swamp-sparrow-dataset-umap.ipynb
[I 17:50:56.011 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/5.0-swamp-sparrow-dataset-umap.ipynb
2019-10-15 17:51:07.137441: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
[I 17:51:09.821 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/5.0-swamp-sparrow-dataset-umap.ipynb
2019-10-15 17:51:11.886205: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-10-15 17:51:11.886375: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: txori
2019-10-15 17:51:11.886406: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: txori
2019-10-15 17:51:11.886705: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.79.0
2019-10-15 17:51:11.886808: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 410.79.0
2019-10-15 17:51:11.886834: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 410.79.0
2019-10-15 17:51:11.961483: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2600090000 Hz
2019-10-15 17:51:11.962642: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5643fd30c520 executing computations on platform Host. Devices:
2019-10-15 17:51:11.962673: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
[I 17:51:59.858 LabApp] KernelRestarter: restarting kernel (1/5), keep random ports
kernel 66f2f873-47e1-418f-a61c-25b4a6627eb9 restarted
[I 17:52:01.900 LabApp] KernelRestarter: restarting kernel (1/5), keep random ports
kernel 2d3054ae-066c-4998-bf0a-040fd272b76e restarted
[C 17:52:17.858 LabApp] received signal 15, stopping
[I 17:52:17.859 LabApp] Shutting down 3 kernels
[I 17:52:18.262 LabApp] Kernel shutdown: 3cd6a1dc-880a-4e21-92b5-3118b29a9780
[I 17:52:18.564 LabApp] Kernel shutdown: 66f2f873-47e1-418f-a61c-25b4a6627eb9
[I 17:52:18.565 LabApp] Kernel shutdown: 2d3054ae-066c-4998-bf0a-040fd272b76e
[I 13:40:39.088 LabApp] The port 8187 is already in use, trying another port.
[I 13:40:39.118 LabApp] The port 8188 is already in use, trying another port.
[W 13:40:39.127 LabApp] Error loading server extension jupyter_nbextensions_configurator
    Traceback (most recent call last):
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/notebook/notebookapp.py", line 1615, in init_server_extensions
        mod = importlib.import_module(modulename)
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/importlib/__init__.py", line 126, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 994, in _gcd_import
      File "<frozen importlib._bootstrap>", line 971, in _find_and_load
      File "<frozen importlib._bootstrap>", line 953, in _find_and_load_unlocked
    ModuleNotFoundError: No module named 'jupyter_nbextensions_configurator'
[I 13:40:39.138 LabApp] JupyterLab extension loaded from /home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/jupyterlab
[I 13:40:39.138 LabApp] JupyterLab application directory is /home/AD/tsainbur/anaconda3/envs/py19/share/jupyter/lab
[W 13:40:39.143 LabApp] Error loading server extension jupyterlab_code_formatter
    Traceback (most recent call last):
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/notebook/notebookapp.py", line 1615, in init_server_extensions
        mod = importlib.import_module(modulename)
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/importlib/__init__.py", line 126, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 994, in _gcd_import
      File "<frozen importlib._bootstrap>", line 971, in _find_and_load
      File "<frozen importlib._bootstrap>", line 953, in _find_and_load_unlocked
    ModuleNotFoundError: No module named 'jupyterlab_code_formatter'
[I 13:40:39.144 LabApp] Serving notebooks from local directory: /home/AD/tsainbur/github_repos
[I 13:40:39.144 LabApp] The Jupyter Notebook is running at:
[I 13:40:39.144 LabApp] http://localhost:8189/?token=bd53599c5969af4b92f1338aacd19759a9f382008dc5c61a
[I 13:40:39.144 LabApp]  or http://127.0.0.1:8189/?token=bd53599c5969af4b92f1338aacd19759a9f382008dc5c61a
[I 13:40:39.144 LabApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[C 13:40:39.155 LabApp] 
    
    To access the notebook, open this file in a browser:
        file:///local/home/tsainbur/.local/share/jupyter/runtime/nbserver-7468-open.html
    Or copy and paste one of these URLs:
        http://localhost:8189/?token=bd53599c5969af4b92f1338aacd19759a9f382008dc5c61a
     or http://127.0.0.1:8189/?token=bd53599c5969af4b92f1338aacd19759a9f382008dc5c61a
[W 13:40:48.319 LabApp] Clearing invalid/expired login cookie username-localhost-8189
[W 13:40:48.321 LabApp] Forbidden
[W 13:40:48.322 LabApp] 403 GET /api/sessions?1571690448324 (::1) 4.39ms referer=http://localhost:8189/lab
[W 13:40:48.324 LabApp] Clearing invalid/expired login cookie username-localhost-8189
[W 13:40:48.325 LabApp] Forbidden
[W 13:40:48.326 LabApp] 403 GET /api/terminals?1571690448325 (::1) 2.35ms referer=http://localhost:8189/lab
[W 13:40:58.319 LabApp] Forbidden
[W 13:40:58.319 LabApp] 403 GET /api/terminals?1571690458326 (::1) 3.39ms referer=http://localhost:8189/lab
[W 13:40:58.320 LabApp] Forbidden
[W 13:40:58.321 LabApp] 403 GET /api/sessions?1571690458325 (::1) 3.24ms referer=http://localhost:8189/lab
[W 13:41:06.048 LabApp] Couldn't authenticate WebSocket connection
[W 13:41:06.106 LabApp] 403 GET /api/kernels/9b38ef34-57ae-4ab1-8720-17f9dd85f29f/channels?session_id=6debf906-f997-4ced-a3ec-9829147dc4a9&token=f3c5d96827bce2f7d647418268b763cc4e2cb68608809b0c (::1) 61.22ms referer=None
[W 13:41:06.128 LabApp] Couldn't authenticate WebSocket connection
[W 13:41:06.129 LabApp] 403 GET /api/kernels/9b38ef34-57ae-4ab1-8720-17f9dd85f29f/channels?session_id=f656359d-86b9-4692-9a72-f23d0da7b976&token=f3c5d96827bce2f7d647418268b763cc4e2cb68608809b0c (::1) 3.92ms referer=None
[W 13:41:08.316 LabApp] Forbidden
[W 13:41:08.317 LabApp] 403 GET /api/terminals?1571690468324 (::1) 3.06ms referer=http://localhost:8189/lab
[W 13:41:08.318 LabApp] Forbidden
[W 13:41:08.318 LabApp] 403 GET /api/sessions?1571690468324 (::1) 3.03ms referer=http://localhost:8189/lab
[W 13:41:18.321 LabApp] Forbidden
[W 13:41:18.322 LabApp] 403 GET /api/sessions?1571690478328 (::1) 2.37ms referer=http://localhost:8189/lab
[W 13:41:18.324 LabApp] Forbidden
[W 13:41:18.324 LabApp] 403 GET /api/terminals?1571690478329 (::1) 1.76ms referer=http://localhost:8189/lab
[W 13:41:28.317 LabApp] Forbidden
[W 13:41:28.317 LabApp] 403 GET /api/sessions?1571690488324 (::1) 3.51ms referer=http://localhost:8189/lab
[W 13:41:28.318 LabApp] Forbidden
[W 13:41:28.319 LabApp] 403 GET /api/terminals?1571690488325 (::1) 3.24ms referer=http://localhost:8189/lab
[C 13:41:32.686 LabApp] received signal 15, stopping
[I 13:41:32.688 LabApp] Shutting down 0 kernels
[W 13:41:51.576 LabApp] Error loading server extension jupyter_nbextensions_configurator
    Traceback (most recent call last):
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/notebook/notebookapp.py", line 1615, in init_server_extensions
        mod = importlib.import_module(modulename)
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/importlib/__init__.py", line 126, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 994, in _gcd_import
      File "<frozen importlib._bootstrap>", line 971, in _find_and_load
      File "<frozen importlib._bootstrap>", line 953, in _find_and_load_unlocked
    ModuleNotFoundError: No module named 'jupyter_nbextensions_configurator'
[I 13:41:51.581 LabApp] JupyterLab extension loaded from /home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/jupyterlab
[I 13:41:51.581 LabApp] JupyterLab application directory is /home/AD/tsainbur/anaconda3/envs/py19/share/jupyter/lab
[W 13:41:51.584 LabApp] Error loading server extension jupyterlab_code_formatter
    Traceback (most recent call last):
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/notebook/notebookapp.py", line 1615, in init_server_extensions
        mod = importlib.import_module(modulename)
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/importlib/__init__.py", line 126, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
      File "<frozen importlib._bootstrap>", line 994, in _gcd_import
      File "<frozen importlib._bootstrap>", line 971, in _find_and_load
      File "<frozen importlib._bootstrap>", line 953, in _find_and_load_unlocked
    ModuleNotFoundError: No module named 'jupyterlab_code_formatter'
[I 13:41:51.584 LabApp] Serving notebooks from local directory: /home/AD/tsainbur/github_repos
[I 13:41:51.584 LabApp] The Jupyter Notebook is running at:
[I 13:41:51.584 LabApp] http://localhost:8187/?token=b4ed1a543622a3b1aba049c8e4efa3b834277ab07c15002e
[I 13:41:51.584 LabApp]  or http://127.0.0.1:8187/?token=b4ed1a543622a3b1aba049c8e4efa3b834277ab07c15002e
[I 13:41:51.585 LabApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[C 13:41:51.590 LabApp] 
    
    To access the notebook, open this file in a browser:
        file:///local/home/tsainbur/.local/share/jupyter/runtime/nbserver-7490-open.html
    Or copy and paste one of these URLs:
        http://localhost:8187/?token=b4ed1a543622a3b1aba049c8e4efa3b834277ab07c15002e
     or http://127.0.0.1:8187/?token=b4ed1a543622a3b1aba049c8e4efa3b834277ab07c15002e
[W 13:41:54.378 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 13.49ms referer=http://localhost:8187/tree/avgn_paper/figures/barcode/bengalese_finch_sober
[W 13:41:58.680 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 9.11ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/humpback-PCA-projections.ipynb
[I 13:41:58.880 LabApp] Kernel started: 978d9916-af35-4406-97da-0a0aa693d3c0
[W 13:41:58.923 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 2.17ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/humpback-PCA-projections.ipynb
[I 13:42:08.995 LabApp] Adapting from protocol version 5.1 (kernel 978d9916-af35-4406-97da-0a0aa693d3c0) to 5.3 (client).
[I 13:43:59.564 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/humpback-PCA-projections.ipynb
[I 13:46:33.859 LabApp] Build is up to date
[I 13:46:34.957 LabApp] Adapting from protocol version 5.1 (kernel 978d9916-af35-4406-97da-0a0aa693d3c0) to 5.3 (client).
[I 13:46:43.491 LabApp] Adapting from protocol version 5.1 (kernel 978d9916-af35-4406-97da-0a0aa693d3c0) to 5.3 (client).
[W 13:47:24.092 LabApp] 404 GET /nbextensions (::1) 3.83ms referer=None
[I 13:47:34.617 LabApp] 302 GET / (::1) 0.95ms
[I 13:47:35.265 LabApp] 301 GET /lab/workspaces/auto-g/?clone (::1) 5.20ms
[I 13:47:36.327 LabApp] Build is up to date
[I 13:47:37.248 LabApp] Adapting from protocol version 5.1 (kernel 978d9916-af35-4406-97da-0a0aa693d3c0) to 5.3 (client).
[I 13:47:45.917 LabApp] Adapting from protocol version 5.1 (kernel 978d9916-af35-4406-97da-0a0aa693d3c0) to 5.3 (client).
[I 13:49:37.205 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/humpback-PCA-projections.ipynb
[I 13:51:05.850 LabApp] Kernel interrupted: 978d9916-af35-4406-97da-0a0aa693d3c0
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/sklearn/__init__.py", line 64, in <module>
    from .base import clone
  File "/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/sklearn/base.py", line 13, in <module>
    from .utils.fixes import signature
  File "/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/sklearn/utils/__init__.py", line 16, in <module>
    from .fixes import _Sequence as Sequence
  File "/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/sklearn/utils/fixes.py", line 92, in <module>
    from scipy.sparse.linalg import lsqr as sparse_lsqr  # noqa
  File "/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/scipy/sparse/linalg/__init__.py", line 114, in <module>
    from .isolve import *
  File "/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/scipy/sparse/linalg/isolve/__init__.py", line 6, in <module>
    from .iterative import *
  File "/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/scipy/sparse/linalg/isolve/iterative.py", line 14, in <module>
    from .utils import make_system
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 764, in get_code
  File "<frozen importlib._bootstrap_external>", line 832, in get_data
KeyboardInterrupt
[I 13:51:11.585 LabApp] Kernel interrupted: 978d9916-af35-4406-97da-0a0aa693d3c0
[I 13:51:14.575 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/humpback-PCA-projections.ipynb
[I 13:53:14.775 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/humpback-PCA-projections.ipynb
2019-10-21 13:57:00.526271: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-21 13:57:05.366068: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-10-21 13:57:05.366210: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: txori
2019-10-21 13:57:05.366241: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: txori
2019-10-21 13:57:05.366455: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.79.0
2019-10-21 13:57:05.366559: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 410.79.0
2019-10-21 13:57:05.366587: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 410.79.0
2019-10-21 13:57:05.405559: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-21 13:57:05.406696: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a6e1e56360 executing computations on platform Host. Devices:
2019-10-21 13:57:05.406727: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
[I 13:57:15.003 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/humpback-PCA-projections.ipynb
[IPKernelApp] WARNING | No such comm: b9a7101ba5ea4dc79afc189bbb3c5790
[IPKernelApp] WARNING | No such comm: 679abbb5e73c4c62834b62af417c8576
[IPKernelApp] WARNING | No such comm: 00495ad95f2c44b3b06d044f2906dbf5
[IPKernelApp] WARNING | No such comm: 1f55de03bdda469c9c1bc270c7493de7
[IPKernelApp] WARNING | No such comm: 2a9c95e851fc4db29c8149483f3472af
[IPKernelApp] WARNING | No such comm: a310431fc3cb4db1b64aec4dad986073
[IPKernelApp] WARNING | No such comm: 6b642d24cb3548cc8db06d7eaa707d3f
[IPKernelApp] WARNING | No such comm: 8ff4cf5853c641fa8f6220487a0b6ef3
[IPKernelApp] WARNING | No such comm: b8a87c7350ad433baef0874dbd1a7242
[IPKernelApp] WARNING | No such comm: 9febedf1777a4dd4b399983b49cd3581
[IPKernelApp] WARNING | No such comm: 8e77df261b1f4725b4db76f12f55516a
[IPKernelApp] WARNING | No such comm: 3adfadaf4d5f45c4b1586ffa85c32346
[IPKernelApp] WARNING | No such comm: 62fcd7612e7245ee94c97539f2bf6d60
[IPKernelApp] WARNING | No such comm: 17b711c809194159aa5a927e8735201d
[IPKernelApp] WARNING | No such comm: 4319ea617795461fac371622a5bc8526
[IPKernelApp] WARNING | No such comm: 64c6882bdf4c4d8daac30ee5feabeb6e
[IPKernelApp] WARNING | No such comm: 64c6882bdf4c4d8daac30ee5feabeb6e
[I 13:59:15.221 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/humpback-PCA-projections.ipynb
[I 14:21:20.241 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/humpback-PCA-projections.ipynb
[I 14:23:20.534 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/humpback-PCA-projections.ipynb
[I 14:33:20.790 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/humpback-PCA-projections.ipynb
[I 14:33:23.379 LabApp] Kernel started: 5e7b4be6-7cfb-4bed-be7a-1317135b8c1c
[I 14:33:38.951 LabApp] Kernel restarted: 5e7b4be6-7cfb-4bed-be7a-1317135b8c1c
[I 14:33:44.467 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/bf-sober-transitions-barcode.ipynb
[I 14:34:17.594 LabApp] Kernel interrupted: 5e7b4be6-7cfb-4bed-be7a-1317135b8c1c
Traceback (most recent call last):
  File "/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/ipykernel_launcher.py", line 15, in <module>
    from ipykernel import kernelapp as app
  File "/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/ipykernel/__init__.py", line 2, in <module>
    from .connect import *
  File "/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/ipykernel/connect.py", line 13, in <module>
    from IPython.core.profiledir import ProfileDir
  File "/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/IPython/__init__.py", line 55, in <module>
    from .terminal.embed import embed
  File "/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/IPython/terminal/embed.py", line 16, in <module>
    from IPython.terminal.interactiveshell import TerminalInteractiveShell
  File "/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/IPython/terminal/interactiveshell.py", line 33, in <module>
    from .debugger import TerminalPdb, Pdb
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 764, in get_code
  File "<frozen importlib._bootstrap_external>", line 832, in get_data
KeyboardInterrupt
[I 14:34:20.951 LabApp] KernelRestarter: restarting kernel (1/5), keep random ports
[I 14:34:27.048 LabApp] Kernel restarted: 5e7b4be6-7cfb-4bed-be7a-1317135b8c1c
[W 14:34:27.051 LabApp] Timeout waiting for kernel_info reply from 5e7b4be6-7cfb-4bed-be7a-1317135b8c1c
[I 14:34:32.151 LabApp] Kernel restarted: 5e7b4be6-7cfb-4bed-be7a-1317135b8c1c
[I 14:34:32.209 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/bf-sober-transitions-barcode.ipynb
[W 14:34:38.369 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.78ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/2.0-make-syllable_df/humpback-whale-syllable_df.ipynb
[W 14:34:38.954 LabApp] Timeout waiting for kernel_info_reply: 5e7b4be6-7cfb-4bed-be7a-1317135b8c1c
[E 14:34:38.955 LabApp] Exception restarting kernel
    Traceback (most recent call last):
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/notebook/services/kernels/handlers.py", line 83, in post
        yield maybe_future(km.restart_kernel(kernel_id))
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/tornado/gen.py", line 735, in run
        value = future.result()
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/tornado/gen.py", line 742, in run
        yielded = self.gen.throw(*exc_info)  # type: ignore
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/notebook/services/kernels/kernelmanager.py", line 345, in restart_kernel
        yield future
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/tornado/gen.py", line 735, in run
        value = future.result()
    tornado.util.TimeoutError: Timeout waiting for restart
[E 14:34:38.957 LabApp] {
      "Host": "localhost:8187",
      "Connection": "keep-alive",
      "Content-Length": "0",
      "Sec-Fetch-Mode": "cors",
      "Origin": "http://localhost:8187",
      "Authorization": "token b4ed1a543622a3b1aba049c8e4efa3b834277ab07c15002e",
      "X-Xsrftoken": "2|2b997e67|29d4ea20755e92079558d090866cac7e|1571165215",
      "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.120 Safari/537.36",
      "Content-Type": "application/json",
      "Accept": "*/*",
      "Sec-Fetch-Site": "same-origin",
      "Referer": "http://localhost:8187/lab/workspaces/auto-g",
      "Accept-Encoding": "gzip, deflate, br",
      "Accept-Language": "en-US,en;q=0.9,fr;q=0.8",
      "Cookie": "_ga=GA1.1.2135320950.1566148815; username-localhost-8195=\"2|1:0|10:1570831591|23:username-localhost-8195|44:Y2Q0M2Y0YjJhMDQxNDQwZThhOGNjZTdhNDFiNDNkNjI=|4fc2d73bc3298178be788038ba7812e8e7e1ca4ae1891ffcc42a6bd3445055ab\"; username-localhost-8186=\"2|1:0|10:1570831618|23:username-localhost-8186|44:OGQ0ZDZhMzA0OGU3NGJjNmE3ZWQzZTNlNjE0OTE5YTc=|c35b67c47b69b28e578cd086622671b22c440c459eb1f804d2a3d6e6da842624\"; _xsrf=2|2b997e67|29d4ea20755e92079558d090866cac7e|1571165215; username-localhost-8187=\"2|1:0|10:1571693609|23:username-localhost-8187|44:NjBlZTdmZjFiYzkxNGU2NmFmYmI2ZjdiYzIwMGVhYmQ=|e57148debb7068526bf27674a3e72ff297f23f43d201046f549ada1931a9b294\""
    }
[E 14:34:38.957 LabApp] 500 POST /api/kernels/5e7b4be6-7cfb-4bed-be7a-1317135b8c1c/restart?1571693613909 (::1) 65043.63ms referer=http://localhost:8187/lab/workspaces/auto-g
[I 14:34:39.582 LabApp] Kernel started: babf27cf-00b4-45ab-82dd-018ae6524543
[W 14:34:39.599 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 4.21ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/2.0-make-syllable_df/humpback-whale-syllable_df.ipynb
[W 14:34:52.887 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 18.03ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/humpback-PCA-projections.ipynb
[I 14:34:53.386 LabApp] Adapting from protocol version 5.1 (kernel 978d9916-af35-4406-97da-0a0aa693d3c0) to 5.3 (client).
[W 14:34:53.402 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 3.57ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/humpback-PCA-projections.ipynb
[I 14:35:07.271 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/humpback-PCA-projections.ipynb
[W 14:35:27.051 LabApp] Timeout waiting for kernel_info_reply: 5e7b4be6-7cfb-4bed-be7a-1317135b8c1c
[E 14:35:27.052 LabApp] Exception restarting kernel
    Traceback (most recent call last):
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/notebook/services/kernels/handlers.py", line 83, in post
        yield maybe_future(km.restart_kernel(kernel_id))
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/tornado/gen.py", line 735, in run
        value = future.result()
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/tornado/gen.py", line 742, in run
        yielded = self.gen.throw(*exc_info)  # type: ignore
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/notebook/services/kernels/kernelmanager.py", line 345, in restart_kernel
        yield future
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/tornado/gen.py", line 735, in run
        value = future.result()
    tornado.util.TimeoutError: Timeout waiting for restart
[E 14:35:27.053 LabApp] {
      "Host": "localhost:8187",
      "Connection": "keep-alive",
      "Content-Length": "0",
      "Sec-Fetch-Mode": "cors",
      "Origin": "http://localhost:8187",
      "Authorization": "token b4ed1a543622a3b1aba049c8e4efa3b834277ab07c15002e",
      "X-Xsrftoken": "2|2b997e67|29d4ea20755e92079558d090866cac7e|1571165215",
      "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.120 Safari/537.36",
      "Content-Type": "application/json",
      "Accept": "*/*",
      "Sec-Fetch-Site": "same-origin",
      "Referer": "http://localhost:8187/lab/workspaces/auto-g",
      "Accept-Encoding": "gzip, deflate, br",
      "Accept-Language": "en-US,en;q=0.9,fr;q=0.8",
      "Cookie": "_ga=GA1.1.2135320950.1566148815; username-localhost-8195=\"2|1:0|10:1570831591|23:username-localhost-8195|44:Y2Q0M2Y0YjJhMDQxNDQwZThhOGNjZTdhNDFiNDNkNjI=|4fc2d73bc3298178be788038ba7812e8e7e1ca4ae1891ffcc42a6bd3445055ab\"; username-localhost-8186=\"2|1:0|10:1570831618|23:username-localhost-8186|44:OGQ0ZDZhMzA0OGU3NGJjNmE3ZWQzZTNlNjE0OTE5YTc=|c35b67c47b69b28e578cd086622671b22c440c459eb1f804d2a3d6e6da842624\"; _xsrf=2|2b997e67|29d4ea20755e92079558d090866cac7e|1571165215; username-localhost-8187=\"2|1:0|10:1571693659|23:username-localhost-8187|44:YzlmZTg0MDY3NmUyNDE2NTg2OGRjMTBjZWI5OTZkZjQ=|6b1de8e438b105316a4e7bd61d9efadf0c2de8497cc288e739e919c5dfeed4ff\""
    }
[E 14:35:27.053 LabApp] 500 POST /api/kernels/5e7b4be6-7cfb-4bed-be7a-1317135b8c1c/restart?1571693661780 (::1) 65262.20ms referer=http://localhost:8187/lab/workspaces/auto-g
[W 14:35:32.154 LabApp] Timeout waiting for kernel_info_reply: 5e7b4be6-7cfb-4bed-be7a-1317135b8c1c
[E 14:35:32.155 LabApp] Exception restarting kernel
    Traceback (most recent call last):
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/notebook/services/kernels/handlers.py", line 83, in post
        yield maybe_future(km.restart_kernel(kernel_id))
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/tornado/gen.py", line 735, in run
        value = future.result()
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/tornado/gen.py", line 742, in run
        yielded = self.gen.throw(*exc_info)  # type: ignore
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/notebook/services/kernels/kernelmanager.py", line 345, in restart_kernel
        yield future
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/tornado/gen.py", line 735, in run
        value = future.result()
    tornado.util.TimeoutError: Timeout waiting for restart
[E 14:35:32.156 LabApp] {
      "Host": "localhost:8187",
      "Connection": "keep-alive",
      "Content-Length": "0",
      "Sec-Fetch-Mode": "cors",
      "Origin": "http://localhost:8187",
      "Authorization": "token b4ed1a543622a3b1aba049c8e4efa3b834277ab07c15002e",
      "X-Xsrftoken": "2|2b997e67|29d4ea20755e92079558d090866cac7e|1571165215",
      "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.120 Safari/537.36",
      "Content-Type": "application/json",
      "Accept": "*/*",
      "Sec-Fetch-Site": "same-origin",
      "Referer": "http://localhost:8187/lab/workspaces/auto-g",
      "Accept-Encoding": "gzip, deflate, br",
      "Accept-Language": "en-US,en;q=0.9,fr;q=0.8",
      "Cookie": "_ga=GA1.1.2135320950.1566148815; username-localhost-8195=\"2|1:0|10:1570831591|23:username-localhost-8195|44:Y2Q0M2Y0YjJhMDQxNDQwZThhOGNjZTdhNDFiNDNkNjI=|4fc2d73bc3298178be788038ba7812e8e7e1ca4ae1891ffcc42a6bd3445055ab\"; username-localhost-8186=\"2|1:0|10:1570831618|23:username-localhost-8186|44:OGQ0ZDZhMzA0OGU3NGJjNmE3ZWQzZTNlNjE0OTE5YTc=|c35b67c47b69b28e578cd086622671b22c440c459eb1f804d2a3d6e6da842624\"; _xsrf=2|2b997e67|29d4ea20755e92079558d090866cac7e|1571165215; username-localhost-8187=\"2|1:0|10:1571693659|23:username-localhost-8187|44:YzlmZTg0MDY3NmUyNDE2NTg2OGRjMTBjZWI5OTZkZjQ=|6b1de8e438b105316a4e7bd61d9efadf0c2de8497cc288e739e919c5dfeed4ff\""
    }
[E 14:35:32.156 LabApp] 500 POST /api/kernels/5e7b4be6-7cfb-4bed-be7a-1317135b8c1c/restart?1571693666267 (::1) 65101.49ms referer=http://localhost:8187/lab/workspaces/auto-g
[W 14:35:39.787 LabApp] Timeout waiting for kernel_info reply from babf27cf-00b4-45ab-82dd-018ae6524543
[I 14:35:43.831 LabApp] Kernel interrupted: 978d9916-af35-4406-97da-0a0aa693d3c0
[I 14:35:47.905 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/humpback-PCA-projections.ipynb
[I 14:36:13.516 LabApp] Starting buffering for 5e7b4be6-7cfb-4bed-be7a-1317135b8c1c:2ac05d41-5ce9-4373-90c1-b827a06a616d
[I 14:36:55.790 LabApp] Adapting from protocol version 5.1 (kernel 5e7b4be6-7cfb-4bed-be7a-1317135b8c1c) to 5.3 (client).
[W 14:36:55.793 LabApp] zmq message arrived on closed channel
[W 14:36:55.796 LabApp] zmq message arrived on closed channel
[W 14:36:55.797 LabApp] zmq message arrived on closed channel
[I 14:36:55.799 LabApp] Adapting from protocol version 5.1 (kernel babf27cf-00b4-45ab-82dd-018ae6524543) to 5.3 (client).
[I 14:37:42.896 LabApp] Adapting from protocol version 5.1 (kernel 978d9916-af35-4406-97da-0a0aa693d3c0) to 5.3 (client).
[W 14:37:43.399 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.58ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/humpback-PCA-projections.ipynb
[W 14:37:44.440 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 3.45ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/humpback-PCA-projections.ipynb
[W 14:42:42.898 LabApp] WebSocket ping timeout after 119995 ms.
[I 14:42:47.902 LabApp] Starting buffering for 978d9916-af35-4406-97da-0a0aa693d3c0:666cb0f0607840c1b9b9b7f2ac0652a5
[I 15:31:01.460 LabApp] 302 GET / (::1) 0.99ms
[I 15:31:04.275 LabApp] Build is up to date
[I 15:31:05.287 LabApp] Adapting from protocol version 5.1 (kernel 978d9916-af35-4406-97da-0a0aa693d3c0) to 5.3 (client).
[I 15:31:05.289 LabApp] Discarding 30 buffered messages for 978d9916-af35-4406-97da-0a0aa693d3c0:666cb0f0607840c1b9b9b7f2ac0652a5
[I 15:31:10.379 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/humpback-PCA-projections.ipynb
[W 15:31:13.512 LabApp] zmq message arrived on closed channel
[W 15:31:13.514 LabApp] zmq message arrived on closed channel
[I 15:31:13.576 LabApp] Starting buffering for babf27cf-00b4-45ab-82dd-018ae6524543:1b8c6885-c2f8-46b9-a5d6-f02756b0c80f
[IPKernelApp] WARNING | No such comm: 0de925d437c144188d1c08ed4d9505fd
[I 15:33:10.713 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/humpback-PCA-projections.ipynb
[I 15:37:03.856 LabApp] Copying avgn_paper/notebooks/5.0-visualize-transitions/humpback-PCA-projections.ipynb to /avgn_paper/notebooks/5.0-visualize-transitions
[I 15:37:06.909 LabApp] Kernel started: a1604992-8268-4eb3-b439-c9685c429d94
[I 15:37:09.478 LabApp] Adapting from protocol version 5.1 (kernel a1604992-8268-4eb3-b439-c9685c429d94) to 5.3 (client).
[I 18:07:36.511 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/mouse-usv-PCA-projections.ipynb
2019-10-21 18:07:44.265725: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-21 18:07:50.098113: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-10-21 18:07:50.098243: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: txori
2019-10-21 18:07:50.098258: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: txori
2019-10-21 18:07:50.098652: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.79.0
2019-10-21 18:07:50.098721: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 410.79.0
2019-10-21 18:07:50.098733: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 410.79.0
2019-10-21 18:07:50.133459: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-21 18:07:50.134498: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b9373e5310 executing computations on platform Host. Devices:
2019-10-21 18:07:50.134527: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
[IPKernelApp] WARNING | No such comm: c9d55b9e204e4a97ab2b9209e32908f9
[I 18:09:36.783 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/mouse-usv-PCA-projections.ipynb
[I 18:09:48.808 LabApp] Kernel started: 29ddd7f9-f029-4ab6-9ac4-ae3b0bbb1ef9
[I 18:09:51.078 LabApp] Adapting from protocol version 5.1 (kernel 29ddd7f9-f029-4ab6-9ac4-ae3b0bbb1ef9) to 5.3 (client).
[I 18:10:15.341 LabApp] Discarding 6 buffered messages for 5e7b4be6-7cfb-4bed-be7a-1317135b8c1c:2ac05d41-5ce9-4373-90c1-b827a06a616d
[I 18:10:21.735 LabApp] Kernel restarted: 5e7b4be6-7cfb-4bed-be7a-1317135b8c1c
[I 18:11:48.730 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/1.0-starling-to-tfrecord.ipynb
[I 18:12:15.117 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/bf-sober-transitions-barcode.ipynb
[I 18:13:49.010 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/1.0-starling-to-tfrecord.ipynb
[I 18:13:52.128 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/1.0-starling-to-tfrecord.ipynb
[I 18:14:15.422 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/bf-sober-transitions-barcode.ipynb
[I 18:15:32.937 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/1.0-starling-to-tfrecord.ipynb
[I 18:17:33.369 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/1.0-starling-to-tfrecord.ipynb
[I 18:18:15.779 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/bf-sober-transitions-barcode.ipynb
[I 18:18:45.000 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/1.0-starling-to-tfrecord.ipynb
[I 18:20:16.114 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/bf-sober-transitions-barcode.ipynb
[I 18:20:35.411 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/1.0-starling-to-tfrecord.ipynb
[I 18:20:38.301 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/1.0-starling-to-tfrecord.ipynb
[I 18:20:39.099 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/1.0-starling-to-tfrecord.ipynb
2019-10-21 18:22:32.029645: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-21 18:22:37.212512: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-10-21 18:22:37.212613: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: txori
2019-10-21 18:22:37.212626: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: txori
2019-10-21 18:22:37.213027: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.79.0
2019-10-21 18:22:37.213093: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 410.79.0
2019-10-21 18:22:37.213106: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 410.79.0
2019-10-21 18:22:37.297471: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-21 18:22:37.298964: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555974a4c530 executing computations on platform Host. Devices:
2019-10-21 18:22:37.298998: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
[I 18:22:39.462 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/1.0-starling-to-tfrecord.ipynb
[I 18:24:24.095 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/bf-sober-transitions-barcode.ipynb
[I 18:24:39.730 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/1.0-starling-to-tfrecord.ipynb
2019-10-21 18:24:48.385115: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-21 18:24:52.740775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-21 18:24:52.741543: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-21 18:24:52.742376: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 2 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
2019-10-21 18:24:52.743317: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 3 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-21 18:24:52.903876: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-21 18:24:53.159912: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-21 18:24:53.545772: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-21 18:24:54.508187: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-21 18:24:54.925217: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-21 18:24:55.526183: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-21 18:24:56.705039: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-21 18:24:56.711615: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1, 2, 3
2019-10-21 18:24:57.200931: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563631eb1b40 executing computations on platform CUDA. Devices:
2019-10-21 18:24:57.200981: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-21 18:24:57.200992: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (1): TITAN Xp, Compute Capability 6.1
2019-10-21 18:24:57.201001: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (2): Tesla K40c, Compute Capability 3.5
2019-10-21 18:24:57.201010: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (3): Tesla K40c, Compute Capability 3.5
2019-10-21 18:24:57.205662: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-21 18:24:57.206824: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563631bf4b10 executing computations on platform Host. Devices:
2019-10-21 18:24:57.206853: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-21 18:24:57.209329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-21 18:24:57.210016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-21 18:24:57.210871: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 2 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
2019-10-21 18:24:57.211736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 3 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-21 18:24:57.211829: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-21 18:24:57.211869: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-21 18:24:57.211903: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-21 18:24:57.211937: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-21 18:24:57.211970: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-21 18:24:57.212004: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-21 18:24:57.212038: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-21 18:24:57.218546: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1, 2, 3
2019-10-21 18:24:57.218663: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-21 18:24:57.223198: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-21 18:24:57.223220: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 1 2 3 
2019-10-21 18:24:57.223233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N Y N N 
2019-10-21 18:24:57.223242: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 1:   Y N N N 
2019-10-21 18:24:57.223251: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 2:   N N N Y 
2019-10-21 18:24:57.223261: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 3:   N N Y N 
2019-10-21 18:24:57.228081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-21 18:24:57.229180: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 153 MB memory) -> physical GPU (device: 1, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-21 18:24:57.230438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 10791 MB memory) -> physical GPU (device: 2, name: Tesla K40c, pci bus id: 0000:02:00.0, compute capability: 3.5)
2019-10-21 18:24:57.232526: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 10791 MB memory) -> physical GPU (device: 3, name: Tesla K40c, pci bus id: 0000:03:00.0, compute capability: 3.5)
[I 18:26:39.973 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/bf-sober-transitions-barcode.ipynb
[I 18:26:40.663 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/1.0-starling-to-tfrecord.ipynb
[IPKernelApp] WARNING | No such comm: 63a1db8eafef4e448ab34d8b81b0a663
[IPKernelApp] WARNING | No such comm: e17fe304e6104bc39de4f0538adcc9e0
[IPKernelApp] WARNING | No such comm: e67703be73b3429cb3592a232dd24494
[IPKernelApp] WARNING | No such comm: e24c6d6f01e7479c8937748c451adbbd
[IPKernelApp] WARNING | No such comm: 9979ab854ba4404eb2dadb89365fc7cd
[IPKernelApp] WARNING | No such comm: 159ad13e8e434560a588ac3abeaf05a0
[IPKernelApp] WARNING | No such comm: 25d47a3cc67e4396a2c4c1b4a6efbf3f
[IPKernelApp] WARNING | No such comm: f0f3b075cae2446a9e392def9cfdb127
[IPKernelApp] WARNING | No such comm: 222f90833ddd41e390851e19684d910e
[IPKernelApp] WARNING | No such comm: 97fbe2aea224452eafffd38fd09611c1
[IPKernelApp] WARNING | No such comm: 50443823f8eb4b29a0742a44be85513a
[IPKernelApp] WARNING | No such comm: 14a968bfbd8a4dfaab796d59529a8e06
[IPKernelApp] WARNING | No such comm: f1867ce817f343698189c841b739d73d
[I 18:28:10.920 LabApp] 302 GET / (::1) 0.65ms
[I 18:28:12.814 LabApp] 301 GET /lab/workspaces/auto-v/?clone (::1) 0.92ms
[I 18:28:13.839 LabApp] Build is up to date
[I 18:28:15.643 LabApp] Adapting from protocol version 5.1 (kernel a1604992-8268-4eb3-b439-c9685c429d94) to 5.3 (client).
[I 18:28:15.961 LabApp] Adapting from protocol version 5.1 (kernel 978d9916-af35-4406-97da-0a0aa693d3c0) to 5.3 (client).
[I 18:28:16.148 LabApp] Adapting from protocol version 5.1 (kernel 29ddd7f9-f029-4ab6-9ac4-ae3b0bbb1ef9) to 5.3 (client).
[W 18:28:16.472 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 1.72ms referer=http://localhost:8187/tree
[I 18:29:39.836 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/bf-sober-transitions-barcode.ipynb
[I 19:07:08.693 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/bf-sober-transitions-barcode.ipynb
[I 19:10:17.372 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/bf-sober-transitions-barcode.ipynb
[I 19:12:12.116 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/bf-sober-transitions-barcode.ipynb
[I 19:12:12.430 LabApp] Kernel interrupted: 5e7b4be6-7cfb-4bed-be7a-1317135b8c1c
[I 19:12:47.613 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/bf-sober-transitions-barcode.ipynb
[I 19:13:31.595 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/bf-sober-transitions-barcode.ipynb
[W 19:14:12.605 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 1.57ms referer=http://localhost:8187/tree
[I 19:14:22.923 LabApp] Creating new notebook in /avgn_paper/notebooks/6.0-neural-networks
[I 19:14:24.901 LabApp] Kernel started: 44f876b4-ca09-4660-b00e-315e5964640a
[W 19:14:24.908 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.66ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Untitled.ipynb?kernel_name=python3
[W 19:14:25.266 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 1.81ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Untitled.ipynb?kernel_name=python3
[I 19:14:26.430 LabApp] Adapting from protocol version 5.1 (kernel 44f876b4-ca09-4660-b00e-315e5964640a) to 5.3 (client).
[I 19:16:25.878 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 19:16:30.750 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/bf-sober-transitions-barcode.ipynb
[I 19:16:59.853 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[W 19:18:08.261 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.72ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/1.0-starling-to-tfrecord.ipynb
[I 19:18:08.788 LabApp] Adapting from protocol version 5.1 (kernel 29ddd7f9-f029-4ab6-9ac4-ae3b0bbb1ef9) to 5.3 (client).
[W 19:18:08.835 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 1.71ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/1.0-starling-to-tfrecord.ipynb
[I 19:18:25.679 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 19:18:43.762 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/bf-sober-transitions-barcode.ipynb
[I 19:20:08.786 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/1.0-starling-to-tfrecord.ipynb
[I 19:20:25.948 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 19:21:14.650 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/bf-sober-transitions-barcode.ipynb
2019-10-21 19:22:06.687401: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-21 19:22:06.712726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-21 19:22:06.713986: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-21 19:22:06.715602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 2 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
2019-10-21 19:22:06.717146: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 3 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-21 19:22:06.718240: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-21 19:22:06.721537: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-21 19:22:06.724079: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-21 19:22:06.725090: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-21 19:22:06.728400: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-21 19:22:06.731292: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-21 19:22:06.737557: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-21 19:22:06.748368: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1, 2, 3
2019-10-21 19:22:07.299789: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fce0194020 executing computations on platform CUDA. Devices:
2019-10-21 19:22:07.299848: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-21 19:22:07.299860: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (1): TITAN Xp, Compute Capability 6.1
2019-10-21 19:22:07.299869: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (2): Tesla K40c, Compute Capability 3.5
2019-10-21 19:22:07.299879: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (3): Tesla K40c, Compute Capability 3.5
2019-10-21 19:22:07.305232: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-21 19:22:07.306506: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fce09adf30 executing computations on platform Host. Devices:
2019-10-21 19:22:07.306535: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-21 19:22:07.308009: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-21 19:22:07.308795: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-21 19:22:07.309867: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 2 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
2019-10-21 19:22:07.310909: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 3 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-21 19:22:07.311014: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-21 19:22:07.311063: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-21 19:22:07.311120: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-21 19:22:07.311180: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-21 19:22:07.311220: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-21 19:22:07.311258: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-21 19:22:07.311297: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-21 19:22:07.320210: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1, 2, 3
2019-10-21 19:22:07.320281: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-21 19:22:07.325487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-21 19:22:07.325514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 1 2 3 
2019-10-21 19:22:07.325528: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N Y N N 
2019-10-21 19:22:07.325539: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 1:   Y N N N 
2019-10-21 19:22:07.325550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 2:   N N N Y 
2019-10-21 19:22:07.325561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 3:   N N Y N 
2019-10-21 19:22:07.331289: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11277 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-21 19:22:07.332352: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 221 MB memory) -> physical GPU (device: 1, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-21 19:22:07.333664: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 10725 MB memory) -> physical GPU (device: 2, name: Tesla K40c, pci bus id: 0000:02:00.0, compute capability: 3.5)
2019-10-21 19:22:07.334998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 10725 MB memory) -> physical GPU (device: 3, name: Tesla K40c, pci bus id: 0000:03:00.0, compute capability: 3.5)
[I 19:22:24.855 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 19:22:43.018 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 19:26:24.893 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 19:28:09.495 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/1.0-starling-to-tfrecord.ipynb
[I 19:28:24.839 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 19:30:19.448 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 19:30:24.838 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 19:31:58.092 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 19:32:07.478 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 19:32:19.901 LabApp] Starting buffering for 44f876b4-ca09-4660-b00e-315e5964640a:cdde91beb9a84e34acb57a3d99340dd1
[I 19:32:21.320 LabApp] Kernel restarted: 44f876b4-ca09-4660-b00e-315e5964640a
[I 19:32:22.327 LabApp] Adapting from protocol version 5.1 (kernel 44f876b4-ca09-4660-b00e-315e5964640a) to 5.3 (client).
[I 19:32:22.328 LabApp] Restoring connection for 44f876b4-ca09-4660-b00e-315e5964640a:cdde91beb9a84e34acb57a3d99340dd1
[I 19:32:22.328 LabApp] Replaying 6 buffered messages
[I 19:32:24.843 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
2019-10-21 19:32:42.667561: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-21 19:32:42.686247: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-21 19:32:42.687024: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-21 19:32:42.688037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 2 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
2019-10-21 19:32:42.688966: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 3 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-21 19:32:42.689752: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-21 19:32:42.691617: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-21 19:32:42.693082: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-21 19:32:42.693747: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-21 19:32:42.695713: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-21 19:32:42.697388: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-21 19:32:42.701045: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-21 19:32:42.709134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1, 2, 3
2019-10-21 19:32:43.262760: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f3113f8da0 executing computations on platform CUDA. Devices:
2019-10-21 19:32:43.262810: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-21 19:32:43.262822: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (1): TITAN Xp, Compute Capability 6.1
2019-10-21 19:32:43.262832: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (2): Tesla K40c, Compute Capability 3.5
2019-10-21 19:32:43.262842: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (3): Tesla K40c, Compute Capability 3.5
2019-10-21 19:32:43.267356: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-21 19:32:43.268450: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f311cb2290 executing computations on platform Host. Devices:
2019-10-21 19:32:43.268481: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-21 19:32:43.270015: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-21 19:32:43.270739: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-21 19:32:43.271729: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 2 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
2019-10-21 19:32:43.272632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 3 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-21 19:32:43.272711: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-21 19:32:43.272751: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-21 19:32:43.272787: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-21 19:32:43.272824: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-21 19:32:43.272861: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-21 19:32:43.272898: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-21 19:32:43.272936: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-21 19:32:43.279594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1, 2, 3
2019-10-21 19:32:43.279659: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-21 19:32:43.284783: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-21 19:32:43.284807: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 1 2 3 
2019-10-21 19:32:43.284820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N Y N N 
2019-10-21 19:32:43.284830: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 1:   Y N N N 
2019-10-21 19:32:43.284839: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 2:   N N N Y 
2019-10-21 19:32:43.284849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 3:   N N Y N 
2019-10-21 19:32:43.290114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11277 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-21 19:32:43.291158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 221 MB memory) -> physical GPU (device: 1, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-21 19:32:43.292369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 10725 MB memory) -> physical GPU (device: 2, name: Tesla K40c, pci bus id: 0000:02:00.0, compute capability: 3.5)
2019-10-21 19:32:43.293604: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 10725 MB memory) -> physical GPU (device: 3, name: Tesla K40c, pci bus id: 0000:03:00.0, compute capability: 3.5)
[W 19:33:41.076 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 4.49ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/2.0-make-syllable_df/starling-syllable-df.ipynb
[I 19:33:43.543 LabApp] Kernel started: b0d6db59-8f03-4124-99a3-ab6c5a0f8d31
[I 19:33:44.806 LabApp] Adapting from protocol version 5.1 (kernel b0d6db59-8f03-4124-99a3-ab6c5a0f8d31) to 5.3 (client).
[I 19:34:26.290 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 19:35:57.766 LabApp] Saving file at /avgn_paper/notebooks/2.0-make-syllable_df/starling-syllable-df.ipynb
[I 19:38:36.486 LabApp] Copying avgn_paper/notebooks/2.0-make-syllable_df/starling-syllable-df.ipynb to /avgn_paper/notebooks/2.0-make-syllable_df
[W 19:38:39.412 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.94ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/2.0-make-syllable_df/starling-syllable-df-Copy1.ipynb
[W 19:38:40.538 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 1.82ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/2.0-make-syllable_df/starling-syllable-df-Copy1.ipynb
[I 19:38:41.679 LabApp] Kernel started: a62ba8c7-71ba-48f9-8581-aee04b99949f
[I 19:38:43.034 LabApp] Adapting from protocol version 5.1 (kernel a62ba8c7-71ba-48f9-8581-aee04b99949f) to 5.3 (client).
[I 19:40:55.887 LabApp] Saving file at /avgn_paper/notebooks/2.0-make-syllable_df/starling-syllable-df-128.ipynb
[I 19:41:29.352 LabApp] Saving file at /avgn_paper/notebooks/2.0-make-syllable_df/starling-syllable-df-128.ipynb
2019-10-21 19:41:36.938156: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-21 19:41:36.957361: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-10-21 19:41:36.957416: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: txori
2019-10-21 19:41:36.957432: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: txori
2019-10-21 19:41:36.957537: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.79.0
2019-10-21 19:41:36.957591: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 410.79.0
2019-10-21 19:41:36.957607: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 410.79.0
2019-10-21 19:41:36.995787: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-21 19:41:36.996949: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5573aa007d30 executing computations on platform Host. Devices:
2019-10-21 19:41:36.996977: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
[I 19:43:50.845 LabApp] Saving file at /avgn_paper/notebooks/2.0-make-syllable_df/starling-syllable-df-128.ipynb
[I 19:44:47.645 LabApp] Saving file at /avgn_paper/notebooks/2.0-make-syllable_df/starling-syllable-df-128.ipynb
[I 19:44:51.482 LabApp] Saving file at /avgn_paper/notebooks/2.0-make-syllable_df/starling-syllable-df-128.ipynb
[I 19:49:26.739 LabApp] Saving file at /avgn_paper/notebooks/2.0-make-syllable_df/starling-syllable-df-128.ipynb
/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/scipy/signal/signaltools.py:1344: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.
  out = out_full[ind]
/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/scipy/signal/signaltools.py:1344: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.
  out = out_full[ind]
/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/scipy/signal/signaltools.py:1344: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.
  out = out_full[ind]
[I 19:53:46.528 LabApp] Saving file at /avgn_paper/notebooks/2.0-make-syllable_df/starling-syllable-df-128.ipynb
/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/scipy/signal/signaltools.py:1344: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.
  out = out_full[ind]
/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/scipy/signal/signaltools.py:1344: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.
  out = out_full[ind]
/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/scipy/signal/signaltools.py:1344: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.
  out = out_full[ind]
/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/scipy/signal/signaltools.py:1344: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.
  out = out_full[ind]
/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/scipy/signal/signaltools.py:1344: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.
  out = out_full[ind]
/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/scipy/signal/signaltools.py:1344: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.
  out = out_full[ind]
/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/scipy/signal/signaltools.py:1344: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.
  out = out_full[ind]
/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/scipy/signal/signaltools.py:1344: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.
  out = out_full[ind]
/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/scipy/signal/signaltools.py:1344: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.
  out = out_full[ind]
/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/scipy/signal/signaltools.py:1344: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.
  out = out_full[ind]
/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/scipy/signal/signaltools.py:1344: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.
  out = out_full[ind]
/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/scipy/signal/signaltools.py:1344: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.
  out = out_full[ind]
[I 19:57:14.252 LabApp] Saving file at /avgn_paper/notebooks/2.0-make-syllable_df/starling-syllable-df-128.ipynb
/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/scipy/signal/signaltools.py:1344: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.
  out = out_full[ind]
/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/scipy/signal/signaltools.py:1344: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.
  out = out_full[ind]
/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/scipy/signal/signaltools.py:1344: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.
  out = out_full[ind]
[I 19:58:06.612 LabApp] Saving file at /avgn_paper/notebooks/2.0-make-syllable_df/starling-syllable-df-128.ipynb
/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/scipy/signal/signaltools.py:1344: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.
  out = out_full[ind]
/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/scipy/signal/signaltools.py:1344: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.
  out = out_full[ind]
/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/scipy/signal/signaltools.py:1344: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.
  out = out_full[ind]
/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/scipy/signal/signaltools.py:1344: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.
  out = out_full[ind]
[I 19:59:08.784 LabApp] Kernel interrupted: a62ba8c7-71ba-48f9-8581-aee04b99949f
/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/scipy/signal/signaltools.py:1344: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.
  out = out_full[ind]
Process LokyProcess-3:
Traceback (most recent call last):
  File "/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py", line 415, in _process_worker
    with worker_exit_lock:
  File "/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/backend/synchronize.py", line 104, in __enter__
    return self._semlock.acquire()
KeyboardInterrupt
/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/scipy/signal/signaltools.py:1344: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.
  out = out_full[ind]
Process LokyProcess-5:
Traceback (most recent call last):
  File "/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py", line 415, in _process_worker
    with worker_exit_lock:
  File "/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/backend/synchronize.py", line 104, in __enter__
    return self._semlock.acquire()
KeyboardInterrupt
[I 20:01:14.644 LabApp] Saving file at /avgn_paper/notebooks/2.0-make-syllable_df/starling-syllable-df-128.ipynb
[I 20:02:27.233 LabApp] Saving file at /avgn_paper/notebooks/2.0-make-syllable_df/starling-syllable-df-128.ipynb
[I 20:04:53.787 LabApp] Saving file at /avgn_paper/notebooks/2.0-make-syllable_df/starling-syllable-df-128.ipynb
[I 20:06:00.865 LabApp] Kernel shutdown: 44f876b4-ca09-4660-b00e-315e5964640a
[I 20:06:00.918 LabApp] Starting buffering for a1604992-8268-4eb3-b439-c9685c429d94:a19ee4ff-eda7-427e-940e-1bd63f6c0abf
[I 20:06:05.993 LabApp] Kernel shutdown: 29ddd7f9-f029-4ab6-9ac4-ae3b0bbb1ef9
[I 20:06:11.044 LabApp] Kernel shutdown: a1604992-8268-4eb3-b439-c9685c429d94
[I 20:06:11.473 LabApp] Kernel shutdown: babf27cf-00b4-45ab-82dd-018ae6524543
[W 20:06:11.479 LabApp] zmq message arrived on closed channel
[W 20:06:11.480 LabApp] zmq message arrived on closed channel
[W 20:06:11.481 LabApp] zmq message arrived on closed channel
[I 20:06:48.555 LabApp] Saving file at /avgn_paper/notebooks/2.0-make-syllable_df/starling-syllable-df-128.ipynb
[I 20:13:48.683 LabApp] Starting buffering for 5e7b4be6-7cfb-4bed-be7a-1317135b8c1c:ead04705-4a9c-4ca8-bd85-18fdc11bf731
[I 20:13:48.684 LabApp] Starting buffering for 978d9916-af35-4406-97da-0a0aa693d3c0:fa4b002b-66bb-4a25-ad20-fecbc8135b5c
[I 20:13:56.121 LabApp] Build is up to date
[I 20:13:57.688 LabApp] Adapting from protocol version 5.1 (kernel 978d9916-af35-4406-97da-0a0aa693d3c0) to 5.3 (client).
[I 20:13:57.763 LabApp] Kernel started: 567f8b1e-f0e6-44ce-aaf6-0db2311add48
[I 20:13:59.173 LabApp] Adapting from protocol version 5.1 (kernel 567f8b1e-f0e6-44ce-aaf6-0db2311add48) to 5.3 (client).
[I 20:13:59.173 LabApp] Adapting from protocol version 5.1 (kernel 567f8b1e-f0e6-44ce-aaf6-0db2311add48) to 5.3 (client).
[W 20:14:25.562 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 2.46ms referer=http://localhost:8187/tree/avgn_paper/figures/barcode/bengalese_finch_sober
[I 20:31:05.588 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/1.0-starling-to-tfrecord.ipynb
[W 20:31:12.435 LabApp] 404 DELETE /api/sessions/973a3627-f3a7-441d-809e-65ee8e9c9348 (::1): Session not found: session_id='973a3627-f3a7-441d-809e-65ee8e9c9348'
[W 20:31:12.435 LabApp] Session not found: session_id='973a3627-f3a7-441d-809e-65ee8e9c9348'
[W 20:31:12.435 LabApp] 404 DELETE /api/sessions/973a3627-f3a7-441d-809e-65ee8e9c9348 (::1) 2.27ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/1.0-starling-to-tfrecord.ipynb
/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/backend/semaphore_tracker.py:198: UserWarning: semaphore_tracker: There appear to be 6 leaked semaphores to clean up at shutdown
  len(cache))
[I 20:31:26.678 LabApp] KernelRestarter: restarting kernel (1/5), keep random ports
kernel a62ba8c7-71ba-48f9-8581-aee04b99949f restarted
[I 20:31:39.094 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/1.0-starling-to-tfrecord.ipynb
[W 20:31:47.365 LabApp] 404 POST /api/kernels/29ddd7f9-f029-4ab6-9ac4-ae3b0bbb1ef9/interrupt (::1): Kernel does not exist: 29ddd7f9-f029-4ab6-9ac4-ae3b0bbb1ef9
[W 20:31:47.365 LabApp] Kernel does not exist: 29ddd7f9-f029-4ab6-9ac4-ae3b0bbb1ef9
[W 20:31:47.365 LabApp] 404 POST /api/kernels/29ddd7f9-f029-4ab6-9ac4-ae3b0bbb1ef9/interrupt (::1) 1.57ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/1.0-starling-to-tfrecord.ipynb
[I 20:31:47.948 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/1.0-starling-to-tfrecord.ipynb
[W 20:32:27.621 LabApp] 404 POST /api/kernels/29ddd7f9-f029-4ab6-9ac4-ae3b0bbb1ef9/interrupt (::1): Kernel does not exist: 29ddd7f9-f029-4ab6-9ac4-ae3b0bbb1ef9
[W 20:32:27.621 LabApp] Kernel does not exist: 29ddd7f9-f029-4ab6-9ac4-ae3b0bbb1ef9
[W 20:32:27.621 LabApp] 404 POST /api/kernels/29ddd7f9-f029-4ab6-9ac4-ae3b0bbb1ef9/interrupt (::1) 1.65ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/1.0-starling-to-tfrecord.ipynb
[I 20:32:27.998 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/1.0-starling-to-tfrecord.ipynb
[E 20:32:29.761 LabApp] Exception restarting kernel
    Traceback (most recent call last):
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/notebook/services/kernels/handlers.py", line 83, in post
        yield maybe_future(km.restart_kernel(kernel_id))
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/tornado/gen.py", line 735, in run
        value = future.result()
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/tornado/gen.py", line 209, in wrapper
        yielded = next(result)
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/notebook/services/kernels/kernelmanager.py", line 307, in restart_kernel
        self._check_kernel_id(kernel_id)
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/notebook/services/kernels/kernelmanager.py", line 387, in _check_kernel_id
        raise web.HTTPError(404, u'Kernel does not exist: %s' % kernel_id)
    tornado.web.HTTPError: HTTP 404: Not Found (Kernel does not exist: 29ddd7f9-f029-4ab6-9ac4-ae3b0bbb1ef9)
[E 20:32:29.775 LabApp] {
      "Host": "localhost:8187",
      "Connection": "keep-alive",
      "Content-Length": "0",
      "Accept": "application/json, text/javascript, */*; q=0.01",
      "Origin": "http://localhost:8187",
      "X-Requested-With": "XMLHttpRequest",
      "X-Xsrftoken": "2|2b997e67|29d4ea20755e92079558d090866cac7e|1571165215",
      "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.120 Safari/537.36",
      "Sec-Fetch-Mode": "cors",
      "Sec-Fetch-Site": "same-origin",
      "Referer": "http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/1.0-starling-to-tfrecord.ipynb",
      "Accept-Encoding": "gzip, deflate, br",
      "Accept-Language": "en-US,en;q=0.9,fr;q=0.8",
      "Cookie": "_ga=GA1.1.2135320950.1566148815; username-localhost-8195=\"2|1:0|10:1570831591|23:username-localhost-8195|44:Y2Q0M2Y0YjJhMDQxNDQwZThhOGNjZTdhNDFiNDNkNjI=|4fc2d73bc3298178be788038ba7812e8e7e1ca4ae1891ffcc42a6bd3445055ab\"; username-localhost-8186=\"2|1:0|10:1570831618|23:username-localhost-8186|44:OGQ0ZDZhMzA0OGU3NGJjNmE3ZWQzZTNlNjE0OTE5YTc=|c35b67c47b69b28e578cd086622671b22c440c459eb1f804d2a3d6e6da842624\"; _xsrf=2|2b997e67|29d4ea20755e92079558d090866cac7e|1571165215; username-localhost-8187=\"2|1:0|10:1571714062|23:username-localhost-8187|44:Mzg3ODQ5M2FhZTBmNDA1ODgyYTJiMmMyZDg2MGExOTY=|eb72d7fe09f5cb6b1d2f1fd36428ad9ec3b98a61bac7e8ecb8f2abdf07abf623\""
    }
[E 20:32:29.775 LabApp] 500 POST /api/kernels/29ddd7f9-f029-4ab6-9ac4-ae3b0bbb1ef9/restart (::1) 15.03ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/1.0-starling-to-tfrecord.ipynb
[W 20:32:29.807 LabApp] 404 DELETE /api/sessions/973a3627-f3a7-441d-809e-65ee8e9c9348 (::1): Session not found: session_id='973a3627-f3a7-441d-809e-65ee8e9c9348'
[W 20:32:29.807 LabApp] Session not found: session_id='973a3627-f3a7-441d-809e-65ee8e9c9348'
[W 20:32:29.808 LabApp] 404 DELETE /api/sessions/973a3627-f3a7-441d-809e-65ee8e9c9348 (::1) 2.13ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/1.0-starling-to-tfrecord.ipynb
[I 20:32:29.851 LabApp] Kernel started: 18eabf2b-2c7e-44ff-93f7-53f289fada24
[I 20:32:30.887 LabApp] Adapting from protocol version 5.1 (kernel 18eabf2b-2c7e-44ff-93f7-53f289fada24) to 5.3 (client).
[I 20:32:55.844 LabApp] Saving file at /avgn_paper/notebooks/2.0-make-syllable_df/starling-syllable-df-128.ipynb
[I 20:34:06.342 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/1.0-starling-to-tfrecord.ipynb
[I 20:34:11.129 LabApp] Starting buffering for 18eabf2b-2c7e-44ff-93f7-53f289fada24:ee544d1b2a4842c5a5fbb14358bbddc1
[I 20:34:11.950 LabApp] Kernel restarted: 18eabf2b-2c7e-44ff-93f7-53f289fada24
[I 20:34:13.331 LabApp] Adapting from protocol version 5.1 (kernel 18eabf2b-2c7e-44ff-93f7-53f289fada24) to 5.3 (client).
[I 20:34:13.332 LabApp] Restoring connection for 18eabf2b-2c7e-44ff-93f7-53f289fada24:ee544d1b2a4842c5a5fbb14358bbddc1
[I 20:34:13.332 LabApp] Replaying 6 buffered messages
[I 20:35:13.840 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
2019-10-21 20:35:18.081381: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-21 20:35:24.357114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-21 20:35:24.357900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-21 20:35:24.358836: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 2 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
2019-10-21 20:35:24.359816: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 3 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-21 20:35:24.361137: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-21 20:35:24.363157: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-21 20:35:24.364744: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-21 20:35:24.365607: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-21 20:35:24.368178: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-21 20:35:24.370726: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-21 20:35:24.374899: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-21 20:35:24.381458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1, 2, 3
2019-10-21 20:35:24.988098: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5573aef90550 executing computations on platform CUDA. Devices:
2019-10-21 20:35:24.988164: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-21 20:35:24.988175: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (1): TITAN Xp, Compute Capability 6.1
2019-10-21 20:35:24.988184: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (2): Tesla K40c, Compute Capability 3.5
2019-10-21 20:35:24.988193: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (3): Tesla K40c, Compute Capability 3.5
2019-10-21 20:35:24.992535: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-21 20:35:24.993614: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5573af7bfae0 executing computations on platform Host. Devices:
2019-10-21 20:35:24.993645: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-21 20:35:24.996254: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-21 20:35:24.996969: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-21 20:35:24.997879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 2 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
2019-10-21 20:35:24.998787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 3 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-21 20:35:24.998871: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-21 20:35:24.998911: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-21 20:35:24.998948: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-21 20:35:24.998986: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-21 20:35:24.999024: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-21 20:35:24.999062: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-21 20:35:24.999108: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-21 20:35:25.006597: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1, 2, 3
2019-10-21 20:35:25.006663: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-21 20:35:25.011271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-21 20:35:25.011297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 1 2 3 
2019-10-21 20:35:25.011311: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N Y N N 
2019-10-21 20:35:25.011321: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 1:   Y N N N 
2019-10-21 20:35:25.011340: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 2:   N N N Y 
2019-10-21 20:35:25.011350: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 3:   N N Y N 
2019-10-21 20:35:25.016730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-21 20:35:25.017766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 153 MB memory) -> physical GPU (device: 1, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-21 20:35:25.018963: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 10791 MB memory) -> physical GPU (device: 2, name: Tesla K40c, pci bus id: 0000:02:00.0, compute capability: 3.5)
2019-10-21 20:35:25.020142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 10791 MB memory) -> physical GPU (device: 3, name: Tesla K40c, pci bus id: 0000:03:00.0, compute capability: 3.5)
[I 20:35:34.314 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 20:36:09.663 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/1.0-starling-to-tfrecord.ipynb
[I 20:36:21.340 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[E 20:36:40.768 LabApp] Exception restarting kernel
    Traceback (most recent call last):
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/notebook/services/kernels/handlers.py", line 83, in post
        yield maybe_future(km.restart_kernel(kernel_id))
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/tornado/gen.py", line 735, in run
        value = future.result()
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/tornado/gen.py", line 209, in wrapper
        yielded = next(result)
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/notebook/services/kernels/kernelmanager.py", line 307, in restart_kernel
        self._check_kernel_id(kernel_id)
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/notebook/services/kernels/kernelmanager.py", line 387, in _check_kernel_id
        raise web.HTTPError(404, u'Kernel does not exist: %s' % kernel_id)
    tornado.web.HTTPError: HTTP 404: Not Found (Kernel does not exist: 44f876b4-ca09-4660-b00e-315e5964640a)
[E 20:36:40.769 LabApp] {
      "Host": "localhost:8187",
      "Connection": "keep-alive",
      "Content-Length": "0",
      "Accept": "application/json, text/javascript, */*; q=0.01",
      "Origin": "http://localhost:8187",
      "X-Requested-With": "XMLHttpRequest",
      "X-Xsrftoken": "2|2b997e67|29d4ea20755e92079558d090866cac7e|1571165215",
      "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.120 Safari/537.36",
      "Sec-Fetch-Mode": "cors",
      "Sec-Fetch-Site": "same-origin",
      "Referer": "http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb",
      "Accept-Encoding": "gzip, deflate, br",
      "Accept-Language": "en-US,en;q=0.9,fr;q=0.8",
      "Cookie": "_ga=GA1.1.2135320950.1566148815; username-localhost-8195=\"2|1:0|10:1570831591|23:username-localhost-8195|44:Y2Q0M2Y0YjJhMDQxNDQwZThhOGNjZTdhNDFiNDNkNjI=|4fc2d73bc3298178be788038ba7812e8e7e1ca4ae1891ffcc42a6bd3445055ab\"; username-localhost-8186=\"2|1:0|10:1570831618|23:username-localhost-8186|44:OGQ0ZDZhMzA0OGU3NGJjNmE3ZWQzZTNlNjE0OTE5YTc=|c35b67c47b69b28e578cd086622671b22c440c459eb1f804d2a3d6e6da842624\"; _xsrf=2|2b997e67|29d4ea20755e92079558d090866cac7e|1571165215; username-localhost-8187=\"2|1:0|10:1571714062|23:username-localhost-8187|44:Mzg3ODQ5M2FhZTBmNDA1ODgyYTJiMmMyZDg2MGExOTY=|eb72d7fe09f5cb6b1d2f1fd36428ad9ec3b98a61bac7e8ecb8f2abdf07abf623\""
    }
[E 20:36:40.769 LabApp] 500 POST /api/kernels/44f876b4-ca09-4660-b00e-315e5964640a/restart (::1) 1.55ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[W 20:36:40.806 LabApp] 404 DELETE /api/sessions/742f13de-be72-4e9f-818d-f3ad7f570747 (::1): Session not found: session_id='742f13de-be72-4e9f-818d-f3ad7f570747'
[W 20:36:40.806 LabApp] Session not found: session_id='742f13de-be72-4e9f-818d-f3ad7f570747'
[W 20:36:40.806 LabApp] 404 DELETE /api/sessions/742f13de-be72-4e9f-818d-f3ad7f570747 (::1) 1.43ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 20:36:40.867 LabApp] Kernel started: b41395eb-52e2-4a6a-bda4-d3ea858d5ff5
[I 20:36:42.135 LabApp] Adapting from protocol version 5.1 (kernel b41395eb-52e2-4a6a-bda4-d3ea858d5ff5) to 5.3 (client).
2019-10-21 20:37:46.435648: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-21 20:37:46.454399: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-21 20:37:46.455179: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-21 20:37:46.456120: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 2 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
2019-10-21 20:37:46.457050: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 3 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-21 20:37:46.457779: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-21 20:37:46.459903: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-21 20:37:46.461505: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-21 20:37:46.462203: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-21 20:37:46.464358: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-21 20:37:46.466218: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-21 20:37:46.470189: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-21 20:37:46.477741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1, 2, 3
2019-10-21 20:37:47.024924: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55aa76054340 executing computations on platform CUDA. Devices:
2019-10-21 20:37:47.024985: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-21 20:37:47.024998: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (1): TITAN Xp, Compute Capability 6.1
2019-10-21 20:37:47.025009: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (2): Tesla K40c, Compute Capability 3.5
2019-10-21 20:37:47.025020: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (3): Tesla K40c, Compute Capability 3.5
2019-10-21 20:37:47.029651: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-21 20:37:47.031204: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55aa768bfe60 executing computations on platform Host. Devices:
2019-10-21 20:37:47.031237: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-21 20:37:47.032690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-21 20:37:47.033442: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-21 20:37:47.034445: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 2 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
2019-10-21 20:37:47.035370: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 3 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-21 20:37:47.035462: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-21 20:37:47.035501: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-21 20:37:47.035538: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-21 20:37:47.035576: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-21 20:37:47.035612: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-21 20:37:47.035651: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-21 20:37:47.035689: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-21 20:37:47.042271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1, 2, 3
2019-10-21 20:37:47.042333: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-21 20:37:47.046990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-21 20:37:47.047027: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 1 2 3 
2019-10-21 20:37:47.047041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N Y N N 
2019-10-21 20:37:47.047051: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 1:   Y N N N 
2019-10-21 20:37:47.047061: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 2:   N N N Y 
2019-10-21 20:37:47.047070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 3:   N N Y N 
2019-10-21 20:37:47.052639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11277 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-21 20:37:47.053767: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 221 MB memory) -> physical GPU (device: 1, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-21 20:37:47.054938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 10725 MB memory) -> physical GPU (device: 2, name: Tesla K40c, pci bus id: 0000:02:00.0, compute capability: 3.5)
2019-10-21 20:37:47.056173: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 10725 MB memory) -> physical GPU (device: 3, name: Tesla K40c, pci bus id: 0000:03:00.0, compute capability: 3.5)
[I 20:38:24.927 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 20:40:25.529 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 20:42:25.009 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 20:44:24.994 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
2019-10-21 20:45:02.392948: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-21 20:45:03.310527: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 20:45:03.610 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 20:46:24.968 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 20:46:33.909 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 20:46:57.192 LabApp] Starting buffering for b41395eb-52e2-4a6a-bda4-d3ea858d5ff5:cdde91beb9a84e34acb57a3d99340dd1
[I 20:46:59.114 LabApp] Kernel restarted: b41395eb-52e2-4a6a-bda4-d3ea858d5ff5
[I 20:47:00.214 LabApp] Adapting from protocol version 5.1 (kernel b41395eb-52e2-4a6a-bda4-d3ea858d5ff5) to 5.3 (client).
[I 20:47:00.215 LabApp] Restoring connection for b41395eb-52e2-4a6a-bda4-d3ea858d5ff5:cdde91beb9a84e34acb57a3d99340dd1
[I 20:47:00.215 LabApp] Replaying 7 buffered messages
2019-10-21 20:47:07.480215: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-21 20:47:07.498544: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-21 20:47:07.499387: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-21 20:47:07.500329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 2 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
2019-10-21 20:47:07.501308: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 3 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-21 20:47:07.502100: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-21 20:47:07.504208: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-21 20:47:07.505832: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-21 20:47:07.506650: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-21 20:47:07.508880: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-21 20:47:07.510750: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-21 20:47:07.514706: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-21 20:47:07.524878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1, 2, 3
2019-10-21 20:47:08.077425: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c25ec54690 executing computations on platform CUDA. Devices:
2019-10-21 20:47:08.077480: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-21 20:47:08.077492: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (1): TITAN Xp, Compute Capability 6.1
2019-10-21 20:47:08.077502: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (2): Tesla K40c, Compute Capability 3.5
2019-10-21 20:47:08.077511: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (3): Tesla K40c, Compute Capability 3.5
2019-10-21 20:47:08.082949: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-21 20:47:08.084232: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c25f4719a0 executing computations on platform Host. Devices:
2019-10-21 20:47:08.084266: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-21 20:47:08.085979: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-21 20:47:08.086799: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-21 20:47:08.087834: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 2 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
2019-10-21 20:47:08.089192: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 3 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-21 20:47:08.089277: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-21 20:47:08.089317: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-21 20:47:08.089354: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-21 20:47:08.089391: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-21 20:47:08.089428: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-21 20:47:08.089465: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-21 20:47:08.089503: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-21 20:47:08.096118: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1, 2, 3
2019-10-21 20:47:08.096187: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-21 20:47:08.100970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-21 20:47:08.100998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 1 2 3 
2019-10-21 20:47:08.101011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N Y N N 
2019-10-21 20:47:08.101021: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 1:   Y N N N 
2019-10-21 20:47:08.101030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 2:   N N N Y 
2019-10-21 20:47:08.101040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 3:   N N Y N 
2019-10-21 20:47:08.106571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11277 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-21 20:47:08.107706: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 221 MB memory) -> physical GPU (device: 1, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-21 20:47:08.110065: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 10725 MB memory) -> physical GPU (device: 2, name: Tesla K40c, pci bus id: 0000:02:00.0, compute capability: 3.5)
2019-10-21 20:47:08.111362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 10725 MB memory) -> physical GPU (device: 3, name: Tesla K40c, pci bus id: 0000:03:00.0, compute capability: 3.5)
2019-10-21 20:47:11.035492: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-21 20:47:12.059548: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
[I 20:47:23.645 LabApp] Starting buffering for b41395eb-52e2-4a6a-bda4-d3ea858d5ff5:cdde91beb9a84e34acb57a3d99340dd1
[I 20:47:28.933 LabApp] Kernel restarted: b41395eb-52e2-4a6a-bda4-d3ea858d5ff5
[I 20:47:29.903 LabApp] Adapting from protocol version 5.1 (kernel b41395eb-52e2-4a6a-bda4-d3ea858d5ff5) to 5.3 (client).
[I 20:47:29.904 LabApp] Restoring connection for b41395eb-52e2-4a6a-bda4-d3ea858d5ff5:cdde91beb9a84e34acb57a3d99340dd1
[I 20:47:29.904 LabApp] Replaying 25 buffered messages
[I 20:47:33.242 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
2019-10-21 20:47:35.718896: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-21 20:47:35.735685: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-21 20:47:35.736458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-21 20:47:35.737339: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 2 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
2019-10-21 20:47:35.738225: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 3 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-21 20:47:35.738614: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-21 20:47:35.740237: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-21 20:47:35.741509: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-21 20:47:35.741955: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-21 20:47:35.743719: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-21 20:47:35.745160: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-21 20:47:35.748796: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-21 20:47:35.755599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1, 2, 3
2019-10-21 20:47:36.289679: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5591f8b8df90 executing computations on platform CUDA. Devices:
2019-10-21 20:47:36.289727: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-21 20:47:36.289739: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (1): TITAN Xp, Compute Capability 6.1
2019-10-21 20:47:36.289749: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (2): Tesla K40c, Compute Capability 3.5
2019-10-21 20:47:36.289758: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (3): Tesla K40c, Compute Capability 3.5
2019-10-21 20:47:36.294041: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-21 20:47:36.295247: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5591f93ac340 executing computations on platform Host. Devices:
2019-10-21 20:47:36.295290: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-21 20:47:36.296654: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-21 20:47:36.297482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-21 20:47:36.298493: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 2 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
2019-10-21 20:47:36.299378: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 3 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-21 20:47:36.299455: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-21 20:47:36.299495: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-21 20:47:36.299532: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-21 20:47:36.299568: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-21 20:47:36.299616: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-21 20:47:36.299661: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-21 20:47:36.299699: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-21 20:47:36.306448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1, 2, 3
2019-10-21 20:47:36.306511: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-21 20:47:36.311412: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-21 20:47:36.311444: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 1 2 3 
2019-10-21 20:47:36.311458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N Y N N 
2019-10-21 20:47:36.311468: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 1:   Y N N N 
2019-10-21 20:47:36.311477: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 2:   N N N Y 
2019-10-21 20:47:36.311486: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 3:   N N Y N 
2019-10-21 20:47:36.316847: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11277 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-21 20:47:36.318112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 221 MB memory) -> physical GPU (device: 1, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-21 20:47:36.319352: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 10725 MB memory) -> physical GPU (device: 2, name: Tesla K40c, pci bus id: 0000:02:00.0, compute capability: 3.5)
2019-10-21 20:47:36.320484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 10725 MB memory) -> physical GPU (device: 3, name: Tesla K40c, pci bus id: 0000:03:00.0, compute capability: 3.5)
2019-10-21 20:47:43.386786: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-21 20:47:43.614424: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 20:48:24.958 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 20:50:24.967 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 20:52:07.086 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 20:52:25.123 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 20:53:17.066 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 20:53:17.433 LabApp] Copying avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb to /avgn_paper/notebooks/6.0-neural-networks
[W 20:53:19.692 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 20.82ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-Copy1.ipynb
[I 20:53:20.033 LabApp] Kernel started: 548a1f23-9561-4b3f-9bf8-28e403821af7
[W 20:53:20.266 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 2.83ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-Copy1.ipynb
[I 20:53:21.170 LabApp] Adapting from protocol version 5.1 (kernel 548a1f23-9561-4b3f-9bf8-28e403821af7) to 5.3 (client).
[I 20:54:40.118 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-Copy1.ipynb
[I 20:54:53.001 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-Copy1.ipynb
[I 20:55:01.644 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-Copy1.ipynb
[I 20:55:06.445 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
2019-10-21 20:55:14.827860: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-21 20:55:14.856533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-21 20:55:14.857671: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-21 20:55:14.859230: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 2 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
2019-10-21 20:55:14.860630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 3 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-21 20:55:14.861526: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-21 20:55:14.864640: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-21 20:55:14.866977: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-21 20:55:14.867985: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-21 20:55:14.871075: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-21 20:55:14.873562: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-21 20:55:14.879179: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-21 20:55:14.888715: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1, 2, 3
2019-10-21 20:55:15.427530: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c22d188ae0 executing computations on platform CUDA. Devices:
2019-10-21 20:55:15.427606: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-21 20:55:15.427619: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (1): TITAN Xp, Compute Capability 6.1
2019-10-21 20:55:15.427629: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (2): Tesla K40c, Compute Capability 3.5
2019-10-21 20:55:15.427639: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (3): Tesla K40c, Compute Capability 3.5
2019-10-21 20:55:15.433152: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-21 20:55:15.435313: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c22d9f5150 executing computations on platform Host. Devices:
2019-10-21 20:55:15.435364: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-21 20:55:15.437406: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-21 20:55:15.438580: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-21 20:55:15.439997: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 2 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
2019-10-21 20:55:15.441125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 3 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-21 20:55:15.441206: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-21 20:55:15.441246: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-21 20:55:15.441283: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-21 20:55:15.441320: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-21 20:55:15.441357: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-21 20:55:15.441394: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-21 20:55:15.441432: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-21 20:55:15.448873: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1, 2, 3
2019-10-21 20:55:15.448957: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-21 20:55:15.454172: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-21 20:55:15.454201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 1 2 3 
2019-10-21 20:55:15.454217: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N Y N N 
2019-10-21 20:55:15.454230: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 1:   Y N N N 
2019-10-21 20:55:15.454243: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 2:   N N N Y 
2019-10-21 20:55:15.454255: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 3:   N N Y N 
2019-10-21 20:55:15.459110: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 195 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-21 20:55:15.460141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 64 MB memory) -> physical GPU (device: 1, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-21 20:55:15.461386: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 10658 MB memory) -> physical GPU (device: 2, name: Tesla K40c, pci bus id: 0000:02:00.0, compute capability: 3.5)
2019-10-21 20:55:15.462619: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 10658 MB memory) -> physical GPU (device: 3, name: Tesla K40c, pci bus id: 0000:03:00.0, compute capability: 3.5)
[I 20:55:20.230 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
2019-10-21 20:55:27.635708: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 195.75M (205258752 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2019-10-21 20:55:27.741203: F ./tensorflow/core/kernels/random_op_gpu.h:227] Non-OK-status: GpuLaunchKernel(FillPhiloxRandomKernelLaunch<Distribution>, num_blocks, block_size, 0, d.stream(), gen, data, size, dist) status: Internal: out of memory
[I 20:55:32.031 LabApp] KernelRestarter: restarting kernel (1/5), keep random ports
kernel 548a1f23-9561-4b3f-9bf8-28e403821af7 restarted
[I 20:55:46.000 LabApp] Starting buffering for b41395eb-52e2-4a6a-bda4-d3ea858d5ff5:cdde91beb9a84e34acb57a3d99340dd1
[I 20:55:48.119 LabApp] Kernel restarted: b41395eb-52e2-4a6a-bda4-d3ea858d5ff5
[I 20:55:49.111 LabApp] Adapting from protocol version 5.1 (kernel b41395eb-52e2-4a6a-bda4-d3ea858d5ff5) to 5.3 (client).
[I 20:55:49.112 LabApp] Restoring connection for b41395eb-52e2-4a6a-bda4-d3ea858d5ff5:cdde91beb9a84e34acb57a3d99340dd1
[I 20:55:49.112 LabApp] Replaying 7 buffered messages
[I 20:56:14.951 LabApp] KernelRestarter: restarting kernel (1/5), keep random ports
kernel 18eabf2b-2c7e-44ff-93f7-53f289fada24 restarted
2019-10-21 20:56:25.750998: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
[I 20:56:28.669 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
2019-10-21 20:56:30.694807: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-21 20:56:30.695743: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-21 20:56:30.697859: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-21 20:56:30.699426: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-21 20:56:30.700121: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-21 20:56:30.702161: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-21 20:56:30.703855: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-21 20:56:30.707654: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-21 20:56:30.709357: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-21 20:56:30.919913: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55eb49ca10f0 executing computations on platform CUDA. Devices:
2019-10-21 20:56:30.919979: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-21 20:56:30.923736: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-21 20:56:30.925410: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55eb49d77ba0 executing computations on platform Host. Devices:
2019-10-21 20:56:30.925466: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-21 20:56:30.926289: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-21 20:56:30.926372: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-21 20:56:30.926412: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-21 20:56:30.926449: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-21 20:56:30.926487: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-21 20:56:30.926524: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-21 20:56:30.926562: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-21 20:56:30.926600: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-21 20:56:30.928035: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-21 20:56:30.928102: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-21 20:56:30.929999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-21 20:56:30.930019: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-21 20:56:30.930031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-21 20:56:30.931800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-21 20:56:56.200305: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-21 20:56:56.411707: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 20:57:14.511 LabApp] Starting buffering for 548a1f23-9561-4b3f-9bf8-28e403821af7:ca1e4ec89d7949638b5c15eaed06829b
[I 20:57:16.429 LabApp] Kernel restarted: 548a1f23-9561-4b3f-9bf8-28e403821af7
[I 20:57:17.485 LabApp] Adapting from protocol version 5.1 (kernel 548a1f23-9561-4b3f-9bf8-28e403821af7) to 5.3 (client).
[I 20:57:17.486 LabApp] Restoring connection for 548a1f23-9561-4b3f-9bf8-28e403821af7:ca1e4ec89d7949638b5c15eaed06829b
[I 20:57:17.486 LabApp] Replaying 6 buffered messages
[I 20:57:20.049 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
2019-10-21 20:57:23.456399: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-21 20:57:29.322261: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-21 20:57:29.322995: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-21 20:57:29.324997: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-21 20:57:29.326200: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-21 20:57:29.326646: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-21 20:57:29.328329: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-21 20:57:29.329692: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-21 20:57:29.333077: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-21 20:57:29.334698: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-21 20:57:29.528407: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5615a95c01a0 executing computations on platform CUDA. Devices:
2019-10-21 20:57:29.528468: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-21 20:57:29.531854: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-21 20:57:29.532958: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5615a9696c50 executing computations on platform Host. Devices:
2019-10-21 20:57:29.532986: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-21 20:57:29.533894: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-21 20:57:29.533984: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-21 20:57:29.534027: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-21 20:57:29.534068: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-21 20:57:29.534109: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-21 20:57:29.534149: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-21 20:57:29.534190: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-21 20:57:29.534231: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-21 20:57:29.535704: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-21 20:57:29.535772: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-21 20:57:29.538453: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-21 20:57:29.538491: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-21 20:57:29.538511: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-21 20:57:29.541469: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-21 20:57:31.755371: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-21 20:57:31.964694: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 20:59:21.313 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 21:01:20.361 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 21:01:54.637 LabApp] Kernel interrupted: 548a1f23-9561-4b3f-9bf8-28e403821af7
[I 21:02:02.293 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 21:03:20.428 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 21:05:20.544 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 21:07:20.351 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 21:09:20.372 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 21:09:55.387 LabApp] Starting buffering for 548a1f23-9561-4b3f-9bf8-28e403821af7:ca1e4ec89d7949638b5c15eaed06829b
[I 21:09:57.907 LabApp] Kernel restarted: 548a1f23-9561-4b3f-9bf8-28e403821af7
[I 21:09:59.068 LabApp] Adapting from protocol version 5.1 (kernel 548a1f23-9561-4b3f-9bf8-28e403821af7) to 5.3 (client).
[I 21:09:59.069 LabApp] Restoring connection for 548a1f23-9561-4b3f-9bf8-28e403821af7:ca1e4ec89d7949638b5c15eaed06829b
[I 21:09:59.069 LabApp] Replaying 7 buffered messages
[I 21:10:01.226 LabApp] Kernel interrupted: 548a1f23-9561-4b3f-9bf8-28e403821af7
[I 21:10:01.876 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 21:10:04.573 LabApp] Starting buffering for 548a1f23-9561-4b3f-9bf8-28e403821af7:ca1e4ec89d7949638b5c15eaed06829b
[I 21:10:05.085 LabApp] Kernel restarted: 548a1f23-9561-4b3f-9bf8-28e403821af7
[I 21:10:06.001 LabApp] Adapting from protocol version 5.1 (kernel 548a1f23-9561-4b3f-9bf8-28e403821af7) to 5.3 (client).
[I 21:10:06.002 LabApp] Restoring connection for 548a1f23-9561-4b3f-9bf8-28e403821af7:ca1e4ec89d7949638b5c15eaed06829b
[I 21:10:06.002 LabApp] Replaying 6 buffered messages
2019-10-21 21:10:13.124922: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-21 21:10:17.557265: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-21 21:10:17.558234: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-21 21:10:17.560297: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-21 21:10:17.561780: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-21 21:10:17.562457: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-21 21:10:17.564463: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-21 21:10:17.566156: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-21 21:10:17.569803: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-21 21:10:17.571512: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-21 21:10:17.772260: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a1ee7b8680 executing computations on platform CUDA. Devices:
2019-10-21 21:10:17.772330: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-21 21:10:17.776091: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-21 21:10:17.777221: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a1ee88f150 executing computations on platform Host. Devices:
2019-10-21 21:10:17.777252: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-21 21:10:17.778124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-21 21:10:17.778224: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-21 21:10:17.778267: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-21 21:10:17.778320: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-21 21:10:17.778362: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-21 21:10:17.778403: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-21 21:10:17.778444: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-21 21:10:17.778485: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-21 21:10:17.780007: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-21 21:10:17.780076: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-21 21:10:17.782116: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-21 21:10:17.782136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-21 21:10:17.782147: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-21 21:10:17.784031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-21 21:10:19.841744: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-21 21:10:20.060346: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 21:11:20.163 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 21:11:33.456 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 21:11:45.267 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 21:11:47.884 LabApp] Kernel interrupted: 548a1f23-9561-4b3f-9bf8-28e403821af7
[I 21:11:48.724 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 21:12:06.098 LabApp] Starting buffering for 548a1f23-9561-4b3f-9bf8-28e403821af7:ca1e4ec89d7949638b5c15eaed06829b
[I 21:12:08.218 LabApp] Kernel restarted: 548a1f23-9561-4b3f-9bf8-28e403821af7
[I 21:12:09.154 LabApp] Adapting from protocol version 5.1 (kernel 548a1f23-9561-4b3f-9bf8-28e403821af7) to 5.3 (client).
[I 21:12:09.156 LabApp] Restoring connection for 548a1f23-9561-4b3f-9bf8-28e403821af7:ca1e4ec89d7949638b5c15eaed06829b
[I 21:12:09.157 LabApp] Replaying 6 buffered messages
2019-10-21 21:12:16.293876: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-21 21:12:20.806041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-21 21:12:20.806966: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-21 21:12:20.809187: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-21 21:12:20.810803: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-21 21:12:20.811476: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-21 21:12:20.813579: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-21 21:12:20.815419: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-21 21:12:20.819318: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-21 21:12:20.820849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-21 21:12:21.086926: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e124be0e60 executing computations on platform CUDA. Devices:
2019-10-21 21:12:21.086985: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-21 21:12:21.090422: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-21 21:12:21.091556: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e124cb78f0 executing computations on platform Host. Devices:
2019-10-21 21:12:21.091581: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-21 21:12:21.092405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-21 21:12:21.092486: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-21 21:12:21.092526: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-21 21:12:21.092563: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-21 21:12:21.092600: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-21 21:12:21.092637: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-21 21:12:21.092674: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-21 21:12:21.092712: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-21 21:12:21.094246: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-21 21:12:21.094309: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-21 21:12:21.096201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-21 21:12:21.096222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-21 21:12:21.096233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-21 21:12:21.097992: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-21 21:12:23.285762: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-21 21:12:23.498762: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 21:13:20.338 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 21:13:41.629 LabApp] Kernel interrupted: 548a1f23-9561-4b3f-9bf8-28e403821af7
[I 21:14:33.710 LabApp] Kernel interrupted: 548a1f23-9561-4b3f-9bf8-28e403821af7
[I 21:15:20.519 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 21:15:25.531 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 21:17:00.334 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 21:17:00.814 LabApp] Kernel interrupted: 548a1f23-9561-4b3f-9bf8-28e403821af7
[I 21:17:20.553 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 21:18:58.985 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 21:18:59.685 LabApp] Kernel interrupted: 548a1f23-9561-4b3f-9bf8-28e403821af7
[I 21:19:04.703 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 21:19:06.418 LabApp] Starting buffering for 548a1f23-9561-4b3f-9bf8-28e403821af7:ca1e4ec89d7949638b5c15eaed06829b
[I 21:19:08.433 LabApp] Kernel restarted: 548a1f23-9561-4b3f-9bf8-28e403821af7
[I 21:19:09.574 LabApp] Adapting from protocol version 5.1 (kernel 548a1f23-9561-4b3f-9bf8-28e403821af7) to 5.3 (client).
[I 21:19:09.575 LabApp] Restoring connection for 548a1f23-9561-4b3f-9bf8-28e403821af7:ca1e4ec89d7949638b5c15eaed06829b
[I 21:19:09.575 LabApp] Replaying 6 buffered messages
2019-10-21 21:19:17.811053: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
[I 21:19:20.047 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
2019-10-21 21:19:23.588994: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-21 21:19:23.589893: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-21 21:19:23.592126: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-21 21:19:23.593567: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-21 21:19:23.594166: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-21 21:19:23.596037: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-21 21:19:23.597622: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-21 21:19:23.600967: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-21 21:19:23.602547: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-21 21:19:23.823927: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b444b3cbd0 executing computations on platform CUDA. Devices:
2019-10-21 21:19:23.823987: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-21 21:19:23.827406: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-21 21:19:23.828569: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b444c13660 executing computations on platform Host. Devices:
2019-10-21 21:19:23.828598: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-21 21:19:23.829462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-21 21:19:23.829540: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-21 21:19:23.829580: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-21 21:19:23.829617: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-21 21:19:23.829655: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-21 21:19:23.829692: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-21 21:19:23.829730: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-21 21:19:23.829781: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-21 21:19:23.831213: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-21 21:19:23.831284: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-21 21:19:23.835038: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-21 21:19:23.835081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-21 21:19:23.835120: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-21 21:19:23.839565: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-21 21:19:25.860852: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-21 21:19:26.045867: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 21:20:22.275 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 21:20:23.616 LabApp] Kernel interrupted: 548a1f23-9561-4b3f-9bf8-28e403821af7
[I 21:21:21.098 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 21:21:30.724 LabApp] 302 GET /notebooks/avgn_paper (::1) 1.32ms
[W 21:21:31.663 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 2.11ms referer=http://localhost:8187/tree/avgn_paper
[W 21:22:00.892 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 1.62ms referer=http://localhost:8187/tree/avgn_paper/notebooks/2.0-make-syllable_df
[W 21:22:10.422 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 2.17ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/2.0-make-syllable_df/make-beaked-whale-click-dataset.ipynb
[I 21:22:11.720 LabApp] Kernel started: 15dca1e2-311b-40a6-8455-274ab82f472d
[I 21:22:12.768 LabApp] Adapting from protocol version 5.1 (kernel 15dca1e2-311b-40a6-8455-274ab82f472d) to 5.3 (client).
[W 21:22:15.833 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/hidebrand_beaked_whale-umap.ipynb is not trusted
[W 21:22:15.863 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.50ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/2.0-project-UMAP/hidebrand_beaked_whale-umap.ipynb
[I 21:22:16.283 LabApp] Kernel started: 737b3e2e-60ed-44d5-a20a-c7c4a02ed91a
[W 21:22:16.357 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 3.19ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/2.0-project-UMAP/hidebrand_beaked_whale-umap.ipynb
[I 21:22:17.128 LabApp] Adapting from protocol version 5.1 (kernel 737b3e2e-60ed-44d5-a20a-c7c4a02ed91a) to 5.3 (client).
[I 21:22:45.071 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/hidebrand_beaked_whale-umap.ipynb
[W 21:22:45.072 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/hidebrand_beaked_whale-umap.ipynb is not trusted
[I 21:22:52.614 LabApp] Starting buffering for 737b3e2e-60ed-44d5-a20a-c7c4a02ed91a:167e9319a6924455bf18121d125486d5
[I 21:22:53.042 LabApp] Kernel restarted: 737b3e2e-60ed-44d5-a20a-c7c4a02ed91a
[I 21:22:53.958 LabApp] Adapting from protocol version 5.1 (kernel 737b3e2e-60ed-44d5-a20a-c7c4a02ed91a) to 5.3 (client).
[I 21:22:53.959 LabApp] Restoring connection for 737b3e2e-60ed-44d5-a20a-c7c4a02ed91a:167e9319a6924455bf18121d125486d5
[I 21:22:53.959 LabApp] Replaying 6 buffered messages
[W 21:23:01.884 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/NA-birds-syllable-umap.ipynb is not trusted
[W 21:23:01.911 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 2.31ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/2.0-project-UMAP/NA-birds-syllable-umap.ipynb
[I 21:23:02.427 LabApp] Kernel started: aaac4ddf-99c2-4d66-83ad-ef06f18a778b
[W 21:23:02.479 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 2.24ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/2.0-project-UMAP/NA-birds-syllable-umap.ipynb
[I 21:23:03.370 LabApp] Adapting from protocol version 5.1 (kernel aaac4ddf-99c2-4d66-83ad-ef06f18a778b) to 5.3 (client).
[I 21:23:13.691 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/NA-birds-syllable-umap.ipynb
[W 21:23:13.692 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/NA-birds-syllable-umap.ipynb is not trusted
[I 21:23:17.969 LabApp] Starting buffering for aaac4ddf-99c2-4d66-83ad-ef06f18a778b:5ac515b897384d49807b4fb891ac6ace
[I 21:23:18.386 LabApp] Kernel restarted: aaac4ddf-99c2-4d66-83ad-ef06f18a778b
[I 21:23:19.517 LabApp] Adapting from protocol version 5.1 (kernel aaac4ddf-99c2-4d66-83ad-ef06f18a778b) to 5.3 (client).
[I 21:23:19.518 LabApp] Restoring connection for aaac4ddf-99c2-4d66-83ad-ef06f18a778b:5ac515b897384d49807b4fb891ac6ace
[I 21:23:19.518 LabApp] Replaying 6 buffered messages
[I 21:23:21.291 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 21:24:17.662 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/hidebrand_beaked_whale-umap.ipynb
[I 21:24:21.594 LabApp] Saving file at /avgn_paper/notebooks/2.0-make-syllable_df/make-beaked-whale-click-dataset.ipynb
[I 21:25:02.976 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/NA-birds-syllable-umap.ipynb
[I 21:25:21.149 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 21:26:17.585 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/hidebrand_beaked_whale-umap.ipynb
[I 21:27:03.464 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/NA-birds-syllable-umap.ipynb
[I 21:27:22.273 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 21:29:21.616 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 21:31:21.171 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 21:31:32.871 LabApp] Kernel interrupted: 548a1f23-9561-4b3f-9bf8-28e403821af7
[I 21:31:38.801 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 21:31:44.784 LabApp] Starting buffering for 548a1f23-9561-4b3f-9bf8-28e403821af7:ca1e4ec89d7949638b5c15eaed06829b
[I 21:31:46.702 LabApp] Kernel restarted: 548a1f23-9561-4b3f-9bf8-28e403821af7
[I 21:31:47.811 LabApp] Adapting from protocol version 5.1 (kernel 548a1f23-9561-4b3f-9bf8-28e403821af7) to 5.3 (client).
[I 21:31:47.812 LabApp] Restoring connection for 548a1f23-9561-4b3f-9bf8-28e403821af7:ca1e4ec89d7949638b5c15eaed06829b
[I 21:31:47.812 LabApp] Replaying 8 buffered messages
2019-10-21 21:31:55.557864: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-21 21:32:02.007271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-21 21:32:02.008197: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-21 21:32:02.010322: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-21 21:32:02.011709: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-21 21:32:02.012346: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-21 21:32:02.014154: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-21 21:32:02.015757: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-21 21:32:02.019058: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-21 21:32:02.021818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-21 21:32:02.237690: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555b84e7d290 executing computations on platform CUDA. Devices:
2019-10-21 21:32:02.237748: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-21 21:32:02.241161: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-21 21:32:02.242262: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555b84f53d20 executing computations on platform Host. Devices:
2019-10-21 21:32:02.242290: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-21 21:32:02.243137: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-21 21:32:02.243224: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-21 21:32:02.243264: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-21 21:32:02.243301: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-21 21:32:02.243338: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-21 21:32:02.243375: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-21 21:32:02.243420: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-21 21:32:02.243466: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-21 21:32:02.244888: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-21 21:32:02.244953: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-21 21:32:02.248536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-21 21:32:02.248582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-21 21:32:02.248604: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-21 21:32:02.251651: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
[I 21:32:03.188 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
2019-10-21 21:32:04.232381: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-21 21:32:04.437871: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 21:32:09.962 LabApp] Starting buffering for aaac4ddf-99c2-4d66-83ad-ef06f18a778b:5ac515b897384d49807b4fb891ac6ace
[I 21:32:10.596 LabApp] Starting buffering for 737b3e2e-60ed-44d5-a20a-c7c4a02ed91a:167e9319a6924455bf18121d125486d5
[I 21:32:12.819 LabApp] Starting buffering for 15dca1e2-311b-40a6-8455-274ab82f472d:530e61494a5145cf93ae50a4c5add245
[I 21:33:20.461 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 21:34:20.273 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 21:34:31.872 LabApp] Kernel interrupted: 548a1f23-9561-4b3f-9bf8-28e403821af7
[W 21:35:06.075 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 1.90ms referer=http://localhost:8187/tree/avgn_paper/figures/barcode/bengalese_finch_sober
[I 21:35:21.025 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 21:35:21.990 LabApp] Starting buffering for b41395eb-52e2-4a6a-bda4-d3ea858d5ff5:cdde91beb9a84e34acb57a3d99340dd1
[I 21:35:29.620 LabApp] Starting buffering for 18eabf2b-2c7e-44ff-93f7-53f289fada24:ee544d1b2a4842c5a5fbb14358bbddc1
[I 21:35:30.893 LabApp] Starting buffering for a62ba8c7-71ba-48f9-8581-aee04b99949f:c629f0b0f4dd427ba70451311890cc80
[I 21:35:31.632 LabApp] Starting buffering for b0d6db59-8f03-4124-99a3-ab6c5a0f8d31:da6d03b0077040b9875452e3fec3a0d0
[I 21:35:39.293 LabApp] 302 GET /notebooks/avgn_paper/notebooks (::1) 1.52ms
[W 21:35:39.858 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 1.83ms referer=http://localhost:8187/tree/avgn_paper/notebooks
[I 21:35:49.520 LabApp] Copying avgn_paper/notebooks/5.0-visualize-transitions/bf-sober-transitions-barcode.ipynb to /avgn_paper/notebooks/5.0-visualize-transitions
[W 21:35:53.424 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 2.30ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/bf-sober-transitions-barcode-Copy1.ipynb
[I 21:35:56.011 LabApp] Kernel started: f4cb2bac-28c3-4830-b001-be6be3f23c36
[I 21:35:57.073 LabApp] Adapting from protocol version 5.1 (kernel f4cb2bac-28c3-4830-b001-be6be3f23c36) to 5.3 (client).
[W 21:36:10.990 LabApp] Notebook avgn_paper/notebooks/2.0-project-UMAP/starling-syllable-umap.ipynb is not trusted
[W 21:36:12.277 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.01ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/2.0-project-UMAP/starling-syllable-umap.ipynb
[I 21:36:12.551 LabApp] Kernel started: 78035f26-95be-4e04-82aa-a7cc1f959e7a
[W 21:36:12.563 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 2.32ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/2.0-project-UMAP/starling-umap.ipynb
[W 21:36:13.068 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 2.75ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/2.0-project-UMAP/starling-umap.ipynb
[I 21:36:13.501 LabApp] Adapting from protocol version 5.1 (kernel 78035f26-95be-4e04-82aa-a7cc1f959e7a) to 5.3 (client).
[I 21:36:14.564 LabApp] Kernel started: a2c77d6b-ee8a-46ce-b107-091963dc16ee
[I 21:36:15.472 LabApp] Adapting from protocol version 5.1 (kernel a2c77d6b-ee8a-46ce-b107-091963dc16ee) to 5.3 (client).
[I 21:36:35.124 LabApp] Uploading file to /avgn_paper/notebooks/5.0-visualize-transitions/bf-sober-transitions-barcode-Copy1.ipynb
[I 21:36:42.689 LabApp] Starting buffering for 78035f26-95be-4e04-82aa-a7cc1f959e7a:e3f9de48750a4c89bb12edb621c8be13
[I 21:36:44.571 LabApp] Starting buffering for a2c77d6b-ee8a-46ce-b107-091963dc16ee:8d71b1b0bd88410f8c8fdeb49c0eb3a5
[W 21:36:56.615 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 4.26ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/transitions-bengalese-finch-sober-with-dendrogram.ipynb
[I 21:36:57.221 LabApp] Kernel started: a64a2193-19ce-4f69-9641-e19bc2fee84d
[W 21:36:57.457 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 2.10ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/transitions-bengalese-finch-sober-with-dendrogram.ipynb
[I 21:36:58.256 LabApp] Adapting from protocol version 5.1 (kernel a64a2193-19ce-4f69-9641-e19bc2fee84d) to 5.3 (client).
[I 21:36:59.889 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/transitions-bengalese-finch-sober-with-dendrogram.ipynb
[I 21:37:00.663 LabApp] Copying avgn_paper/notebooks/5.0-visualize-transitions/transitions-bengalese-finch-sober-with-dendrogram.ipynb to /avgn_paper/notebooks/5.0-visualize-transitions
[I 21:37:01.956 LabApp] Starting buffering for a64a2193-19ce-4f69-9641-e19bc2fee84d:2a255c9c99484b6e905fb9b6d6cfc86d
[W 21:37:02.337 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.50ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/transitions-bengalese-finch-sober-with-dendrogram-Copy1.ipynb
[I 21:37:02.859 LabApp] Kernel started: 1a299ce2-5104-456b-ac5b-02c132cf99a5
[W 21:37:03.007 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 4.12ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/transitions-bengalese-finch-sober-with-dendrogram-Copy1.ipynb
[I 21:37:03.728 LabApp] Adapting from protocol version 5.1 (kernel 1a299ce2-5104-456b-ac5b-02c132cf99a5) to 5.3 (client).
[I 21:37:21.168 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
2019-10-21 21:37:36.351204: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-21 21:37:40.087824: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-10-21 21:37:40.087928: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: txori
2019-10-21 21:37:40.087944: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: txori
2019-10-21 21:37:40.088109: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.79.0
2019-10-21 21:37:40.088171: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 410.79.0
2019-10-21 21:37:40.088185: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 410.79.0
2019-10-21 21:37:40.129373: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-21 21:37:40.130860: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e2ded97960 executing computations on platform Host. Devices:
2019-10-21 21:37:40.130923: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
[I 21:38:50.297 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/transitions-starling-add-umap-hdbscan.ipynb
[I 21:38:52.450 LabApp] Kernel interrupted: 1a299ce2-5104-456b-ac5b-02c132cf99a5
[I 21:39:03.000 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/transitions-starling-add-umap-hdbscan.ipynb
[I 21:39:05.099 LabApp] Kernel interrupted: 1a299ce2-5104-456b-ac5b-02c132cf99a5
[I 21:39:15.278 LabApp] Starting buffering for 1a299ce2-5104-456b-ac5b-02c132cf99a5:3e6e2384f2ba429088ce8432e4064595
[I 21:39:16.897 LabApp] Kernel restarted: 1a299ce2-5104-456b-ac5b-02c132cf99a5
[I 21:39:17.979 LabApp] Adapting from protocol version 5.1 (kernel 1a299ce2-5104-456b-ac5b-02c132cf99a5) to 5.3 (client).
[I 21:39:17.980 LabApp] Restoring connection for 1a299ce2-5104-456b-ac5b-02c132cf99a5:3e6e2384f2ba429088ce8432e4064595
[I 21:39:17.980 LabApp] Replaying 7 buffered messages
[I 21:39:21.558 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 21:39:32.107 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/transitions-starling-add-umap-hdbscan.ipynb
2019-10-21 21:39:32.618389: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-21 21:39:37.394245: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-10-21 21:39:37.394394: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: txori
2019-10-21 21:39:37.406679: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: txori
2019-10-21 21:39:37.406920: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.79.0
2019-10-21 21:39:37.406991: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 410.79.0
2019-10-21 21:39:37.407004: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 410.79.0
2019-10-21 21:39:37.438266: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-21 21:39:37.439367: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c61bb67360 executing computations on platform Host. Devices:
2019-10-21 21:39:37.439395: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
[I 21:41:02.966 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/transitions-starling-add-umap-hdbscan.ipynb
[I 21:41:21.563 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[W 21:41:42.688 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 4.85ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/mouse-usv-PCA-projections.ipynb
[I 21:41:43.073 LabApp] Adapting from protocol version 5.1 (kernel 567f8b1e-f0e6-44ce-aaf6-0db2311add48) to 5.3 (client).
[W 21:41:43.093 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 1.53ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/mouse-usv-PCA-projections.ipynb
[I 21:42:37.866 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/mouse-usv-PCA-projections.ipynb
[I 21:42:38.144 LabApp] Copying avgn_paper/notebooks/5.0-visualize-transitions/mouse-usv-PCA-projections.ipynb to /avgn_paper/notebooks/5.0-visualize-transitions
[I 21:42:40.211 LabApp] Kernel started: cdb62f00-42fe-47a1-88ee-60ee589c4fad
[W 21:42:40.699 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.16ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/mouse-usv-PCA-projections-Copy1.ipynb
[I 21:42:41.242 LabApp] Adapting from protocol version 5.1 (kernel cdb62f00-42fe-47a1-88ee-60ee589c4fad) to 5.3 (client).
[W 21:42:50.871 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 5.55ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/transitions-bengalese-finch-sober-with-dendrogram.ipynb
[I 21:42:51.798 LabApp] Adapting from protocol version 5.1 (kernel a64a2193-19ce-4f69-9641-e19bc2fee84d) to 5.3 (client).
[W 21:42:52.566 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 2.00ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/transitions-bengalese-finch-sober-with-dendrogram.ipynb
[I 21:43:02.912 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/transitions-starling-add-umap-hdbscan.ipynb
[I 21:43:21.133 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
2019-10-21 21:43:31.528948: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-21 21:43:35.541163: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-10-21 21:43:35.541251: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: txori
2019-10-21 21:43:35.541264: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: txori
2019-10-21 21:43:35.541670: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.79.0
2019-10-21 21:43:35.541739: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 410.79.0
2019-10-21 21:43:35.541754: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 410.79.0
2019-10-21 21:43:35.572857: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-21 21:43:35.574047: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562471614020 executing computations on platform Host. Devices:
2019-10-21 21:43:35.574073: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
[I 21:44:40.249 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 21:44:53.275 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/transitions-bengalese-finch-sober-with-dendrogram.ipynb
[I 21:45:04.201 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/transitions-starling-add-umap-hdbscan.ipynb
[I 21:45:21.178 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 21:46:40.240 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 21:47:03.690 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/transitions-starling-add-umap-hdbscan.ipynb
[I 21:47:21.291 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 21:48:40.263 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 21:49:03.815 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/transitions-starling-add-umap-hdbscan.ipynb
[I 21:49:21.705 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 21:50:41.310 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 21:51:21.799 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 21:52:41.853 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 21:53:21.281 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 21:53:55.348 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 21:53:57.911 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 21:54:41.325 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 21:55:21.979 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 21:56:41.368 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 21:57:21.354 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 21:58:41.185 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 21:59:21.118 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 22:00:41.674 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 22:01:21.160 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 22:02:06.619 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-transitions-barcode.ipynb
[I 22:02:41.213 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 22:03:21.186 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 22:03:43.419 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 22:03:47.171 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 22:04:17.183 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-transitions-barcode.ipynb
[I 22:05:21.169 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 22:06:41.569 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 22:07:46.676 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-transitions-barcode.ipynb
[I 22:08:41.799 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 22:09:21.434 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 22:10:36.596 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-transitions-barcode.ipynb
[I 22:10:42.330 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 22:11:21.237 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 22:12:42.401 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 22:13:21.164 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 22:13:26.609 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-transitions-barcode.ipynb
[I 22:14:43.249 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 22:15:21.336 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 22:16:16.655 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-transitions-barcode.ipynb
[I 22:16:43.230 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 22:17:21.523 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
2019-10-21 22:18:27.457054: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-21 22:18:31.923458: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-10-21 22:18:31.923576: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: txori
2019-10-21 22:18:31.923593: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: txori
2019-10-21 22:18:31.923761: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.79.0
2019-10-21 22:18:31.923819: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 410.79.0
2019-10-21 22:18:31.923833: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 410.79.0
2019-10-21 22:18:32.066611: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-21 22:18:32.068292: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562de5120e50 executing computations on platform Host. Devices:
2019-10-21 22:18:32.068357: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
[I 22:18:43.496 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 22:19:08.611 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-transitions-barcode.ipynb
[I 22:19:21.193 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 22:20:33.939 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 22:21:21.160 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 22:22:05.919 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-transitions-barcode.ipynb
[I 22:22:44.139 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 22:23:21.205 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 22:24:43.250 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 22:24:58.827 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-transitions-barcode.ipynb
[I 22:25:21.133 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 22:26:43.552 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 22:27:21.210 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 22:27:56.120 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-transitions-barcode.ipynb
[I 22:28:43.338 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 22:29:21.160 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 22:30:43.298 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 22:31:21.297 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 22:32:43.698 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 22:33:03.351 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/transitions-starling-add-umap-hdbscan.ipynb
[I 22:33:08.497 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/transitions-starling-add-umap-hdbscan.ipynb
[I 22:33:11.573 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/transitions-starling-add-umap-hdbscan.ipynb
[I 22:33:21.205 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 22:33:21.666 LabApp] Starting buffering for 1a299ce2-5104-456b-ac5b-02c132cf99a5:3e6e2384f2ba429088ce8432e4064595
[I 22:33:23.488 LabApp] Kernel restarted: 1a299ce2-5104-456b-ac5b-02c132cf99a5
[I 22:33:24.530 LabApp] Adapting from protocol version 5.1 (kernel 1a299ce2-5104-456b-ac5b-02c132cf99a5) to 5.3 (client).
[I 22:33:24.531 LabApp] Restoring connection for 1a299ce2-5104-456b-ac5b-02c132cf99a5:3e6e2384f2ba429088ce8432e4064595
[I 22:33:24.531 LabApp] Replaying 6 buffered messages
2019-10-21 22:33:39.142919: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-21 22:33:43.532561: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-10-21 22:33:43.532672: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: txori
2019-10-21 22:33:43.532694: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: txori
2019-10-21 22:33:43.532849: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.79.0
2019-10-21 22:33:43.532906: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 410.79.0
2019-10-21 22:33:43.532919: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 410.79.0
2019-10-21 22:33:43.563724: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-21 22:33:43.564596: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a08d348ee0 executing computations on platform Host. Devices:
2019-10-21 22:33:43.564620: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
[I 22:35:04.491 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/transitions-starling-add-umap-hdbscan.ipynb
[I 22:35:13.766 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-transitions-barcode.ipynb
[I 22:35:21.144 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 22:35:40.344 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-transitions-barcode.ipynb
[I 22:36:10.450 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-transitions-barcode.ipynb
[I 22:36:51.042 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-transitions-barcode.ipynb
[I 22:37:04.321 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/transitions-starling-add-umap-hdbscan.ipynb
[I 22:37:05.347 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-transitions-barcode.ipynb
[I 22:37:18.681 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-transitions-barcode.ipynb
[I 22:37:22.961 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 22:37:38.914 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-transitions-barcode.ipynb
[I 22:37:40.082 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-transitions-barcode.ipynb
[I 22:37:47.711 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-transitions-barcode.ipynb
[W 22:37:53.617 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 2.07ms referer=http://localhost:8187/tree/avgn_paper/notebooks/6.0-neural-networks
[W 22:37:58.204 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 1.58ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 22:37:58.298 LabApp] Adapting from protocol version 5.1 (kernel b41395eb-52e2-4a6a-bda4-d3ea858d5ff5) to 5.3 (client).
[W 22:37:58.384 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 1.85ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 22:38:06.177 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 22:38:16.924 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 22:38:18.890 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 22:38:28.167 LabApp] Starting buffering for b41395eb-52e2-4a6a-bda4-d3ea858d5ff5:97db3f135c8548ca8220862debe111ad
[I 22:38:28.586 LabApp] Kernel restarted: b41395eb-52e2-4a6a-bda4-d3ea858d5ff5
[I 22:38:29.662 LabApp] Adapting from protocol version 5.1 (kernel b41395eb-52e2-4a6a-bda4-d3ea858d5ff5) to 5.3 (client).
[I 22:38:29.663 LabApp] Restoring connection for b41395eb-52e2-4a6a-bda4-d3ea858d5ff5:97db3f135c8548ca8220862debe111ad
[I 22:38:29.663 LabApp] Replaying 6 buffered messages
2019-10-21 22:38:36.002351: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-21 22:38:40.217379: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
2019-10-21 22:38:40.218134: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-21 22:38:40.219888: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-21 22:38:40.221286: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-21 22:38:40.221888: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-21 22:38:40.223696: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-21 22:38:40.225191: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-21 22:38:40.228507: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-21 22:38:40.230918: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-21 22:38:40.381309: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5607d0a18530 executing computations on platform CUDA. Devices:
2019-10-21 22:38:40.381370: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K40c, Compute Capability 3.5
2019-10-21 22:38:40.384417: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-21 22:38:40.385812: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5607d0aeefc0 executing computations on platform Host. Devices:
2019-10-21 22:38:40.385840: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-21 22:38:40.387026: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
2019-10-21 22:38:40.387126: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-21 22:38:40.387170: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-21 22:38:40.387213: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-21 22:38:40.387253: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-21 22:38:40.387295: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-21 22:38:40.387336: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-21 22:38:40.387380: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-21 22:38:40.389229: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-21 22:38:40.389294: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-21 22:38:40.391484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-21 22:38:40.391507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-21 22:38:40.391523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-21 22:38:40.394164: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10794 MB memory) -> physical GPU (device: 0, name: Tesla K40c, pci bus id: 0000:02:00.0, compute capability: 3.5)
2019-10-21 22:38:47.500300: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-21 22:38:48.191565: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 22:38:50.284 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 22:39:03.001 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/transitions-starling-add-umap-hdbscan.ipynb
[I 22:39:21.337 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 22:39:27.755 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 22:39:58.708 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 22:40:18.481 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 22:40:43.501 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 22:41:04.109 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/transitions-starling-add-umap-hdbscan.ipynb
[I 22:41:21.629 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 22:42:43.960 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 22:43:04.162 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/transitions-starling-add-umap-hdbscan.ipynb
[I 22:43:21.198 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 22:43:58.691 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 22:44:26.756 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/transitions-starling-add-umap-hdbscan.ipynb
[I 22:44:43.563 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 22:45:03.466 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/transitions-starling-add-umap-hdbscan.ipynb
[I 22:45:21.182 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 22:46:43.592 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 22:47:03.745 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/transitions-starling-add-umap-hdbscan.ipynb
[I 22:47:21.210 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 22:48:00.416 LabApp] Kernel interrupted: 1a299ce2-5104-456b-ac5b-02c132cf99a5
[I 22:48:04.764 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/transitions-starling-add-umap-hdbscan.ipynb
[I 22:49:04.983 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/transitions-starling-add-umap-hdbscan.ipynb
[I 22:49:21.607 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 22:50:53.138 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/transitions-starling-add-umap-hdbscan.ipynb
[I 22:51:21.154 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 22:52:46.272 LabApp] Starting buffering for f4cb2bac-28c3-4830-b001-be6be3f23c36:3a77ec59d2c944608a6688e975f52db5
[I 22:52:47.893 LabApp] Kernel restarted: f4cb2bac-28c3-4830-b001-be6be3f23c36
[I 22:52:48.865 LabApp] Adapting from protocol version 5.1 (kernel f4cb2bac-28c3-4830-b001-be6be3f23c36) to 5.3 (client).
[I 22:52:48.866 LabApp] Restoring connection for f4cb2bac-28c3-4830-b001-be6be3f23c36:3a77ec59d2c944608a6688e975f52db5
[I 22:52:48.866 LabApp] Replaying 6 buffered messages
[I 22:53:06.160 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/transitions-starling-add-umap-hdbscan.ipynb
[I 22:53:21.326 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 22:54:15.140 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 22:54:43.716 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 22:55:21.220 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 22:56:44.180 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 22:56:50.292 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 22:56:56.634 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 22:57:21.175 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 22:58:44.422 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 22:59:08.077 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 22:59:21.504 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 22:59:46.669 LabApp] Kernel interrupted: cdb62f00-42fe-47a1-88ee-60ee589c4fad
[I 22:59:47.587 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 22:59:52.612 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 23:00:00.054 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-transitions-barcode.ipynb
[I 23:00:47.019 LabApp] Kernel interrupted: cdb62f00-42fe-47a1-88ee-60ee589c4fad
[I 23:00:49.615 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 23:00:54.888 LabApp] Kernel interrupted: cdb62f00-42fe-47a1-88ee-60ee589c4fad
[I 23:00:55.538 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 23:00:59.351 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 23:01:20.935 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 23:01:21.473 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 23:01:31.798 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 23:02:06.227 LabApp] Copying avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb to /avgn_paper/notebooks/5.0-visualize-transitions
[I 23:02:10.382 LabApp] Kernel started: 38a56180-e126-4229-8295-7902ea0386cc
[W 23:02:10.472 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 2.51ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections-Copy1.ipynb
[I 23:02:11.452 LabApp] Adapting from protocol version 5.1 (kernel 38a56180-e126-4229-8295-7902ea0386cc) to 5.3 (client).
[I 23:02:20.207 LabApp] Starting buffering for cdb62f00-42fe-47a1-88ee-60ee589c4fad:69f67bf98e054e14a0ebebe149df079f
[I 23:02:20.230 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 23:02:25.952 LabApp] Kernel restarted: cdb62f00-42fe-47a1-88ee-60ee589c4fad
[I 23:02:27.202 LabApp] Adapting from protocol version 5.1 (kernel cdb62f00-42fe-47a1-88ee-60ee589c4fad) to 5.3 (client).
[I 23:02:27.203 LabApp] Restoring connection for cdb62f00-42fe-47a1-88ee-60ee589c4fad:69f67bf98e054e14a0ebebe149df079f
[I 23:02:27.203 LabApp] Replaying 3 buffered messages
[I 23:02:40.311 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 23:03:00.948 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 23:03:18.472 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
2019-10-21 23:03:19.946886: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-21 23:03:22.107785: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-10-21 23:03:22.107884: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: txori
2019-10-21 23:03:22.107905: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: txori
2019-10-21 23:03:22.108050: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.79.0
2019-10-21 23:03:22.108115: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 410.79.0
2019-10-21 23:03:22.108134: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 410.79.0
2019-10-21 23:03:22.202858: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-21 23:03:22.231314: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5560aa954c10 executing computations on platform Host. Devices:
2019-10-21 23:03:22.231354: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
[I 23:04:14.864 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections.ipynb
[I 23:04:42.017 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 23:05:21.349 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 23:06:02.198 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections.ipynb
[I 23:06:41.627 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 23:07:21.427 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
2019-10-21 23:07:38.981709: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-21 23:07:41.355276: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-10-21 23:07:41.355398: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: txori
2019-10-21 23:07:41.355420: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: txori
2019-10-21 23:07:41.355616: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.79.0
2019-10-21 23:07:41.355692: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 410.79.0
2019-10-21 23:07:41.355712: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 410.79.0
2019-10-21 23:07:41.528064: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-21 23:07:41.603321: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b81d94a020 executing computations on platform Host. Devices:
2019-10-21 23:07:41.603400: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
[I 23:08:14.537 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections.ipynb
[I 23:08:41.652 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 23:09:21.191 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 23:10:13.408 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections.ipynb
[I 23:10:40.395 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections.ipynb
[I 23:10:43.470 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
2019-10-21 23:11:02.278435: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-21 23:11:04.532607: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-10-21 23:11:04.532701: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: txori
2019-10-21 23:11:04.532715: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: txori
2019-10-21 23:11:04.532862: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.79.0
2019-10-21 23:11:04.532914: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 410.79.0
2019-10-21 23:11:04.532927: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 410.79.0
2019-10-21 23:11:04.606699: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-21 23:11:04.607811: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555d853bd690 executing computations on platform Host. Devices:
2019-10-21 23:11:04.607839: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
[I 23:11:11.432 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-transitions-barcode.ipynb
[I 23:11:21.219 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 23:12:14.578 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections.ipynb
[I 23:12:25.415 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections.ipynb
[I 23:12:26.169 LabApp] Kernel interrupted: 38a56180-e126-4229-8295-7902ea0386cc
[I 23:13:12.166 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections.ipynb
[I 23:13:21.222 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 23:14:14.605 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections.ipynb
[I 23:15:21.218 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 23:15:51.814 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 23:16:17.232 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections.ipynb
[I 23:17:21.232 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 23:18:14.152 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections.ipynb
[I 23:18:26.753 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections.ipynb
[I 23:18:41.437 LabApp] Kernel interrupted: cdb62f00-42fe-47a1-88ee-60ee589c4fad
[I 23:18:43.420 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 23:18:46.846 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 23:19:21.214 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 23:20:13.454 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections.ipynb
[I 23:21:21.241 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 23:22:13.371 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections.ipynb
[I 23:22:26.887 LabApp] Kernel interrupted: cdb62f00-42fe-47a1-88ee-60ee589c4fad
[I 23:22:30.464 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 23:22:38.476 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-transitions-barcode.ipynb
[I 23:22:52.728 LabApp] Kernel interrupted: cdb62f00-42fe-47a1-88ee-60ee589c4fad
[I 23:22:55.768 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 23:23:15.766 LabApp] Kernel interrupted: cdb62f00-42fe-47a1-88ee-60ee589c4fad
[I 23:23:19.095 LabApp] Kernel interrupted: cdb62f00-42fe-47a1-88ee-60ee589c4fad
[I 23:23:19.240 LabApp] Kernel interrupted: cdb62f00-42fe-47a1-88ee-60ee589c4fad
[I 23:23:19.335 LabApp] Kernel interrupted: cdb62f00-42fe-47a1-88ee-60ee589c4fad
[I 23:23:19.529 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 23:23:19.885 LabApp] Kernel interrupted: cdb62f00-42fe-47a1-88ee-60ee589c4fad
[I 23:23:19.888 LabApp] Kernel interrupted: cdb62f00-42fe-47a1-88ee-60ee589c4fad
[I 23:23:19.888 LabApp] Kernel interrupted: cdb62f00-42fe-47a1-88ee-60ee589c4fad
[I 23:23:19.891 LabApp] Kernel interrupted: cdb62f00-42fe-47a1-88ee-60ee589c4fad
[I 23:23:21.287 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 23:23:24.696 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 23:23:28.686 LabApp] Starting buffering for cdb62f00-42fe-47a1-88ee-60ee589c4fad:69f67bf98e054e14a0ebebe149df079f
[I 23:23:33.920 LabApp] Kernel restarted: cdb62f00-42fe-47a1-88ee-60ee589c4fad
[I 23:23:35.945 LabApp] Adapting from protocol version 5.1 (kernel cdb62f00-42fe-47a1-88ee-60ee589c4fad) to 5.3 (client).
[I 23:23:35.947 LabApp] Restoring connection for cdb62f00-42fe-47a1-88ee-60ee589c4fad:69f67bf98e054e14a0ebebe149df079f
[I 23:23:35.947 LabApp] Replaying 3 buffered messages
[I 23:23:43.246 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections.ipynb
[I 23:23:53.262 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections.ipynb
[I 23:23:59.008 LabApp] Kernel interrupted: 38a56180-e126-4229-8295-7902ea0386cc
2019-10-21 23:24:04.050242: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-21 23:24:06.136659: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-10-21 23:24:06.136726: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: txori
2019-10-21 23:24:06.136739: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: txori
2019-10-21 23:24:06.136863: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.79.0
2019-10-21 23:24:06.136911: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 410.79.0
2019-10-21 23:24:06.136924: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 410.79.0
2019-10-21 23:24:06.174618: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-21 23:24:06.175686: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f5e8d23890 executing computations on platform Host. Devices:
2019-10-21 23:24:06.175709: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
[I 23:24:12.901 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections.ipynb
[I 23:24:41.644 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 23:25:21.199 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 23:26:12.834 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections.ipynb
[I 23:26:41.465 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 23:27:21.249 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 23:27:58.376 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 23:28:15.517 LabApp] Kernel restarted: b41395eb-52e2-4a6a-bda4-d3ea858d5ff5
[I 23:28:15.536 LabApp] Starting buffering for b41395eb-52e2-4a6a-bda4-d3ea858d5ff5:97db3f135c8548ca8220862debe111ad
[I 23:28:15.552 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections.ipynb
[I 23:28:16.761 LabApp] Adapting from protocol version 5.1 (kernel b41395eb-52e2-4a6a-bda4-d3ea858d5ff5) to 5.3 (client).
[I 23:28:16.762 LabApp] Restoring connection for b41395eb-52e2-4a6a-bda4-d3ea858d5ff5:97db3f135c8548ca8220862debe111ad
[I 23:28:16.762 LabApp] Replaying 4 buffered messages
2019-10-21 23:28:24.690363: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-21 23:28:29.092456: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
2019-10-21 23:28:29.093383: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-21 23:28:29.095611: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-21 23:28:29.097198: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-21 23:28:29.097911: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-21 23:28:29.099960: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-21 23:28:29.101956: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-21 23:28:29.105965: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-21 23:28:29.107749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-21 23:28:29.272697: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564b6a9eda50 executing computations on platform CUDA. Devices:
2019-10-21 23:28:29.272753: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K40c, Compute Capability 3.5
2019-10-21 23:28:29.275880: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-21 23:28:29.277079: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564b6aac4500 executing computations on platform Host. Devices:
2019-10-21 23:28:29.277106: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-21 23:28:29.278035: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
2019-10-21 23:28:29.278109: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-21 23:28:29.278144: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-21 23:28:29.278178: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-21 23:28:29.278212: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-21 23:28:29.278245: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-21 23:28:29.278279: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-21 23:28:29.278313: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-21 23:28:29.279808: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-21 23:28:29.279869: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-21 23:28:29.281819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-21 23:28:29.281838: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-21 23:28:29.281849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-21 23:28:29.284603: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10794 MB memory) -> physical GPU (device: 0, name: Tesla K40c, pci bus id: 0000:02:00.0, compute capability: 3.5)
2019-10-21 23:28:36.892559: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-21 23:28:37.071764: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 23:28:41.665 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 23:29:21.379 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 23:29:59.014 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 23:30:12.838 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections.ipynb
[I 23:30:43.262 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 23:31:21.474 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 23:32:44.438 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 23:32:58.505 LabApp] Kernel interrupted: cdb62f00-42fe-47a1-88ee-60ee589c4fad
[I 23:33:00.477 LabApp] Kernel interrupted: cdb62f00-42fe-47a1-88ee-60ee589c4fad
[I 23:33:10.690 LabApp] Kernel interrupted: cdb62f00-42fe-47a1-88ee-60ee589c4fad
[I 23:33:11.700 LabApp] Kernel interrupted: cdb62f00-42fe-47a1-88ee-60ee589c4fad
[I 23:33:11.979 LabApp] Kernel interrupted: cdb62f00-42fe-47a1-88ee-60ee589c4fad
[I 23:33:12.250 LabApp] Kernel interrupted: cdb62f00-42fe-47a1-88ee-60ee589c4fad
[I 23:33:12.539 LabApp] Kernel interrupted: cdb62f00-42fe-47a1-88ee-60ee589c4fad
[I 23:33:12.826 LabApp] Kernel interrupted: cdb62f00-42fe-47a1-88ee-60ee589c4fad
[I 23:33:13.107 LabApp] Kernel interrupted: cdb62f00-42fe-47a1-88ee-60ee589c4fad
[I 23:33:13.411 LabApp] Kernel interrupted: cdb62f00-42fe-47a1-88ee-60ee589c4fad
[I 23:33:13.691 LabApp] Kernel interrupted: cdb62f00-42fe-47a1-88ee-60ee589c4fad
[I 23:33:13.987 LabApp] Kernel interrupted: cdb62f00-42fe-47a1-88ee-60ee589c4fad
[I 23:33:14.282 LabApp] Kernel interrupted: cdb62f00-42fe-47a1-88ee-60ee589c4fad
[I 23:33:17.733 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 23:33:21.248 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 23:33:40.103 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 23:33:44.257 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 23:33:52.581 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-transitions-barcode.ipynb
[I 23:33:53.829 LabApp] Starting buffering for cdb62f00-42fe-47a1-88ee-60ee589c4fad:69f67bf98e054e14a0ebebe149df079f
[I 23:33:58.986 LabApp] Kernel restarted: cdb62f00-42fe-47a1-88ee-60ee589c4fad
[I 23:33:59.762 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 23:34:00.261 LabApp] Adapting from protocol version 5.1 (kernel cdb62f00-42fe-47a1-88ee-60ee589c4fad) to 5.3 (client).
[I 23:34:00.262 LabApp] Restoring connection for cdb62f00-42fe-47a1-88ee-60ee589c4fad:69f67bf98e054e14a0ebebe149df079f
[I 23:34:00.262 LabApp] Replaying 3 buffered messages
[I 23:34:13.399 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections.ipynb
2019-10-21 23:34:15.331595: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-21 23:34:17.644482: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-10-21 23:34:17.644593: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: txori
2019-10-21 23:34:17.644606: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: txori
2019-10-21 23:34:17.645097: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.79.0
2019-10-21 23:34:17.645162: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 410.79.0
2019-10-21 23:34:17.645175: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 410.79.0
2019-10-21 23:34:17.681604: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-21 23:34:17.682731: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55aabcb94600 executing computations on platform Host. Devices:
2019-10-21 23:34:17.682758: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
[I 23:34:41.828 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 23:35:21.275 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 23:36:13.455 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections.ipynb
[I 23:36:41.682 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 23:37:21.217 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 23:37:59.138 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 23:38:13.479 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections.ipynb
[I 23:38:41.725 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 23:39:21.241 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 23:40:13.685 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections.ipynb
[I 23:40:43.027 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 23:41:21.235 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 23:41:59.513 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 23:42:13.724 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections.ipynb
[I 23:42:42.966 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 23:43:21.231 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 23:44:43.618 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 23:45:21.619 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 23:45:59.274 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 23:46:14.075 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections.ipynb
[I 23:46:43.585 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 23:47:21.206 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 23:48:43.383 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 23:49:21.401 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 23:49:59.038 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 23:50:43.769 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 23:51:21.213 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 23:52:15.182 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections.ipynb
[I 23:53:21.253 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 23:53:59.893 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 23:54:14.476 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections.ipynb
[I 23:54:44.705 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[W 23:55:00.275 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 4.03ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/mouse-usv-PCA-projections.ipynb
[I 23:55:00.631 LabApp] Adapting from protocol version 5.1 (kernel 567f8b1e-f0e6-44ce-aaf6-0db2311add48) to 5.3 (client).
[W 23:55:00.721 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 3.42ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/mouse-usv-PCA-projections.ipynb
[I 23:55:21.207 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 23:56:15.913 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections.ipynb
[I 23:57:00.689 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/mouse-usv-PCA-projections.ipynb
[I 23:57:21.243 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 23:58:00.110 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 23:58:42.466 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 23:59:21.397 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 00:00:44.289 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 00:01:21.316 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 00:01:59.331 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 00:02:44.311 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 00:03:21.246 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 00:04:44.300 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 00:05:21.220 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 00:05:59.036 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 00:06:43.117 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 00:06:47.410 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 00:07:21.307 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 00:08:45.323 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 00:09:21.238 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 00:09:59.637 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 00:10:45.401 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 00:11:21.401 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[W 00:11:29.002 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 5.48ms referer=http://localhost:8187/tree/avgn_paper/notebooks
[W 00:11:58.305 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 6.55ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/bf-sober-transitions-barcode.ipynb
[W 00:11:59.426 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 2.48ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/bf-sober-transitions-barcode.ipynb
[I 00:12:45.420 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 00:13:21.221 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 00:13:58.944 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 00:14:46.771 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 00:15:21.428 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 00:16:18.098 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/bf-sober-transitions-barcode.ipynb
[I 00:16:46.086 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 00:17:06.274 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 00:17:21.349 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 00:17:59.210 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 00:18:20.100 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections.ipynb
[I 00:18:47.322 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 00:19:21.332 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 00:20:16.355 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections.ipynb
[I 00:20:49.810 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 00:21:21.437 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 00:21:59.095 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 00:22:35.822 LabApp] 302 GET /notebooks/avgn_paper/ (::1) 1.26ms
[I 00:22:35.860 LabApp] 302 GET /notebooks/avgn_paper (::1) 1.81ms
[W 00:22:36.459 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 2.25ms referer=http://localhost:8187/tree/avgn_paper
[I 00:22:47.418 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 00:23:21.257 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 00:24:47.208 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 00:25:21.230 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 00:25:59.297 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 00:27:21.258 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 00:29:21.266 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 00:29:59.515 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 00:31:21.397 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 00:33:21.229 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 00:33:59.111 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 00:35:21.247 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 00:37:21.349 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 00:37:58.788 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 00:39:21.269 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 00:39:58.986 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 00:41:21.250 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 00:41:59.007 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 00:43:21.247 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 00:43:59.044 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 00:45:21.296 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 00:45:59.185 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 00:47:21.305 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 00:47:59.178 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 00:49:21.247 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 00:49:59.178 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 00:51:21.289 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 00:51:59.067 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 00:53:21.251 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 00:55:21.454 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 00:55:59.259 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 00:57:21.374 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 00:59:21.281 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 00:59:59.252 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 01:01:21.260 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 01:03:21.297 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 01:03:59.295 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 01:05:21.292 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 01:07:21.746 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 01:07:59.252 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 01:09:21.268 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 01:11:21.252 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 01:11:59.538 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 01:13:21.281 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 01:15:21.727 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 01:15:59.192 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 01:17:21.296 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 01:19:21.275 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 01:19:58.994 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 01:21:21.285 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 01:23:21.272 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 01:23:59.392 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 01:25:21.307 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 01:27:21.268 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 01:27:59.025 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 01:29:21.270 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 01:31:21.266 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 01:31:59.976 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 01:33:21.296 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 01:35:21.721 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 01:35:59.287 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 01:37:21.466 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 01:39:21.274 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 01:39:59.118 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 01:41:21.220 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 01:43:21.290 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 01:43:59.366 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 01:45:21.291 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 01:47:21.275 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 01:47:59.476 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 01:49:21.314 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 01:51:21.293 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 01:51:59.543 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 01:53:21.281 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 01:55:21.299 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 01:55:59.250 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 01:57:21.313 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 01:59:21.421 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 01:59:59.424 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 02:01:21.390 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 02:03:21.299 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 02:03:59.373 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 02:05:21.315 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 02:07:21.443 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 02:07:59.197 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 02:09:21.404 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 02:11:21.331 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 02:11:59.068 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 02:13:21.320 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 02:15:21.069 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 02:15:59.240 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 02:17:21.292 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 02:19:21.301 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 02:19:59.687 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 02:21:21.328 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 02:23:21.442 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 02:23:59.061 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 02:25:21.382 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 02:27:21.311 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 02:27:59.394 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 02:29:21.313 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 02:31:21.517 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 02:31:59.278 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 02:33:21.450 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 02:35:21.369 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 02:35:59.141 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 02:37:21.347 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 02:39:21.491 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 02:39:59.282 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 02:41:21.323 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 02:41:59.045 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 02:43:21.257 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 02:43:59.072 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 02:45:21.415 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 02:45:59.355 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 02:47:21.401 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 02:47:59.127 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 02:49:21.443 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 02:49:59.288 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 02:51:21.329 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 02:51:59.079 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 02:53:21.319 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 02:54:00.107 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 02:55:21.413 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 02:57:21.330 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 02:59:21.354 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 03:01:21.324 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 03:03:21.421 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 03:05:21.379 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 03:07:21.446 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 03:09:21.470 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 03:11:21.386 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 03:13:21.334 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 03:15:21.361 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 03:17:21.922 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 03:19:21.352 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 03:21:21.458 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 03:23:21.357 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 03:25:21.495 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 03:27:21.381 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 03:29:21.355 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 03:31:21.362 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 03:33:21.417 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 03:35:21.366 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 03:37:21.461 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 03:39:21.371 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 03:41:21.468 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 03:43:21.364 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 03:45:21.422 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 03:47:21.371 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 03:49:21.380 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 03:51:21.376 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 03:53:21.388 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 03:55:21.384 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 03:57:21.416 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 03:59:21.405 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 04:01:21.498 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 04:03:21.378 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 04:05:21.499 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 04:07:21.435 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 04:09:21.531 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 04:11:21.394 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 04:13:21.384 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 04:15:21.412 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 04:17:21.426 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 04:19:21.461 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 04:21:21.582 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 04:23:21.392 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 04:25:21.396 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 04:27:21.386 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 04:29:21.416 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 04:31:21.439 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 04:33:21.399 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 04:35:21.526 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 04:37:21.455 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 04:39:21.398 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 04:41:21.390 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 04:43:21.518 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 04:45:21.408 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 04:47:21.524 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 04:49:21.413 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 04:51:21.413 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 04:53:21.409 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 04:55:21.421 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 04:57:21.519 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 04:59:21.413 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 05:01:21.508 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 05:03:21.413 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 05:05:21.532 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 05:07:21.416 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 05:09:21.520 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 05:11:21.433 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 05:13:21.457 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 05:15:21.427 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 05:17:21.456 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 05:19:21.435 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 05:21:21.424 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 05:23:21.483 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 05:25:21.427 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 05:27:21.426 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 05:29:21.558 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 05:31:21.434 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 05:33:21.519 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 05:35:21.447 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 05:37:21.550 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 05:39:21.452 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 05:41:21.603 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 05:43:21.437 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 05:45:21.572 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 05:47:21.443 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 05:49:21.551 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 05:51:21.520 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 05:53:21.449 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 05:55:21.500 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 05:57:21.487 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 05:59:21.460 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 06:01:21.473 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 06:03:21.471 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 06:05:21.462 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 06:07:21.467 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 06:09:21.504 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 06:11:21.564 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 06:13:21.450 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 06:15:21.456 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 06:17:21.465 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 06:19:21.459 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 06:21:21.465 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 06:23:21.452 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 06:25:21.452 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 06:27:21.478 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 06:29:21.472 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 06:31:21.459 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 06:33:21.570 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 06:35:21.473 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 06:37:21.598 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 06:39:21.473 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 06:41:21.598 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 06:43:21.500 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 06:45:21.562 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 06:47:21.496 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 06:49:21.536 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 06:51:21.485 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 06:53:21.499 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 06:55:21.522 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 06:57:21.626 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 06:59:21.485 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 07:01:21.483 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 07:03:21.582 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 07:05:21.525 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 07:07:21.503 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 07:09:21.247 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 07:11:21.500 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 07:13:21.633 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 07:15:21.504 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 07:17:21.504 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 07:19:21.561 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 07:21:21.513 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 07:23:21.516 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 07:25:21.669 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 07:27:21.535 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 07:29:21.533 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 07:31:21.498 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 07:33:21.620 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 07:35:21.516 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 07:37:21.521 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 07:39:21.514 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 07:41:21.672 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 07:43:21.503 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 07:45:21.521 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 07:47:21.555 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 07:49:21.520 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 07:51:21.637 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 07:53:21.537 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 07:55:21.712 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 07:57:21.535 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 07:59:21.542 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 08:01:21.647 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 08:03:21.999 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 08:05:21.691 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 08:07:21.552 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 08:09:21.629 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 08:11:21.544 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 08:13:21.948 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 08:15:21.525 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 08:17:21.548 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 08:19:21.638 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 08:21:21.544 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 08:23:21.554 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 08:25:21.656 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 08:27:21.555 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 08:29:21.595 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 08:31:21.542 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 08:32:34.503 LabApp] Kernel interrupted: 548a1f23-9561-4b3f-9bf8-28e403821af7
[I 08:33:21.390 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 08:36:38.689 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections.ipynb
[W 08:40:47.813 LabApp] WebSocket ping timeout after 119952 ms.
[W 08:40:48.867 LabApp] WebSocket ping timeout after 119880 ms.
[W 08:40:51.799 LabApp] WebSocket ping timeout after 119951 ms.
[I 08:40:52.815 LabApp] Starting buffering for 548a1f23-9561-4b3f-9bf8-28e403821af7:ca1e4ec89d7949638b5c15eaed06829b
[I 08:40:53.868 LabApp] Starting buffering for f4cb2bac-28c3-4830-b001-be6be3f23c36:3a77ec59d2c944608a6688e975f52db5
[W 08:40:54.531 LabApp] WebSocket ping timeout after 119936 ms.
[I 08:40:56.801 LabApp] Starting buffering for a64a2193-19ce-4f69-9641-e19bc2fee84d:1b336dd38f5947d2af2e490490363ef8
[W 08:40:57.690 LabApp] WebSocket ping timeout after 119780 ms.
[W 08:40:59.175 LabApp] WebSocket ping timeout after 119978 ms.
[W 08:40:59.238 LabApp] WebSocket ping timeout after 119842 ms.
[I 08:40:59.532 LabApp] Starting buffering for 1a299ce2-5104-456b-ac5b-02c132cf99a5:3e6e2384f2ba429088ce8432e4064595
[W 08:41:00.262 LabApp] WebSocket ping timeout after 119977 ms.
[I 08:41:02.691 LabApp] Starting buffering for 978d9916-af35-4406-97da-0a0aa693d3c0:2588aa6e-2c06-4bd2-b556-7d22ed7d4eba
[I 08:41:04.176 LabApp] Starting buffering for 567f8b1e-f0e6-44ce-aaf6-0db2311add48:a6344707-dbde-4e42-a03c-807641a42d39
[I 08:41:04.239 LabApp] Starting buffering for 5e7b4be6-7cfb-4bed-be7a-1317135b8c1c:b71663c1-bef6-4dc2-9014-21a936c78795
[I 08:41:05.264 LabApp] Starting buffering for cdb62f00-42fe-47a1-88ee-60ee589c4fad:69f67bf98e054e14a0ebebe149df079f
[W 08:41:11.455 LabApp] WebSocket ping timeout after 119971 ms.
[I 08:41:16.456 LabApp] Starting buffering for 38a56180-e126-4229-8295-7902ea0386cc:9c14a4bb30634ef086ee5e7b0eaaf86d
[W 08:41:16.763 LabApp] WebSocket ping timeout after 119922 ms.
[I 08:41:21.764 LabApp] Starting buffering for b41395eb-52e2-4a6a-bda4-d3ea858d5ff5:97db3f135c8548ca8220862debe111ad
[I 12:14:55.171 LabApp] Adapting from protocol version 5.1 (kernel 38a56180-e126-4229-8295-7902ea0386cc) to 5.3 (client).
[I 12:14:55.172 LabApp] Restoring connection for 38a56180-e126-4229-8295-7902ea0386cc:9c14a4bb30634ef086ee5e7b0eaaf86d
[I 12:15:02.887 LabApp] Copying avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections.ipynb to /avgn_paper/notebooks/5.0-visualize-transitions
[W 12:15:06.480 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 4.27ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-Copy1.ipynb
[W 12:15:06.769 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 3.28ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-Copy1.ipynb
[I 12:15:07.724 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 12:15:08.239 LabApp] Kernel started: b1525541-acf6-46ec-a4c2-f05c6c9f83e5
[I 12:15:11.204 LabApp] Adapting from protocol version 5.1 (kernel b1525541-acf6-46ec-a4c2-f05c6c9f83e5) to 5.3 (client).
2019-10-22 12:15:52.664015: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-22 12:15:54.831846: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-10-22 12:15:54.831928: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: txori
2019-10-22 12:15:54.831949: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: txori
2019-10-22 12:15:54.832079: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.79.0
2019-10-22 12:15:54.832145: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 410.79.0
2019-10-22 12:15:54.832165: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 410.79.0
2019-10-22 12:15:54.865925: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-22 12:15:54.867097: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5637bad15630 executing computations on platform Host. Devices:
2019-10-22 12:15:54.867130: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
[I 12:16:29.704 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 12:17:08.541 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 12:19:08.389 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 12:19:11.145 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 12:19:31.097 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 12:19:49.863 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 12:21:08.390 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 12:22:23.542 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 12:23:08.390 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 12:23:26.053 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 12:24:28.003 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 12:25:08.449 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 12:26:40.584 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 12:27:00.817 LabApp] Kernel interrupted: b1525541-acf6-46ec-a4c2-f05c6c9f83e5
[I 12:27:07.991 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 12:27:08.865 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 12:29:08.488 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 12:30:27.022 LabApp] Adapting from protocol version 5.1 (kernel b41395eb-52e2-4a6a-bda4-d3ea858d5ff5) to 5.3 (client).
[I 12:30:27.023 LabApp] Restoring connection for b41395eb-52e2-4a6a-bda4-d3ea858d5ff5:97db3f135c8548ca8220862debe111ad
[I 12:31:08.444 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 12:31:18.311 LabApp] Adapting from protocol version 5.1 (kernel 548a1f23-9561-4b3f-9bf8-28e403821af7) to 5.3 (client).
[I 12:31:18.312 LabApp] Restoring connection for 548a1f23-9561-4b3f-9bf8-28e403821af7:ca1e4ec89d7949638b5c15eaed06829b
[I 12:32:28.874 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 12:34:28.870 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 12:36:28.872 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 12:38:28.976 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 12:39:07.412 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 12:40:28.906 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 12:40:48.975 LabApp] Starting buffering for 548a1f23-9561-4b3f-9bf8-28e403821af7:ca1e4ec89d7949638b5c15eaed06829b
[I 12:40:51.817 LabApp] Kernel shutdown: 548a1f23-9561-4b3f-9bf8-28e403821af7
[I 12:41:08.028 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 12:41:20.149 LabApp] Starting buffering for b41395eb-52e2-4a6a-bda4-d3ea858d5ff5:97db3f135c8548ca8220862debe111ad
[I 12:41:22.982 LabApp] Kernel restarted: b41395eb-52e2-4a6a-bda4-d3ea858d5ff5
[I 12:41:25.043 LabApp] Adapting from protocol version 5.1 (kernel b41395eb-52e2-4a6a-bda4-d3ea858d5ff5) to 5.3 (client).
[I 12:41:25.045 LabApp] Restoring connection for b41395eb-52e2-4a6a-bda4-d3ea858d5ff5:97db3f135c8548ca8220862debe111ad
[I 12:41:25.045 LabApp] Replaying 6 buffered messages
2019-10-22 12:41:34.675412: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-22 12:41:41.200020: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-22 12:41:41.201470: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-22 12:41:41.205201: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-22 12:41:41.208020: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-22 12:41:41.209143: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-22 12:41:41.213084: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-22 12:41:41.216215: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-22 12:41:41.223171: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-22 12:41:41.226129: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-22 12:41:41.451364: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b11efeedb0 executing computations on platform CUDA. Devices:
2019-10-22 12:41:41.451452: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-22 12:41:41.456154: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-22 12:41:41.458470: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b11f0c5860 executing computations on platform Host. Devices:
2019-10-22 12:41:41.458512: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-22 12:41:41.459494: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-22 12:41:41.459663: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-22 12:41:41.459774: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-22 12:41:41.459856: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-22 12:41:41.459937: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-22 12:41:41.460016: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-22 12:41:41.460096: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-22 12:41:41.460177: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-22 12:41:41.462964: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-22 12:41:41.463089: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-22 12:41:41.466779: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-22 12:41:41.466821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-22 12:41:41.466845: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-22 12:41:41.469929: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-22 12:41:48.266846: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-22 12:41:48.458754: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 12:42:28.927 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 12:42:50.823 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 12:43:07.459 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 12:43:08.416 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 12:44:03.233 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 12:44:32.284 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 12:45:07.444 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 12:45:40.794 LabApp] Copying avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections.ipynb to /avgn_paper/notebooks/5.0-visualize-transitions
[W 12:45:42.409 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 4.86ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-Copy1.ipynb
[W 12:45:43.070 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 1.55ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-Copy1.ipynb
[I 12:45:44.315 LabApp] Kernel started: 073e0049-65f0-4a3f-b6a4-42a203713fe6
[I 12:45:47.760 LabApp] Adapting from protocol version 5.1 (kernel 073e0049-65f0-4a3f-b6a4-42a203713fe6) to 5.3 (client).
[I 12:47:07.493 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 12:47:08.501 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 12:47:44.646 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-Copy1.ipynb
[I 12:47:49.384 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 12:48:16.853 LabApp] Adapting from protocol version 5.1 (kernel cdb62f00-42fe-47a1-88ee-60ee589c4fad) to 5.3 (client).
[I 12:48:16.854 LabApp] Restoring connection for cdb62f00-42fe-47a1-88ee-60ee589c4fad:69f67bf98e054e14a0ebebe149df079f
[I 12:49:07.468 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 12:49:49.577 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 12:51:05.932 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 12:51:07.429 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 12:51:49.791 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 12:52:01.431 LabApp] Kernel interrupted: b41395eb-52e2-4a6a-bda4-d3ea858d5ff5
[I 12:53:07.010 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 12:53:11.981 LabApp] Kernel interrupted: b41395eb-52e2-4a6a-bda4-d3ea858d5ff5
[I 12:53:15.075 LabApp] Starting buffering for b41395eb-52e2-4a6a-bda4-d3ea858d5ff5:97db3f135c8548ca8220862debe111ad
[I 12:53:18.753 LabApp] Kernel restarted: b41395eb-52e2-4a6a-bda4-d3ea858d5ff5
[I 12:53:21.600 LabApp] Adapting from protocol version 5.1 (kernel b41395eb-52e2-4a6a-bda4-d3ea858d5ff5) to 5.3 (client).
[I 12:53:21.602 LabApp] Restoring connection for b41395eb-52e2-4a6a-bda4-d3ea858d5ff5:97db3f135c8548ca8220862debe111ad
[I 12:53:21.602 LabApp] Replaying 6 buffered messages
[W 12:53:23.010 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 3.97ms referer=http://localhost:8187/tree/avgn_paper/notebooks/6.0-neural-networks
2019-10-22 12:53:36.276222: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-22 12:53:44.268267: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-22 12:53:44.270326: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-22 12:53:44.276473: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-22 12:53:44.280483: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-22 12:53:44.282486: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-22 12:53:44.286686: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-22 12:53:44.290993: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-22 12:53:44.298847: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-22 12:53:44.301482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-22 12:53:44.590906: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d464728e80 executing computations on platform CUDA. Devices:
2019-10-22 12:53:44.590974: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-22 12:53:44.596611: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-22 12:53:44.598200: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d4647ff910 executing computations on platform Host. Devices:
2019-10-22 12:53:44.598394: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-22 12:53:44.600332: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-22 12:53:44.601236: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-22 12:53:44.601390: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-22 12:53:44.601438: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-22 12:53:44.601481: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-22 12:53:44.601525: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-22 12:53:44.601571: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-22 12:53:44.601618: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-22 12:53:44.603947: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-22 12:53:44.604656: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-22 12:53:44.607340: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-22 12:53:44.607455: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-22 12:53:44.607466: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-22 12:53:44.610160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
[I 12:53:48.363 LabApp] 302 GET /notebooks/avgn_paper/figures (::1) 1.67ms
[W 12:53:48.883 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 4.25ms referer=http://localhost:8187/tree/avgn_paper/figures
[I 12:53:49.939 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[W 12:53:53.541 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 5.02ms referer=http://localhost:8187/tree/avgn_paper/figures/umap_seqs
2019-10-22 12:53:58.476306: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-22 12:53:58.819964: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 12:55:07.448 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 12:57:07.417 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 12:59:07.412 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 13:01:07.006 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[W 13:04:11.207 LabApp] WebSocket ping timeout after 119995 ms.
[I 13:04:16.210 LabApp] Starting buffering for b1525541-acf6-46ec-a4c2-f05c6c9f83e5:f17fa2536e3640f68f95d7d8de63b71b
[W 13:04:16.854 LabApp] WebSocket ping timeout after 119993 ms.
[W 13:04:17.761 LabApp] WebSocket ping timeout after 119990 ms.
[W 13:04:21.604 LabApp] WebSocket ping timeout after 119994 ms.
[W 13:04:21.673 LabApp] zmq message arrived on closed channel
[W 13:04:21.675 LabApp] zmq message arrived on closed channel
[W 13:04:21.814 LabApp] zmq message arrived on closed channel
[W 13:04:21.816 LabApp] zmq message arrived on closed channel
[I 13:04:21.856 LabApp] Starting buffering for cdb62f00-42fe-47a1-88ee-60ee589c4fad:69f67bf98e054e14a0ebebe149df079f
[W 13:04:21.955 LabApp] zmq message arrived on closed channel
[W 13:04:21.956 LabApp] zmq message arrived on closed channel
[W 13:04:22.097 LabApp] zmq message arrived on closed channel
[W 13:04:22.100 LabApp] zmq message arrived on closed channel
[W 13:04:22.240 LabApp] zmq message arrived on closed channel
[W 13:04:22.241 LabApp] zmq message arrived on closed channel
[W 13:04:22.384 LabApp] zmq message arrived on closed channel
[W 13:04:22.386 LabApp] zmq message arrived on closed channel
[W 13:04:22.525 LabApp] zmq message arrived on closed channel
[W 13:04:22.527 LabApp] zmq message arrived on closed channel
[W 13:04:22.669 LabApp] zmq message arrived on closed channel
[W 13:04:22.670 LabApp] zmq message arrived on closed channel
[I 13:04:22.763 LabApp] Starting buffering for 073e0049-65f0-4a3f-b6a4-42a203713fe6:24caeaec0bf64b96854aa3b4b67f6f3c
[W 13:04:22.813 LabApp] zmq message arrived on closed channel
[W 13:04:22.815 LabApp] zmq message arrived on closed channel
[W 13:04:22.956 LabApp] zmq message arrived on closed channel
[W 13:04:22.957 LabApp] zmq message arrived on closed channel
[W 13:04:23.106 LabApp] zmq message arrived on closed channel
[W 13:04:23.108 LabApp] zmq message arrived on closed channel
[W 13:04:23.250 LabApp] zmq message arrived on closed channel
[W 13:04:23.252 LabApp] zmq message arrived on closed channel
[W 13:04:23.394 LabApp] zmq message arrived on closed channel
[W 13:04:23.396 LabApp] zmq message arrived on closed channel
[W 13:04:23.533 LabApp] zmq message arrived on closed channel
[W 13:04:23.534 LabApp] zmq message arrived on closed channel
[W 13:04:23.678 LabApp] zmq message arrived on closed channel
[W 13:04:23.679 LabApp] zmq message arrived on closed channel
[W 13:04:23.819 LabApp] zmq message arrived on closed channel
[W 13:04:23.820 LabApp] zmq message arrived on closed channel
[W 13:04:23.963 LabApp] zmq message arrived on closed channel
[W 13:04:23.966 LabApp] zmq message arrived on closed channel
[W 13:04:24.102 LabApp] zmq message arrived on closed channel
[W 13:04:24.104 LabApp] zmq message arrived on closed channel
[W 13:04:24.245 LabApp] zmq message arrived on closed channel
[W 13:04:24.246 LabApp] zmq message arrived on closed channel
[W 13:04:24.389 LabApp] zmq message arrived on closed channel
[W 13:04:24.391 LabApp] zmq message arrived on closed channel
[W 13:04:24.532 LabApp] zmq message arrived on closed channel
[W 13:04:24.533 LabApp] zmq message arrived on closed channel
[W 13:04:24.672 LabApp] zmq message arrived on closed channel
[W 13:04:24.674 LabApp] zmq message arrived on closed channel
[W 13:04:24.816 LabApp] zmq message arrived on closed channel
[W 13:04:24.818 LabApp] zmq message arrived on closed channel
[W 13:04:24.960 LabApp] zmq message arrived on closed channel
[W 13:04:24.962 LabApp] zmq message arrived on closed channel
[W 13:04:25.100 LabApp] zmq message arrived on closed channel
[W 13:04:25.101 LabApp] zmq message arrived on closed channel
[W 13:04:25.173 LabApp] WebSocket ping timeout after 119941 ms.
[W 13:04:25.243 LabApp] zmq message arrived on closed channel
[W 13:04:25.245 LabApp] zmq message arrived on closed channel
[W 13:04:25.389 LabApp] zmq message arrived on closed channel
[W 13:04:25.390 LabApp] zmq message arrived on closed channel
[W 13:04:25.534 LabApp] zmq message arrived on closed channel
[W 13:04:25.535 LabApp] zmq message arrived on closed channel
[W 13:04:25.681 LabApp] zmq message arrived on closed channel
[W 13:04:25.682 LabApp] zmq message arrived on closed channel
[W 13:04:25.823 LabApp] zmq message arrived on closed channel
[W 13:04:25.824 LabApp] zmq message arrived on closed channel
[W 13:04:25.963 LabApp] zmq message arrived on closed channel
[W 13:04:25.965 LabApp] zmq message arrived on closed channel
[W 13:04:26.102 LabApp] zmq message arrived on closed channel
[W 13:04:26.103 LabApp] zmq message arrived on closed channel
[W 13:04:26.247 LabApp] zmq message arrived on closed channel
[W 13:04:26.248 LabApp] zmq message arrived on closed channel
[W 13:04:26.389 LabApp] zmq message arrived on closed channel
[W 13:04:26.391 LabApp] zmq message arrived on closed channel
[W 13:04:26.534 LabApp] zmq message arrived on closed channel
[W 13:04:26.535 LabApp] zmq message arrived on closed channel
[I 13:04:26.605 LabApp] Starting buffering for b41395eb-52e2-4a6a-bda4-d3ea858d5ff5:97db3f135c8548ca8220862debe111ad
[I 13:04:30.057 LabApp] Starting buffering for 38a56180-e126-4229-8295-7902ea0386cc:9c14a4bb30634ef086ee5e7b0eaaf86d
[I 13:04:30.129 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 13:04:31.202 LabApp] Adapting from protocol version 5.1 (kernel b41395eb-52e2-4a6a-bda4-d3ea858d5ff5) to 5.3 (client).
[I 13:04:31.204 LabApp] Restoring connection for b41395eb-52e2-4a6a-bda4-d3ea858d5ff5:97db3f135c8548ca8220862debe111ad
[I 13:04:31.204 LabApp] Replaying 86 buffered messages
[I 13:04:32.832 LabApp] Adapting from protocol version 5.1 (kernel b1525541-acf6-46ec-a4c2-f05c6c9f83e5) to 5.3 (client).
[I 13:04:32.835 LabApp] Restoring connection for b1525541-acf6-46ec-a4c2-f05c6c9f83e5:f17fa2536e3640f68f95d7d8de63b71b
[I 13:04:32.967 LabApp] Adapting from protocol version 5.1 (kernel 38a56180-e126-4229-8295-7902ea0386cc) to 5.3 (client).
[I 13:04:32.968 LabApp] Restoring connection for 38a56180-e126-4229-8295-7902ea0386cc:9c14a4bb30634ef086ee5e7b0eaaf86d
[I 13:04:34.436 LabApp] Adapting from protocol version 5.1 (kernel cdb62f00-42fe-47a1-88ee-60ee589c4fad) to 5.3 (client).
[I 13:04:34.437 LabApp] Restoring connection for cdb62f00-42fe-47a1-88ee-60ee589c4fad:69f67bf98e054e14a0ebebe149df079f
[I 13:04:35.541 LabApp] Adapting from protocol version 5.1 (kernel 073e0049-65f0-4a3f-b6a4-42a203713fe6) to 5.3 (client).
[I 13:04:35.542 LabApp] Restoring connection for 073e0049-65f0-4a3f-b6a4-42a203713fe6:24caeaec0bf64b96854aa3b4b67f6f3c
[W 13:12:31.205 LabApp] WebSocket ping timeout after 119993 ms.
[W 13:12:31.322 LabApp] zmq message arrived on closed channel
[W 13:12:31.323 LabApp] zmq message arrived on closed channel
[W 13:12:31.446 LabApp] zmq message arrived on closed channel
[W 13:12:31.447 LabApp] zmq message arrived on closed channel
[W 13:12:31.567 LabApp] zmq message arrived on closed channel
[W 13:12:31.568 LabApp] zmq message arrived on closed channel
[W 13:12:31.694 LabApp] zmq message arrived on closed channel
[W 13:12:31.694 LabApp] zmq message arrived on closed channel
[W 13:12:31.818 LabApp] zmq message arrived on closed channel
[W 13:12:31.820 LabApp] zmq message arrived on closed channel
[W 13:12:31.941 LabApp] zmq message arrived on closed channel
[W 13:12:31.941 LabApp] zmq message arrived on closed channel
[W 13:12:32.065 LabApp] zmq message arrived on closed channel
[W 13:12:32.066 LabApp] zmq message arrived on closed channel
[W 13:12:32.191 LabApp] zmq message arrived on closed channel
[W 13:12:32.192 LabApp] zmq message arrived on closed channel
[W 13:12:32.313 LabApp] zmq message arrived on closed channel
[W 13:12:32.313 LabApp] zmq message arrived on closed channel
[W 13:12:32.446 LabApp] zmq message arrived on closed channel
[W 13:12:32.448 LabApp] zmq message arrived on closed channel
[W 13:12:32.577 LabApp] zmq message arrived on closed channel
[W 13:12:32.579 LabApp] zmq message arrived on closed channel
[W 13:12:32.708 LabApp] zmq message arrived on closed channel
[W 13:12:32.710 LabApp] zmq message arrived on closed channel
[W 13:12:32.835 LabApp] WebSocket ping timeout after 119994 ms.
[W 13:12:32.839 LabApp] zmq message arrived on closed channel
[W 13:12:32.841 LabApp] zmq message arrived on closed channel
[W 13:12:32.969 LabApp] zmq message arrived on closed channel
[W 13:12:32.970 LabApp] zmq message arrived on closed channel
[W 13:12:32.972 LabApp] WebSocket ping timeout after 119998 ms.
[W 13:12:33.102 LabApp] zmq message arrived on closed channel
[W 13:12:33.103 LabApp] zmq message arrived on closed channel
[W 13:12:33.231 LabApp] zmq message arrived on closed channel
[W 13:12:33.232 LabApp] zmq message arrived on closed channel
[W 13:12:33.369 LabApp] zmq message arrived on closed channel
[W 13:12:33.371 LabApp] zmq message arrived on closed channel
[W 13:12:33.498 LabApp] zmq message arrived on closed channel
[W 13:12:33.500 LabApp] zmq message arrived on closed channel
[W 13:12:33.629 LabApp] zmq message arrived on closed channel
[W 13:12:33.630 LabApp] zmq message arrived on closed channel
[W 13:12:33.758 LabApp] zmq message arrived on closed channel
[W 13:12:33.760 LabApp] zmq message arrived on closed channel
[W 13:12:33.889 LabApp] zmq message arrived on closed channel
[W 13:12:33.891 LabApp] zmq message arrived on closed channel
[W 13:12:34.022 LabApp] zmq message arrived on closed channel
[W 13:12:34.023 LabApp] zmq message arrived on closed channel
[W 13:12:34.150 LabApp] zmq message arrived on closed channel
[W 13:12:34.151 LabApp] zmq message arrived on closed channel
[W 13:12:34.281 LabApp] zmq message arrived on closed channel
[W 13:12:34.282 LabApp] zmq message arrived on closed channel
[W 13:12:34.412 LabApp] zmq message arrived on closed channel
[W 13:12:34.414 LabApp] zmq message arrived on closed channel
[W 13:12:34.438 LabApp] WebSocket ping timeout after 119994 ms.
[W 13:12:34.546 LabApp] zmq message arrived on closed channel
[W 13:12:34.548 LabApp] zmq message arrived on closed channel
[W 13:12:34.680 LabApp] zmq message arrived on closed channel
[W 13:12:34.681 LabApp] zmq message arrived on closed channel
[W 13:12:34.816 LabApp] zmq message arrived on closed channel
[W 13:12:34.819 LabApp] zmq message arrived on closed channel
[W 13:12:34.947 LabApp] zmq message arrived on closed channel
[W 13:12:34.949 LabApp] zmq message arrived on closed channel
[W 13:12:35.080 LabApp] zmq message arrived on closed channel
[W 13:12:35.081 LabApp] zmq message arrived on closed channel
[W 13:12:35.214 LabApp] zmq message arrived on closed channel
[W 13:12:35.216 LabApp] zmq message arrived on closed channel
[W 13:12:35.347 LabApp] zmq message arrived on closed channel
[W 13:12:35.348 LabApp] zmq message arrived on closed channel
[W 13:12:35.480 LabApp] zmq message arrived on closed channel
[W 13:12:35.481 LabApp] zmq message arrived on closed channel
[W 13:12:35.543 LabApp] WebSocket ping timeout after 119994 ms.
[W 13:12:35.611 LabApp] zmq message arrived on closed channel
[W 13:12:35.611 LabApp] zmq message arrived on closed channel
[W 13:12:35.743 LabApp] zmq message arrived on closed channel
[W 13:12:35.744 LabApp] zmq message arrived on closed channel
[W 13:12:35.879 LabApp] zmq message arrived on closed channel
[W 13:12:35.880 LabApp] zmq message arrived on closed channel
[W 13:12:36.010 LabApp] zmq message arrived on closed channel
[W 13:12:36.012 LabApp] zmq message arrived on closed channel
[W 13:12:36.143 LabApp] zmq message arrived on closed channel
[W 13:12:36.144 LabApp] zmq message arrived on closed channel
[I 13:12:36.207 LabApp] Starting buffering for b41395eb-52e2-4a6a-bda4-d3ea858d5ff5:97db3f135c8548ca8220862debe111ad
[I 13:12:37.838 LabApp] Starting buffering for b1525541-acf6-46ec-a4c2-f05c6c9f83e5:f17fa2536e3640f68f95d7d8de63b71b
[I 13:12:37.975 LabApp] Starting buffering for 38a56180-e126-4229-8295-7902ea0386cc:9c14a4bb30634ef086ee5e7b0eaaf86d
[I 13:12:39.440 LabApp] Starting buffering for cdb62f00-42fe-47a1-88ee-60ee589c4fad:69f67bf98e054e14a0ebebe149df079f
[I 13:12:40.545 LabApp] Starting buffering for 073e0049-65f0-4a3f-b6a4-42a203713fe6:24caeaec0bf64b96854aa3b4b67f6f3c
[I 13:21:54.108 LabApp] Adapting from protocol version 5.1 (kernel b1525541-acf6-46ec-a4c2-f05c6c9f83e5) to 5.3 (client).
[I 13:21:54.111 LabApp] Restoring connection for b1525541-acf6-46ec-a4c2-f05c6c9f83e5:f17fa2536e3640f68f95d7d8de63b71b
[I 13:21:54.635 LabApp] Adapting from protocol version 5.1 (kernel 073e0049-65f0-4a3f-b6a4-42a203713fe6) to 5.3 (client).
[I 13:21:54.637 LabApp] Restoring connection for 073e0049-65f0-4a3f-b6a4-42a203713fe6:24caeaec0bf64b96854aa3b4b67f6f3c
[I 13:21:55.658 LabApp] Adapting from protocol version 5.1 (kernel 38a56180-e126-4229-8295-7902ea0386cc) to 5.3 (client).
[I 13:21:55.661 LabApp] Restoring connection for 38a56180-e126-4229-8295-7902ea0386cc:9c14a4bb30634ef086ee5e7b0eaaf86d
[I 13:21:57.793 LabApp] Adapting from protocol version 5.1 (kernel cdb62f00-42fe-47a1-88ee-60ee589c4fad) to 5.3 (client).
[I 13:21:57.795 LabApp] Restoring connection for cdb62f00-42fe-47a1-88ee-60ee589c4fad:69f67bf98e054e14a0ebebe149df079f
[I 13:22:03.856 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 13:22:46.051 LabApp] Adapting from protocol version 5.1 (kernel b41395eb-52e2-4a6a-bda4-d3ea858d5ff5) to 5.3 (client).
[I 13:22:46.053 LabApp] Restoring connection for b41395eb-52e2-4a6a-bda4-d3ea858d5ff5:97db3f135c8548ca8220862debe111ad
[I 13:22:46.053 LabApp] Replaying 8983 buffered messages
[W 13:22:48.644 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 13:22:49.611 LabApp] iopub messages resumed
[W 13:22:51.006 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 13:22:51.532 LabApp] iopub messages resumed
[W 13:26:25.662 LabApp] WebSocket ping timeout after 119996 ms.
[W 13:26:27.795 LabApp] WebSocket ping timeout after 119994 ms.
[I 13:26:30.665 LabApp] Starting buffering for 38a56180-e126-4229-8295-7902ea0386cc:9c14a4bb30634ef086ee5e7b0eaaf86d
[I 13:26:32.796 LabApp] Starting buffering for cdb62f00-42fe-47a1-88ee-60ee589c4fad:69f67bf98e054e14a0ebebe149df079f
[W 13:26:46.053 LabApp] WebSocket ping timeout after 119994 ms.
[W 13:26:46.081 LabApp] zmq message arrived on closed channel
[W 13:26:46.082 LabApp] zmq message arrived on closed channel
[W 13:26:46.212 LabApp] zmq message arrived on closed channel
[W 13:26:46.213 LabApp] zmq message arrived on closed channel
[W 13:26:46.340 LabApp] zmq message arrived on closed channel
[W 13:26:46.341 LabApp] zmq message arrived on closed channel
[W 13:26:46.470 LabApp] zmq message arrived on closed channel
[W 13:26:46.471 LabApp] zmq message arrived on closed channel
[W 13:26:46.607 LabApp] zmq message arrived on closed channel
[W 13:26:46.609 LabApp] zmq message arrived on closed channel
[W 13:26:46.734 LabApp] zmq message arrived on closed channel
[W 13:26:46.735 LabApp] zmq message arrived on closed channel
[W 13:26:46.874 LabApp] zmq message arrived on closed channel
[W 13:26:46.876 LabApp] zmq message arrived on closed channel
[W 13:26:47.006 LabApp] zmq message arrived on closed channel
[W 13:26:47.009 LabApp] zmq message arrived on closed channel
[W 13:26:47.129 LabApp] zmq message arrived on closed channel
[W 13:26:47.129 LabApp] zmq message arrived on closed channel
[W 13:26:47.265 LabApp] zmq message arrived on closed channel
[W 13:26:47.268 LabApp] zmq message arrived on closed channel
[W 13:26:47.393 LabApp] zmq message arrived on closed channel
[W 13:26:47.395 LabApp] zmq message arrived on closed channel
[W 13:26:47.519 LabApp] zmq message arrived on closed channel
[W 13:26:47.520 LabApp] zmq message arrived on closed channel
[W 13:26:47.656 LabApp] zmq message arrived on closed channel
[W 13:26:47.657 LabApp] zmq message arrived on closed channel
[W 13:26:47.787 LabApp] zmq message arrived on closed channel
[W 13:26:47.788 LabApp] zmq message arrived on closed channel
[W 13:26:47.920 LabApp] zmq message arrived on closed channel
[W 13:26:47.921 LabApp] zmq message arrived on closed channel
[W 13:26:48.046 LabApp] zmq message arrived on closed channel
[W 13:26:48.047 LabApp] zmq message arrived on closed channel
[W 13:26:48.186 LabApp] zmq message arrived on closed channel
[W 13:26:48.187 LabApp] zmq message arrived on closed channel
[W 13:26:48.319 LabApp] zmq message arrived on closed channel
[W 13:26:48.322 LabApp] zmq message arrived on closed channel
[W 13:26:48.455 LabApp] zmq message arrived on closed channel
[W 13:26:48.457 LabApp] zmq message arrived on closed channel
[W 13:26:48.580 LabApp] zmq message arrived on closed channel
[W 13:26:48.582 LabApp] zmq message arrived on closed channel
[W 13:26:48.714 LabApp] zmq message arrived on closed channel
[W 13:26:48.715 LabApp] zmq message arrived on closed channel
[W 13:26:48.854 LabApp] zmq message arrived on closed channel
[W 13:26:48.857 LabApp] zmq message arrived on closed channel
[W 13:26:48.991 LabApp] zmq message arrived on closed channel
[W 13:26:48.993 LabApp] zmq message arrived on closed channel
[W 13:26:49.120 LabApp] zmq message arrived on closed channel
[W 13:26:49.120 LabApp] zmq message arrived on closed channel
[W 13:26:49.262 LabApp] zmq message arrived on closed channel
[W 13:26:49.263 LabApp] zmq message arrived on closed channel
[W 13:26:49.404 LabApp] zmq message arrived on closed channel
[W 13:26:49.406 LabApp] zmq message arrived on closed channel
[W 13:26:49.542 LabApp] zmq message arrived on closed channel
[W 13:26:49.544 LabApp] zmq message arrived on closed channel
[W 13:26:49.679 LabApp] zmq message arrived on closed channel
[W 13:26:49.681 LabApp] zmq message arrived on closed channel
[W 13:26:49.817 LabApp] zmq message arrived on closed channel
[W 13:26:49.818 LabApp] zmq message arrived on closed channel
[W 13:26:49.960 LabApp] zmq message arrived on closed channel
[W 13:26:49.962 LabApp] zmq message arrived on closed channel
[W 13:26:50.097 LabApp] zmq message arrived on closed channel
[W 13:26:50.098 LabApp] zmq message arrived on closed channel
[W 13:26:50.245 LabApp] zmq message arrived on closed channel
[W 13:26:50.248 LabApp] zmq message arrived on closed channel
[W 13:26:50.386 LabApp] zmq message arrived on closed channel
[W 13:26:50.388 LabApp] zmq message arrived on closed channel
[W 13:26:50.530 LabApp] zmq message arrived on closed channel
[W 13:26:50.532 LabApp] zmq message arrived on closed channel
[W 13:26:50.657 LabApp] zmq message arrived on closed channel
[W 13:26:50.659 LabApp] zmq message arrived on closed channel
[W 13:26:50.798 LabApp] zmq message arrived on closed channel
[W 13:26:50.799 LabApp] zmq message arrived on closed channel
[W 13:26:50.931 LabApp] zmq message arrived on closed channel
[W 13:26:50.932 LabApp] zmq message arrived on closed channel
[I 13:26:51.055 LabApp] Starting buffering for b41395eb-52e2-4a6a-bda4-d3ea858d5ff5:97db3f135c8548ca8220862debe111ad
[W 13:26:54.111 LabApp] WebSocket ping timeout after 119995 ms.
[W 13:26:54.637 LabApp] WebSocket ping timeout after 119995 ms.
[I 13:26:59.113 LabApp] Starting buffering for b1525541-acf6-46ec-a4c2-f05c6c9f83e5:f17fa2536e3640f68f95d7d8de63b71b
[I 13:26:59.639 LabApp] Starting buffering for 073e0049-65f0-4a3f-b6a4-42a203713fe6:24caeaec0bf64b96854aa3b4b67f6f3c
[I 13:52:14.116 LabApp] Adapting from protocol version 5.1 (kernel 073e0049-65f0-4a3f-b6a4-42a203713fe6) to 5.3 (client).
[I 13:52:14.117 LabApp] Restoring connection for 073e0049-65f0-4a3f-b6a4-42a203713fe6:24caeaec0bf64b96854aa3b4b67f6f3c
[I 13:52:17.262 LabApp] Adapting from protocol version 5.1 (kernel 38a56180-e126-4229-8295-7902ea0386cc) to 5.3 (client).
[I 13:52:17.263 LabApp] Restoring connection for 38a56180-e126-4229-8295-7902ea0386cc:9c14a4bb30634ef086ee5e7b0eaaf86d
[I 13:52:38.436 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 13:52:44.190 LabApp] Adapting from protocol version 5.1 (kernel cdb62f00-42fe-47a1-88ee-60ee589c4fad) to 5.3 (client).
[I 13:52:44.191 LabApp] Restoring connection for cdb62f00-42fe-47a1-88ee-60ee589c4fad:69f67bf98e054e14a0ebebe149df079f
[I 13:52:46.356 LabApp] Adapting from protocol version 5.1 (kernel b1525541-acf6-46ec-a4c2-f05c6c9f83e5) to 5.3 (client).
[I 13:52:46.357 LabApp] Restoring connection for b1525541-acf6-46ec-a4c2-f05c6c9f83e5:f17fa2536e3640f68f95d7d8de63b71b
[I 13:52:47.661 LabApp] Adapting from protocol version 5.1 (kernel b41395eb-52e2-4a6a-bda4-d3ea858d5ff5) to 5.3 (client).
[I 13:52:47.662 LabApp] Restoring connection for b41395eb-52e2-4a6a-bda4-d3ea858d5ff5:97db3f135c8548ca8220862debe111ad
[I 13:52:47.662 LabApp] Replaying 23027 buffered messages
[W 13:52:49.603 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 13:52:51.029 LabApp] iopub messages resumed
[W 13:52:52.909 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 13:52:54.411 LabApp] iopub messages resumed
[W 13:52:56.365 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 13:52:57.792 LabApp] iopub messages resumed
[W 13:52:59.679 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 13:53:01.269 LabApp] iopub messages resumed
[I 13:53:54.391 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[W 13:58:14.118 LabApp] WebSocket ping timeout after 119995 ms.
[W 13:58:14.192 LabApp] WebSocket ping timeout after 119996 ms.
[W 13:58:16.358 LabApp] WebSocket ping timeout after 119996 ms.
[W 13:58:17.263 LabApp] WebSocket ping timeout after 119995 ms.
[W 13:58:17.662 LabApp] WebSocket ping timeout after 119995 ms.
[W 13:58:17.683 LabApp] zmq message arrived on closed channel
[W 13:58:17.684 LabApp] zmq message arrived on closed channel
[W 13:58:17.821 LabApp] zmq message arrived on closed channel
[W 13:58:17.822 LabApp] zmq message arrived on closed channel
[W 13:58:17.963 LabApp] zmq message arrived on closed channel
[W 13:58:17.965 LabApp] zmq message arrived on closed channel
[W 13:58:18.095 LabApp] zmq message arrived on closed channel
[W 13:58:18.095 LabApp] zmq message arrived on closed channel
[W 13:58:18.237 LabApp] zmq message arrived on closed channel
[W 13:58:18.238 LabApp] zmq message arrived on closed channel
[W 13:58:18.370 LabApp] zmq message arrived on closed channel
[W 13:58:18.371 LabApp] zmq message arrived on closed channel
[W 13:58:18.508 LabApp] zmq message arrived on closed channel
[W 13:58:18.509 LabApp] zmq message arrived on closed channel
[W 13:58:18.648 LabApp] zmq message arrived on closed channel
[W 13:58:18.649 LabApp] zmq message arrived on closed channel
[W 13:58:18.788 LabApp] zmq message arrived on closed channel
[W 13:58:18.789 LabApp] zmq message arrived on closed channel
[W 13:58:18.927 LabApp] zmq message arrived on closed channel
[W 13:58:18.928 LabApp] zmq message arrived on closed channel
[W 13:58:19.064 LabApp] zmq message arrived on closed channel
[W 13:58:19.066 LabApp] zmq message arrived on closed channel
[I 13:58:19.119 LabApp] Starting buffering for 073e0049-65f0-4a3f-b6a4-42a203713fe6:24caeaec0bf64b96854aa3b4b67f6f3c
[I 13:58:19.193 LabApp] Starting buffering for cdb62f00-42fe-47a1-88ee-60ee589c4fad:69f67bf98e054e14a0ebebe149df079f
[W 13:58:19.204 LabApp] zmq message arrived on closed channel
[W 13:58:19.204 LabApp] zmq message arrived on closed channel
[W 13:58:19.336 LabApp] zmq message arrived on closed channel
[W 13:58:19.337 LabApp] zmq message arrived on closed channel
[W 13:58:19.473 LabApp] zmq message arrived on closed channel
[W 13:58:19.474 LabApp] zmq message arrived on closed channel
[W 13:58:19.604 LabApp] zmq message arrived on closed channel
[W 13:58:19.605 LabApp] zmq message arrived on closed channel
[W 13:58:19.738 LabApp] zmq message arrived on closed channel
[W 13:58:19.740 LabApp] zmq message arrived on closed channel
[W 13:58:19.883 LabApp] zmq message arrived on closed channel
[W 13:58:19.885 LabApp] zmq message arrived on closed channel
[W 13:58:20.016 LabApp] zmq message arrived on closed channel
[W 13:58:20.017 LabApp] zmq message arrived on closed channel
[W 13:58:20.154 LabApp] zmq message arrived on closed channel
[W 13:58:20.155 LabApp] zmq message arrived on closed channel
[W 13:58:20.301 LabApp] zmq message arrived on closed channel
[W 13:58:20.303 LabApp] zmq message arrived on closed channel
[W 13:58:20.437 LabApp] zmq message arrived on closed channel
[W 13:58:20.438 LabApp] zmq message arrived on closed channel
[W 13:58:20.572 LabApp] zmq message arrived on closed channel
[W 13:58:20.573 LabApp] zmq message arrived on closed channel
[W 13:58:20.706 LabApp] zmq message arrived on closed channel
[W 13:58:20.707 LabApp] zmq message arrived on closed channel
[W 13:58:20.842 LabApp] zmq message arrived on closed channel
[W 13:58:20.844 LabApp] zmq message arrived on closed channel
[W 13:58:20.980 LabApp] zmq message arrived on closed channel
[W 13:58:20.982 LabApp] zmq message arrived on closed channel
[W 13:58:21.130 LabApp] zmq message arrived on closed channel
[W 13:58:21.131 LabApp] zmq message arrived on closed channel
[W 13:58:21.264 LabApp] zmq message arrived on closed channel
[W 13:58:21.266 LabApp] zmq message arrived on closed channel
[I 13:58:21.359 LabApp] Starting buffering for b1525541-acf6-46ec-a4c2-f05c6c9f83e5:f17fa2536e3640f68f95d7d8de63b71b
[W 13:58:21.395 LabApp] zmq message arrived on closed channel
[W 13:58:21.397 LabApp] zmq message arrived on closed channel
[W 13:58:21.529 LabApp] zmq message arrived on closed channel
[W 13:58:21.530 LabApp] zmq message arrived on closed channel
[W 13:58:21.662 LabApp] zmq message arrived on closed channel
[W 13:58:21.664 LabApp] zmq message arrived on closed channel
[W 13:58:21.797 LabApp] zmq message arrived on closed channel
[W 13:58:21.798 LabApp] zmq message arrived on closed channel
[W 13:58:21.930 LabApp] zmq message arrived on closed channel
[W 13:58:21.931 LabApp] zmq message arrived on closed channel
[W 13:58:22.064 LabApp] zmq message arrived on closed channel
[W 13:58:22.065 LabApp] zmq message arrived on closed channel
[W 13:58:22.206 LabApp] zmq message arrived on closed channel
[W 13:58:22.207 LabApp] zmq message arrived on closed channel
[I 13:58:22.265 LabApp] Starting buffering for 38a56180-e126-4229-8295-7902ea0386cc:9c14a4bb30634ef086ee5e7b0eaaf86d
[W 13:58:22.339 LabApp] zmq message arrived on closed channel
[W 13:58:22.340 LabApp] zmq message arrived on closed channel
[W 13:58:22.474 LabApp] zmq message arrived on closed channel
[W 13:58:22.474 LabApp] zmq message arrived on closed channel
[W 13:58:22.608 LabApp] zmq message arrived on closed channel
[W 13:58:22.609 LabApp] zmq message arrived on closed channel
[I 13:58:22.663 LabApp] Starting buffering for b41395eb-52e2-4a6a-bda4-d3ea858d5ff5:97db3f135c8548ca8220862debe111ad
[I 18:42:18.276 LabApp] Adapting from protocol version 5.1 (kernel 073e0049-65f0-4a3f-b6a4-42a203713fe6) to 5.3 (client).
[I 18:42:18.277 LabApp] Restoring connection for 073e0049-65f0-4a3f-b6a4-42a203713fe6:24caeaec0bf64b96854aa3b4b67f6f3c
[I 18:42:24.667 LabApp] Adapting from protocol version 5.1 (kernel b1525541-acf6-46ec-a4c2-f05c6c9f83e5) to 5.3 (client).
[I 18:42:24.668 LabApp] Restoring connection for b1525541-acf6-46ec-a4c2-f05c6c9f83e5:f17fa2536e3640f68f95d7d8de63b71b
[I 18:42:24.668 LabApp] Replaying 26 buffered messages
[I 18:43:37.353 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 18:44:01.738 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 18:44:37.168 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 18:46:04.082 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 18:46:31.531 LabApp] Creating new notebook in /avgn_paper/notebooks/5.0-visualize-transitions
[W 18:46:33.140 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 2.12ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/Untitled.ipynb?kernel_name=python3
[I 18:46:33.254 LabApp] Kernel started: 8b0a7942-bad4-4496-bf94-2db10ebceaa8
[W 18:46:33.302 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 2.03ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/Untitled.ipynb?kernel_name=python3
[I 18:46:37.545 LabApp] Adapting from protocol version 5.1 (kernel 8b0a7942-bad4-4496-bf94-2db10ebceaa8) to 5.3 (client).
[I 18:47:18.794 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
Faiss assertion 'err == cudaSuccess' failed in char* faiss::gpu::StackDeviceMemory::Stack::getAlloc(size_t, cudaStream_t) at utils/StackDeviceMemory.cpp:84; details: cudaMalloc error 2 on alloc size 1000000
[I 18:47:42.253 LabApp] KernelRestarter: restarting kernel (1/5), keep random ports
kernel 8b0a7942-bad4-4496-bf94-2db10ebceaa8 restarted
[I 18:48:33.224 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/umap-test.ipynb
[I 18:52:04.643 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 18:52:33.228 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/umap-test.ipynb
[I 18:53:37.723 LabApp] Starting buffering for 8b0a7942-bad4-4496-bf94-2db10ebceaa8:5252c64acfb6453b8c0720808d63f0c8
[I 18:53:38.560 LabApp] Kernel restarted: 8b0a7942-bad4-4496-bf94-2db10ebceaa8
[I 18:53:44.568 LabApp] Adapting from protocol version 5.1 (kernel 8b0a7942-bad4-4496-bf94-2db10ebceaa8) to 5.3 (client).
[I 18:53:44.569 LabApp] Restoring connection for 8b0a7942-bad4-4496-bf94-2db10ebceaa8:5252c64acfb6453b8c0720808d63f0c8
[I 18:53:44.580 LabApp] Replaying 6 buffered messages
[I 18:54:18.269 LabApp] Adapting from protocol version 5.1 (kernel b41395eb-52e2-4a6a-bda4-d3ea858d5ff5) to 5.3 (client).
[I 18:54:18.270 LabApp] Restoring connection for b41395eb-52e2-4a6a-bda4-d3ea858d5ff5:97db3f135c8548ca8220862debe111ad
[I 18:54:18.270 LabApp] Replaying 261590 buffered messages
[W 18:54:20.489 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 18:54:21.662 LabApp] iopub messages resumed
[W 18:54:23.547 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 18:54:25.039 LabApp] iopub messages resumed
[W 18:54:26.926 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 18:54:28.422 LabApp] iopub messages resumed
[W 18:54:30.130 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 18:54:31.768 LabApp] iopub messages resumed
[W 18:54:33.735 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 18:54:35.320 LabApp] iopub messages resumed
[W 18:54:37.162 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 18:54:38.699 LabApp] iopub messages resumed
[W 18:54:40.574 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 18:54:42.082 LabApp] iopub messages resumed
[W 18:54:43.777 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 18:54:45.431 LabApp] iopub messages resumed
[W 18:54:47.138 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 18:54:48.782 LabApp] iopub messages resumed
[W 18:54:50.778 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 18:54:52.418 LabApp] iopub messages resumed
[W 18:54:54.130 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 18:54:55.774 LabApp] iopub messages resumed
[W 18:54:57.503 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 18:54:59.118 LabApp] iopub messages resumed
[W 18:55:00.880 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 18:55:02.475 LabApp] iopub messages resumed
[W 18:55:04.250 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 18:55:05.823 LabApp] iopub messages resumed
[W 18:55:07.607 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 18:55:09.184 LabApp] iopub messages resumed
[W 18:55:11.259 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 18:55:12.530 LabApp] iopub messages resumed
[W 18:55:14.322 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 18:55:15.878 LabApp] iopub messages resumed
[W 18:55:17.769 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 18:55:19.256 LabApp] iopub messages resumed
[W 18:55:21.020 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 18:55:22.603 LabApp] iopub messages resumed
[W 18:55:24.374 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 18:55:25.957 LabApp] iopub messages resumed
[W 18:55:27.725 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 18:55:29.303 LabApp] iopub messages resumed
[W 18:55:31.078 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 18:55:32.509 LabApp] zmq message arrived on closed channel
[W 18:55:32.509 LabApp] zmq message arrived on closed channel
[W 18:55:32.510 LabApp] zmq message arrived on closed channel
[W 18:55:32.510 LabApp] zmq message arrived on closed channel
[W 18:55:32.511 LabApp] zmq message arrived on closed channel
[W 18:55:32.511 LabApp] zmq message arrived on closed channel
[W 18:55:32.568 LabApp] zmq message arrived on closed channel
[W 18:55:32.568 LabApp] zmq message arrived on closed channel
[W 18:55:32.569 LabApp] zmq message arrived on closed channel
[W 18:55:32.569 LabApp] zmq message arrived on closed channel
[W 18:55:32.569 LabApp] zmq message arrived on closed channel
[W 18:55:32.570 LabApp] zmq message arrived on closed channel
[W 18:55:32.570 LabApp] zmq message arrived on closed channel
[W 18:55:32.571 LabApp] zmq message arrived on closed channel
[W 18:55:32.671 LabApp] iopub messages resumed
[W 18:55:32.672 LabApp] zmq message arrived on closed channel
[W 18:55:32.672 LabApp] zmq message arrived on closed channel
[W 18:55:32.672 LabApp] zmq message arrived on closed channel
[W 18:55:32.673 LabApp] zmq message arrived on closed channel
[W 18:55:32.673 LabApp] zmq message arrived on closed channel
[W 18:55:32.674 LabApp] zmq message arrived on closed channel
[W 18:55:32.674 LabApp] zmq message arrived on closed channel
[W 18:55:32.675 LabApp] zmq message arrived on closed channel
[W 18:55:32.675 LabApp] zmq message arrived on closed channel
[W 18:55:32.676 LabApp] zmq message arrived on closed channel
[W 18:55:32.676 LabApp] zmq message arrived on closed channel
[W 18:55:32.677 LabApp] zmq message arrived on closed channel
[W 18:55:32.677 LabApp] zmq message arrived on closed channel
[W 18:55:32.678 LabApp] zmq message arrived on closed channel
[W 18:55:32.678 LabApp] zmq message arrived on closed channel
[W 18:55:32.678 LabApp] zmq message arrived on closed channel
[W 18:55:32.679 LabApp] zmq message arrived on closed channel
[W 18:55:32.679 LabApp] zmq message arrived on closed channel
[W 18:55:32.680 LabApp] zmq message arrived on closed channel
[W 18:55:32.680 LabApp] zmq message arrived on closed channel
[W 18:55:32.681 LabApp] zmq message arrived on closed channel
[W 18:55:32.681 LabApp] zmq message arrived on closed channel
[W 18:55:32.682 LabApp] zmq message arrived on closed channel
[W 18:55:32.682 LabApp] zmq message arrived on closed channel
[W 18:55:32.683 LabApp] zmq message arrived on closed channel
[W 18:55:32.683 LabApp] zmq message arrived on closed channel
[W 18:55:32.683 LabApp] zmq message arrived on closed channel
[W 18:55:32.684 LabApp] zmq message arrived on closed channel
[W 18:55:32.684 LabApp] zmq message arrived on closed channel
[W 18:55:32.685 LabApp] zmq message arrived on closed channel
[W 18:55:32.685 LabApp] zmq message arrived on closed channel
[W 18:55:32.686 LabApp] zmq message arrived on closed channel
[W 18:55:32.686 LabApp] zmq message arrived on closed channel
[W 18:55:32.687 LabApp] zmq message arrived on closed channel
[W 18:55:32.687 LabApp] zmq message arrived on closed channel
[W 18:55:32.688 LabApp] zmq message arrived on closed channel
[W 18:55:32.688 LabApp] zmq message arrived on closed channel
[W 18:55:32.689 LabApp] zmq message arrived on closed channel
[W 18:55:32.689 LabApp] zmq message arrived on closed channel
[W 18:55:32.689 LabApp] zmq message arrived on closed channel
[W 18:55:32.690 LabApp] zmq message arrived on closed channel
[W 18:55:32.690 LabApp] zmq message arrived on closed channel
[W 18:55:32.691 LabApp] zmq message arrived on closed channel
[W 18:55:32.691 LabApp] zmq message arrived on closed channel
[W 18:55:32.692 LabApp] zmq message arrived on closed channel
[W 18:55:32.692 LabApp] zmq message arrived on closed channel
[W 18:55:32.693 LabApp] zmq message arrived on closed channel
[W 18:55:32.693 LabApp] zmq message arrived on closed channel
[W 18:55:32.694 LabApp] zmq message arrived on closed channel
[W 18:55:32.694 LabApp] zmq message arrived on closed channel
[W 18:55:32.695 LabApp] zmq message arrived on closed channel
[W 18:55:32.695 LabApp] zmq message arrived on closed channel
[W 18:55:32.696 LabApp] zmq message arrived on closed channel
[W 18:55:32.696 LabApp] zmq message arrived on closed channel
[W 18:55:32.696 LabApp] zmq message arrived on closed channel
[W 18:55:32.697 LabApp] zmq message arrived on closed channel
[W 18:55:32.697 LabApp] zmq message arrived on closed channel
[W 18:55:32.698 LabApp] zmq message arrived on closed channel
[W 18:55:32.698 LabApp] zmq message arrived on closed channel
[W 18:55:32.699 LabApp] zmq message arrived on closed channel
[W 18:55:32.699 LabApp] zmq message arrived on closed channel
[W 18:55:32.700 LabApp] zmq message arrived on closed channel
[W 18:55:32.700 LabApp] zmq message arrived on closed channel
[W 18:55:32.701 LabApp] zmq message arrived on closed channel
[W 18:55:32.701 LabApp] zmq message arrived on closed channel
[W 18:55:32.702 LabApp] zmq message arrived on closed channel
[W 18:55:32.702 LabApp] zmq message arrived on closed channel
[W 18:55:32.702 LabApp] zmq message arrived on closed channel
[W 18:55:32.703 LabApp] zmq message arrived on closed channel
[W 18:55:32.703 LabApp] zmq message arrived on closed channel
[W 18:55:32.704 LabApp] zmq message arrived on closed channel
[W 18:55:32.704 LabApp] zmq message arrived on closed channel
[W 18:55:32.705 LabApp] zmq message arrived on closed channel
[W 18:55:32.705 LabApp] zmq message arrived on closed channel
[W 18:55:32.706 LabApp] zmq message arrived on closed channel
[W 18:55:32.706 LabApp] zmq message arrived on closed channel
[W 18:55:32.707 LabApp] zmq message arrived on closed channel
[W 18:55:32.707 LabApp] zmq message arrived on closed channel
[W 18:55:32.708 LabApp] zmq message arrived on closed channel
[W 18:55:32.708 LabApp] zmq message arrived on closed channel
[W 18:55:32.708 LabApp] zmq message arrived on closed channel
[W 18:55:32.709 LabApp] zmq message arrived on closed channel
[W 18:55:32.709 LabApp] zmq message arrived on closed channel
[W 18:55:32.710 LabApp] zmq message arrived on closed channel
[W 18:55:32.710 LabApp] zmq message arrived on closed channel
[W 18:55:32.711 LabApp] zmq message arrived on closed channel
[W 18:55:32.711 LabApp] zmq message arrived on closed channel
[W 18:55:32.712 LabApp] zmq message arrived on closed channel
[W 18:55:32.712 LabApp] zmq message arrived on closed channel
[W 18:55:32.713 LabApp] zmq message arrived on closed channel
[W 18:55:32.713 LabApp] zmq message arrived on closed channel
[W 18:55:32.714 LabApp] zmq message arrived on closed channel
[W 18:55:32.714 LabApp] zmq message arrived on closed channel
[W 18:55:32.714 LabApp] zmq message arrived on closed channel
[W 18:55:32.715 LabApp] zmq message arrived on closed channel
[W 18:55:32.715 LabApp] zmq message arrived on closed channel
[W 18:55:32.716 LabApp] zmq message arrived on closed channel
[W 18:55:32.716 LabApp] zmq message arrived on closed channel
[W 18:55:32.717 LabApp] zmq message arrived on closed channel
[W 18:55:32.717 LabApp] zmq message arrived on closed channel
[W 18:55:32.718 LabApp] zmq message arrived on closed channel
[W 18:55:32.718 LabApp] zmq message arrived on closed channel
[W 18:55:32.719 LabApp] zmq message arrived on closed channel
[W 18:55:32.719 LabApp] zmq message arrived on closed channel
[W 18:55:32.720 LabApp] zmq message arrived on closed channel
[W 18:55:32.720 LabApp] zmq message arrived on closed channel
[W 18:55:32.720 LabApp] zmq message arrived on closed channel
[W 18:55:32.721 LabApp] zmq message arrived on closed channel
[W 18:55:32.721 LabApp] zmq message arrived on closed channel
[W 18:55:32.722 LabApp] zmq message arrived on closed channel
[W 18:55:32.722 LabApp] zmq message arrived on closed channel
[W 18:55:32.723 LabApp] zmq message arrived on closed channel
[W 18:55:32.723 LabApp] zmq message arrived on closed channel
[W 18:55:32.724 LabApp] zmq message arrived on closed channel
[W 18:55:32.724 LabApp] zmq message arrived on closed channel
[W 18:55:32.725 LabApp] zmq message arrived on closed channel
[W 18:55:32.725 LabApp] zmq message arrived on closed channel
[W 18:55:32.726 LabApp] zmq message arrived on closed channel
[W 18:55:32.726 LabApp] zmq message arrived on closed channel
[W 18:55:32.726 LabApp] zmq message arrived on closed channel
[W 18:55:32.727 LabApp] zmq message arrived on closed channel
[W 18:55:32.727 LabApp] zmq message arrived on closed channel
[W 18:55:32.728 LabApp] zmq message arrived on closed channel
[W 18:55:32.728 LabApp] zmq message arrived on closed channel
[W 18:55:32.729 LabApp] zmq message arrived on closed channel
[W 18:55:32.729 LabApp] zmq message arrived on closed channel
[W 18:55:32.730 LabApp] zmq message arrived on closed channel
[W 18:55:32.730 LabApp] zmq message arrived on closed channel
[W 18:55:32.731 LabApp] zmq message arrived on closed channel
[W 18:55:32.731 LabApp] zmq message arrived on closed channel
[W 18:55:32.732 LabApp] zmq message arrived on closed channel
[W 18:55:32.732 LabApp] zmq message arrived on closed channel
[W 18:55:32.733 LabApp] zmq message arrived on closed channel
[W 18:55:32.733 LabApp] zmq message arrived on closed channel
[W 18:55:32.733 LabApp] zmq message arrived on closed channel
[W 18:55:32.734 LabApp] zmq message arrived on closed channel
[W 18:55:32.734 LabApp] zmq message arrived on closed channel
[W 18:55:32.735 LabApp] zmq message arrived on closed channel
[W 18:55:32.735 LabApp] zmq message arrived on closed channel
[W 18:55:32.736 LabApp] zmq message arrived on closed channel
[W 18:55:32.736 LabApp] zmq message arrived on closed channel
[W 18:55:32.737 LabApp] zmq message arrived on closed channel
[W 18:55:32.737 LabApp] zmq message arrived on closed channel
[W 18:55:32.738 LabApp] zmq message arrived on closed channel
[W 18:55:32.738 LabApp] zmq message arrived on closed channel
[W 18:55:32.739 LabApp] zmq message arrived on closed channel
[W 18:55:32.739 LabApp] zmq message arrived on closed channel
[W 18:55:32.739 LabApp] zmq message arrived on closed channel
[W 18:55:32.740 LabApp] zmq message arrived on closed channel
[W 18:55:32.740 LabApp] zmq message arrived on closed channel
[W 18:55:32.741 LabApp] zmq message arrived on closed channel
[W 18:55:32.741 LabApp] zmq message arrived on closed channel
[W 18:55:32.742 LabApp] zmq message arrived on closed channel
[W 18:55:32.742 LabApp] zmq message arrived on closed channel
[W 18:55:32.743 LabApp] zmq message arrived on closed channel
[W 18:55:32.743 LabApp] zmq message arrived on closed channel
[W 18:55:32.744 LabApp] zmq message arrived on closed channel
[W 18:55:32.744 LabApp] zmq message arrived on closed channel
[W 18:55:32.744 LabApp] zmq message arrived on closed channel
[W 18:55:32.745 LabApp] zmq message arrived on closed channel
[W 18:55:32.745 LabApp] zmq message arrived on closed channel
[W 18:55:32.746 LabApp] zmq message arrived on closed channel
[W 18:55:32.746 LabApp] zmq message arrived on closed channel
[W 18:55:32.747 LabApp] zmq message arrived on closed channel
[W 18:55:32.747 LabApp] zmq message arrived on closed channel
[W 18:55:32.748 LabApp] zmq message arrived on closed channel
[W 18:55:32.748 LabApp] zmq message arrived on closed channel
[W 18:55:32.749 LabApp] zmq message arrived on closed channel
[W 18:55:32.749 LabApp] zmq message arrived on closed channel
[W 18:55:32.749 LabApp] zmq message arrived on closed channel
[W 18:55:32.750 LabApp] zmq message arrived on closed channel
[W 18:55:32.750 LabApp] zmq message arrived on closed channel
[W 18:55:32.751 LabApp] zmq message arrived on closed channel
[W 18:55:32.751 LabApp] zmq message arrived on closed channel
[W 18:55:32.752 LabApp] zmq message arrived on closed channel
[W 18:55:32.752 LabApp] zmq message arrived on closed channel
[W 18:55:32.753 LabApp] zmq message arrived on closed channel
[W 18:55:32.753 LabApp] zmq message arrived on closed channel
[W 18:55:32.754 LabApp] zmq message arrived on closed channel
[W 18:55:32.754 LabApp] zmq message arrived on closed channel
[W 18:55:32.754 LabApp] zmq message arrived on closed channel
[W 18:55:32.755 LabApp] zmq message arrived on closed channel
[W 18:55:32.755 LabApp] zmq message arrived on closed channel
[W 18:55:32.756 LabApp] zmq message arrived on closed channel
[W 18:55:32.756 LabApp] zmq message arrived on closed channel
[W 18:55:32.757 LabApp] zmq message arrived on closed channel
[W 18:55:32.757 LabApp] zmq message arrived on closed channel
[W 18:55:32.758 LabApp] zmq message arrived on closed channel
[W 18:55:32.758 LabApp] zmq message arrived on closed channel
[W 18:55:32.759 LabApp] zmq message arrived on closed channel
[W 18:55:32.759 LabApp] zmq message arrived on closed channel
[W 18:55:32.759 LabApp] zmq message arrived on closed channel
[W 18:55:32.760 LabApp] zmq message arrived on closed channel
[W 18:55:32.760 LabApp] zmq message arrived on closed channel
[W 18:55:32.761 LabApp] zmq message arrived on closed channel
[W 18:55:32.761 LabApp] zmq message arrived on closed channel
[W 18:55:32.762 LabApp] zmq message arrived on closed channel
[W 18:55:32.762 LabApp] zmq message arrived on closed channel
[W 18:55:32.763 LabApp] zmq message arrived on closed channel
[W 18:55:32.763 LabApp] zmq message arrived on closed channel
[W 18:55:32.764 LabApp] zmq message arrived on closed channel
[W 18:55:32.764 LabApp] zmq message arrived on closed channel
[W 18:55:32.764 LabApp] zmq message arrived on closed channel
[W 18:55:32.765 LabApp] zmq message arrived on closed channel
[W 18:55:32.765 LabApp] zmq message arrived on closed channel
[W 18:55:32.766 LabApp] zmq message arrived on closed channel
[W 18:55:32.766 LabApp] zmq message arrived on closed channel
[W 18:55:32.767 LabApp] zmq message arrived on closed channel
[W 18:55:32.767 LabApp] zmq message arrived on closed channel
[W 18:55:32.768 LabApp] zmq message arrived on closed channel
[W 18:55:32.768 LabApp] zmq message arrived on closed channel
[W 18:55:32.769 LabApp] zmq message arrived on closed channel
[W 18:55:32.769 LabApp] zmq message arrived on closed channel
[W 18:55:32.769 LabApp] zmq message arrived on closed channel
[W 18:55:32.770 LabApp] zmq message arrived on closed channel
[W 18:55:32.770 LabApp] zmq message arrived on closed channel
[W 18:55:32.771 LabApp] zmq message arrived on closed channel
[W 18:55:32.771 LabApp] zmq message arrived on closed channel
[W 18:55:32.772 LabApp] zmq message arrived on closed channel
[W 18:55:32.772 LabApp] zmq message arrived on closed channel
[W 18:55:32.773 LabApp] zmq message arrived on closed channel
[W 18:55:32.773 LabApp] zmq message arrived on closed channel
[W 18:55:32.774 LabApp] zmq message arrived on closed channel
[W 18:55:32.774 LabApp] zmq message arrived on closed channel
[W 18:55:32.775 LabApp] zmq message arrived on closed channel
[W 18:55:32.775 LabApp] zmq message arrived on closed channel
[W 18:55:32.775 LabApp] zmq message arrived on closed channel
[W 18:55:32.776 LabApp] zmq message arrived on closed channel
[W 18:55:32.776 LabApp] zmq message arrived on closed channel
[W 18:55:32.777 LabApp] zmq message arrived on closed channel
[W 18:55:32.777 LabApp] zmq message arrived on closed channel
[W 18:55:32.778 LabApp] zmq message arrived on closed channel
[W 18:55:32.778 LabApp] zmq message arrived on closed channel
[W 18:55:32.779 LabApp] zmq message arrived on closed channel
[W 18:55:32.779 LabApp] zmq message arrived on closed channel
[W 18:55:32.780 LabApp] zmq message arrived on closed channel
[W 18:55:32.780 LabApp] zmq message arrived on closed channel
[W 18:55:32.780 LabApp] zmq message arrived on closed channel
[W 18:55:32.781 LabApp] zmq message arrived on closed channel
[W 18:55:32.781 LabApp] zmq message arrived on closed channel
[W 18:55:32.782 LabApp] zmq message arrived on closed channel
[W 18:55:32.782 LabApp] zmq message arrived on closed channel
[W 18:55:32.783 LabApp] zmq message arrived on closed channel
[W 18:55:32.783 LabApp] zmq message arrived on closed channel
[W 18:55:32.784 LabApp] zmq message arrived on closed channel
[W 18:55:32.784 LabApp] zmq message arrived on closed channel
[W 18:55:32.785 LabApp] zmq message arrived on closed channel
[W 18:55:32.785 LabApp] zmq message arrived on closed channel
[W 18:55:32.785 LabApp] zmq message arrived on closed channel
[W 18:55:32.786 LabApp] zmq message arrived on closed channel
[W 18:55:32.786 LabApp] zmq message arrived on closed channel
[W 18:55:32.787 LabApp] zmq message arrived on closed channel
[W 18:55:32.787 LabApp] zmq message arrived on closed channel
[W 18:55:32.788 LabApp] zmq message arrived on closed channel
[W 18:55:32.788 LabApp] zmq message arrived on closed channel
[W 18:55:32.789 LabApp] zmq message arrived on closed channel
[W 18:55:32.789 LabApp] zmq message arrived on closed channel
[W 18:55:32.790 LabApp] zmq message arrived on closed channel
[W 18:55:32.790 LabApp] zmq message arrived on closed channel
[W 18:55:32.790 LabApp] zmq message arrived on closed channel
[W 18:55:32.791 LabApp] zmq message arrived on closed channel
[W 18:55:32.791 LabApp] zmq message arrived on closed channel
[W 18:55:32.792 LabApp] zmq message arrived on closed channel
[W 18:55:32.792 LabApp] zmq message arrived on closed channel
[W 18:55:32.793 LabApp] zmq message arrived on closed channel
[W 18:55:32.793 LabApp] zmq message arrived on closed channel
[W 18:55:32.794 LabApp] zmq message arrived on closed channel
[W 18:55:32.794 LabApp] zmq message arrived on closed channel
[W 18:55:32.795 LabApp] zmq message arrived on closed channel
[W 18:55:32.795 LabApp] zmq message arrived on closed channel
[W 18:55:32.796 LabApp] zmq message arrived on closed channel
[W 18:55:32.796 LabApp] zmq message arrived on closed channel
[W 18:55:32.796 LabApp] zmq message arrived on closed channel
[W 18:55:32.797 LabApp] zmq message arrived on closed channel
[W 18:55:32.797 LabApp] zmq message arrived on closed channel
[W 18:55:32.798 LabApp] zmq message arrived on closed channel
[W 18:55:32.798 LabApp] zmq message arrived on closed channel
[W 18:55:32.799 LabApp] zmq message arrived on closed channel
[W 18:55:32.799 LabApp] zmq message arrived on closed channel
[W 18:55:32.800 LabApp] zmq message arrived on closed channel
[W 18:55:32.800 LabApp] zmq message arrived on closed channel
[W 18:55:32.801 LabApp] zmq message arrived on closed channel
[W 18:55:32.801 LabApp] zmq message arrived on closed channel
[W 18:55:32.802 LabApp] zmq message arrived on closed channel
[W 18:55:32.802 LabApp] zmq message arrived on closed channel
[W 18:55:32.802 LabApp] zmq message arrived on closed channel
[W 18:55:32.803 LabApp] zmq message arrived on closed channel
[W 18:55:32.803 LabApp] zmq message arrived on closed channel
[W 18:55:32.804 LabApp] zmq message arrived on closed channel
[W 18:55:32.804 LabApp] zmq message arrived on closed channel
[W 18:55:32.805 LabApp] zmq message arrived on closed channel
[W 18:55:32.805 LabApp] zmq message arrived on closed channel
[W 18:55:32.806 LabApp] zmq message arrived on closed channel
[W 18:55:32.806 LabApp] zmq message arrived on closed channel
[W 18:55:32.807 LabApp] zmq message arrived on closed channel
[W 18:55:32.807 LabApp] zmq message arrived on closed channel
[W 18:55:32.808 LabApp] zmq message arrived on closed channel
[W 18:55:32.808 LabApp] zmq message arrived on closed channel
[W 18:55:32.808 LabApp] zmq message arrived on closed channel
[W 18:55:32.809 LabApp] zmq message arrived on closed channel
[W 18:55:32.809 LabApp] zmq message arrived on closed channel
[W 18:55:32.810 LabApp] zmq message arrived on closed channel
[W 18:55:32.810 LabApp] zmq message arrived on closed channel
[W 18:55:32.811 LabApp] zmq message arrived on closed channel
[W 18:55:32.811 LabApp] zmq message arrived on closed channel
[W 18:55:32.812 LabApp] zmq message arrived on closed channel
[W 18:55:32.812 LabApp] zmq message arrived on closed channel
[W 18:55:32.813 LabApp] zmq message arrived on closed channel
[W 18:55:32.813 LabApp] zmq message arrived on closed channel
[W 18:55:32.814 LabApp] zmq message arrived on closed channel
[W 18:55:32.814 LabApp] zmq message arrived on closed channel
[W 18:55:32.814 LabApp] zmq message arrived on closed channel
[W 18:55:32.815 LabApp] zmq message arrived on closed channel
[W 18:55:32.815 LabApp] zmq message arrived on closed channel
[W 18:55:32.816 LabApp] zmq message arrived on closed channel
[W 18:55:32.816 LabApp] zmq message arrived on closed channel
[W 18:55:32.817 LabApp] zmq message arrived on closed channel
[W 18:55:32.817 LabApp] zmq message arrived on closed channel
[W 18:55:32.818 LabApp] zmq message arrived on closed channel
[W 18:55:32.818 LabApp] zmq message arrived on closed channel
[W 18:55:32.819 LabApp] zmq message arrived on closed channel
[W 18:55:32.819 LabApp] zmq message arrived on closed channel
[W 18:55:32.820 LabApp] zmq message arrived on closed channel
[W 18:55:32.820 LabApp] zmq message arrived on closed channel
[W 18:55:32.820 LabApp] zmq message arrived on closed channel
[W 18:55:32.821 LabApp] zmq message arrived on closed channel
[W 18:55:32.821 LabApp] zmq message arrived on closed channel
[W 18:55:32.822 LabApp] zmq message arrived on closed channel
[W 18:55:32.822 LabApp] zmq message arrived on closed channel
[W 18:55:32.823 LabApp] zmq message arrived on closed channel
[W 18:55:32.823 LabApp] zmq message arrived on closed channel
[W 18:55:32.824 LabApp] zmq message arrived on closed channel
[W 18:55:32.824 LabApp] zmq message arrived on closed channel
[W 18:55:32.825 LabApp] zmq message arrived on closed channel
[W 18:55:32.825 LabApp] zmq message arrived on closed channel
[W 18:55:32.826 LabApp] zmq message arrived on closed channel
[W 18:55:32.826 LabApp] zmq message arrived on closed channel
[W 18:55:32.826 LabApp] zmq message arrived on closed channel
[W 18:55:32.827 LabApp] zmq message arrived on closed channel
[W 18:55:32.827 LabApp] zmq message arrived on closed channel
[W 18:55:32.828 LabApp] zmq message arrived on closed channel
[W 18:55:32.828 LabApp] zmq message arrived on closed channel
[W 18:55:32.829 LabApp] zmq message arrived on closed channel
[W 18:55:32.829 LabApp] zmq message arrived on closed channel
[W 18:55:32.830 LabApp] zmq message arrived on closed channel
[W 18:55:32.830 LabApp] zmq message arrived on closed channel
[W 18:55:32.831 LabApp] zmq message arrived on closed channel
[W 18:55:32.831 LabApp] zmq message arrived on closed channel
[W 18:55:32.831 LabApp] zmq message arrived on closed channel
[W 18:55:32.832 LabApp] zmq message arrived on closed channel
[W 18:55:32.832 LabApp] zmq message arrived on closed channel
[W 18:55:32.833 LabApp] zmq message arrived on closed channel
[W 18:55:32.833 LabApp] zmq message arrived on closed channel
[W 18:55:32.834 LabApp] zmq message arrived on closed channel
[W 18:55:32.834 LabApp] zmq message arrived on closed channel
[W 18:55:32.835 LabApp] zmq message arrived on closed channel
[W 18:55:32.835 LabApp] zmq message arrived on closed channel
[W 18:55:32.836 LabApp] zmq message arrived on closed channel
[W 18:55:32.836 LabApp] zmq message arrived on closed channel
[W 18:55:32.836 LabApp] zmq message arrived on closed channel
[W 18:55:32.837 LabApp] zmq message arrived on closed channel
[W 18:55:32.837 LabApp] zmq message arrived on closed channel
[W 18:55:32.838 LabApp] zmq message arrived on closed channel
[W 18:55:32.838 LabApp] zmq message arrived on closed channel
[W 18:55:32.839 LabApp] zmq message arrived on closed channel
[W 18:55:32.839 LabApp] zmq message arrived on closed channel
[W 18:55:32.840 LabApp] zmq message arrived on closed channel
[W 18:55:32.840 LabApp] zmq message arrived on closed channel
[W 18:55:32.841 LabApp] zmq message arrived on closed channel
[W 18:55:32.841 LabApp] zmq message arrived on closed channel
[W 18:55:32.841 LabApp] zmq message arrived on closed channel
[W 18:55:32.842 LabApp] zmq message arrived on closed channel
[W 18:55:32.842 LabApp] zmq message arrived on closed channel
[W 18:55:32.843 LabApp] zmq message arrived on closed channel
[W 18:55:32.843 LabApp] zmq message arrived on closed channel
[W 18:55:32.844 LabApp] zmq message arrived on closed channel
[W 18:55:32.844 LabApp] zmq message arrived on closed channel
[W 18:55:32.845 LabApp] zmq message arrived on closed channel
[W 18:55:32.845 LabApp] zmq message arrived on closed channel
[W 18:55:32.846 LabApp] zmq message arrived on closed channel
[W 18:55:32.846 LabApp] zmq message arrived on closed channel
[W 18:55:32.846 LabApp] zmq message arrived on closed channel
[W 18:55:32.847 LabApp] zmq message arrived on closed channel
[W 18:55:32.847 LabApp] zmq message arrived on closed channel
[W 18:55:32.848 LabApp] zmq message arrived on closed channel
[W 18:55:32.848 LabApp] zmq message arrived on closed channel
[W 18:55:32.849 LabApp] zmq message arrived on closed channel
[W 18:55:32.849 LabApp] zmq message arrived on closed channel
[W 18:55:32.850 LabApp] zmq message arrived on closed channel
[W 18:55:32.850 LabApp] zmq message arrived on closed channel
[W 18:55:32.851 LabApp] zmq message arrived on closed channel
[W 18:55:32.851 LabApp] zmq message arrived on closed channel
[W 18:55:32.852 LabApp] zmq message arrived on closed channel
[W 18:55:32.852 LabApp] zmq message arrived on closed channel
[W 18:55:32.852 LabApp] zmq message arrived on closed channel
[W 18:55:32.853 LabApp] zmq message arrived on closed channel
[W 18:55:32.853 LabApp] zmq message arrived on closed channel
[W 18:55:32.854 LabApp] zmq message arrived on closed channel
[W 18:55:32.854 LabApp] zmq message arrived on closed channel
[W 18:55:32.855 LabApp] zmq message arrived on closed channel
[W 18:55:32.855 LabApp] zmq message arrived on closed channel
[W 18:55:32.856 LabApp] zmq message arrived on closed channel
[W 18:55:32.856 LabApp] zmq message arrived on closed channel
[W 18:55:32.856 LabApp] zmq message arrived on closed channel
[W 18:55:32.857 LabApp] zmq message arrived on closed channel
[W 18:55:32.857 LabApp] zmq message arrived on closed channel
[W 18:55:32.858 LabApp] zmq message arrived on closed channel
[W 18:55:32.858 LabApp] zmq message arrived on closed channel
[W 18:55:32.859 LabApp] zmq message arrived on closed channel
[W 18:55:32.859 LabApp] zmq message arrived on closed channel
[W 18:55:32.860 LabApp] zmq message arrived on closed channel
[W 18:55:32.860 LabApp] zmq message arrived on closed channel
[W 18:55:32.861 LabApp] zmq message arrived on closed channel
[W 18:55:32.861 LabApp] zmq message arrived on closed channel
[W 18:55:32.862 LabApp] zmq message arrived on closed channel
[W 18:55:32.862 LabApp] zmq message arrived on closed channel
[W 18:55:32.862 LabApp] zmq message arrived on closed channel
[W 18:55:32.863 LabApp] zmq message arrived on closed channel
[W 18:55:32.863 LabApp] zmq message arrived on closed channel
[W 18:55:32.864 LabApp] zmq message arrived on closed channel
[W 18:55:32.864 LabApp] zmq message arrived on closed channel
[W 18:55:32.865 LabApp] zmq message arrived on closed channel
[W 18:55:32.865 LabApp] zmq message arrived on closed channel
[W 18:55:32.866 LabApp] zmq message arrived on closed channel
[W 18:55:32.866 LabApp] zmq message arrived on closed channel
[W 18:55:32.867 LabApp] zmq message arrived on closed channel
[W 18:55:32.867 LabApp] zmq message arrived on closed channel
[W 18:55:32.867 LabApp] zmq message arrived on closed channel
[W 18:55:32.868 LabApp] zmq message arrived on closed channel
[W 18:55:32.868 LabApp] zmq message arrived on closed channel
[W 18:55:32.869 LabApp] zmq message arrived on closed channel
[W 18:55:32.869 LabApp] zmq message arrived on closed channel
[W 18:55:32.870 LabApp] zmq message arrived on closed channel
[W 18:55:32.870 LabApp] zmq message arrived on closed channel
[W 18:55:32.871 LabApp] zmq message arrived on closed channel
[W 18:55:32.871 LabApp] zmq message arrived on closed channel
[W 18:55:32.872 LabApp] zmq message arrived on closed channel
[W 18:55:32.872 LabApp] zmq message arrived on closed channel
[W 18:55:32.873 LabApp] zmq message arrived on closed channel
[W 18:55:32.873 LabApp] zmq message arrived on closed channel
[W 18:55:32.873 LabApp] zmq message arrived on closed channel
[W 18:55:32.874 LabApp] zmq message arrived on closed channel
[W 18:55:32.874 LabApp] zmq message arrived on closed channel
[W 18:55:32.875 LabApp] zmq message arrived on closed channel
[W 18:55:32.875 LabApp] zmq message arrived on closed channel
[W 18:55:32.876 LabApp] zmq message arrived on closed channel
[W 18:55:32.876 LabApp] zmq message arrived on closed channel
[W 18:55:32.877 LabApp] zmq message arrived on closed channel
[W 18:55:32.877 LabApp] zmq message arrived on closed channel
[W 18:55:32.878 LabApp] zmq message arrived on closed channel
[W 18:55:32.878 LabApp] zmq message arrived on closed channel
[W 18:55:32.878 LabApp] zmq message arrived on closed channel
[W 18:55:32.879 LabApp] zmq message arrived on closed channel
[W 18:55:32.879 LabApp] zmq message arrived on closed channel
[W 18:55:32.880 LabApp] zmq message arrived on closed channel
[W 18:55:32.880 LabApp] zmq message arrived on closed channel
[W 18:55:32.881 LabApp] zmq message arrived on closed channel
[W 18:55:32.881 LabApp] zmq message arrived on closed channel
[W 18:55:32.882 LabApp] zmq message arrived on closed channel
[W 18:55:32.882 LabApp] zmq message arrived on closed channel
[W 18:55:32.883 LabApp] zmq message arrived on closed channel
[W 18:55:32.883 LabApp] zmq message arrived on closed channel
[W 18:55:32.884 LabApp] zmq message arrived on closed channel
[W 18:55:32.884 LabApp] zmq message arrived on closed channel
[W 18:55:32.884 LabApp] zmq message arrived on closed channel
[W 18:55:32.885 LabApp] zmq message arrived on closed channel
[W 18:55:32.885 LabApp] zmq message arrived on closed channel
[W 18:55:32.886 LabApp] zmq message arrived on closed channel
[W 18:55:32.886 LabApp] zmq message arrived on closed channel
[W 18:55:32.887 LabApp] zmq message arrived on closed channel
[W 18:55:32.887 LabApp] zmq message arrived on closed channel
[W 18:55:32.888 LabApp] zmq message arrived on closed channel
[W 18:55:32.888 LabApp] zmq message arrived on closed channel
[W 18:55:32.889 LabApp] zmq message arrived on closed channel
[W 18:55:32.889 LabApp] zmq message arrived on closed channel
[W 18:55:32.889 LabApp] zmq message arrived on closed channel
[W 18:55:32.890 LabApp] zmq message arrived on closed channel
[W 18:55:32.890 LabApp] zmq message arrived on closed channel
[W 18:55:32.891 LabApp] zmq message arrived on closed channel
[W 18:55:32.891 LabApp] zmq message arrived on closed channel
[W 18:55:32.892 LabApp] zmq message arrived on closed channel
[W 18:55:32.892 LabApp] zmq message arrived on closed channel
[W 18:55:32.893 LabApp] zmq message arrived on closed channel
[W 18:55:32.893 LabApp] zmq message arrived on closed channel
[W 18:55:32.894 LabApp] zmq message arrived on closed channel
[W 18:55:32.894 LabApp] zmq message arrived on closed channel
[W 18:55:32.894 LabApp] zmq message arrived on closed channel
[W 18:55:32.895 LabApp] zmq message arrived on closed channel
[W 18:55:32.895 LabApp] zmq message arrived on closed channel
[W 18:55:32.896 LabApp] zmq message arrived on closed channel
[W 18:55:32.896 LabApp] zmq message arrived on closed channel
[W 18:55:32.897 LabApp] zmq message arrived on closed channel
[W 18:55:32.897 LabApp] zmq message arrived on closed channel
[W 18:55:32.898 LabApp] zmq message arrived on closed channel
[W 18:55:32.898 LabApp] zmq message arrived on closed channel
[W 18:55:32.899 LabApp] zmq message arrived on closed channel
[W 18:55:32.899 LabApp] zmq message arrived on closed channel
[W 18:55:32.899 LabApp] zmq message arrived on closed channel
[W 18:55:32.900 LabApp] zmq message arrived on closed channel
[W 18:55:32.900 LabApp] zmq message arrived on closed channel
[W 18:55:32.901 LabApp] zmq message arrived on closed channel
[W 18:55:32.901 LabApp] zmq message arrived on closed channel
[W 18:55:32.902 LabApp] zmq message arrived on closed channel
[W 18:55:32.902 LabApp] zmq message arrived on closed channel
[W 18:55:32.903 LabApp] zmq message arrived on closed channel
[W 18:55:32.903 LabApp] zmq message arrived on closed channel
[W 18:55:32.904 LabApp] zmq message arrived on closed channel
[W 18:55:32.904 LabApp] zmq message arrived on closed channel
[W 18:55:32.904 LabApp] zmq message arrived on closed channel
[W 18:55:32.905 LabApp] zmq message arrived on closed channel
[W 18:55:32.905 LabApp] zmq message arrived on closed channel
[W 18:55:32.906 LabApp] zmq message arrived on closed channel
[W 18:55:32.906 LabApp] zmq message arrived on closed channel
[W 18:55:32.907 LabApp] zmq message arrived on closed channel
[W 18:55:32.907 LabApp] zmq message arrived on closed channel
[W 18:55:32.908 LabApp] zmq message arrived on closed channel
[W 18:55:32.908 LabApp] zmq message arrived on closed channel
[W 18:55:32.909 LabApp] zmq message arrived on closed channel
[W 18:55:32.909 LabApp] zmq message arrived on closed channel
[W 18:55:32.909 LabApp] zmq message arrived on closed channel
[W 18:55:32.910 LabApp] zmq message arrived on closed channel
[W 18:55:32.910 LabApp] zmq message arrived on closed channel
[W 18:55:32.911 LabApp] zmq message arrived on closed channel
[W 18:55:32.911 LabApp] zmq message arrived on closed channel
[W 18:55:32.912 LabApp] zmq message arrived on closed channel
[W 18:55:32.912 LabApp] zmq message arrived on closed channel
[W 18:55:32.913 LabApp] zmq message arrived on closed channel
[W 18:55:32.913 LabApp] zmq message arrived on closed channel
[W 18:55:32.914 LabApp] zmq message arrived on closed channel
[W 18:55:32.914 LabApp] zmq message arrived on closed channel
[W 18:55:32.914 LabApp] zmq message arrived on closed channel
[W 18:55:32.915 LabApp] zmq message arrived on closed channel
[W 18:55:32.915 LabApp] zmq message arrived on closed channel
[W 18:55:32.916 LabApp] zmq message arrived on closed channel
[W 18:55:32.916 LabApp] zmq message arrived on closed channel
[W 18:55:32.917 LabApp] zmq message arrived on closed channel
[W 18:55:32.917 LabApp] zmq message arrived on closed channel
[W 18:55:32.918 LabApp] zmq message arrived on closed channel
[W 18:55:32.918 LabApp] zmq message arrived on closed channel
[W 18:55:32.919 LabApp] zmq message arrived on closed channel
[W 18:55:32.919 LabApp] zmq message arrived on closed channel
[W 18:55:32.919 LabApp] zmq message arrived on closed channel
[W 18:55:32.920 LabApp] zmq message arrived on closed channel
[W 18:55:32.920 LabApp] zmq message arrived on closed channel
[W 18:55:32.921 LabApp] zmq message arrived on closed channel
[W 18:55:32.921 LabApp] zmq message arrived on closed channel
[W 18:55:32.922 LabApp] zmq message arrived on closed channel
[W 18:55:32.922 LabApp] zmq message arrived on closed channel
[W 18:55:32.923 LabApp] zmq message arrived on closed channel
[W 18:55:32.923 LabApp] zmq message arrived on closed channel
[W 18:55:32.924 LabApp] zmq message arrived on closed channel
[W 18:55:32.924 LabApp] zmq message arrived on closed channel
[W 18:55:32.924 LabApp] zmq message arrived on closed channel
[W 18:55:32.925 LabApp] zmq message arrived on closed channel
[W 18:55:32.925 LabApp] zmq message arrived on closed channel
[W 18:55:32.926 LabApp] zmq message arrived on closed channel
[W 18:55:32.926 LabApp] zmq message arrived on closed channel
[W 18:55:32.927 LabApp] zmq message arrived on closed channel
[W 18:55:32.927 LabApp] zmq message arrived on closed channel
[W 18:55:32.928 LabApp] zmq message arrived on closed channel
[W 18:55:32.928 LabApp] zmq message arrived on closed channel
[W 18:55:32.929 LabApp] zmq message arrived on closed channel
[W 18:55:32.929 LabApp] zmq message arrived on closed channel
[W 18:55:32.929 LabApp] zmq message arrived on closed channel
[W 18:55:32.930 LabApp] zmq message arrived on closed channel
[W 18:55:32.930 LabApp] zmq message arrived on closed channel
[W 18:55:32.931 LabApp] zmq message arrived on closed channel
[W 18:55:32.931 LabApp] zmq message arrived on closed channel
[W 18:55:32.932 LabApp] zmq message arrived on closed channel
[W 18:55:32.932 LabApp] zmq message arrived on closed channel
[W 18:55:32.933 LabApp] zmq message arrived on closed channel
[W 18:55:32.933 LabApp] zmq message arrived on closed channel
[W 18:55:32.934 LabApp] zmq message arrived on closed channel
[W 18:55:32.934 LabApp] zmq message arrived on closed channel
[W 18:55:32.935 LabApp] zmq message arrived on closed channel
[W 18:55:32.935 LabApp] zmq message arrived on closed channel
[W 18:55:32.935 LabApp] zmq message arrived on closed channel
[W 18:55:32.936 LabApp] zmq message arrived on closed channel
[W 18:55:32.936 LabApp] zmq message arrived on closed channel
[W 18:55:32.937 LabApp] zmq message arrived on closed channel
[W 18:55:32.937 LabApp] zmq message arrived on closed channel
[W 18:55:32.938 LabApp] zmq message arrived on closed channel
[W 18:55:32.938 LabApp] zmq message arrived on closed channel
[W 18:55:32.939 LabApp] zmq message arrived on closed channel
[W 18:55:32.939 LabApp] zmq message arrived on closed channel
[W 18:55:32.940 LabApp] zmq message arrived on closed channel
[W 18:55:32.940 LabApp] zmq message arrived on closed channel
[W 18:55:32.940 LabApp] zmq message arrived on closed channel
[W 18:55:32.941 LabApp] zmq message arrived on closed channel
[W 18:55:32.941 LabApp] zmq message arrived on closed channel
[W 18:55:32.942 LabApp] zmq message arrived on closed channel
[W 18:55:32.942 LabApp] zmq message arrived on closed channel
[W 18:55:32.943 LabApp] zmq message arrived on closed channel
[W 18:55:32.943 LabApp] zmq message arrived on closed channel
[W 18:55:32.944 LabApp] zmq message arrived on closed channel
[W 18:55:32.944 LabApp] zmq message arrived on closed channel
[W 18:55:32.945 LabApp] zmq message arrived on closed channel
[W 18:55:32.945 LabApp] zmq message arrived on closed channel
[W 18:55:32.946 LabApp] zmq message arrived on closed channel
[W 18:55:32.946 LabApp] zmq message arrived on closed channel
[W 18:55:32.946 LabApp] zmq message arrived on closed channel
[W 18:55:32.947 LabApp] zmq message arrived on closed channel
[W 18:55:32.947 LabApp] zmq message arrived on closed channel
[W 18:55:32.948 LabApp] zmq message arrived on closed channel
[W 18:55:32.948 LabApp] zmq message arrived on closed channel
[W 18:55:32.949 LabApp] zmq message arrived on closed channel
[W 18:55:32.949 LabApp] zmq message arrived on closed channel
[W 18:55:32.950 LabApp] zmq message arrived on closed channel
[W 18:55:32.950 LabApp] zmq message arrived on closed channel
[W 18:55:32.951 LabApp] zmq message arrived on closed channel
[W 18:55:32.951 LabApp] zmq message arrived on closed channel
[W 18:55:32.952 LabApp] zmq message arrived on closed channel
[W 18:55:32.952 LabApp] zmq message arrived on closed channel
[W 18:55:32.953 LabApp] zmq message arrived on closed channel
[W 18:55:32.953 LabApp] zmq message arrived on closed channel
[W 18:55:32.953 LabApp] zmq message arrived on closed channel
[W 18:55:32.954 LabApp] zmq message arrived on closed channel
[W 18:55:32.954 LabApp] zmq message arrived on closed channel
[W 18:55:32.955 LabApp] zmq message arrived on closed channel
[W 18:55:32.955 LabApp] zmq message arrived on closed channel
[W 18:55:32.956 LabApp] zmq message arrived on closed channel
[W 18:55:32.956 LabApp] zmq message arrived on closed channel
[W 18:55:32.957 LabApp] zmq message arrived on closed channel
[W 18:55:32.957 LabApp] zmq message arrived on closed channel
[W 18:55:32.958 LabApp] zmq message arrived on closed channel
[W 18:55:32.958 LabApp] zmq message arrived on closed channel
[W 18:55:32.959 LabApp] zmq message arrived on closed channel
[W 18:55:32.959 LabApp] zmq message arrived on closed channel
[W 18:55:32.959 LabApp] zmq message arrived on closed channel
[W 18:55:32.960 LabApp] zmq message arrived on closed channel
[W 18:55:32.960 LabApp] zmq message arrived on closed channel
[W 18:55:32.961 LabApp] zmq message arrived on closed channel
[W 18:55:32.961 LabApp] zmq message arrived on closed channel
[W 18:55:32.962 LabApp] zmq message arrived on closed channel
[W 18:55:32.962 LabApp] zmq message arrived on closed channel
[W 18:55:32.963 LabApp] zmq message arrived on closed channel
[W 18:55:32.963 LabApp] zmq message arrived on closed channel
[W 18:55:32.964 LabApp] zmq message arrived on closed channel
[W 18:55:32.964 LabApp] zmq message arrived on closed channel
[W 18:55:32.964 LabApp] zmq message arrived on closed channel
[W 18:55:32.965 LabApp] zmq message arrived on closed channel
[W 18:55:32.965 LabApp] zmq message arrived on closed channel
[W 18:55:32.966 LabApp] zmq message arrived on closed channel
[W 18:55:32.966 LabApp] zmq message arrived on closed channel
[W 18:55:32.967 LabApp] zmq message arrived on closed channel
[W 18:55:32.967 LabApp] zmq message arrived on closed channel
[W 18:55:32.968 LabApp] zmq message arrived on closed channel
[W 18:55:32.968 LabApp] zmq message arrived on closed channel
[W 18:55:32.969 LabApp] zmq message arrived on closed channel
[W 18:55:32.969 LabApp] zmq message arrived on closed channel
[W 18:55:32.970 LabApp] zmq message arrived on closed channel
[W 18:55:32.970 LabApp] zmq message arrived on closed channel
[W 18:55:32.970 LabApp] zmq message arrived on closed channel
[W 18:55:32.971 LabApp] zmq message arrived on closed channel
[W 18:55:32.971 LabApp] zmq message arrived on closed channel
[W 18:55:32.972 LabApp] zmq message arrived on closed channel
[W 18:55:32.972 LabApp] zmq message arrived on closed channel
[W 18:55:32.973 LabApp] zmq message arrived on closed channel
[W 18:55:32.973 LabApp] zmq message arrived on closed channel
[W 18:55:32.974 LabApp] zmq message arrived on closed channel
[W 18:55:32.974 LabApp] zmq message arrived on closed channel
[W 18:55:32.975 LabApp] zmq message arrived on closed channel
[W 18:55:32.975 LabApp] zmq message arrived on closed channel
[W 18:55:32.976 LabApp] zmq message arrived on closed channel
[W 18:55:32.976 LabApp] zmq message arrived on closed channel
[W 18:55:32.976 LabApp] zmq message arrived on closed channel
[W 18:55:32.977 LabApp] zmq message arrived on closed channel
[W 18:55:32.977 LabApp] zmq message arrived on closed channel
[W 18:55:32.978 LabApp] zmq message arrived on closed channel
[W 18:55:32.978 LabApp] zmq message arrived on closed channel
[W 18:55:32.979 LabApp] zmq message arrived on closed channel
[W 18:55:32.979 LabApp] zmq message arrived on closed channel
[W 18:55:32.980 LabApp] zmq message arrived on closed channel
[W 18:55:32.980 LabApp] zmq message arrived on closed channel
[W 18:55:32.981 LabApp] zmq message arrived on closed channel
[W 18:55:32.981 LabApp] zmq message arrived on closed channel
[W 18:55:32.981 LabApp] zmq message arrived on closed channel
[W 18:55:32.982 LabApp] zmq message arrived on closed channel
[W 18:55:32.982 LabApp] zmq message arrived on closed channel
[W 18:55:32.983 LabApp] zmq message arrived on closed channel
[W 18:55:32.983 LabApp] zmq message arrived on closed channel
[W 18:55:32.984 LabApp] zmq message arrived on closed channel
[W 18:55:32.984 LabApp] zmq message arrived on closed channel
[W 18:55:32.985 LabApp] zmq message arrived on closed channel
[W 18:55:32.985 LabApp] zmq message arrived on closed channel
[W 18:55:32.986 LabApp] zmq message arrived on closed channel
[W 18:55:32.986 LabApp] zmq message arrived on closed channel
[W 18:55:32.987 LabApp] zmq message arrived on closed channel
[W 18:55:32.987 LabApp] zmq message arrived on closed channel
[W 18:55:32.987 LabApp] zmq message arrived on closed channel
[W 18:55:32.988 LabApp] zmq message arrived on closed channel
[W 18:55:32.988 LabApp] zmq message arrived on closed channel
[W 18:55:32.989 LabApp] zmq message arrived on closed channel
[W 18:55:32.989 LabApp] zmq message arrived on closed channel
[W 18:55:32.990 LabApp] zmq message arrived on closed channel
[W 18:55:32.990 LabApp] zmq message arrived on closed channel
[W 18:55:32.991 LabApp] zmq message arrived on closed channel
[W 18:55:32.991 LabApp] zmq message arrived on closed channel
[W 18:55:32.992 LabApp] zmq message arrived on closed channel
[W 18:55:32.992 LabApp] zmq message arrived on closed channel
[W 18:55:32.992 LabApp] zmq message arrived on closed channel
[W 18:55:32.993 LabApp] zmq message arrived on closed channel
[W 18:55:32.993 LabApp] zmq message arrived on closed channel
[W 18:55:32.994 LabApp] zmq message arrived on closed channel
[W 18:55:32.994 LabApp] zmq message arrived on closed channel
[W 18:55:32.995 LabApp] zmq message arrived on closed channel
[W 18:55:32.995 LabApp] zmq message arrived on closed channel
[W 18:55:32.996 LabApp] zmq message arrived on closed channel
[W 18:55:32.996 LabApp] zmq message arrived on closed channel
[W 18:55:32.997 LabApp] zmq message arrived on closed channel
[W 18:55:32.997 LabApp] zmq message arrived on closed channel
[W 18:55:32.997 LabApp] zmq message arrived on closed channel
[W 18:55:32.998 LabApp] zmq message arrived on closed channel
[W 18:55:32.998 LabApp] zmq message arrived on closed channel
[W 18:55:32.999 LabApp] zmq message arrived on closed channel
[W 18:55:32.999 LabApp] zmq message arrived on closed channel
[W 18:55:33.000 LabApp] zmq message arrived on closed channel
[W 18:55:33.000 LabApp] zmq message arrived on closed channel
[W 18:55:33.001 LabApp] zmq message arrived on closed channel
[W 18:55:33.001 LabApp] zmq message arrived on closed channel
[W 18:55:33.002 LabApp] zmq message arrived on closed channel
[W 18:55:33.002 LabApp] zmq message arrived on closed channel
[W 18:55:33.002 LabApp] zmq message arrived on closed channel
[W 18:55:33.003 LabApp] zmq message arrived on closed channel
[W 18:55:33.003 LabApp] zmq message arrived on closed channel
[W 18:55:33.004 LabApp] zmq message arrived on closed channel
[W 18:55:33.004 LabApp] zmq message arrived on closed channel
[W 18:55:33.005 LabApp] zmq message arrived on closed channel
[W 18:55:33.005 LabApp] zmq message arrived on closed channel
[W 18:55:33.006 LabApp] zmq message arrived on closed channel
[W 18:55:33.006 LabApp] zmq message arrived on closed channel
[W 18:55:33.007 LabApp] zmq message arrived on closed channel
[W 18:55:33.007 LabApp] zmq message arrived on closed channel
[W 18:55:33.008 LabApp] zmq message arrived on closed channel
[W 18:55:33.008 LabApp] zmq message arrived on closed channel
[W 18:55:33.008 LabApp] zmq message arrived on closed channel
[W 18:55:33.009 LabApp] zmq message arrived on closed channel
[W 18:55:33.009 LabApp] zmq message arrived on closed channel
[W 18:55:33.010 LabApp] zmq message arrived on closed channel
[W 18:55:33.010 LabApp] zmq message arrived on closed channel
[W 18:55:33.011 LabApp] zmq message arrived on closed channel
[W 18:55:33.011 LabApp] zmq message arrived on closed channel
[W 18:55:33.012 LabApp] zmq message arrived on closed channel
[W 18:55:33.012 LabApp] zmq message arrived on closed channel
[W 18:55:33.013 LabApp] zmq message arrived on closed channel
[W 18:55:33.013 LabApp] zmq message arrived on closed channel
[W 18:55:33.013 LabApp] zmq message arrived on closed channel
[W 18:55:33.014 LabApp] zmq message arrived on closed channel
[W 18:55:33.014 LabApp] zmq message arrived on closed channel
[W 18:55:33.015 LabApp] zmq message arrived on closed channel
[W 18:55:33.015 LabApp] zmq message arrived on closed channel
[W 18:55:33.016 LabApp] zmq message arrived on closed channel
[W 18:55:33.016 LabApp] zmq message arrived on closed channel
[W 18:55:33.017 LabApp] zmq message arrived on closed channel
[W 18:55:33.017 LabApp] zmq message arrived on closed channel
[W 18:55:33.018 LabApp] zmq message arrived on closed channel
[W 18:55:33.018 LabApp] zmq message arrived on closed channel
[W 18:55:33.018 LabApp] zmq message arrived on closed channel
[W 18:55:33.019 LabApp] zmq message arrived on closed channel
[W 18:55:33.019 LabApp] zmq message arrived on closed channel
[W 18:55:33.020 LabApp] zmq message arrived on closed channel
[W 18:55:33.020 LabApp] zmq message arrived on closed channel
[W 18:55:33.021 LabApp] zmq message arrived on closed channel
[W 18:55:33.021 LabApp] zmq message arrived on closed channel
[W 18:55:33.022 LabApp] zmq message arrived on closed channel
[W 18:55:33.022 LabApp] zmq message arrived on closed channel
[W 18:55:33.023 LabApp] zmq message arrived on closed channel
[W 18:55:33.023 LabApp] zmq message arrived on closed channel
[W 18:55:33.023 LabApp] zmq message arrived on closed channel
[W 18:55:33.024 LabApp] zmq message arrived on closed channel
[W 18:55:33.024 LabApp] zmq message arrived on closed channel
[W 18:55:33.025 LabApp] zmq message arrived on closed channel
[W 18:55:33.025 LabApp] zmq message arrived on closed channel
[W 18:55:33.026 LabApp] zmq message arrived on closed channel
[W 18:55:33.026 LabApp] zmq message arrived on closed channel
[W 18:55:33.027 LabApp] zmq message arrived on closed channel
[W 18:55:33.027 LabApp] zmq message arrived on closed channel
[W 18:55:33.028 LabApp] zmq message arrived on closed channel
[W 18:55:33.028 LabApp] zmq message arrived on closed channel
[W 18:55:33.029 LabApp] zmq message arrived on closed channel
[W 18:55:33.029 LabApp] zmq message arrived on closed channel
[W 18:55:33.029 LabApp] zmq message arrived on closed channel
[W 18:55:33.030 LabApp] zmq message arrived on closed channel
[W 18:55:33.030 LabApp] zmq message arrived on closed channel
[W 18:55:33.031 LabApp] zmq message arrived on closed channel
[W 18:55:33.031 LabApp] zmq message arrived on closed channel
[W 18:55:33.032 LabApp] zmq message arrived on closed channel
[W 18:55:33.032 LabApp] zmq message arrived on closed channel
[W 18:55:33.033 LabApp] zmq message arrived on closed channel
[W 18:55:33.033 LabApp] zmq message arrived on closed channel
[W 18:55:33.034 LabApp] zmq message arrived on closed channel
[W 18:55:33.034 LabApp] zmq message arrived on closed channel
[W 18:55:33.034 LabApp] zmq message arrived on closed channel
[W 18:55:33.035 LabApp] zmq message arrived on closed channel
[W 18:55:33.035 LabApp] zmq message arrived on closed channel
[W 18:55:33.036 LabApp] zmq message arrived on closed channel
[W 18:55:33.036 LabApp] zmq message arrived on closed channel
[W 18:55:33.037 LabApp] zmq message arrived on closed channel
[W 18:55:33.037 LabApp] zmq message arrived on closed channel
[W 18:55:33.038 LabApp] zmq message arrived on closed channel
[W 18:55:33.038 LabApp] zmq message arrived on closed channel
[W 18:55:33.039 LabApp] zmq message arrived on closed channel
[W 18:55:33.039 LabApp] zmq message arrived on closed channel
[W 18:55:33.040 LabApp] zmq message arrived on closed channel
[W 18:55:33.040 LabApp] zmq message arrived on closed channel
[W 18:55:33.040 LabApp] zmq message arrived on closed channel
[W 18:55:33.041 LabApp] zmq message arrived on closed channel
[W 18:55:33.041 LabApp] zmq message arrived on closed channel
[W 18:55:33.042 LabApp] zmq message arrived on closed channel
[W 18:55:33.042 LabApp] zmq message arrived on closed channel
[W 18:55:33.043 LabApp] zmq message arrived on closed channel
[W 18:55:33.043 LabApp] zmq message arrived on closed channel
[W 18:55:33.044 LabApp] zmq message arrived on closed channel
[W 18:55:33.044 LabApp] zmq message arrived on closed channel
[W 18:55:33.045 LabApp] zmq message arrived on closed channel
[W 18:55:33.045 LabApp] zmq message arrived on closed channel
[W 18:55:33.046 LabApp] zmq message arrived on closed channel
[W 18:55:33.046 LabApp] zmq message arrived on closed channel
[W 18:55:33.047 LabApp] zmq message arrived on closed channel
[W 18:55:33.048 LabApp] zmq message arrived on closed channel
[W 18:55:33.048 LabApp] zmq message arrived on closed channel
[W 18:55:33.048 LabApp] zmq message arrived on closed channel
[W 18:55:33.049 LabApp] zmq message arrived on closed channel
[W 18:55:33.049 LabApp] zmq message arrived on closed channel
[W 18:55:33.050 LabApp] zmq message arrived on closed channel
[W 18:55:33.050 LabApp] zmq message arrived on closed channel
[W 18:55:33.051 LabApp] zmq message arrived on closed channel
[W 18:55:33.051 LabApp] zmq message arrived on closed channel
[W 18:55:33.052 LabApp] zmq message arrived on closed channel
[W 18:55:33.052 LabApp] zmq message arrived on closed channel
[W 18:55:33.053 LabApp] zmq message arrived on closed channel
[W 18:55:33.053 LabApp] zmq message arrived on closed channel
[W 18:55:33.053 LabApp] zmq message arrived on closed channel
[W 18:55:33.054 LabApp] zmq message arrived on closed channel
[W 18:55:33.054 LabApp] zmq message arrived on closed channel
[W 18:55:33.055 LabApp] zmq message arrived on closed channel
[W 18:55:33.055 LabApp] zmq message arrived on closed channel
[W 18:55:33.056 LabApp] zmq message arrived on closed channel
[W 18:55:33.056 LabApp] zmq message arrived on closed channel
[W 18:55:33.057 LabApp] zmq message arrived on closed channel
[W 18:55:33.057 LabApp] zmq message arrived on closed channel
[W 18:55:33.058 LabApp] zmq message arrived on closed channel
[W 18:55:33.058 LabApp] zmq message arrived on closed channel
[W 18:55:33.058 LabApp] zmq message arrived on closed channel
[W 18:55:33.059 LabApp] zmq message arrived on closed channel
[W 18:55:33.060 LabApp] zmq message arrived on closed channel
[W 18:55:33.060 LabApp] zmq message arrived on closed channel
[W 18:55:33.060 LabApp] zmq message arrived on closed channel
[W 18:55:33.061 LabApp] zmq message arrived on closed channel
[W 18:55:33.061 LabApp] zmq message arrived on closed channel
[W 18:55:33.062 LabApp] zmq message arrived on closed channel
[W 18:55:33.062 LabApp] zmq message arrived on closed channel
[W 18:55:33.063 LabApp] zmq message arrived on closed channel
[W 18:55:33.063 LabApp] zmq message arrived on closed channel
[W 18:55:33.064 LabApp] zmq message arrived on closed channel
[W 18:55:33.064 LabApp] zmq message arrived on closed channel
[W 18:55:33.065 LabApp] zmq message arrived on closed channel
[W 18:55:33.065 LabApp] zmq message arrived on closed channel
[W 18:55:33.065 LabApp] zmq message arrived on closed channel
[W 18:55:33.066 LabApp] zmq message arrived on closed channel
[W 18:55:33.066 LabApp] zmq message arrived on closed channel
[W 18:55:33.067 LabApp] zmq message arrived on closed channel
[W 18:55:33.067 LabApp] zmq message arrived on closed channel
[W 18:55:33.068 LabApp] zmq message arrived on closed channel
[W 18:55:33.068 LabApp] zmq message arrived on closed channel
[W 18:55:33.069 LabApp] zmq message arrived on closed channel
[W 18:55:33.069 LabApp] zmq message arrived on closed channel
[W 18:55:33.070 LabApp] zmq message arrived on closed channel
[W 18:55:33.070 LabApp] zmq message arrived on closed channel
[W 18:55:33.070 LabApp] zmq message arrived on closed channel
[W 18:55:33.071 LabApp] zmq message arrived on closed channel
[W 18:55:33.071 LabApp] zmq message arrived on closed channel
[W 18:55:33.072 LabApp] zmq message arrived on closed channel
[W 18:55:33.072 LabApp] zmq message arrived on closed channel
[W 18:55:33.073 LabApp] zmq message arrived on closed channel
[W 18:55:33.073 LabApp] zmq message arrived on closed channel
[W 18:55:33.074 LabApp] zmq message arrived on closed channel
[W 18:55:33.074 LabApp] zmq message arrived on closed channel
[W 18:55:33.075 LabApp] zmq message arrived on closed channel
[W 18:55:33.075 LabApp] zmq message arrived on closed channel
[W 18:55:33.076 LabApp] zmq message arrived on closed channel
[W 18:55:33.076 LabApp] zmq message arrived on closed channel
[W 18:55:33.077 LabApp] zmq message arrived on closed channel
[W 18:55:33.077 LabApp] zmq message arrived on closed channel
[W 18:55:33.077 LabApp] zmq message arrived on closed channel
[W 18:55:33.078 LabApp] zmq message arrived on closed channel
[W 18:55:33.078 LabApp] zmq message arrived on closed channel
[W 18:55:33.079 LabApp] zmq message arrived on closed channel
[W 18:55:33.079 LabApp] zmq message arrived on closed channel
[W 18:55:33.080 LabApp] zmq message arrived on closed channel
[W 18:55:33.080 LabApp] zmq message arrived on closed channel
[W 18:55:33.081 LabApp] zmq message arrived on closed channel
[W 18:55:33.081 LabApp] zmq message arrived on closed channel
[W 18:55:33.082 LabApp] zmq message arrived on closed channel
[W 18:55:33.082 LabApp] zmq message arrived on closed channel
[W 18:55:33.082 LabApp] zmq message arrived on closed channel
[W 18:55:33.083 LabApp] zmq message arrived on closed channel
[W 18:55:33.083 LabApp] zmq message arrived on closed channel
[W 18:55:33.084 LabApp] zmq message arrived on closed channel
[W 18:55:33.084 LabApp] zmq message arrived on closed channel
[W 18:55:33.085 LabApp] zmq message arrived on closed channel
[W 18:55:33.085 LabApp] zmq message arrived on closed channel
[W 18:55:33.086 LabApp] zmq message arrived on closed channel
[W 18:55:33.086 LabApp] zmq message arrived on closed channel
[W 18:55:33.087 LabApp] zmq message arrived on closed channel
[W 18:55:33.087 LabApp] zmq message arrived on closed channel
[W 18:55:33.088 LabApp] zmq message arrived on closed channel
[W 18:55:33.088 LabApp] zmq message arrived on closed channel
[W 18:55:33.088 LabApp] zmq message arrived on closed channel
[W 18:55:33.089 LabApp] zmq message arrived on closed channel
[W 18:55:33.089 LabApp] zmq message arrived on closed channel
[W 18:55:33.090 LabApp] zmq message arrived on closed channel
[W 18:55:33.090 LabApp] zmq message arrived on closed channel
[W 18:55:33.091 LabApp] zmq message arrived on closed channel
[W 18:55:33.091 LabApp] zmq message arrived on closed channel
[W 18:55:33.092 LabApp] zmq message arrived on closed channel
[W 18:55:33.092 LabApp] zmq message arrived on closed channel
[W 18:55:33.093 LabApp] zmq message arrived on closed channel
[W 18:55:33.093 LabApp] zmq message arrived on closed channel
[W 18:55:33.094 LabApp] zmq message arrived on closed channel
[W 18:55:33.094 LabApp] zmq message arrived on closed channel
[W 18:55:33.094 LabApp] zmq message arrived on closed channel
[W 18:55:33.095 LabApp] zmq message arrived on closed channel
[W 18:55:33.095 LabApp] zmq message arrived on closed channel
[W 18:55:33.096 LabApp] zmq message arrived on closed channel
[W 18:55:33.096 LabApp] zmq message arrived on closed channel
[W 18:55:33.097 LabApp] zmq message arrived on closed channel
[W 18:55:33.097 LabApp] zmq message arrived on closed channel
[W 18:55:33.098 LabApp] zmq message arrived on closed channel
[W 18:55:33.098 LabApp] zmq message arrived on closed channel
[W 18:55:33.099 LabApp] zmq message arrived on closed channel
[W 18:55:33.099 LabApp] zmq message arrived on closed channel
[W 18:55:33.100 LabApp] zmq message arrived on closed channel
[W 18:55:33.100 LabApp] zmq message arrived on closed channel
[W 18:55:33.100 LabApp] zmq message arrived on closed channel
[W 18:55:33.101 LabApp] zmq message arrived on closed channel
[W 18:55:33.101 LabApp] zmq message arrived on closed channel
[W 18:55:33.102 LabApp] zmq message arrived on closed channel
[W 18:55:33.102 LabApp] zmq message arrived on closed channel
[W 18:55:33.103 LabApp] zmq message arrived on closed channel
[W 18:55:33.103 LabApp] zmq message arrived on closed channel
[W 18:55:33.104 LabApp] zmq message arrived on closed channel
[W 18:55:33.104 LabApp] zmq message arrived on closed channel
[W 18:55:33.105 LabApp] zmq message arrived on closed channel
[W 18:55:33.105 LabApp] zmq message arrived on closed channel
[W 18:55:33.106 LabApp] zmq message arrived on closed channel
[W 18:55:33.106 LabApp] zmq message arrived on closed channel
[W 18:55:33.106 LabApp] zmq message arrived on closed channel
[W 18:55:33.107 LabApp] zmq message arrived on closed channel
[W 18:55:33.107 LabApp] zmq message arrived on closed channel
[W 18:55:33.108 LabApp] zmq message arrived on closed channel
[W 18:55:33.108 LabApp] zmq message arrived on closed channel
[W 18:55:33.109 LabApp] zmq message arrived on closed channel
[W 18:55:33.109 LabApp] zmq message arrived on closed channel
[W 18:55:33.110 LabApp] zmq message arrived on closed channel
[W 18:55:33.110 LabApp] zmq message arrived on closed channel
[W 18:55:33.111 LabApp] zmq message arrived on closed channel
[W 18:55:33.111 LabApp] zmq message arrived on closed channel
[W 18:55:33.111 LabApp] zmq message arrived on closed channel
[W 18:55:33.112 LabApp] zmq message arrived on closed channel
[W 18:55:33.112 LabApp] zmq message arrived on closed channel
[W 18:55:33.113 LabApp] zmq message arrived on closed channel
[W 18:55:33.113 LabApp] zmq message arrived on closed channel
[W 18:55:33.114 LabApp] zmq message arrived on closed channel
[W 18:55:33.114 LabApp] zmq message arrived on closed channel
[W 18:55:33.115 LabApp] zmq message arrived on closed channel
[W 18:55:33.115 LabApp] zmq message arrived on closed channel
[W 18:55:33.116 LabApp] zmq message arrived on closed channel
[W 18:55:33.116 LabApp] zmq message arrived on closed channel
[W 18:55:33.116 LabApp] zmq message arrived on closed channel
[W 18:55:33.117 LabApp] zmq message arrived on closed channel
[W 18:55:33.117 LabApp] zmq message arrived on closed channel
[W 18:55:33.118 LabApp] zmq message arrived on closed channel
[W 18:55:33.118 LabApp] zmq message arrived on closed channel
[W 18:55:33.119 LabApp] zmq message arrived on closed channel
[W 18:55:33.119 LabApp] zmq message arrived on closed channel
[W 18:55:33.120 LabApp] zmq message arrived on closed channel
[W 18:55:33.120 LabApp] zmq message arrived on closed channel
[W 18:55:33.121 LabApp] zmq message arrived on closed channel
[W 18:55:33.121 LabApp] zmq message arrived on closed channel
[W 18:55:33.121 LabApp] zmq message arrived on closed channel
[W 18:55:33.122 LabApp] zmq message arrived on closed channel
[W 18:55:33.122 LabApp] zmq message arrived on closed channel
[W 18:55:33.123 LabApp] zmq message arrived on closed channel
[W 18:55:33.123 LabApp] zmq message arrived on closed channel
[W 18:55:33.124 LabApp] zmq message arrived on closed channel
[W 18:55:33.124 LabApp] zmq message arrived on closed channel
[W 18:55:33.125 LabApp] zmq message arrived on closed channel
[W 18:55:33.125 LabApp] zmq message arrived on closed channel
[W 18:55:33.126 LabApp] zmq message arrived on closed channel
[W 18:55:33.126 LabApp] zmq message arrived on closed channel
[W 18:55:33.126 LabApp] zmq message arrived on closed channel
[W 18:55:33.127 LabApp] zmq message arrived on closed channel
[W 18:55:33.127 LabApp] zmq message arrived on closed channel
[W 18:55:33.128 LabApp] zmq message arrived on closed channel
[W 18:55:33.128 LabApp] zmq message arrived on closed channel
[W 18:55:33.129 LabApp] zmq message arrived on closed channel
[W 18:55:33.129 LabApp] zmq message arrived on closed channel
[W 18:55:33.130 LabApp] zmq message arrived on closed channel
[W 18:55:33.130 LabApp] zmq message arrived on closed channel
[W 18:55:33.131 LabApp] zmq message arrived on closed channel
[W 18:55:33.131 LabApp] zmq message arrived on closed channel
[W 18:55:33.132 LabApp] zmq message arrived on closed channel
[W 18:55:33.132 LabApp] zmq message arrived on closed channel
[W 18:55:33.132 LabApp] zmq message arrived on closed channel
[W 18:55:33.133 LabApp] zmq message arrived on closed channel
[W 18:55:33.133 LabApp] zmq message arrived on closed channel
[W 18:55:33.134 LabApp] zmq message arrived on closed channel
[W 18:55:33.134 LabApp] zmq message arrived on closed channel
[W 18:55:33.135 LabApp] zmq message arrived on closed channel
[W 18:55:33.135 LabApp] zmq message arrived on closed channel
[W 18:55:33.136 LabApp] zmq message arrived on closed channel
[W 18:55:33.136 LabApp] zmq message arrived on closed channel
[W 18:55:33.137 LabApp] zmq message arrived on closed channel
[W 18:55:33.137 LabApp] zmq message arrived on closed channel
[W 18:55:33.138 LabApp] zmq message arrived on closed channel
[W 18:55:33.138 LabApp] zmq message arrived on closed channel
[W 18:55:33.139 LabApp] zmq message arrived on closed channel
[W 18:55:33.139 LabApp] zmq message arrived on closed channel
[W 18:55:33.139 LabApp] zmq message arrived on closed channel
[W 18:55:33.140 LabApp] zmq message arrived on closed channel
[W 18:55:33.140 LabApp] zmq message arrived on closed channel
[W 18:55:33.141 LabApp] zmq message arrived on closed channel
[W 18:55:33.141 LabApp] zmq message arrived on closed channel
[W 18:55:33.142 LabApp] zmq message arrived on closed channel
[W 18:55:33.142 LabApp] zmq message arrived on closed channel
[W 18:55:33.143 LabApp] zmq message arrived on closed channel
[W 18:55:33.143 LabApp] zmq message arrived on closed channel
[W 18:55:33.144 LabApp] zmq message arrived on closed channel
[W 18:55:33.144 LabApp] zmq message arrived on closed channel
[W 18:55:33.145 LabApp] zmq message arrived on closed channel
[W 18:55:33.145 LabApp] zmq message arrived on closed channel
[W 18:55:33.145 LabApp] zmq message arrived on closed channel
[W 18:55:33.146 LabApp] zmq message arrived on closed channel
[W 18:55:33.146 LabApp] zmq message arrived on closed channel
[W 18:55:33.147 LabApp] zmq message arrived on closed channel
[W 18:55:33.147 LabApp] zmq message arrived on closed channel
[W 18:55:33.148 LabApp] zmq message arrived on closed channel
[W 18:55:33.148 LabApp] zmq message arrived on closed channel
[W 18:55:33.149 LabApp] zmq message arrived on closed channel
[W 18:55:33.149 LabApp] zmq message arrived on closed channel
[W 18:55:33.150 LabApp] zmq message arrived on closed channel
[W 18:55:33.150 LabApp] zmq message arrived on closed channel
[W 18:55:33.150 LabApp] zmq message arrived on closed channel
[W 18:55:33.151 LabApp] zmq message arrived on closed channel
[W 18:55:33.151 LabApp] zmq message arrived on closed channel
[W 18:55:33.152 LabApp] zmq message arrived on closed channel
[W 18:55:33.152 LabApp] zmq message arrived on closed channel
[W 18:55:33.153 LabApp] zmq message arrived on closed channel
[W 18:55:33.153 LabApp] zmq message arrived on closed channel
[W 18:55:33.154 LabApp] zmq message arrived on closed channel
[W 18:55:33.154 LabApp] zmq message arrived on closed channel
[W 18:55:33.155 LabApp] zmq message arrived on closed channel
[W 18:55:33.155 LabApp] zmq message arrived on closed channel
[W 18:55:33.156 LabApp] zmq message arrived on closed channel
[W 18:55:33.156 LabApp] zmq message arrived on closed channel
[W 18:55:33.156 LabApp] zmq message arrived on closed channel
[W 18:55:33.157 LabApp] zmq message arrived on closed channel
[W 18:55:33.157 LabApp] zmq message arrived on closed channel
[W 18:55:33.158 LabApp] zmq message arrived on closed channel
[W 18:55:33.158 LabApp] zmq message arrived on closed channel
[W 18:55:33.159 LabApp] zmq message arrived on closed channel
[W 18:55:33.159 LabApp] zmq message arrived on closed channel
[W 18:55:33.160 LabApp] zmq message arrived on closed channel
[W 18:55:33.160 LabApp] zmq message arrived on closed channel
[W 18:55:33.161 LabApp] zmq message arrived on closed channel
[W 18:55:33.161 LabApp] zmq message arrived on closed channel
[W 18:55:33.161 LabApp] zmq message arrived on closed channel
[W 18:55:33.162 LabApp] zmq message arrived on closed channel
[W 18:55:33.162 LabApp] zmq message arrived on closed channel
[W 18:55:33.163 LabApp] zmq message arrived on closed channel
[W 18:55:33.163 LabApp] zmq message arrived on closed channel
[W 18:55:33.164 LabApp] zmq message arrived on closed channel
[W 18:55:33.164 LabApp] zmq message arrived on closed channel
[W 18:55:33.165 LabApp] zmq message arrived on closed channel
[W 18:55:33.165 LabApp] zmq message arrived on closed channel
[W 18:55:33.166 LabApp] zmq message arrived on closed channel
[W 18:55:33.166 LabApp] zmq message arrived on closed channel
[W 18:55:33.166 LabApp] zmq message arrived on closed channel
[W 18:55:33.167 LabApp] zmq message arrived on closed channel
[W 18:55:33.167 LabApp] zmq message arrived on closed channel
[W 18:55:33.168 LabApp] zmq message arrived on closed channel
[W 18:55:33.168 LabApp] zmq message arrived on closed channel
[W 18:55:33.169 LabApp] zmq message arrived on closed channel
[W 18:55:33.169 LabApp] zmq message arrived on closed channel
[W 18:55:33.170 LabApp] zmq message arrived on closed channel
[W 18:55:33.170 LabApp] zmq message arrived on closed channel
[W 18:55:33.171 LabApp] zmq message arrived on closed channel
[W 18:55:33.171 LabApp] zmq message arrived on closed channel
[W 18:55:33.172 LabApp] zmq message arrived on closed channel
[W 18:55:33.172 LabApp] zmq message arrived on closed channel
[W 18:55:33.172 LabApp] zmq message arrived on closed channel
[W 18:55:33.173 LabApp] zmq message arrived on closed channel
[W 18:55:33.173 LabApp] zmq message arrived on closed channel
[W 18:55:33.174 LabApp] zmq message arrived on closed channel
[W 18:55:33.174 LabApp] zmq message arrived on closed channel
[W 18:55:33.175 LabApp] zmq message arrived on closed channel
[W 18:55:33.175 LabApp] zmq message arrived on closed channel
[W 18:55:33.176 LabApp] zmq message arrived on closed channel
[W 18:55:33.176 LabApp] zmq message arrived on closed channel
[W 18:55:33.177 LabApp] zmq message arrived on closed channel
[W 18:55:33.177 LabApp] zmq message arrived on closed channel
[W 18:55:33.177 LabApp] zmq message arrived on closed channel
[W 18:55:33.178 LabApp] zmq message arrived on closed channel
[W 18:55:33.178 LabApp] zmq message arrived on closed channel
[W 18:55:33.179 LabApp] zmq message arrived on closed channel
[W 18:55:33.179 LabApp] zmq message arrived on closed channel
[W 18:55:33.180 LabApp] zmq message arrived on closed channel
[W 18:55:33.180 LabApp] zmq message arrived on closed channel
[W 18:55:33.181 LabApp] zmq message arrived on closed channel
[W 18:55:33.181 LabApp] zmq message arrived on closed channel
[W 18:55:33.182 LabApp] zmq message arrived on closed channel
[W 18:55:33.182 LabApp] zmq message arrived on closed channel
[W 18:55:33.182 LabApp] zmq message arrived on closed channel
[W 18:55:33.183 LabApp] zmq message arrived on closed channel
[W 18:55:33.183 LabApp] zmq message arrived on closed channel
[W 18:55:33.184 LabApp] zmq message arrived on closed channel
[W 18:55:33.184 LabApp] zmq message arrived on closed channel
[W 18:55:33.185 LabApp] zmq message arrived on closed channel
[W 18:55:33.185 LabApp] zmq message arrived on closed channel
[W 18:55:33.186 LabApp] zmq message arrived on closed channel
[W 18:55:33.186 LabApp] zmq message arrived on closed channel
[W 18:55:33.187 LabApp] zmq message arrived on closed channel
[W 18:55:33.187 LabApp] zmq message arrived on closed channel
[W 18:55:33.187 LabApp] zmq message arrived on closed channel
[W 18:55:33.188 LabApp] zmq message arrived on closed channel
[W 18:55:33.188 LabApp] zmq message arrived on closed channel
[W 18:55:33.189 LabApp] zmq message arrived on closed channel
[W 18:55:33.189 LabApp] zmq message arrived on closed channel
[W 18:55:33.190 LabApp] zmq message arrived on closed channel
[W 18:55:33.190 LabApp] zmq message arrived on closed channel
[W 18:55:33.191 LabApp] zmq message arrived on closed channel
[W 18:55:33.191 LabApp] zmq message arrived on closed channel
[W 18:55:33.192 LabApp] zmq message arrived on closed channel
[W 18:55:33.192 LabApp] zmq message arrived on closed channel
[W 18:55:33.193 LabApp] zmq message arrived on closed channel
[W 18:55:33.193 LabApp] zmq message arrived on closed channel
[W 18:55:33.193 LabApp] zmq message arrived on closed channel
[W 18:55:33.194 LabApp] zmq message arrived on closed channel
[W 18:55:33.194 LabApp] zmq message arrived on closed channel
[W 18:55:33.195 LabApp] zmq message arrived on closed channel
[W 18:55:33.195 LabApp] zmq message arrived on closed channel
[W 18:55:33.196 LabApp] zmq message arrived on closed channel
[W 18:55:33.196 LabApp] zmq message arrived on closed channel
[W 18:55:33.197 LabApp] zmq message arrived on closed channel
[W 18:55:33.197 LabApp] zmq message arrived on closed channel
[W 18:55:33.198 LabApp] zmq message arrived on closed channel
[W 18:55:33.198 LabApp] zmq message arrived on closed channel
[W 18:55:33.198 LabApp] zmq message arrived on closed channel
[W 18:55:33.199 LabApp] zmq message arrived on closed channel
[W 18:55:33.199 LabApp] zmq message arrived on closed channel
[W 18:55:33.200 LabApp] zmq message arrived on closed channel
[W 18:55:33.200 LabApp] zmq message arrived on closed channel
[W 18:55:33.201 LabApp] zmq message arrived on closed channel
[W 18:55:33.201 LabApp] zmq message arrived on closed channel
[W 18:55:33.202 LabApp] zmq message arrived on closed channel
[W 18:55:33.202 LabApp] zmq message arrived on closed channel
[W 18:55:33.203 LabApp] zmq message arrived on closed channel
[W 18:55:33.203 LabApp] zmq message arrived on closed channel
[W 18:55:33.203 LabApp] zmq message arrived on closed channel
[W 18:55:33.204 LabApp] zmq message arrived on closed channel
[W 18:55:33.204 LabApp] zmq message arrived on closed channel
[W 18:55:33.205 LabApp] zmq message arrived on closed channel
[W 18:55:33.205 LabApp] zmq message arrived on closed channel
[W 18:55:33.206 LabApp] zmq message arrived on closed channel
[W 18:55:33.206 LabApp] zmq message arrived on closed channel
[W 18:55:33.207 LabApp] zmq message arrived on closed channel
[W 18:55:33.207 LabApp] zmq message arrived on closed channel
[W 18:55:33.208 LabApp] zmq message arrived on closed channel
[W 18:55:33.208 LabApp] zmq message arrived on closed channel
[W 18:55:33.208 LabApp] zmq message arrived on closed channel
[W 18:55:33.209 LabApp] zmq message arrived on closed channel
[W 18:55:33.209 LabApp] zmq message arrived on closed channel
[W 18:55:33.210 LabApp] zmq message arrived on closed channel
[W 18:55:33.210 LabApp] zmq message arrived on closed channel
[W 18:55:33.211 LabApp] zmq message arrived on closed channel
[W 18:55:33.211 LabApp] zmq message arrived on closed channel
[W 18:55:33.212 LabApp] zmq message arrived on closed channel
[W 18:55:33.212 LabApp] zmq message arrived on closed channel
[W 18:55:33.213 LabApp] zmq message arrived on closed channel
[W 18:55:33.213 LabApp] zmq message arrived on closed channel
[W 18:55:33.214 LabApp] zmq message arrived on closed channel
[W 18:55:33.214 LabApp] zmq message arrived on closed channel
[W 18:55:33.214 LabApp] zmq message arrived on closed channel
[W 18:55:33.215 LabApp] zmq message arrived on closed channel
[W 18:55:33.215 LabApp] zmq message arrived on closed channel
[W 18:55:33.216 LabApp] zmq message arrived on closed channel
[W 18:55:33.216 LabApp] zmq message arrived on closed channel
[W 18:55:33.217 LabApp] zmq message arrived on closed channel
[W 18:55:33.217 LabApp] zmq message arrived on closed channel
[W 18:55:33.218 LabApp] zmq message arrived on closed channel
[W 18:55:33.218 LabApp] zmq message arrived on closed channel
[W 18:55:33.219 LabApp] zmq message arrived on closed channel
[W 18:55:33.219 LabApp] zmq message arrived on closed channel
[W 18:55:33.219 LabApp] zmq message arrived on closed channel
[W 18:55:33.220 LabApp] zmq message arrived on closed channel
[W 18:55:33.220 LabApp] zmq message arrived on closed channel
[W 18:55:33.221 LabApp] zmq message arrived on closed channel
[W 18:55:33.221 LabApp] zmq message arrived on closed channel
[W 18:55:33.222 LabApp] zmq message arrived on closed channel
[W 18:55:33.222 LabApp] zmq message arrived on closed channel
[W 18:55:33.223 LabApp] zmq message arrived on closed channel
[W 18:55:33.223 LabApp] zmq message arrived on closed channel
[W 18:55:33.224 LabApp] zmq message arrived on closed channel
[W 18:55:33.224 LabApp] zmq message arrived on closed channel
[W 18:55:33.224 LabApp] zmq message arrived on closed channel
[W 18:55:33.225 LabApp] zmq message arrived on closed channel
[W 18:55:33.225 LabApp] zmq message arrived on closed channel
[W 18:55:33.226 LabApp] zmq message arrived on closed channel
[W 18:55:33.226 LabApp] zmq message arrived on closed channel
[W 18:55:33.227 LabApp] zmq message arrived on closed channel
[W 18:55:33.227 LabApp] zmq message arrived on closed channel
[W 18:55:33.228 LabApp] zmq message arrived on closed channel
[W 18:55:33.228 LabApp] zmq message arrived on closed channel
[W 18:55:33.229 LabApp] zmq message arrived on closed channel
[W 18:55:33.229 LabApp] zmq message arrived on closed channel
[W 18:55:33.230 LabApp] zmq message arrived on closed channel
[W 18:55:33.230 LabApp] zmq message arrived on closed channel
[W 18:55:33.230 LabApp] zmq message arrived on closed channel
[W 18:55:33.231 LabApp] zmq message arrived on closed channel
[W 18:55:33.231 LabApp] zmq message arrived on closed channel
[W 18:55:33.232 LabApp] zmq message arrived on closed channel
[W 18:55:33.232 LabApp] zmq message arrived on closed channel
[W 18:55:33.233 LabApp] zmq message arrived on closed channel
[W 18:55:33.233 LabApp] zmq message arrived on closed channel
[W 18:55:33.234 LabApp] zmq message arrived on closed channel
[W 18:55:33.234 LabApp] zmq message arrived on closed channel
[W 18:55:33.235 LabApp] zmq message arrived on closed channel
[W 18:55:33.235 LabApp] zmq message arrived on closed channel
[W 18:55:33.235 LabApp] zmq message arrived on closed channel
[W 18:55:33.236 LabApp] zmq message arrived on closed channel
[W 18:55:33.236 LabApp] zmq message arrived on closed channel
[W 18:55:33.237 LabApp] zmq message arrived on closed channel
[W 18:55:33.237 LabApp] zmq message arrived on closed channel
[W 18:55:33.238 LabApp] zmq message arrived on closed channel
[W 18:55:33.238 LabApp] zmq message arrived on closed channel
[W 18:55:33.239 LabApp] zmq message arrived on closed channel
[W 18:55:33.239 LabApp] zmq message arrived on closed channel
[W 18:55:33.240 LabApp] zmq message arrived on closed channel
[W 18:55:33.240 LabApp] zmq message arrived on closed channel
[W 18:55:33.240 LabApp] zmq message arrived on closed channel
[W 18:55:33.241 LabApp] zmq message arrived on closed channel
[W 18:55:33.241 LabApp] zmq message arrived on closed channel
[W 18:55:33.242 LabApp] zmq message arrived on closed channel
[W 18:55:33.242 LabApp] zmq message arrived on closed channel
[W 18:55:33.243 LabApp] zmq message arrived on closed channel
[W 18:55:33.243 LabApp] zmq message arrived on closed channel
[W 18:55:33.244 LabApp] zmq message arrived on closed channel
[W 18:55:33.244 LabApp] zmq message arrived on closed channel
[W 18:55:33.245 LabApp] zmq message arrived on closed channel
[W 18:55:33.245 LabApp] zmq message arrived on closed channel
[W 18:55:33.246 LabApp] zmq message arrived on closed channel
[W 18:55:33.246 LabApp] zmq message arrived on closed channel
[W 18:55:33.246 LabApp] zmq message arrived on closed channel
[W 18:55:33.247 LabApp] zmq message arrived on closed channel
[W 18:55:33.247 LabApp] zmq message arrived on closed channel
[W 18:55:33.248 LabApp] zmq message arrived on closed channel
[W 18:55:33.248 LabApp] zmq message arrived on closed channel
[W 18:55:33.249 LabApp] zmq message arrived on closed channel
[W 18:55:33.249 LabApp] zmq message arrived on closed channel
[W 18:55:33.250 LabApp] zmq message arrived on closed channel
[W 18:55:33.250 LabApp] zmq message arrived on closed channel
[W 18:55:33.251 LabApp] zmq message arrived on closed channel
[W 18:55:33.251 LabApp] zmq message arrived on closed channel
[W 18:55:33.251 LabApp] zmq message arrived on closed channel
[W 18:55:33.252 LabApp] zmq message arrived on closed channel
[W 18:55:33.252 LabApp] zmq message arrived on closed channel
[W 18:55:33.253 LabApp] zmq message arrived on closed channel
[W 18:55:33.253 LabApp] zmq message arrived on closed channel
[W 18:55:33.254 LabApp] zmq message arrived on closed channel
[W 18:55:33.254 LabApp] zmq message arrived on closed channel
[W 18:55:33.255 LabApp] zmq message arrived on closed channel
[W 18:55:33.255 LabApp] zmq message arrived on closed channel
[W 18:55:33.256 LabApp] zmq message arrived on closed channel
[W 18:55:33.256 LabApp] zmq message arrived on closed channel
[W 18:55:33.256 LabApp] zmq message arrived on closed channel
[W 18:55:33.257 LabApp] zmq message arrived on closed channel
[W 18:55:33.257 LabApp] zmq message arrived on closed channel
[W 18:55:33.258 LabApp] zmq message arrived on closed channel
[W 18:55:33.258 LabApp] zmq message arrived on closed channel
[W 18:55:33.259 LabApp] zmq message arrived on closed channel
[W 18:55:33.259 LabApp] zmq message arrived on closed channel
[W 18:55:33.260 LabApp] zmq message arrived on closed channel
[W 18:55:33.260 LabApp] zmq message arrived on closed channel
[W 18:55:33.261 LabApp] zmq message arrived on closed channel
[W 18:55:33.261 LabApp] zmq message arrived on closed channel
[W 18:55:33.261 LabApp] zmq message arrived on closed channel
[W 18:55:33.262 LabApp] zmq message arrived on closed channel
[W 18:55:33.262 LabApp] zmq message arrived on closed channel
[W 18:55:33.263 LabApp] zmq message arrived on closed channel
[W 18:55:33.263 LabApp] zmq message arrived on closed channel
[W 18:55:33.264 LabApp] zmq message arrived on closed channel
[W 18:55:33.264 LabApp] zmq message arrived on closed channel
[W 18:55:33.265 LabApp] zmq message arrived on closed channel
[W 18:55:33.265 LabApp] zmq message arrived on closed channel
[W 18:55:33.266 LabApp] zmq message arrived on closed channel
[W 18:55:33.266 LabApp] zmq message arrived on closed channel
[W 18:55:33.267 LabApp] zmq message arrived on closed channel
[W 18:55:33.267 LabApp] zmq message arrived on closed channel
[W 18:55:33.268 LabApp] zmq message arrived on closed channel
[W 18:55:33.268 LabApp] zmq message arrived on closed channel
[W 18:55:33.268 LabApp] zmq message arrived on closed channel
[W 18:55:33.269 LabApp] zmq message arrived on closed channel
[W 18:55:33.269 LabApp] zmq message arrived on closed channel
[W 18:55:33.270 LabApp] zmq message arrived on closed channel
[W 18:55:33.270 LabApp] zmq message arrived on closed channel
[W 18:55:33.271 LabApp] zmq message arrived on closed channel
[W 18:55:33.271 LabApp] zmq message arrived on closed channel
[W 18:55:33.272 LabApp] zmq message arrived on closed channel
[W 18:55:33.272 LabApp] zmq message arrived on closed channel
[W 18:55:33.273 LabApp] zmq message arrived on closed channel
[W 18:55:33.273 LabApp] zmq message arrived on closed channel
[W 18:55:33.273 LabApp] zmq message arrived on closed channel
[W 18:55:33.274 LabApp] zmq message arrived on closed channel
[W 18:55:33.274 LabApp] zmq message arrived on closed channel
[W 18:55:33.275 LabApp] zmq message arrived on closed channel
[W 18:55:33.275 LabApp] zmq message arrived on closed channel
[W 18:55:33.276 LabApp] zmq message arrived on closed channel
[W 18:55:33.276 LabApp] zmq message arrived on closed channel
[W 18:55:33.277 LabApp] zmq message arrived on closed channel
[W 18:55:33.277 LabApp] zmq message arrived on closed channel
[W 18:55:33.278 LabApp] zmq message arrived on closed channel
[W 18:55:33.278 LabApp] zmq message arrived on closed channel
[W 18:55:33.279 LabApp] zmq message arrived on closed channel
[W 18:55:33.279 LabApp] zmq message arrived on closed channel
[W 18:55:33.280 LabApp] zmq message arrived on closed channel
[W 18:55:33.280 LabApp] zmq message arrived on closed channel
[W 18:55:33.280 LabApp] zmq message arrived on closed channel
[W 18:55:33.281 LabApp] zmq message arrived on closed channel
[W 18:55:33.281 LabApp] zmq message arrived on closed channel
[W 18:55:33.282 LabApp] zmq message arrived on closed channel
[W 18:55:33.282 LabApp] zmq message arrived on closed channel
[W 18:55:33.283 LabApp] zmq message arrived on closed channel
[W 18:55:33.283 LabApp] zmq message arrived on closed channel
[W 18:55:33.284 LabApp] zmq message arrived on closed channel
[W 18:55:33.284 LabApp] zmq message arrived on closed channel
[W 18:55:33.285 LabApp] zmq message arrived on closed channel
[W 18:55:33.285 LabApp] zmq message arrived on closed channel
[W 18:55:33.285 LabApp] zmq message arrived on closed channel
[W 18:55:33.286 LabApp] zmq message arrived on closed channel
[W 18:55:33.286 LabApp] zmq message arrived on closed channel
[W 18:55:33.287 LabApp] zmq message arrived on closed channel
[W 18:55:33.287 LabApp] zmq message arrived on closed channel
[W 18:55:33.288 LabApp] zmq message arrived on closed channel
[W 18:55:33.288 LabApp] zmq message arrived on closed channel
[W 18:55:33.289 LabApp] zmq message arrived on closed channel
[W 18:55:33.289 LabApp] zmq message arrived on closed channel
[W 18:55:33.290 LabApp] zmq message arrived on closed channel
[W 18:55:33.290 LabApp] zmq message arrived on closed channel
[W 18:55:33.291 LabApp] zmq message arrived on closed channel
[W 18:55:33.291 LabApp] zmq message arrived on closed channel
[W 18:55:33.291 LabApp] zmq message arrived on closed channel
[W 18:55:33.292 LabApp] zmq message arrived on closed channel
[W 18:55:33.292 LabApp] zmq message arrived on closed channel
[W 18:55:33.293 LabApp] zmq message arrived on closed channel
[W 18:55:33.293 LabApp] zmq message arrived on closed channel
[W 18:55:33.294 LabApp] zmq message arrived on closed channel
[W 18:55:33.294 LabApp] zmq message arrived on closed channel
[W 18:55:33.295 LabApp] zmq message arrived on closed channel
[W 18:55:33.295 LabApp] zmq message arrived on closed channel
[W 18:55:33.296 LabApp] zmq message arrived on closed channel
[W 18:55:33.296 LabApp] zmq message arrived on closed channel
[W 18:55:33.297 LabApp] zmq message arrived on closed channel
[W 18:55:33.297 LabApp] zmq message arrived on closed channel
[W 18:55:33.297 LabApp] zmq message arrived on closed channel
[W 18:55:33.298 LabApp] zmq message arrived on closed channel
[W 18:55:33.298 LabApp] zmq message arrived on closed channel
[W 18:55:33.299 LabApp] zmq message arrived on closed channel
[W 18:55:33.299 LabApp] zmq message arrived on closed channel
[W 18:55:33.300 LabApp] zmq message arrived on closed channel
[W 18:55:33.300 LabApp] zmq message arrived on closed channel
[W 18:55:33.301 LabApp] zmq message arrived on closed channel
[W 18:55:33.301 LabApp] zmq message arrived on closed channel
[W 18:55:33.302 LabApp] zmq message arrived on closed channel
[W 18:55:33.302 LabApp] zmq message arrived on closed channel
[W 18:55:33.303 LabApp] zmq message arrived on closed channel
[W 18:55:33.303 LabApp] zmq message arrived on closed channel
[W 18:55:33.303 LabApp] zmq message arrived on closed channel
[W 18:55:33.304 LabApp] zmq message arrived on closed channel
[W 18:55:33.304 LabApp] zmq message arrived on closed channel
[W 18:55:33.305 LabApp] zmq message arrived on closed channel
[W 18:55:33.305 LabApp] zmq message arrived on closed channel
[W 18:55:33.306 LabApp] zmq message arrived on closed channel
[W 18:55:33.306 LabApp] zmq message arrived on closed channel
[W 18:55:33.307 LabApp] zmq message arrived on closed channel
[W 18:55:33.307 LabApp] zmq message arrived on closed channel
[W 18:55:33.308 LabApp] zmq message arrived on closed channel
[W 18:55:33.308 LabApp] zmq message arrived on closed channel
[W 18:55:33.308 LabApp] zmq message arrived on closed channel
[W 18:55:33.309 LabApp] zmq message arrived on closed channel
[W 18:55:33.309 LabApp] zmq message arrived on closed channel
[W 18:55:33.310 LabApp] zmq message arrived on closed channel
[W 18:55:33.310 LabApp] zmq message arrived on closed channel
[W 18:55:33.311 LabApp] zmq message arrived on closed channel
[W 18:55:33.311 LabApp] zmq message arrived on closed channel
[W 18:55:33.312 LabApp] zmq message arrived on closed channel
[W 18:55:33.312 LabApp] zmq message arrived on closed channel
[W 18:55:33.313 LabApp] zmq message arrived on closed channel
[W 18:55:33.313 LabApp] zmq message arrived on closed channel
[W 18:55:33.313 LabApp] zmq message arrived on closed channel
[W 18:55:33.314 LabApp] zmq message arrived on closed channel
[W 18:55:33.314 LabApp] zmq message arrived on closed channel
[W 18:55:33.315 LabApp] zmq message arrived on closed channel
[W 18:55:33.315 LabApp] zmq message arrived on closed channel
[W 18:55:33.316 LabApp] zmq message arrived on closed channel
[W 18:55:33.316 LabApp] zmq message arrived on closed channel
[W 18:55:33.317 LabApp] zmq message arrived on closed channel
[W 18:55:33.317 LabApp] zmq message arrived on closed channel
[W 18:55:33.318 LabApp] zmq message arrived on closed channel
[W 18:55:33.318 LabApp] zmq message arrived on closed channel
[W 18:55:33.318 LabApp] zmq message arrived on closed channel
[W 18:55:33.319 LabApp] zmq message arrived on closed channel
[W 18:55:33.319 LabApp] zmq message arrived on closed channel
[W 18:55:33.320 LabApp] zmq message arrived on closed channel
[W 18:55:33.320 LabApp] zmq message arrived on closed channel
[W 18:55:33.321 LabApp] zmq message arrived on closed channel
[W 18:55:33.321 LabApp] zmq message arrived on closed channel
[W 18:55:33.322 LabApp] zmq message arrived on closed channel
[W 18:55:33.322 LabApp] zmq message arrived on closed channel
[W 18:55:33.323 LabApp] zmq message arrived on closed channel
[W 18:55:33.323 LabApp] zmq message arrived on closed channel
[W 18:55:33.323 LabApp] zmq message arrived on closed channel
[W 18:55:33.324 LabApp] zmq message arrived on closed channel
[W 18:55:33.324 LabApp] zmq message arrived on closed channel
[W 18:55:33.325 LabApp] zmq message arrived on closed channel
[W 18:55:33.325 LabApp] zmq message arrived on closed channel
[W 18:55:33.326 LabApp] zmq message arrived on closed channel
[W 18:55:33.326 LabApp] zmq message arrived on closed channel
[W 18:55:33.327 LabApp] zmq message arrived on closed channel
[W 18:55:33.327 LabApp] zmq message arrived on closed channel
[W 18:55:33.328 LabApp] zmq message arrived on closed channel
[W 18:55:33.328 LabApp] zmq message arrived on closed channel
[W 18:55:33.328 LabApp] zmq message arrived on closed channel
[W 18:55:33.329 LabApp] zmq message arrived on closed channel
[W 18:55:33.329 LabApp] zmq message arrived on closed channel
[W 18:55:33.330 LabApp] zmq message arrived on closed channel
[W 18:55:33.330 LabApp] zmq message arrived on closed channel
[W 18:55:33.331 LabApp] zmq message arrived on closed channel
[W 18:55:33.331 LabApp] zmq message arrived on closed channel
[W 18:55:33.332 LabApp] zmq message arrived on closed channel
[W 18:55:33.332 LabApp] zmq message arrived on closed channel
[W 18:55:33.333 LabApp] zmq message arrived on closed channel
[W 18:55:33.333 LabApp] zmq message arrived on closed channel
[W 18:55:33.333 LabApp] zmq message arrived on closed channel
[W 18:55:33.334 LabApp] zmq message arrived on closed channel
[W 18:55:33.334 LabApp] zmq message arrived on closed channel
[W 18:55:33.335 LabApp] zmq message arrived on closed channel
[W 18:55:33.335 LabApp] zmq message arrived on closed channel
[W 18:55:33.336 LabApp] zmq message arrived on closed channel
[W 18:55:33.336 LabApp] zmq message arrived on closed channel
[W 18:55:33.337 LabApp] zmq message arrived on closed channel
[W 18:55:33.337 LabApp] zmq message arrived on closed channel
[W 18:55:33.338 LabApp] zmq message arrived on closed channel
[W 18:55:33.338 LabApp] zmq message arrived on closed channel
[W 18:55:33.339 LabApp] zmq message arrived on closed channel
[W 18:55:33.339 LabApp] zmq message arrived on closed channel
[W 18:55:33.339 LabApp] zmq message arrived on closed channel
[W 18:55:33.340 LabApp] zmq message arrived on closed channel
[W 18:55:33.340 LabApp] zmq message arrived on closed channel
[W 18:55:33.341 LabApp] zmq message arrived on closed channel
[W 18:55:33.341 LabApp] zmq message arrived on closed channel
[W 18:55:33.342 LabApp] zmq message arrived on closed channel
[W 18:55:33.342 LabApp] zmq message arrived on closed channel
[W 18:55:33.343 LabApp] zmq message arrived on closed channel
[W 18:55:33.343 LabApp] zmq message arrived on closed channel
[W 18:55:33.344 LabApp] zmq message arrived on closed channel
[W 18:55:33.344 LabApp] zmq message arrived on closed channel
[W 18:55:33.344 LabApp] zmq message arrived on closed channel
[W 18:55:33.345 LabApp] zmq message arrived on closed channel
[W 18:55:33.345 LabApp] zmq message arrived on closed channel
[W 18:55:33.346 LabApp] zmq message arrived on closed channel
[W 18:55:33.346 LabApp] zmq message arrived on closed channel
[W 18:55:33.347 LabApp] zmq message arrived on closed channel
[W 18:55:33.347 LabApp] zmq message arrived on closed channel
[W 18:55:33.348 LabApp] zmq message arrived on closed channel
[W 18:55:33.348 LabApp] zmq message arrived on closed channel
[W 18:55:33.349 LabApp] zmq message arrived on closed channel
[W 18:55:33.349 LabApp] zmq message arrived on closed channel
[W 18:55:33.349 LabApp] zmq message arrived on closed channel
[W 18:55:33.350 LabApp] zmq message arrived on closed channel
[W 18:55:33.350 LabApp] zmq message arrived on closed channel
[W 18:55:33.351 LabApp] zmq message arrived on closed channel
[W 18:55:33.351 LabApp] zmq message arrived on closed channel
[W 18:55:33.352 LabApp] zmq message arrived on closed channel
[W 18:55:33.352 LabApp] zmq message arrived on closed channel
[W 18:55:33.353 LabApp] zmq message arrived on closed channel
[W 18:55:33.353 LabApp] zmq message arrived on closed channel
[W 18:55:33.354 LabApp] zmq message arrived on closed channel
[W 18:55:33.354 LabApp] zmq message arrived on closed channel
[W 18:55:33.354 LabApp] zmq message arrived on closed channel
[W 18:55:33.355 LabApp] zmq message arrived on closed channel
[W 18:55:33.355 LabApp] zmq message arrived on closed channel
[W 18:55:33.356 LabApp] zmq message arrived on closed channel
[W 18:55:33.356 LabApp] zmq message arrived on closed channel
[W 18:55:33.357 LabApp] zmq message arrived on closed channel
[W 18:55:33.357 LabApp] zmq message arrived on closed channel
[W 18:55:33.358 LabApp] zmq message arrived on closed channel
[W 18:55:33.358 LabApp] zmq message arrived on closed channel
[W 18:55:33.359 LabApp] zmq message arrived on closed channel
[W 18:55:33.359 LabApp] zmq message arrived on closed channel
[W 18:55:33.359 LabApp] zmq message arrived on closed channel
[W 18:55:33.360 LabApp] zmq message arrived on closed channel
[W 18:55:33.360 LabApp] zmq message arrived on closed channel
[W 18:55:33.361 LabApp] zmq message arrived on closed channel
[W 18:55:33.361 LabApp] zmq message arrived on closed channel
[W 18:55:33.362 LabApp] zmq message arrived on closed channel
[W 18:55:33.362 LabApp] zmq message arrived on closed channel
[W 18:55:33.363 LabApp] zmq message arrived on closed channel
[W 18:55:33.363 LabApp] zmq message arrived on closed channel
[W 18:55:33.364 LabApp] zmq message arrived on closed channel
[W 18:55:33.364 LabApp] zmq message arrived on closed channel
[W 18:55:33.364 LabApp] zmq message arrived on closed channel
[W 18:55:33.365 LabApp] zmq message arrived on closed channel
[W 18:55:33.365 LabApp] zmq message arrived on closed channel
[W 18:55:33.366 LabApp] zmq message arrived on closed channel
[W 18:55:33.366 LabApp] zmq message arrived on closed channel
[W 18:55:33.367 LabApp] zmq message arrived on closed channel
[W 18:55:33.367 LabApp] zmq message arrived on closed channel
[W 18:55:33.368 LabApp] zmq message arrived on closed channel
[W 18:55:33.368 LabApp] zmq message arrived on closed channel
[W 18:55:33.369 LabApp] zmq message arrived on closed channel
[W 18:55:33.369 LabApp] zmq message arrived on closed channel
[W 18:55:33.369 LabApp] zmq message arrived on closed channel
[W 18:55:33.370 LabApp] zmq message arrived on closed channel
[W 18:55:33.370 LabApp] zmq message arrived on closed channel
[W 18:55:33.371 LabApp] zmq message arrived on closed channel
[W 18:55:33.371 LabApp] zmq message arrived on closed channel
[W 18:55:33.372 LabApp] zmq message arrived on closed channel
[W 18:55:33.372 LabApp] zmq message arrived on closed channel
[W 18:55:33.373 LabApp] zmq message arrived on closed channel
[W 18:55:33.373 LabApp] zmq message arrived on closed channel
[W 18:55:33.374 LabApp] zmq message arrived on closed channel
[W 18:55:33.374 LabApp] zmq message arrived on closed channel
[W 18:55:33.375 LabApp] zmq message arrived on closed channel
[W 18:55:33.375 LabApp] zmq message arrived on closed channel
[W 18:55:33.375 LabApp] zmq message arrived on closed channel
[W 18:55:33.376 LabApp] zmq message arrived on closed channel
[W 18:55:33.376 LabApp] zmq message arrived on closed channel
[W 18:55:33.377 LabApp] zmq message arrived on closed channel
[W 18:55:33.377 LabApp] zmq message arrived on closed channel
[W 18:55:33.378 LabApp] zmq message arrived on closed channel
[W 18:55:33.378 LabApp] zmq message arrived on closed channel
[W 18:55:33.379 LabApp] zmq message arrived on closed channel
[W 18:55:33.379 LabApp] zmq message arrived on closed channel
[W 18:55:33.380 LabApp] zmq message arrived on closed channel
[W 18:55:33.380 LabApp] zmq message arrived on closed channel
[W 18:55:33.381 LabApp] zmq message arrived on closed channel
[W 18:55:33.381 LabApp] zmq message arrived on closed channel
[W 18:55:33.381 LabApp] zmq message arrived on closed channel
[W 18:55:33.382 LabApp] zmq message arrived on closed channel
[W 18:55:33.382 LabApp] zmq message arrived on closed channel
[W 18:55:33.383 LabApp] zmq message arrived on closed channel
[W 18:55:33.383 LabApp] zmq message arrived on closed channel
[W 18:55:33.384 LabApp] zmq message arrived on closed channel
[W 18:55:33.384 LabApp] zmq message arrived on closed channel
[W 18:55:33.385 LabApp] zmq message arrived on closed channel
[W 18:55:33.385 LabApp] zmq message arrived on closed channel
[W 18:55:33.386 LabApp] zmq message arrived on closed channel
[W 18:55:33.386 LabApp] zmq message arrived on closed channel
[W 18:55:33.386 LabApp] zmq message arrived on closed channel
[W 18:55:33.387 LabApp] zmq message arrived on closed channel
[W 18:55:33.387 LabApp] zmq message arrived on closed channel
[W 18:55:33.388 LabApp] zmq message arrived on closed channel
[W 18:55:33.388 LabApp] zmq message arrived on closed channel
[W 18:55:33.389 LabApp] zmq message arrived on closed channel
[W 18:55:33.389 LabApp] zmq message arrived on closed channel
[W 18:55:33.390 LabApp] zmq message arrived on closed channel
[W 18:55:33.390 LabApp] zmq message arrived on closed channel
[W 18:55:33.391 LabApp] zmq message arrived on closed channel
[W 18:55:33.391 LabApp] zmq message arrived on closed channel
[W 18:55:33.392 LabApp] zmq message arrived on closed channel
[W 18:55:33.392 LabApp] zmq message arrived on closed channel
[W 18:55:33.393 LabApp] zmq message arrived on closed channel
[W 18:55:33.393 LabApp] zmq message arrived on closed channel
[W 18:55:33.393 LabApp] zmq message arrived on closed channel
[W 18:55:33.394 LabApp] zmq message arrived on closed channel
[W 18:55:33.394 LabApp] zmq message arrived on closed channel
[W 18:55:33.395 LabApp] zmq message arrived on closed channel
[W 18:55:33.395 LabApp] zmq message arrived on closed channel
[W 18:55:33.396 LabApp] zmq message arrived on closed channel
[W 18:55:33.396 LabApp] zmq message arrived on closed channel
[W 18:55:33.397 LabApp] zmq message arrived on closed channel
[W 18:55:33.397 LabApp] zmq message arrived on closed channel
[W 18:55:33.398 LabApp] zmq message arrived on closed channel
[W 18:55:33.398 LabApp] zmq message arrived on closed channel
[W 18:55:33.398 LabApp] zmq message arrived on closed channel
[W 18:55:33.399 LabApp] zmq message arrived on closed channel
[W 18:55:33.399 LabApp] zmq message arrived on closed channel
[W 18:55:33.400 LabApp] zmq message arrived on closed channel
[W 18:55:33.400 LabApp] zmq message arrived on closed channel
[W 18:55:33.401 LabApp] zmq message arrived on closed channel
[W 18:55:33.401 LabApp] zmq message arrived on closed channel
[W 18:55:33.402 LabApp] zmq message arrived on closed channel
[W 18:55:33.402 LabApp] zmq message arrived on closed channel
[W 18:55:33.403 LabApp] zmq message arrived on closed channel
[W 18:55:33.403 LabApp] zmq message arrived on closed channel
[W 18:55:33.404 LabApp] zmq message arrived on closed channel
[W 18:55:33.404 LabApp] zmq message arrived on closed channel
[W 18:55:33.404 LabApp] zmq message arrived on closed channel
[W 18:55:33.405 LabApp] zmq message arrived on closed channel
[W 18:55:33.405 LabApp] zmq message arrived on closed channel
[W 18:55:33.406 LabApp] zmq message arrived on closed channel
[W 18:55:33.406 LabApp] zmq message arrived on closed channel
[W 18:55:33.407 LabApp] zmq message arrived on closed channel
[W 18:55:33.407 LabApp] zmq message arrived on closed channel
[W 18:55:33.408 LabApp] zmq message arrived on closed channel
[W 18:55:33.408 LabApp] zmq message arrived on closed channel
[W 18:55:33.409 LabApp] zmq message arrived on closed channel
[W 18:55:33.409 LabApp] zmq message arrived on closed channel
[W 18:55:33.409 LabApp] zmq message arrived on closed channel
[W 18:55:33.410 LabApp] zmq message arrived on closed channel
[W 18:55:33.410 LabApp] zmq message arrived on closed channel
[W 18:55:33.411 LabApp] zmq message arrived on closed channel
[W 18:55:33.411 LabApp] zmq message arrived on closed channel
[W 18:55:33.412 LabApp] zmq message arrived on closed channel
[W 18:55:33.412 LabApp] zmq message arrived on closed channel
[W 18:55:33.413 LabApp] zmq message arrived on closed channel
[W 18:55:33.413 LabApp] zmq message arrived on closed channel
[W 18:55:33.414 LabApp] zmq message arrived on closed channel
[W 18:55:33.414 LabApp] zmq message arrived on closed channel
[W 18:55:33.414 LabApp] zmq message arrived on closed channel
[W 18:55:33.415 LabApp] zmq message arrived on closed channel
[W 18:55:33.415 LabApp] zmq message arrived on closed channel
[W 18:55:33.416 LabApp] zmq message arrived on closed channel
[W 18:55:33.416 LabApp] zmq message arrived on closed channel
[W 18:55:33.417 LabApp] zmq message arrived on closed channel
[W 18:55:33.417 LabApp] zmq message arrived on closed channel
[W 18:55:33.418 LabApp] zmq message arrived on closed channel
[W 18:55:33.418 LabApp] zmq message arrived on closed channel
[W 18:55:33.419 LabApp] zmq message arrived on closed channel
[W 18:55:33.419 LabApp] zmq message arrived on closed channel
[W 18:55:33.419 LabApp] zmq message arrived on closed channel
[W 18:55:33.420 LabApp] zmq message arrived on closed channel
[W 18:55:33.420 LabApp] zmq message arrived on closed channel
[W 18:55:33.421 LabApp] zmq message arrived on closed channel
[W 18:55:33.421 LabApp] zmq message arrived on closed channel
[W 18:55:33.422 LabApp] zmq message arrived on closed channel
[W 18:55:33.422 LabApp] zmq message arrived on closed channel
[W 18:55:33.423 LabApp] zmq message arrived on closed channel
[W 18:55:33.423 LabApp] zmq message arrived on closed channel
[W 18:55:33.424 LabApp] zmq message arrived on closed channel
[W 18:55:33.424 LabApp] zmq message arrived on closed channel
[W 18:55:33.425 LabApp] zmq message arrived on closed channel
[W 18:55:33.425 LabApp] zmq message arrived on closed channel
[W 18:55:33.425 LabApp] zmq message arrived on closed channel
[W 18:55:33.426 LabApp] zmq message arrived on closed channel
[W 18:55:33.426 LabApp] zmq message arrived on closed channel
[W 18:55:33.427 LabApp] zmq message arrived on closed channel
[W 18:55:33.427 LabApp] zmq message arrived on closed channel
[W 18:55:33.428 LabApp] zmq message arrived on closed channel
[W 18:55:33.428 LabApp] zmq message arrived on closed channel
[W 18:55:33.429 LabApp] zmq message arrived on closed channel
[W 18:55:33.429 LabApp] zmq message arrived on closed channel
[W 18:55:33.430 LabApp] zmq message arrived on closed channel
[W 18:55:33.430 LabApp] zmq message arrived on closed channel
[W 18:55:33.430 LabApp] zmq message arrived on closed channel
[W 18:55:33.431 LabApp] zmq message arrived on closed channel
[W 18:55:33.431 LabApp] zmq message arrived on closed channel
[W 18:55:33.432 LabApp] zmq message arrived on closed channel
[W 18:55:33.432 LabApp] zmq message arrived on closed channel
[W 18:55:33.433 LabApp] zmq message arrived on closed channel
[W 18:55:33.433 LabApp] zmq message arrived on closed channel
[W 18:55:33.434 LabApp] zmq message arrived on closed channel
[W 18:55:33.434 LabApp] zmq message arrived on closed channel
[W 18:55:33.435 LabApp] zmq message arrived on closed channel
[W 18:55:33.435 LabApp] zmq message arrived on closed channel
[W 18:55:33.435 LabApp] zmq message arrived on closed channel
[W 18:55:33.436 LabApp] zmq message arrived on closed channel
[W 18:55:33.436 LabApp] zmq message arrived on closed channel
[W 18:55:33.437 LabApp] zmq message arrived on closed channel
[W 18:55:33.437 LabApp] zmq message arrived on closed channel
[W 18:55:33.438 LabApp] zmq message arrived on closed channel
[W 18:55:33.438 LabApp] zmq message arrived on closed channel
[W 18:55:33.439 LabApp] zmq message arrived on closed channel
[W 18:55:33.439 LabApp] zmq message arrived on closed channel
[W 18:55:33.440 LabApp] zmq message arrived on closed channel
[W 18:55:33.440 LabApp] zmq message arrived on closed channel
[W 18:55:33.441 LabApp] zmq message arrived on closed channel
[W 18:55:33.441 LabApp] zmq message arrived on closed channel
[W 18:55:33.441 LabApp] zmq message arrived on closed channel
[W 18:55:33.442 LabApp] zmq message arrived on closed channel
[W 18:55:33.442 LabApp] zmq message arrived on closed channel
[W 18:55:33.443 LabApp] zmq message arrived on closed channel
[W 18:55:33.443 LabApp] zmq message arrived on closed channel
[W 18:55:33.444 LabApp] zmq message arrived on closed channel
[W 18:55:33.444 LabApp] zmq message arrived on closed channel
[W 18:55:33.445 LabApp] zmq message arrived on closed channel
[W 18:55:33.445 LabApp] zmq message arrived on closed channel
[W 18:55:33.446 LabApp] zmq message arrived on closed channel
[W 18:55:33.446 LabApp] zmq message arrived on closed channel
[W 18:55:33.446 LabApp] zmq message arrived on closed channel
[W 18:55:33.447 LabApp] zmq message arrived on closed channel
[W 18:55:33.447 LabApp] zmq message arrived on closed channel
[W 18:55:33.448 LabApp] zmq message arrived on closed channel
[W 18:55:33.448 LabApp] zmq message arrived on closed channel
[W 18:55:33.449 LabApp] zmq message arrived on closed channel
[W 18:55:33.449 LabApp] zmq message arrived on closed channel
[W 18:55:33.450 LabApp] zmq message arrived on closed channel
[W 18:55:33.450 LabApp] zmq message arrived on closed channel
[W 18:55:33.451 LabApp] zmq message arrived on closed channel
[W 18:55:33.451 LabApp] zmq message arrived on closed channel
[W 18:55:33.452 LabApp] zmq message arrived on closed channel
[W 18:55:33.452 LabApp] zmq message arrived on closed channel
[W 18:55:33.452 LabApp] zmq message arrived on closed channel
[W 18:55:33.453 LabApp] zmq message arrived on closed channel
[W 18:55:33.453 LabApp] zmq message arrived on closed channel
[W 18:55:33.454 LabApp] zmq message arrived on closed channel
[W 18:55:33.454 LabApp] zmq message arrived on closed channel
[W 18:55:33.455 LabApp] zmq message arrived on closed channel
[W 18:55:33.455 LabApp] zmq message arrived on closed channel
[W 18:55:33.456 LabApp] zmq message arrived on closed channel
[W 18:55:33.456 LabApp] zmq message arrived on closed channel
[W 18:55:33.457 LabApp] zmq message arrived on closed channel
[W 18:55:33.457 LabApp] zmq message arrived on closed channel
[W 18:55:33.457 LabApp] zmq message arrived on closed channel
[W 18:55:33.458 LabApp] zmq message arrived on closed channel
[W 18:55:33.458 LabApp] zmq message arrived on closed channel
[W 18:55:33.459 LabApp] zmq message arrived on closed channel
[W 18:55:33.459 LabApp] zmq message arrived on closed channel
[W 18:55:33.460 LabApp] zmq message arrived on closed channel
[W 18:55:33.460 LabApp] zmq message arrived on closed channel
[W 18:55:33.461 LabApp] zmq message arrived on closed channel
[W 18:55:33.461 LabApp] zmq message arrived on closed channel
[W 18:55:33.462 LabApp] zmq message arrived on closed channel
[W 18:55:33.462 LabApp] zmq message arrived on closed channel
[W 18:55:33.462 LabApp] zmq message arrived on closed channel
[W 18:55:33.463 LabApp] zmq message arrived on closed channel
[W 18:55:33.463 LabApp] zmq message arrived on closed channel
[W 18:55:33.464 LabApp] zmq message arrived on closed channel
[W 18:55:33.464 LabApp] zmq message arrived on closed channel
[W 18:55:33.465 LabApp] zmq message arrived on closed channel
[W 18:55:33.465 LabApp] zmq message arrived on closed channel
[W 18:55:33.466 LabApp] zmq message arrived on closed channel
[W 18:55:33.466 LabApp] zmq message arrived on closed channel
[W 18:55:33.467 LabApp] zmq message arrived on closed channel
[W 18:55:33.467 LabApp] zmq message arrived on closed channel
[W 18:55:33.468 LabApp] zmq message arrived on closed channel
[W 18:55:33.468 LabApp] zmq message arrived on closed channel
[W 18:55:33.468 LabApp] zmq message arrived on closed channel
[W 18:55:33.469 LabApp] zmq message arrived on closed channel
[W 18:55:33.469 LabApp] zmq message arrived on closed channel
[W 18:55:33.470 LabApp] zmq message arrived on closed channel
[W 18:55:33.470 LabApp] zmq message arrived on closed channel
[W 18:55:33.471 LabApp] zmq message arrived on closed channel
[W 18:55:33.471 LabApp] zmq message arrived on closed channel
[W 18:55:33.472 LabApp] zmq message arrived on closed channel
[W 18:55:33.472 LabApp] zmq message arrived on closed channel
[W 18:55:33.473 LabApp] zmq message arrived on closed channel
[W 18:55:33.473 LabApp] zmq message arrived on closed channel
[W 18:55:33.473 LabApp] zmq message arrived on closed channel
[W 18:55:33.474 LabApp] zmq message arrived on closed channel
[W 18:55:33.474 LabApp] zmq message arrived on closed channel
[W 18:55:33.475 LabApp] zmq message arrived on closed channel
[W 18:55:33.475 LabApp] zmq message arrived on closed channel
[W 18:55:33.476 LabApp] zmq message arrived on closed channel
[W 18:55:33.476 LabApp] zmq message arrived on closed channel
[W 18:55:33.477 LabApp] zmq message arrived on closed channel
[W 18:55:33.477 LabApp] zmq message arrived on closed channel
[W 18:55:33.478 LabApp] zmq message arrived on closed channel
[W 18:55:33.478 LabApp] zmq message arrived on closed channel
[W 18:55:33.479 LabApp] zmq message arrived on closed channel
[W 18:55:33.479 LabApp] zmq message arrived on closed channel
[W 18:55:33.479 LabApp] zmq message arrived on closed channel
[W 18:55:33.480 LabApp] zmq message arrived on closed channel
[W 18:55:33.480 LabApp] zmq message arrived on closed channel
[W 18:55:33.481 LabApp] zmq message arrived on closed channel
[W 18:55:33.481 LabApp] zmq message arrived on closed channel
[W 18:55:33.482 LabApp] zmq message arrived on closed channel
[W 18:55:33.482 LabApp] zmq message arrived on closed channel
[W 18:55:33.483 LabApp] zmq message arrived on closed channel
[W 18:55:33.483 LabApp] zmq message arrived on closed channel
[W 18:55:33.484 LabApp] zmq message arrived on closed channel
[W 18:55:33.484 LabApp] zmq message arrived on closed channel
[W 18:55:33.484 LabApp] zmq message arrived on closed channel
[W 18:55:33.485 LabApp] zmq message arrived on closed channel
[W 18:55:33.485 LabApp] zmq message arrived on closed channel
[W 18:55:33.486 LabApp] zmq message arrived on closed channel
[W 18:55:33.486 LabApp] zmq message arrived on closed channel
[W 18:55:33.487 LabApp] zmq message arrived on closed channel
[W 18:55:33.487 LabApp] zmq message arrived on closed channel
[W 18:55:33.488 LabApp] zmq message arrived on closed channel
[W 18:55:33.488 LabApp] zmq message arrived on closed channel
[W 18:55:33.489 LabApp] zmq message arrived on closed channel
[W 18:55:33.489 LabApp] zmq message arrived on closed channel
[W 18:55:33.490 LabApp] zmq message arrived on closed channel
[W 18:55:33.490 LabApp] zmq message arrived on closed channel
[W 18:55:33.490 LabApp] zmq message arrived on closed channel
[W 18:55:33.491 LabApp] zmq message arrived on closed channel
[W 18:55:33.491 LabApp] zmq message arrived on closed channel
[W 18:55:33.492 LabApp] zmq message arrived on closed channel
[W 18:55:33.492 LabApp] zmq message arrived on closed channel
[W 18:55:33.493 LabApp] zmq message arrived on closed channel
[W 18:55:33.493 LabApp] zmq message arrived on closed channel
[W 18:55:33.494 LabApp] zmq message arrived on closed channel
[W 18:55:33.494 LabApp] zmq message arrived on closed channel
[W 18:55:33.495 LabApp] zmq message arrived on closed channel
[W 18:55:33.495 LabApp] zmq message arrived on closed channel
[W 18:55:33.496 LabApp] zmq message arrived on closed channel
[W 18:55:33.496 LabApp] zmq message arrived on closed channel
[W 18:55:33.496 LabApp] zmq message arrived on closed channel
[W 18:55:33.497 LabApp] zmq message arrived on closed channel
[W 18:55:33.497 LabApp] zmq message arrived on closed channel
[W 18:55:33.498 LabApp] zmq message arrived on closed channel
[W 18:55:33.498 LabApp] zmq message arrived on closed channel
[W 18:55:33.499 LabApp] zmq message arrived on closed channel
[W 18:55:33.499 LabApp] zmq message arrived on closed channel
[W 18:55:33.500 LabApp] zmq message arrived on closed channel
[W 18:55:33.500 LabApp] zmq message arrived on closed channel
[W 18:55:33.501 LabApp] zmq message arrived on closed channel
[W 18:55:33.501 LabApp] zmq message arrived on closed channel
[W 18:55:33.502 LabApp] zmq message arrived on closed channel
[W 18:55:33.502 LabApp] zmq message arrived on closed channel
[W 18:55:33.502 LabApp] zmq message arrived on closed channel
[W 18:55:33.503 LabApp] zmq message arrived on closed channel
[W 18:55:33.503 LabApp] zmq message arrived on closed channel
[W 18:55:33.504 LabApp] zmq message arrived on closed channel
[W 18:55:33.504 LabApp] zmq message arrived on closed channel
[W 18:55:33.505 LabApp] zmq message arrived on closed channel
[W 18:55:33.505 LabApp] zmq message arrived on closed channel
[W 18:55:33.506 LabApp] zmq message arrived on closed channel
[W 18:55:33.506 LabApp] zmq message arrived on closed channel
[W 18:55:33.507 LabApp] zmq message arrived on closed channel
[W 18:55:33.507 LabApp] zmq message arrived on closed channel
[W 18:55:33.508 LabApp] zmq message arrived on closed channel
[W 18:55:33.508 LabApp] zmq message arrived on closed channel
[W 18:55:33.508 LabApp] zmq message arrived on closed channel
[W 18:55:33.509 LabApp] zmq message arrived on closed channel
[W 18:55:33.509 LabApp] zmq message arrived on closed channel
[W 18:55:33.510 LabApp] zmq message arrived on closed channel
[W 18:55:33.510 LabApp] zmq message arrived on closed channel
[W 18:55:33.511 LabApp] zmq message arrived on closed channel
[W 18:55:33.511 LabApp] zmq message arrived on closed channel
[W 18:55:33.512 LabApp] zmq message arrived on closed channel
[W 18:55:33.512 LabApp] zmq message arrived on closed channel
[W 18:55:33.513 LabApp] zmq message arrived on closed channel
[W 18:55:33.513 LabApp] zmq message arrived on closed channel
[W 18:55:33.514 LabApp] zmq message arrived on closed channel
[W 18:55:33.514 LabApp] zmq message arrived on closed channel
[W 18:55:33.514 LabApp] zmq message arrived on closed channel
[W 18:55:33.515 LabApp] zmq message arrived on closed channel
[W 18:55:33.515 LabApp] zmq message arrived on closed channel
[W 18:55:33.516 LabApp] zmq message arrived on closed channel
[W 18:55:33.516 LabApp] zmq message arrived on closed channel
[W 18:55:33.517 LabApp] zmq message arrived on closed channel
[W 18:55:33.517 LabApp] zmq message arrived on closed channel
[W 18:55:33.518 LabApp] zmq message arrived on closed channel
[W 18:55:33.518 LabApp] zmq message arrived on closed channel
[W 18:55:33.519 LabApp] zmq message arrived on closed channel
[W 18:55:33.519 LabApp] zmq message arrived on closed channel
[W 18:55:33.519 LabApp] zmq message arrived on closed channel
[W 18:55:33.520 LabApp] zmq message arrived on closed channel
[W 18:55:33.520 LabApp] zmq message arrived on closed channel
[W 18:55:33.521 LabApp] zmq message arrived on closed channel
[W 18:55:33.521 LabApp] zmq message arrived on closed channel
[W 18:55:33.522 LabApp] zmq message arrived on closed channel
[W 18:55:33.522 LabApp] zmq message arrived on closed channel
[W 18:55:33.523 LabApp] zmq message arrived on closed channel
[W 18:55:33.523 LabApp] zmq message arrived on closed channel
[W 18:55:33.524 LabApp] zmq message arrived on closed channel
[W 18:55:33.524 LabApp] zmq message arrived on closed channel
[W 18:55:33.524 LabApp] zmq message arrived on closed channel
[W 18:55:33.525 LabApp] zmq message arrived on closed channel
[W 18:55:33.525 LabApp] zmq message arrived on closed channel
[W 18:55:33.526 LabApp] zmq message arrived on closed channel
[W 18:55:33.526 LabApp] zmq message arrived on closed channel
[W 18:55:33.527 LabApp] zmq message arrived on closed channel
[W 18:55:33.527 LabApp] zmq message arrived on closed channel
[W 18:55:33.528 LabApp] zmq message arrived on closed channel
[W 18:55:33.528 LabApp] zmq message arrived on closed channel
[W 18:55:33.529 LabApp] zmq message arrived on closed channel
[W 18:55:33.529 LabApp] zmq message arrived on closed channel
[W 18:55:33.530 LabApp] zmq message arrived on closed channel
[W 18:55:33.530 LabApp] zmq message arrived on closed channel
[W 18:55:33.530 LabApp] zmq message arrived on closed channel
[W 18:55:33.531 LabApp] zmq message arrived on closed channel
[W 18:55:33.531 LabApp] zmq message arrived on closed channel
[W 18:55:33.532 LabApp] zmq message arrived on closed channel
[W 18:55:33.532 LabApp] zmq message arrived on closed channel
[W 18:55:33.533 LabApp] zmq message arrived on closed channel
[W 18:55:33.533 LabApp] zmq message arrived on closed channel
[W 18:55:33.534 LabApp] zmq message arrived on closed channel
[W 18:55:33.534 LabApp] zmq message arrived on closed channel
[W 18:55:33.534 LabApp] zmq message arrived on closed channel
[W 18:55:33.535 LabApp] zmq message arrived on closed channel
[W 18:55:33.535 LabApp] zmq message arrived on closed channel
[W 18:55:33.536 LabApp] zmq message arrived on closed channel
[W 18:55:33.536 LabApp] zmq message arrived on closed channel
[W 18:55:33.537 LabApp] zmq message arrived on closed channel
[W 18:55:33.537 LabApp] zmq message arrived on closed channel
[W 18:55:33.538 LabApp] zmq message arrived on closed channel
[W 18:55:33.538 LabApp] zmq message arrived on closed channel
[W 18:55:33.539 LabApp] zmq message arrived on closed channel
[W 18:55:33.539 LabApp] zmq message arrived on closed channel
[W 18:55:33.540 LabApp] zmq message arrived on closed channel
[W 18:55:33.540 LabApp] zmq message arrived on closed channel
[W 18:55:33.540 LabApp] zmq message arrived on closed channel
[W 18:55:33.541 LabApp] zmq message arrived on closed channel
[W 18:55:33.541 LabApp] zmq message arrived on closed channel
[W 18:55:33.542 LabApp] zmq message arrived on closed channel
[W 18:55:33.542 LabApp] zmq message arrived on closed channel
[W 18:55:33.543 LabApp] zmq message arrived on closed channel
[W 18:55:33.543 LabApp] zmq message arrived on closed channel
[W 18:55:33.544 LabApp] zmq message arrived on closed channel
[W 18:55:33.544 LabApp] zmq message arrived on closed channel
[W 18:55:33.545 LabApp] zmq message arrived on closed channel
[W 18:55:33.545 LabApp] zmq message arrived on closed channel
[W 18:55:33.546 LabApp] zmq message arrived on closed channel
[W 18:55:33.546 LabApp] zmq message arrived on closed channel
[W 18:55:33.546 LabApp] zmq message arrived on closed channel
[W 18:55:33.548 LabApp] zmq message arrived on closed channel
[W 18:55:33.548 LabApp] zmq message arrived on closed channel
[W 18:55:33.548 LabApp] zmq message arrived on closed channel
[W 18:55:33.549 LabApp] zmq message arrived on closed channel
[W 18:55:33.549 LabApp] zmq message arrived on closed channel
[W 18:55:33.550 LabApp] zmq message arrived on closed channel
[W 18:55:33.550 LabApp] zmq message arrived on closed channel
[W 18:55:33.551 LabApp] zmq message arrived on closed channel
[W 18:55:33.551 LabApp] zmq message arrived on closed channel
[W 18:55:33.552 LabApp] zmq message arrived on closed channel
[W 18:55:33.552 LabApp] zmq message arrived on closed channel
[W 18:55:33.553 LabApp] zmq message arrived on closed channel
[W 18:55:33.553 LabApp] zmq message arrived on closed channel
[W 18:55:33.553 LabApp] zmq message arrived on closed channel
[W 18:55:33.554 LabApp] zmq message arrived on closed channel
[W 18:55:33.554 LabApp] zmq message arrived on closed channel
[W 18:55:33.555 LabApp] zmq message arrived on closed channel
[W 18:55:33.555 LabApp] zmq message arrived on closed channel
[W 18:55:33.556 LabApp] zmq message arrived on closed channel
[W 18:55:33.556 LabApp] zmq message arrived on closed channel
[W 18:55:33.557 LabApp] zmq message arrived on closed channel
[W 18:55:33.557 LabApp] zmq message arrived on closed channel
[W 18:55:33.558 LabApp] zmq message arrived on closed channel
[W 18:55:33.558 LabApp] zmq message arrived on closed channel
[W 18:55:33.559 LabApp] zmq message arrived on closed channel
[W 18:55:33.559 LabApp] zmq message arrived on closed channel
[W 18:55:33.560 LabApp] zmq message arrived on closed channel
[W 18:55:33.560 LabApp] zmq message arrived on closed channel
[W 18:55:33.560 LabApp] zmq message arrived on closed channel
[W 18:55:33.561 LabApp] zmq message arrived on closed channel
[W 18:55:33.561 LabApp] zmq message arrived on closed channel
[W 18:55:33.562 LabApp] zmq message arrived on closed channel
[W 18:55:33.562 LabApp] zmq message arrived on closed channel
[W 18:55:33.563 LabApp] zmq message arrived on closed channel
[W 18:55:33.563 LabApp] zmq message arrived on closed channel
[W 18:55:33.564 LabApp] zmq message arrived on closed channel
[W 18:55:33.564 LabApp] zmq message arrived on closed channel
[W 18:55:33.564 LabApp] zmq message arrived on closed channel
[W 18:55:33.565 LabApp] zmq message arrived on closed channel
[W 18:55:33.565 LabApp] zmq message arrived on closed channel
[W 18:55:33.566 LabApp] zmq message arrived on closed channel
[W 18:55:33.566 LabApp] zmq message arrived on closed channel
[W 18:55:33.567 LabApp] zmq message arrived on closed channel
[W 18:55:33.567 LabApp] zmq message arrived on closed channel
[W 18:55:33.568 LabApp] zmq message arrived on closed channel
[W 18:55:33.568 LabApp] zmq message arrived on closed channel
[W 18:55:33.569 LabApp] zmq message arrived on closed channel
[W 18:55:33.569 LabApp] zmq message arrived on closed channel
[W 18:55:33.570 LabApp] zmq message arrived on closed channel
[W 18:55:33.570 LabApp] zmq message arrived on closed channel
[W 18:55:33.570 LabApp] zmq message arrived on closed channel
[W 18:55:33.571 LabApp] zmq message arrived on closed channel
[W 18:55:33.571 LabApp] zmq message arrived on closed channel
[W 18:55:33.572 LabApp] zmq message arrived on closed channel
[W 18:55:33.572 LabApp] zmq message arrived on closed channel
[W 18:55:33.573 LabApp] zmq message arrived on closed channel
[W 18:55:33.573 LabApp] zmq message arrived on closed channel
[W 18:55:33.574 LabApp] zmq message arrived on closed channel
[W 18:55:33.574 LabApp] zmq message arrived on closed channel
[W 18:55:33.575 LabApp] zmq message arrived on closed channel
[W 18:55:33.575 LabApp] zmq message arrived on closed channel
[W 18:55:33.576 LabApp] zmq message arrived on closed channel
[W 18:55:33.576 LabApp] zmq message arrived on closed channel
[W 18:55:33.576 LabApp] zmq message arrived on closed channel
[W 18:55:33.577 LabApp] zmq message arrived on closed channel
[W 18:55:33.577 LabApp] zmq message arrived on closed channel
[W 18:55:33.578 LabApp] zmq message arrived on closed channel
[W 18:55:33.578 LabApp] zmq message arrived on closed channel
[W 18:55:33.579 LabApp] zmq message arrived on closed channel
[W 18:55:33.579 LabApp] zmq message arrived on closed channel
[W 18:55:33.580 LabApp] zmq message arrived on closed channel
[W 18:55:33.580 LabApp] zmq message arrived on closed channel
[W 18:55:33.581 LabApp] zmq message arrived on closed channel
[W 18:55:33.581 LabApp] zmq message arrived on closed channel
[W 18:55:33.582 LabApp] zmq message arrived on closed channel
[W 18:55:33.582 LabApp] zmq message arrived on closed channel
[W 18:55:33.582 LabApp] zmq message arrived on closed channel
[W 18:55:33.583 LabApp] zmq message arrived on closed channel
[W 18:55:33.583 LabApp] zmq message arrived on closed channel
[W 18:55:33.584 LabApp] zmq message arrived on closed channel
[W 18:55:33.584 LabApp] zmq message arrived on closed channel
[W 18:55:33.585 LabApp] zmq message arrived on closed channel
[W 18:55:33.585 LabApp] zmq message arrived on closed channel
[W 18:55:33.586 LabApp] zmq message arrived on closed channel
[W 18:55:33.586 LabApp] zmq message arrived on closed channel
[W 18:55:33.587 LabApp] zmq message arrived on closed channel
[W 18:55:33.587 LabApp] zmq message arrived on closed channel
[W 18:55:33.588 LabApp] zmq message arrived on closed channel
[W 18:55:33.588 LabApp] zmq message arrived on closed channel
[W 18:55:33.589 LabApp] zmq message arrived on closed channel
[W 18:55:33.589 LabApp] zmq message arrived on closed channel
[W 18:55:33.590 LabApp] zmq message arrived on closed channel
[W 18:55:33.590 LabApp] zmq message arrived on closed channel
[W 18:55:33.590 LabApp] zmq message arrived on closed channel
[W 18:55:33.591 LabApp] zmq message arrived on closed channel
[W 18:55:33.591 LabApp] zmq message arrived on closed channel
[W 18:55:33.592 LabApp] zmq message arrived on closed channel
[W 18:55:33.592 LabApp] zmq message arrived on closed channel
[W 18:55:33.593 LabApp] zmq message arrived on closed channel
[W 18:55:33.593 LabApp] zmq message arrived on closed channel
[W 18:55:33.594 LabApp] zmq message arrived on closed channel
[W 18:55:33.594 LabApp] zmq message arrived on closed channel
[W 18:55:33.595 LabApp] zmq message arrived on closed channel
[W 18:55:33.595 LabApp] zmq message arrived on closed channel
[W 18:55:33.596 LabApp] zmq message arrived on closed channel
[W 18:55:33.596 LabApp] zmq message arrived on closed channel
[W 18:55:33.596 LabApp] zmq message arrived on closed channel
[W 18:55:33.597 LabApp] zmq message arrived on closed channel
[W 18:55:33.597 LabApp] zmq message arrived on closed channel
[W 18:55:33.598 LabApp] zmq message arrived on closed channel
[W 18:55:33.598 LabApp] zmq message arrived on closed channel
[W 18:55:33.599 LabApp] zmq message arrived on closed channel
[W 18:55:33.599 LabApp] zmq message arrived on closed channel
[W 18:55:33.600 LabApp] zmq message arrived on closed channel
[W 18:55:33.600 LabApp] zmq message arrived on closed channel
[W 18:55:33.601 LabApp] zmq message arrived on closed channel
[W 18:55:33.601 LabApp] zmq message arrived on closed channel
[W 18:55:33.602 LabApp] zmq message arrived on closed channel
[W 18:55:33.602 LabApp] zmq message arrived on closed channel
[W 18:55:33.602 LabApp] zmq message arrived on closed channel
[W 18:55:33.603 LabApp] zmq message arrived on closed channel
[W 18:55:33.603 LabApp] zmq message arrived on closed channel
[W 18:55:33.604 LabApp] zmq message arrived on closed channel
[W 18:55:33.604 LabApp] zmq message arrived on closed channel
[W 18:55:33.605 LabApp] zmq message arrived on closed channel
[W 18:55:33.605 LabApp] zmq message arrived on closed channel
[W 18:55:33.606 LabApp] zmq message arrived on closed channel
[W 18:55:33.606 LabApp] zmq message arrived on closed channel
[W 18:55:33.607 LabApp] zmq message arrived on closed channel
[W 18:55:33.607 LabApp] zmq message arrived on closed channel
[W 18:55:33.608 LabApp] zmq message arrived on closed channel
[W 18:55:33.608 LabApp] zmq message arrived on closed channel
[W 18:55:33.608 LabApp] zmq message arrived on closed channel
[W 18:55:33.609 LabApp] zmq message arrived on closed channel
[W 18:55:33.609 LabApp] zmq message arrived on closed channel
[W 18:55:33.610 LabApp] zmq message arrived on closed channel
[W 18:55:33.610 LabApp] zmq message arrived on closed channel
[W 18:55:33.611 LabApp] zmq message arrived on closed channel
[W 18:55:33.611 LabApp] zmq message arrived on closed channel
[W 18:55:33.612 LabApp] zmq message arrived on closed channel
[W 18:55:33.612 LabApp] zmq message arrived on closed channel
[W 18:55:33.613 LabApp] zmq message arrived on closed channel
[W 18:55:33.613 LabApp] zmq message arrived on closed channel
[W 18:55:33.613 LabApp] zmq message arrived on closed channel
[W 18:55:33.614 LabApp] zmq message arrived on closed channel
[W 18:55:33.614 LabApp] zmq message arrived on closed channel
[W 18:55:33.615 LabApp] zmq message arrived on closed channel
[W 18:55:33.615 LabApp] zmq message arrived on closed channel
[W 18:55:33.616 LabApp] zmq message arrived on closed channel
[W 18:55:33.616 LabApp] zmq message arrived on closed channel
[W 18:55:33.617 LabApp] zmq message arrived on closed channel
[W 18:55:33.617 LabApp] zmq message arrived on closed channel
[W 18:55:33.618 LabApp] zmq message arrived on closed channel
[W 18:55:33.618 LabApp] zmq message arrived on closed channel
[W 18:55:33.618 LabApp] zmq message arrived on closed channel
[W 18:55:33.619 LabApp] zmq message arrived on closed channel
[W 18:55:33.619 LabApp] zmq message arrived on closed channel
[W 18:55:33.620 LabApp] zmq message arrived on closed channel
[W 18:55:33.620 LabApp] zmq message arrived on closed channel
[W 18:55:33.621 LabApp] zmq message arrived on closed channel
[W 18:55:33.621 LabApp] zmq message arrived on closed channel
[W 18:55:33.622 LabApp] zmq message arrived on closed channel
[W 18:55:33.622 LabApp] zmq message arrived on closed channel
[W 18:55:33.623 LabApp] zmq message arrived on closed channel
[W 18:55:33.623 LabApp] zmq message arrived on closed channel
[W 18:55:33.623 LabApp] zmq message arrived on closed channel
[W 18:55:33.624 LabApp] zmq message arrived on closed channel
[W 18:55:33.624 LabApp] zmq message arrived on closed channel
[W 18:55:33.625 LabApp] zmq message arrived on closed channel
[W 18:55:33.625 LabApp] zmq message arrived on closed channel
[W 18:55:33.626 LabApp] zmq message arrived on closed channel
[W 18:55:33.626 LabApp] zmq message arrived on closed channel
[W 18:55:33.627 LabApp] zmq message arrived on closed channel
[W 18:55:33.627 LabApp] zmq message arrived on closed channel
[W 18:55:33.628 LabApp] zmq message arrived on closed channel
[W 18:55:33.628 LabApp] zmq message arrived on closed channel
[W 18:55:33.628 LabApp] zmq message arrived on closed channel
[W 18:55:33.629 LabApp] zmq message arrived on closed channel
[W 18:55:33.629 LabApp] zmq message arrived on closed channel
[W 18:55:33.630 LabApp] zmq message arrived on closed channel
[W 18:55:33.630 LabApp] zmq message arrived on closed channel
[W 18:55:33.631 LabApp] zmq message arrived on closed channel
[W 18:55:33.631 LabApp] zmq message arrived on closed channel
[W 18:55:33.632 LabApp] zmq message arrived on closed channel
[W 18:55:33.632 LabApp] zmq message arrived on closed channel
[W 18:55:33.633 LabApp] zmq message arrived on closed channel
[W 18:55:33.633 LabApp] zmq message arrived on closed channel
[W 18:55:33.634 LabApp] zmq message arrived on closed channel
[W 18:55:33.634 LabApp] zmq message arrived on closed channel
[W 18:55:33.634 LabApp] zmq message arrived on closed channel
[W 18:55:33.635 LabApp] zmq message arrived on closed channel
[W 18:55:33.635 LabApp] zmq message arrived on closed channel
[W 18:55:33.636 LabApp] zmq message arrived on closed channel
[W 18:55:33.636 LabApp] zmq message arrived on closed channel
[W 18:55:33.637 LabApp] zmq message arrived on closed channel
[W 18:55:33.637 LabApp] zmq message arrived on closed channel
[W 18:55:33.638 LabApp] zmq message arrived on closed channel
[W 18:55:33.638 LabApp] zmq message arrived on closed channel
[W 18:55:33.639 LabApp] zmq message arrived on closed channel
[W 18:55:33.639 LabApp] zmq message arrived on closed channel
[W 18:55:33.640 LabApp] zmq message arrived on closed channel
[W 18:55:33.640 LabApp] zmq message arrived on closed channel
[W 18:55:33.640 LabApp] zmq message arrived on closed channel
[W 18:55:33.641 LabApp] zmq message arrived on closed channel
[W 18:55:33.641 LabApp] zmq message arrived on closed channel
[W 18:55:33.642 LabApp] zmq message arrived on closed channel
[W 18:55:33.642 LabApp] zmq message arrived on closed channel
[W 18:55:33.643 LabApp] zmq message arrived on closed channel
[W 18:55:33.643 LabApp] zmq message arrived on closed channel
[W 18:55:33.644 LabApp] zmq message arrived on closed channel
[W 18:55:33.644 LabApp] zmq message arrived on closed channel
[W 18:55:33.645 LabApp] zmq message arrived on closed channel
[W 18:55:33.645 LabApp] zmq message arrived on closed channel
[W 18:55:33.645 LabApp] zmq message arrived on closed channel
[W 18:55:33.646 LabApp] zmq message arrived on closed channel
[W 18:55:33.646 LabApp] zmq message arrived on closed channel
[W 18:55:33.647 LabApp] zmq message arrived on closed channel
[W 18:55:33.647 LabApp] zmq message arrived on closed channel
[W 18:55:33.648 LabApp] zmq message arrived on closed channel
[W 18:55:33.648 LabApp] zmq message arrived on closed channel
[W 18:55:33.649 LabApp] zmq message arrived on closed channel
[W 18:55:33.649 LabApp] zmq message arrived on closed channel
[W 18:55:33.650 LabApp] zmq message arrived on closed channel
[W 18:55:33.650 LabApp] zmq message arrived on closed channel
[W 18:55:33.651 LabApp] zmq message arrived on closed channel
[W 18:55:33.651 LabApp] zmq message arrived on closed channel
[W 18:55:33.652 LabApp] zmq message arrived on closed channel
[W 18:55:33.652 LabApp] zmq message arrived on closed channel
[W 18:55:33.653 LabApp] zmq message arrived on closed channel
[W 18:55:33.653 LabApp] zmq message arrived on closed channel
[W 18:55:33.653 LabApp] zmq message arrived on closed channel
[W 18:55:33.654 LabApp] zmq message arrived on closed channel
[W 18:55:33.654 LabApp] zmq message arrived on closed channel
[W 18:55:33.655 LabApp] zmq message arrived on closed channel
[W 18:55:33.655 LabApp] zmq message arrived on closed channel
[W 18:55:33.656 LabApp] zmq message arrived on closed channel
[W 18:55:33.656 LabApp] zmq message arrived on closed channel
[W 18:55:33.657 LabApp] zmq message arrived on closed channel
[W 18:55:33.657 LabApp] zmq message arrived on closed channel
[W 18:55:33.658 LabApp] zmq message arrived on closed channel
[W 18:55:33.658 LabApp] zmq message arrived on closed channel
[W 18:55:33.658 LabApp] zmq message arrived on closed channel
[W 18:55:33.659 LabApp] zmq message arrived on closed channel
[W 18:55:33.659 LabApp] zmq message arrived on closed channel
[W 18:55:33.660 LabApp] zmq message arrived on closed channel
[W 18:55:33.660 LabApp] zmq message arrived on closed channel
[W 18:55:33.661 LabApp] zmq message arrived on closed channel
[W 18:55:33.661 LabApp] zmq message arrived on closed channel
[W 18:55:33.662 LabApp] zmq message arrived on closed channel
[W 18:55:33.662 LabApp] zmq message arrived on closed channel
[W 18:55:33.663 LabApp] zmq message arrived on closed channel
[W 18:55:33.663 LabApp] zmq message arrived on closed channel
[W 18:55:33.664 LabApp] zmq message arrived on closed channel
[W 18:55:33.664 LabApp] zmq message arrived on closed channel
[W 18:55:33.665 LabApp] zmq message arrived on closed channel
[W 18:55:33.665 LabApp] zmq message arrived on closed channel
[W 18:55:33.665 LabApp] zmq message arrived on closed channel
[W 18:55:33.666 LabApp] zmq message arrived on closed channel
[W 18:55:33.666 LabApp] zmq message arrived on closed channel
[W 18:55:33.667 LabApp] zmq message arrived on closed channel
[W 18:55:33.667 LabApp] zmq message arrived on closed channel
[W 18:55:33.668 LabApp] zmq message arrived on closed channel
[W 18:55:33.668 LabApp] zmq message arrived on closed channel
[W 18:55:33.669 LabApp] zmq message arrived on closed channel
[W 18:55:33.669 LabApp] zmq message arrived on closed channel
[W 18:55:33.670 LabApp] zmq message arrived on closed channel
[W 18:55:33.670 LabApp] zmq message arrived on closed channel
[W 18:55:33.670 LabApp] zmq message arrived on closed channel
[W 18:55:33.671 LabApp] zmq message arrived on closed channel
[W 18:55:33.671 LabApp] zmq message arrived on closed channel
[W 18:55:33.672 LabApp] zmq message arrived on closed channel
[W 18:55:33.672 LabApp] zmq message arrived on closed channel
[W 18:55:33.673 LabApp] zmq message arrived on closed channel
[W 18:55:33.673 LabApp] zmq message arrived on closed channel
[W 18:55:33.674 LabApp] zmq message arrived on closed channel
[W 18:55:33.674 LabApp] zmq message arrived on closed channel
[W 18:55:33.675 LabApp] zmq message arrived on closed channel
[W 18:55:33.675 LabApp] zmq message arrived on closed channel
[W 18:55:33.675 LabApp] zmq message arrived on closed channel
[W 18:55:33.676 LabApp] zmq message arrived on closed channel
[W 18:55:33.676 LabApp] zmq message arrived on closed channel
[W 18:55:33.677 LabApp] zmq message arrived on closed channel
[W 18:55:33.677 LabApp] zmq message arrived on closed channel
[W 18:55:33.678 LabApp] zmq message arrived on closed channel
[W 18:55:33.678 LabApp] zmq message arrived on closed channel
[W 18:55:33.679 LabApp] zmq message arrived on closed channel
[W 18:55:33.679 LabApp] zmq message arrived on closed channel
[W 18:55:33.680 LabApp] zmq message arrived on closed channel
[W 18:55:33.680 LabApp] zmq message arrived on closed channel
[W 18:55:33.680 LabApp] zmq message arrived on closed channel
[W 18:55:33.681 LabApp] zmq message arrived on closed channel
[W 18:55:33.681 LabApp] zmq message arrived on closed channel
[W 18:55:33.682 LabApp] zmq message arrived on closed channel
[W 18:55:33.682 LabApp] zmq message arrived on closed channel
[W 18:55:33.683 LabApp] zmq message arrived on closed channel
[W 18:55:33.683 LabApp] zmq message arrived on closed channel
[W 18:55:33.684 LabApp] zmq message arrived on closed channel
[W 18:55:33.684 LabApp] zmq message arrived on closed channel
[W 18:55:33.685 LabApp] zmq message arrived on closed channel
[W 18:55:33.685 LabApp] zmq message arrived on closed channel
[W 18:55:33.685 LabApp] zmq message arrived on closed channel
[W 18:55:33.686 LabApp] zmq message arrived on closed channel
[W 18:55:33.686 LabApp] zmq message arrived on closed channel
[W 18:55:33.687 LabApp] zmq message arrived on closed channel
[W 18:55:33.687 LabApp] zmq message arrived on closed channel
[W 18:55:33.688 LabApp] zmq message arrived on closed channel
[W 18:55:33.688 LabApp] zmq message arrived on closed channel
[W 18:55:33.689 LabApp] zmq message arrived on closed channel
[W 18:55:33.689 LabApp] zmq message arrived on closed channel
[W 18:55:33.690 LabApp] zmq message arrived on closed channel
[W 18:55:33.690 LabApp] zmq message arrived on closed channel
[W 18:55:33.690 LabApp] zmq message arrived on closed channel
[W 18:55:33.691 LabApp] zmq message arrived on closed channel
[W 18:55:33.691 LabApp] zmq message arrived on closed channel
[W 18:55:33.692 LabApp] zmq message arrived on closed channel
[W 18:55:33.692 LabApp] zmq message arrived on closed channel
[W 18:55:33.693 LabApp] zmq message arrived on closed channel
[W 18:55:33.693 LabApp] zmq message arrived on closed channel
[W 18:55:33.694 LabApp] zmq message arrived on closed channel
[W 18:55:33.694 LabApp] zmq message arrived on closed channel
[W 18:55:33.695 LabApp] zmq message arrived on closed channel
[W 18:55:33.695 LabApp] zmq message arrived on closed channel
[W 18:55:33.696 LabApp] zmq message arrived on closed channel
[W 18:55:33.696 LabApp] zmq message arrived on closed channel
[W 18:55:33.696 LabApp] zmq message arrived on closed channel
[W 18:55:33.697 LabApp] zmq message arrived on closed channel
[W 18:55:33.697 LabApp] zmq message arrived on closed channel
[W 18:55:33.698 LabApp] zmq message arrived on closed channel
[W 18:55:33.698 LabApp] zmq message arrived on closed channel
[W 18:55:33.699 LabApp] zmq message arrived on closed channel
[W 18:55:33.699 LabApp] zmq message arrived on closed channel
[W 18:55:33.700 LabApp] zmq message arrived on closed channel
[W 18:55:33.700 LabApp] zmq message arrived on closed channel
[W 18:55:33.701 LabApp] zmq message arrived on closed channel
[W 18:55:33.701 LabApp] zmq message arrived on closed channel
[W 18:55:33.701 LabApp] zmq message arrived on closed channel
[W 18:55:33.702 LabApp] zmq message arrived on closed channel
[W 18:55:33.702 LabApp] zmq message arrived on closed channel
[W 18:55:33.703 LabApp] zmq message arrived on closed channel
[W 18:55:33.703 LabApp] zmq message arrived on closed channel
[W 18:55:33.704 LabApp] zmq message arrived on closed channel
[W 18:55:33.704 LabApp] zmq message arrived on closed channel
[W 18:55:33.705 LabApp] zmq message arrived on closed channel
[W 18:55:33.705 LabApp] zmq message arrived on closed channel
[W 18:55:33.706 LabApp] zmq message arrived on closed channel
[W 18:55:33.706 LabApp] zmq message arrived on closed channel
[W 18:55:33.706 LabApp] zmq message arrived on closed channel
[W 18:55:33.707 LabApp] zmq message arrived on closed channel
[W 18:55:33.707 LabApp] zmq message arrived on closed channel
[W 18:55:33.708 LabApp] zmq message arrived on closed channel
[W 18:55:33.708 LabApp] zmq message arrived on closed channel
[W 18:55:33.709 LabApp] zmq message arrived on closed channel
[W 18:55:33.709 LabApp] zmq message arrived on closed channel
[W 18:55:33.710 LabApp] zmq message arrived on closed channel
[W 18:55:33.710 LabApp] zmq message arrived on closed channel
[W 18:55:33.711 LabApp] zmq message arrived on closed channel
[W 18:55:33.711 LabApp] zmq message arrived on closed channel
[W 18:55:33.711 LabApp] zmq message arrived on closed channel
[W 18:55:33.712 LabApp] zmq message arrived on closed channel
[W 18:55:33.712 LabApp] zmq message arrived on closed channel
[W 18:55:33.713 LabApp] zmq message arrived on closed channel
[W 18:55:33.713 LabApp] zmq message arrived on closed channel
[W 18:55:33.714 LabApp] zmq message arrived on closed channel
[W 18:55:33.714 LabApp] zmq message arrived on closed channel
[W 18:55:33.715 LabApp] zmq message arrived on closed channel
[W 18:55:33.715 LabApp] zmq message arrived on closed channel
[W 18:55:33.716 LabApp] zmq message arrived on closed channel
[W 18:55:33.716 LabApp] zmq message arrived on closed channel
[W 18:55:33.717 LabApp] zmq message arrived on closed channel
[W 18:55:33.717 LabApp] zmq message arrived on closed channel
[W 18:55:33.717 LabApp] zmq message arrived on closed channel
[W 18:55:33.718 LabApp] zmq message arrived on closed channel
[W 18:55:33.718 LabApp] zmq message arrived on closed channel
[W 18:55:33.719 LabApp] zmq message arrived on closed channel
[W 18:55:33.719 LabApp] zmq message arrived on closed channel
[W 18:55:33.720 LabApp] zmq message arrived on closed channel
[W 18:55:33.720 LabApp] zmq message arrived on closed channel
[W 18:55:33.721 LabApp] zmq message arrived on closed channel
[W 18:55:33.721 LabApp] zmq message arrived on closed channel
[W 18:55:33.722 LabApp] zmq message arrived on closed channel
[W 18:55:33.722 LabApp] zmq message arrived on closed channel
[W 18:55:33.723 LabApp] zmq message arrived on closed channel
[W 18:55:33.723 LabApp] zmq message arrived on closed channel
[W 18:55:33.724 LabApp] zmq message arrived on closed channel
[W 18:55:33.724 LabApp] zmq message arrived on closed channel
[W 18:55:33.724 LabApp] zmq message arrived on closed channel
[W 18:55:33.725 LabApp] zmq message arrived on closed channel
[W 18:55:33.725 LabApp] zmq message arrived on closed channel
[W 18:55:33.726 LabApp] zmq message arrived on closed channel
[W 18:55:33.726 LabApp] zmq message arrived on closed channel
[W 18:55:33.727 LabApp] zmq message arrived on closed channel
[W 18:55:33.727 LabApp] zmq message arrived on closed channel
[W 18:55:33.728 LabApp] zmq message arrived on closed channel
[W 18:55:33.728 LabApp] zmq message arrived on closed channel
[W 18:55:33.729 LabApp] zmq message arrived on closed channel
[W 18:55:33.729 LabApp] zmq message arrived on closed channel
[W 18:55:33.729 LabApp] zmq message arrived on closed channel
[W 18:55:33.730 LabApp] zmq message arrived on closed channel
[W 18:55:33.730 LabApp] zmq message arrived on closed channel
[W 18:55:33.731 LabApp] zmq message arrived on closed channel
[W 18:55:33.731 LabApp] zmq message arrived on closed channel
[W 18:55:33.732 LabApp] zmq message arrived on closed channel
[W 18:55:33.732 LabApp] zmq message arrived on closed channel
[W 18:55:33.733 LabApp] zmq message arrived on closed channel
[W 18:55:33.733 LabApp] zmq message arrived on closed channel
[W 18:55:33.734 LabApp] zmq message arrived on closed channel
[W 18:55:33.734 LabApp] zmq message arrived on closed channel
[W 18:55:33.735 LabApp] zmq message arrived on closed channel
[W 18:55:33.735 LabApp] zmq message arrived on closed channel
[W 18:55:33.736 LabApp] zmq message arrived on closed channel
[W 18:55:33.736 LabApp] zmq message arrived on closed channel
[W 18:55:33.736 LabApp] zmq message arrived on closed channel
[W 18:55:33.737 LabApp] zmq message arrived on closed channel
[W 18:55:33.737 LabApp] zmq message arrived on closed channel
[W 18:55:33.738 LabApp] zmq message arrived on closed channel
[W 18:55:33.738 LabApp] zmq message arrived on closed channel
[W 18:55:33.739 LabApp] zmq message arrived on closed channel
[W 18:55:33.739 LabApp] zmq message arrived on closed channel
[W 18:55:33.740 LabApp] zmq message arrived on closed channel
[W 18:55:33.740 LabApp] zmq message arrived on closed channel
[W 18:55:33.741 LabApp] zmq message arrived on closed channel
[W 18:55:33.741 LabApp] zmq message arrived on closed channel
[W 18:55:33.742 LabApp] zmq message arrived on closed channel
[W 18:55:33.742 LabApp] zmq message arrived on closed channel
[W 18:55:33.742 LabApp] zmq message arrived on closed channel
[W 18:55:33.743 LabApp] zmq message arrived on closed channel
[W 18:55:33.743 LabApp] zmq message arrived on closed channel
[W 18:55:33.744 LabApp] zmq message arrived on closed channel
[W 18:55:33.744 LabApp] zmq message arrived on closed channel
[W 18:55:33.745 LabApp] zmq message arrived on closed channel
[W 18:55:33.745 LabApp] zmq message arrived on closed channel
[W 18:55:33.746 LabApp] zmq message arrived on closed channel
[W 18:55:33.746 LabApp] zmq message arrived on closed channel
[W 18:55:33.747 LabApp] zmq message arrived on closed channel
[W 18:55:33.747 LabApp] zmq message arrived on closed channel
[W 18:55:33.747 LabApp] zmq message arrived on closed channel
[W 18:55:33.748 LabApp] zmq message arrived on closed channel
[W 18:55:33.748 LabApp] zmq message arrived on closed channel
[W 18:55:33.749 LabApp] zmq message arrived on closed channel
[W 18:55:33.749 LabApp] zmq message arrived on closed channel
[W 18:55:33.750 LabApp] zmq message arrived on closed channel
[W 18:55:33.750 LabApp] zmq message arrived on closed channel
[W 18:55:33.751 LabApp] zmq message arrived on closed channel
[W 18:55:33.751 LabApp] zmq message arrived on closed channel
[W 18:55:33.752 LabApp] zmq message arrived on closed channel
[W 18:55:33.752 LabApp] zmq message arrived on closed channel
[W 18:55:33.752 LabApp] zmq message arrived on closed channel
[W 18:55:33.753 LabApp] zmq message arrived on closed channel
[W 18:55:33.753 LabApp] zmq message arrived on closed channel
[W 18:55:33.754 LabApp] zmq message arrived on closed channel
[W 18:55:33.754 LabApp] zmq message arrived on closed channel
[W 18:55:33.755 LabApp] zmq message arrived on closed channel
[W 18:55:33.755 LabApp] zmq message arrived on closed channel
[W 18:55:33.756 LabApp] zmq message arrived on closed channel
[W 18:55:33.756 LabApp] zmq message arrived on closed channel
[W 18:55:33.757 LabApp] zmq message arrived on closed channel
[W 18:55:33.757 LabApp] zmq message arrived on closed channel
[W 18:55:33.757 LabApp] zmq message arrived on closed channel
[W 18:55:33.758 LabApp] zmq message arrived on closed channel
[W 18:55:33.758 LabApp] zmq message arrived on closed channel
[W 18:55:33.759 LabApp] zmq message arrived on closed channel
[W 18:55:33.759 LabApp] zmq message arrived on closed channel
[W 18:55:33.760 LabApp] zmq message arrived on closed channel
[W 18:55:33.760 LabApp] zmq message arrived on closed channel
[W 18:55:33.761 LabApp] zmq message arrived on closed channel
[W 18:55:33.761 LabApp] zmq message arrived on closed channel
[W 18:55:33.762 LabApp] zmq message arrived on closed channel
[W 18:55:33.762 LabApp] zmq message arrived on closed channel
[W 18:55:33.762 LabApp] zmq message arrived on closed channel
[W 18:55:33.763 LabApp] zmq message arrived on closed channel
[W 18:55:33.763 LabApp] zmq message arrived on closed channel
[W 18:55:33.764 LabApp] zmq message arrived on closed channel
[W 18:55:33.764 LabApp] zmq message arrived on closed channel
[W 18:55:33.765 LabApp] zmq message arrived on closed channel
[W 18:55:33.765 LabApp] zmq message arrived on closed channel
[W 18:55:33.766 LabApp] zmq message arrived on closed channel
[W 18:55:33.766 LabApp] zmq message arrived on closed channel
[W 18:55:33.767 LabApp] zmq message arrived on closed channel
[W 18:55:33.767 LabApp] zmq message arrived on closed channel
[W 18:55:33.767 LabApp] zmq message arrived on closed channel
[W 18:55:33.768 LabApp] zmq message arrived on closed channel
[W 18:55:33.768 LabApp] zmq message arrived on closed channel
[W 18:55:33.769 LabApp] zmq message arrived on closed channel
[W 18:55:33.769 LabApp] zmq message arrived on closed channel
[W 18:55:33.770 LabApp] zmq message arrived on closed channel
[W 18:55:33.770 LabApp] zmq message arrived on closed channel
[W 18:55:33.771 LabApp] zmq message arrived on closed channel
[W 18:55:33.771 LabApp] zmq message arrived on closed channel
[W 18:55:33.772 LabApp] zmq message arrived on closed channel
[W 18:55:33.772 LabApp] zmq message arrived on closed channel
[W 18:55:33.772 LabApp] zmq message arrived on closed channel
[W 18:55:33.773 LabApp] zmq message arrived on closed channel
[W 18:55:33.773 LabApp] zmq message arrived on closed channel
[W 18:55:33.774 LabApp] zmq message arrived on closed channel
[W 18:55:33.774 LabApp] zmq message arrived on closed channel
[W 18:55:33.775 LabApp] zmq message arrived on closed channel
[W 18:55:33.775 LabApp] zmq message arrived on closed channel
[W 18:55:33.776 LabApp] zmq message arrived on closed channel
[W 18:55:33.776 LabApp] zmq message arrived on closed channel
[W 18:55:33.777 LabApp] zmq message arrived on closed channel
[W 18:55:33.777 LabApp] zmq message arrived on closed channel
[W 18:55:33.777 LabApp] zmq message arrived on closed channel
[W 18:55:33.778 LabApp] zmq message arrived on closed channel
[W 18:55:33.778 LabApp] zmq message arrived on closed channel
[W 18:55:33.779 LabApp] zmq message arrived on closed channel
[W 18:55:33.779 LabApp] zmq message arrived on closed channel
[W 18:55:33.780 LabApp] zmq message arrived on closed channel
[W 18:55:33.780 LabApp] zmq message arrived on closed channel
[W 18:55:33.781 LabApp] zmq message arrived on closed channel
[W 18:55:33.781 LabApp] zmq message arrived on closed channel
[W 18:55:33.782 LabApp] zmq message arrived on closed channel
[W 18:55:33.782 LabApp] zmq message arrived on closed channel
[W 18:55:33.782 LabApp] zmq message arrived on closed channel
[W 18:55:33.783 LabApp] zmq message arrived on closed channel
[W 18:55:33.783 LabApp] zmq message arrived on closed channel
[W 18:55:33.784 LabApp] zmq message arrived on closed channel
[W 18:55:33.784 LabApp] zmq message arrived on closed channel
[W 18:55:33.785 LabApp] zmq message arrived on closed channel
[W 18:55:33.785 LabApp] zmq message arrived on closed channel
[W 18:55:33.786 LabApp] zmq message arrived on closed channel
[W 18:55:33.786 LabApp] zmq message arrived on closed channel
[W 18:55:33.787 LabApp] zmq message arrived on closed channel
[W 18:55:33.787 LabApp] zmq message arrived on closed channel
[W 18:55:33.787 LabApp] zmq message arrived on closed channel
[W 18:55:33.788 LabApp] zmq message arrived on closed channel
[W 18:55:33.788 LabApp] zmq message arrived on closed channel
[W 18:55:33.789 LabApp] zmq message arrived on closed channel
[W 18:55:33.789 LabApp] zmq message arrived on closed channel
[W 18:55:33.790 LabApp] zmq message arrived on closed channel
[W 18:55:33.790 LabApp] zmq message arrived on closed channel
[W 18:55:33.791 LabApp] zmq message arrived on closed channel
[W 18:55:33.791 LabApp] zmq message arrived on closed channel
[W 18:55:33.792 LabApp] zmq message arrived on closed channel
[W 18:55:33.792 LabApp] zmq message arrived on closed channel
[W 18:55:33.792 LabApp] zmq message arrived on closed channel
[W 18:55:33.793 LabApp] zmq message arrived on closed channel
[W 18:55:33.793 LabApp] zmq message arrived on closed channel
[W 18:55:33.794 LabApp] zmq message arrived on closed channel
[W 18:55:33.794 LabApp] zmq message arrived on closed channel
[W 18:55:33.795 LabApp] zmq message arrived on closed channel
[W 18:55:33.795 LabApp] zmq message arrived on closed channel
[W 18:55:33.796 LabApp] zmq message arrived on closed channel
[W 18:55:33.796 LabApp] zmq message arrived on closed channel
[W 18:55:33.797 LabApp] zmq message arrived on closed channel
[W 18:55:33.797 LabApp] zmq message arrived on closed channel
[W 18:55:33.797 LabApp] zmq message arrived on closed channel
[W 18:55:33.798 LabApp] zmq message arrived on closed channel
[W 18:55:33.798 LabApp] zmq message arrived on closed channel
[W 18:55:33.799 LabApp] zmq message arrived on closed channel
[W 18:55:33.799 LabApp] zmq message arrived on closed channel
[W 18:55:33.800 LabApp] zmq message arrived on closed channel
[W 18:55:33.800 LabApp] zmq message arrived on closed channel
[W 18:55:33.801 LabApp] zmq message arrived on closed channel
[W 18:55:33.801 LabApp] zmq message arrived on closed channel
[W 18:55:33.802 LabApp] zmq message arrived on closed channel
[W 18:55:33.802 LabApp] zmq message arrived on closed channel
[W 18:55:33.803 LabApp] zmq message arrived on closed channel
[W 18:55:33.803 LabApp] zmq message arrived on closed channel
[W 18:55:33.803 LabApp] zmq message arrived on closed channel
[W 18:55:33.804 LabApp] zmq message arrived on closed channel
[W 18:55:33.804 LabApp] zmq message arrived on closed channel
[W 18:55:33.805 LabApp] zmq message arrived on closed channel
[W 18:55:33.805 LabApp] zmq message arrived on closed channel
[W 18:55:33.806 LabApp] zmq message arrived on closed channel
[W 18:55:33.806 LabApp] zmq message arrived on closed channel
[W 18:55:33.807 LabApp] zmq message arrived on closed channel
[W 18:55:33.807 LabApp] zmq message arrived on closed channel
[W 18:55:33.808 LabApp] zmq message arrived on closed channel
[W 18:55:33.808 LabApp] zmq message arrived on closed channel
[W 18:55:33.808 LabApp] zmq message arrived on closed channel
[W 18:55:33.809 LabApp] zmq message arrived on closed channel
[W 18:55:33.809 LabApp] zmq message arrived on closed channel
[W 18:55:33.810 LabApp] zmq message arrived on closed channel
[W 18:55:33.810 LabApp] zmq message arrived on closed channel
[W 18:55:33.811 LabApp] zmq message arrived on closed channel
[W 18:55:33.811 LabApp] zmq message arrived on closed channel
[W 18:55:33.812 LabApp] zmq message arrived on closed channel
[W 18:55:33.812 LabApp] zmq message arrived on closed channel
[W 18:55:33.813 LabApp] zmq message arrived on closed channel
[W 18:55:33.813 LabApp] zmq message arrived on closed channel
[W 18:55:33.813 LabApp] zmq message arrived on closed channel
[W 18:55:33.814 LabApp] zmq message arrived on closed channel
[W 18:55:33.814 LabApp] zmq message arrived on closed channel
[W 18:55:33.815 LabApp] zmq message arrived on closed channel
[W 18:55:33.815 LabApp] zmq message arrived on closed channel
[W 18:55:33.816 LabApp] zmq message arrived on closed channel
[W 18:55:33.816 LabApp] zmq message arrived on closed channel
[W 18:55:33.817 LabApp] zmq message arrived on closed channel
[W 18:55:33.817 LabApp] zmq message arrived on closed channel
[W 18:55:33.818 LabApp] zmq message arrived on closed channel
[W 18:55:33.818 LabApp] zmq message arrived on closed channel
[W 18:55:33.818 LabApp] zmq message arrived on closed channel
[W 18:55:33.819 LabApp] zmq message arrived on closed channel
[W 18:55:33.819 LabApp] zmq message arrived on closed channel
[W 18:55:33.820 LabApp] zmq message arrived on closed channel
[W 18:55:33.820 LabApp] zmq message arrived on closed channel
[W 18:55:33.821 LabApp] zmq message arrived on closed channel
[W 18:55:33.821 LabApp] zmq message arrived on closed channel
[W 18:55:33.822 LabApp] zmq message arrived on closed channel
[W 18:55:33.822 LabApp] zmq message arrived on closed channel
[W 18:55:33.823 LabApp] zmq message arrived on closed channel
[W 18:55:33.823 LabApp] zmq message arrived on closed channel
[W 18:55:33.823 LabApp] zmq message arrived on closed channel
[W 18:55:33.824 LabApp] zmq message arrived on closed channel
[W 18:55:33.824 LabApp] zmq message arrived on closed channel
[W 18:55:33.825 LabApp] zmq message arrived on closed channel
[W 18:55:33.825 LabApp] zmq message arrived on closed channel
[W 18:55:33.826 LabApp] zmq message arrived on closed channel
[W 18:55:33.826 LabApp] zmq message arrived on closed channel
[W 18:55:33.827 LabApp] zmq message arrived on closed channel
[W 18:55:33.827 LabApp] zmq message arrived on closed channel
[W 18:55:33.828 LabApp] zmq message arrived on closed channel
[W 18:55:33.828 LabApp] zmq message arrived on closed channel
[W 18:55:33.829 LabApp] zmq message arrived on closed channel
[W 18:55:33.829 LabApp] zmq message arrived on closed channel
[W 18:55:33.829 LabApp] zmq message arrived on closed channel
[W 18:55:33.830 LabApp] zmq message arrived on closed channel
[W 18:55:33.830 LabApp] zmq message arrived on closed channel
[W 18:55:33.831 LabApp] zmq message arrived on closed channel
[W 18:55:33.831 LabApp] zmq message arrived on closed channel
[W 18:55:33.832 LabApp] zmq message arrived on closed channel
[W 18:55:33.832 LabApp] zmq message arrived on closed channel
[W 18:55:33.833 LabApp] zmq message arrived on closed channel
[W 18:55:33.833 LabApp] zmq message arrived on closed channel
[W 18:55:33.834 LabApp] zmq message arrived on closed channel
[W 18:55:33.834 LabApp] zmq message arrived on closed channel
[W 18:55:33.834 LabApp] zmq message arrived on closed channel
[W 18:55:33.835 LabApp] zmq message arrived on closed channel
[W 18:55:33.835 LabApp] zmq message arrived on closed channel
[W 18:55:33.836 LabApp] zmq message arrived on closed channel
[W 18:55:33.836 LabApp] zmq message arrived on closed channel
[W 18:55:33.837 LabApp] zmq message arrived on closed channel
[W 18:55:33.837 LabApp] zmq message arrived on closed channel
[W 18:55:33.838 LabApp] zmq message arrived on closed channel
[W 18:55:33.838 LabApp] zmq message arrived on closed channel
[W 18:55:33.839 LabApp] zmq message arrived on closed channel
[W 18:55:33.839 LabApp] zmq message arrived on closed channel
[W 18:55:33.840 LabApp] zmq message arrived on closed channel
[W 18:55:33.840 LabApp] zmq message arrived on closed channel
[W 18:55:33.841 LabApp] zmq message arrived on closed channel
[W 18:55:33.841 LabApp] zmq message arrived on closed channel
[W 18:55:33.841 LabApp] zmq message arrived on closed channel
[W 18:55:33.842 LabApp] zmq message arrived on closed channel
[W 18:55:33.842 LabApp] zmq message arrived on closed channel
[W 18:55:33.843 LabApp] zmq message arrived on closed channel
[W 18:55:33.843 LabApp] zmq message arrived on closed channel
[W 18:55:33.844 LabApp] zmq message arrived on closed channel
[W 18:55:33.844 LabApp] zmq message arrived on closed channel
[W 18:55:33.845 LabApp] zmq message arrived on closed channel
[W 18:55:33.845 LabApp] zmq message arrived on closed channel
[W 18:55:33.846 LabApp] zmq message arrived on closed channel
[W 18:55:33.846 LabApp] zmq message arrived on closed channel
[W 18:55:33.846 LabApp] zmq message arrived on closed channel
[W 18:55:33.847 LabApp] zmq message arrived on closed channel
[W 18:55:33.847 LabApp] zmq message arrived on closed channel
[W 18:55:33.848 LabApp] zmq message arrived on closed channel
[W 18:55:33.848 LabApp] zmq message arrived on closed channel
[W 18:55:33.849 LabApp] zmq message arrived on closed channel
[W 18:55:33.849 LabApp] zmq message arrived on closed channel
[W 18:55:33.850 LabApp] zmq message arrived on closed channel
[W 18:55:33.850 LabApp] zmq message arrived on closed channel
[W 18:55:33.851 LabApp] zmq message arrived on closed channel
[W 18:55:33.851 LabApp] zmq message arrived on closed channel
[W 18:55:33.852 LabApp] zmq message arrived on closed channel
[W 18:55:33.852 LabApp] zmq message arrived on closed channel
[W 18:55:33.852 LabApp] zmq message arrived on closed channel
[W 18:55:33.853 LabApp] zmq message arrived on closed channel
[W 18:55:33.853 LabApp] zmq message arrived on closed channel
[W 18:55:33.854 LabApp] zmq message arrived on closed channel
[W 18:55:33.854 LabApp] zmq message arrived on closed channel
[W 18:55:33.855 LabApp] zmq message arrived on closed channel
[W 18:55:33.855 LabApp] zmq message arrived on closed channel
[W 18:55:33.856 LabApp] zmq message arrived on closed channel
[W 18:55:33.856 LabApp] zmq message arrived on closed channel
[W 18:55:33.857 LabApp] zmq message arrived on closed channel
[W 18:55:33.857 LabApp] zmq message arrived on closed channel
[W 18:55:33.857 LabApp] zmq message arrived on closed channel
[W 18:55:33.858 LabApp] zmq message arrived on closed channel
[W 18:55:33.858 LabApp] zmq message arrived on closed channel
[W 18:55:33.859 LabApp] zmq message arrived on closed channel
[W 18:55:33.859 LabApp] zmq message arrived on closed channel
[W 18:55:33.860 LabApp] zmq message arrived on closed channel
[W 18:55:33.860 LabApp] zmq message arrived on closed channel
[W 18:55:33.861 LabApp] zmq message arrived on closed channel
[W 18:55:33.861 LabApp] zmq message arrived on closed channel
[W 18:55:33.862 LabApp] zmq message arrived on closed channel
[W 18:55:33.862 LabApp] zmq message arrived on closed channel
[W 18:55:33.863 LabApp] zmq message arrived on closed channel
[W 18:55:33.863 LabApp] zmq message arrived on closed channel
[W 18:55:33.863 LabApp] zmq message arrived on closed channel
[W 18:55:33.864 LabApp] zmq message arrived on closed channel
[W 18:55:33.864 LabApp] zmq message arrived on closed channel
[W 18:55:33.865 LabApp] zmq message arrived on closed channel
[W 18:55:33.865 LabApp] zmq message arrived on closed channel
[W 18:55:33.866 LabApp] zmq message arrived on closed channel
[W 18:55:33.866 LabApp] zmq message arrived on closed channel
[W 18:55:33.867 LabApp] zmq message arrived on closed channel
[W 18:55:33.867 LabApp] zmq message arrived on closed channel
[W 18:55:33.868 LabApp] zmq message arrived on closed channel
[W 18:55:33.868 LabApp] zmq message arrived on closed channel
[W 18:55:33.869 LabApp] zmq message arrived on closed channel
[W 18:55:33.869 LabApp] zmq message arrived on closed channel
[W 18:55:33.869 LabApp] zmq message arrived on closed channel
[W 18:55:33.870 LabApp] zmq message arrived on closed channel
[W 18:55:33.870 LabApp] zmq message arrived on closed channel
[W 18:55:33.871 LabApp] zmq message arrived on closed channel
[W 18:55:33.871 LabApp] zmq message arrived on closed channel
[W 18:55:33.872 LabApp] zmq message arrived on closed channel
[W 18:55:33.872 LabApp] zmq message arrived on closed channel
[W 18:55:33.873 LabApp] zmq message arrived on closed channel
[W 18:55:33.873 LabApp] zmq message arrived on closed channel
[W 18:55:33.874 LabApp] zmq message arrived on closed channel
[W 18:55:33.874 LabApp] zmq message arrived on closed channel
[W 18:55:33.875 LabApp] zmq message arrived on closed channel
[W 18:55:33.875 LabApp] zmq message arrived on closed channel
[W 18:55:33.875 LabApp] zmq message arrived on closed channel
[W 18:55:33.876 LabApp] zmq message arrived on closed channel
[W 18:55:33.876 LabApp] zmq message arrived on closed channel
[W 18:55:33.877 LabApp] zmq message arrived on closed channel
[W 18:55:33.877 LabApp] zmq message arrived on closed channel
[W 18:55:33.878 LabApp] zmq message arrived on closed channel
[W 18:55:33.878 LabApp] zmq message arrived on closed channel
[W 18:55:33.879 LabApp] zmq message arrived on closed channel
[W 18:55:33.879 LabApp] zmq message arrived on closed channel
[W 18:55:33.880 LabApp] zmq message arrived on closed channel
[W 18:55:33.880 LabApp] zmq message arrived on closed channel
[W 18:55:33.881 LabApp] zmq message arrived on closed channel
[W 18:55:33.881 LabApp] zmq message arrived on closed channel
[W 18:55:33.881 LabApp] zmq message arrived on closed channel
[W 18:55:33.882 LabApp] zmq message arrived on closed channel
[W 18:55:33.882 LabApp] zmq message arrived on closed channel
[W 18:55:33.883 LabApp] zmq message arrived on closed channel
[W 18:55:33.883 LabApp] zmq message arrived on closed channel
[W 18:55:33.884 LabApp] zmq message arrived on closed channel
[W 18:55:33.884 LabApp] zmq message arrived on closed channel
[W 18:55:33.885 LabApp] zmq message arrived on closed channel
[W 18:55:33.885 LabApp] zmq message arrived on closed channel
[W 18:55:33.886 LabApp] zmq message arrived on closed channel
[W 18:55:33.886 LabApp] zmq message arrived on closed channel
[W 18:55:33.886 LabApp] zmq message arrived on closed channel
[W 18:55:33.887 LabApp] zmq message arrived on closed channel
[W 18:55:33.887 LabApp] zmq message arrived on closed channel
[W 18:55:33.888 LabApp] zmq message arrived on closed channel
[W 18:55:33.888 LabApp] zmq message arrived on closed channel
[W 18:55:33.889 LabApp] zmq message arrived on closed channel
[W 18:55:33.889 LabApp] zmq message arrived on closed channel
[W 18:55:33.890 LabApp] zmq message arrived on closed channel
[W 18:55:33.890 LabApp] zmq message arrived on closed channel
[W 18:55:33.891 LabApp] zmq message arrived on closed channel
[W 18:55:33.891 LabApp] zmq message arrived on closed channel
[W 18:55:33.891 LabApp] zmq message arrived on closed channel
[W 18:55:33.892 LabApp] zmq message arrived on closed channel
[W 18:55:33.892 LabApp] zmq message arrived on closed channel
[W 18:55:33.893 LabApp] zmq message arrived on closed channel
[W 18:55:33.893 LabApp] zmq message arrived on closed channel
[W 18:55:33.894 LabApp] zmq message arrived on closed channel
[W 18:55:33.894 LabApp] zmq message arrived on closed channel
[W 18:55:33.895 LabApp] zmq message arrived on closed channel
[W 18:55:33.895 LabApp] zmq message arrived on closed channel
[W 18:55:33.896 LabApp] zmq message arrived on closed channel
[W 18:55:33.896 LabApp] zmq message arrived on closed channel
[W 18:55:33.896 LabApp] zmq message arrived on closed channel
[W 18:55:33.897 LabApp] zmq message arrived on closed channel
[W 18:55:33.897 LabApp] zmq message arrived on closed channel
[W 18:55:33.898 LabApp] zmq message arrived on closed channel
[W 18:55:33.898 LabApp] zmq message arrived on closed channel
[W 18:55:33.899 LabApp] zmq message arrived on closed channel
[W 18:55:33.899 LabApp] zmq message arrived on closed channel
[W 18:55:33.900 LabApp] zmq message arrived on closed channel
[W 18:55:33.900 LabApp] zmq message arrived on closed channel
[W 18:55:33.901 LabApp] zmq message arrived on closed channel
[W 18:55:33.901 LabApp] zmq message arrived on closed channel
[W 18:55:33.901 LabApp] zmq message arrived on closed channel
[W 18:55:33.902 LabApp] zmq message arrived on closed channel
[W 18:55:33.902 LabApp] zmq message arrived on closed channel
[W 18:55:33.903 LabApp] zmq message arrived on closed channel
[W 18:55:33.903 LabApp] zmq message arrived on closed channel
[W 18:55:33.904 LabApp] zmq message arrived on closed channel
[W 18:55:33.904 LabApp] zmq message arrived on closed channel
[W 18:55:33.905 LabApp] zmq message arrived on closed channel
[W 18:55:33.905 LabApp] zmq message arrived on closed channel
[W 18:55:33.906 LabApp] zmq message arrived on closed channel
[W 18:55:33.906 LabApp] zmq message arrived on closed channel
[W 18:55:33.906 LabApp] zmq message arrived on closed channel
[W 18:55:33.907 LabApp] zmq message arrived on closed channel
[W 18:55:33.907 LabApp] zmq message arrived on closed channel
[W 18:55:33.908 LabApp] zmq message arrived on closed channel
[W 18:55:33.908 LabApp] zmq message arrived on closed channel
[W 18:55:33.909 LabApp] zmq message arrived on closed channel
[W 18:55:33.909 LabApp] zmq message arrived on closed channel
[W 18:55:33.910 LabApp] zmq message arrived on closed channel
[W 18:55:33.910 LabApp] zmq message arrived on closed channel
[W 18:55:33.911 LabApp] zmq message arrived on closed channel
[W 18:55:33.911 LabApp] zmq message arrived on closed channel
[W 18:55:33.911 LabApp] zmq message arrived on closed channel
[W 18:55:33.912 LabApp] zmq message arrived on closed channel
[W 18:55:33.912 LabApp] zmq message arrived on closed channel
[W 18:55:33.913 LabApp] zmq message arrived on closed channel
[W 18:55:33.913 LabApp] zmq message arrived on closed channel
[W 18:55:33.914 LabApp] zmq message arrived on closed channel
[W 18:55:33.914 LabApp] zmq message arrived on closed channel
[W 18:55:33.915 LabApp] zmq message arrived on closed channel
[W 18:55:33.915 LabApp] zmq message arrived on closed channel
[W 18:55:33.916 LabApp] zmq message arrived on closed channel
[W 18:55:33.916 LabApp] zmq message arrived on closed channel
[W 18:55:33.916 LabApp] zmq message arrived on closed channel
[W 18:55:33.917 LabApp] zmq message arrived on closed channel
[W 18:55:33.917 LabApp] zmq message arrived on closed channel
[W 18:55:33.918 LabApp] zmq message arrived on closed channel
[W 18:55:33.918 LabApp] zmq message arrived on closed channel
[W 18:55:33.919 LabApp] zmq message arrived on closed channel
[W 18:55:33.919 LabApp] zmq message arrived on closed channel
[W 18:55:33.920 LabApp] zmq message arrived on closed channel
[W 18:55:33.920 LabApp] zmq message arrived on closed channel
[W 18:55:33.921 LabApp] zmq message arrived on closed channel
[W 18:55:33.921 LabApp] zmq message arrived on closed channel
[W 18:55:33.921 LabApp] zmq message arrived on closed channel
[W 18:55:33.922 LabApp] zmq message arrived on closed channel
[W 18:55:33.922 LabApp] zmq message arrived on closed channel
[W 18:55:33.923 LabApp] zmq message arrived on closed channel
[W 18:55:33.923 LabApp] zmq message arrived on closed channel
[W 18:55:33.924 LabApp] zmq message arrived on closed channel
[W 18:55:33.924 LabApp] zmq message arrived on closed channel
[W 18:55:33.925 LabApp] zmq message arrived on closed channel
[W 18:55:33.925 LabApp] zmq message arrived on closed channel
[W 18:55:33.926 LabApp] zmq message arrived on closed channel
[W 18:55:33.926 LabApp] zmq message arrived on closed channel
[W 18:55:33.926 LabApp] zmq message arrived on closed channel
[W 18:55:33.927 LabApp] zmq message arrived on closed channel
[W 18:55:33.927 LabApp] zmq message arrived on closed channel
[W 18:55:33.928 LabApp] zmq message arrived on closed channel
[W 18:55:33.928 LabApp] zmq message arrived on closed channel
[W 18:55:33.929 LabApp] zmq message arrived on closed channel
[W 18:55:33.929 LabApp] zmq message arrived on closed channel
[W 18:55:33.930 LabApp] zmq message arrived on closed channel
[W 18:55:33.930 LabApp] zmq message arrived on closed channel
[W 18:55:33.931 LabApp] zmq message arrived on closed channel
[W 18:55:33.931 LabApp] zmq message arrived on closed channel
[W 18:55:33.931 LabApp] zmq message arrived on closed channel
[W 18:55:33.932 LabApp] zmq message arrived on closed channel
[W 18:55:33.932 LabApp] zmq message arrived on closed channel
[W 18:55:33.933 LabApp] zmq message arrived on closed channel
[W 18:55:33.933 LabApp] zmq message arrived on closed channel
[W 18:55:33.934 LabApp] zmq message arrived on closed channel
[W 18:55:33.934 LabApp] zmq message arrived on closed channel
[W 18:55:33.935 LabApp] zmq message arrived on closed channel
[W 18:55:33.935 LabApp] zmq message arrived on closed channel
[W 18:55:33.936 LabApp] zmq message arrived on closed channel
[W 18:55:33.936 LabApp] zmq message arrived on closed channel
[W 18:55:33.937 LabApp] zmq message arrived on closed channel
[W 18:55:33.937 LabApp] zmq message arrived on closed channel
[W 18:55:33.937 LabApp] zmq message arrived on closed channel
[W 18:55:33.938 LabApp] zmq message arrived on closed channel
[W 18:55:33.938 LabApp] zmq message arrived on closed channel
[W 18:55:33.939 LabApp] zmq message arrived on closed channel
[W 18:55:33.939 LabApp] zmq message arrived on closed channel
[W 18:55:33.940 LabApp] zmq message arrived on closed channel
[W 18:55:33.940 LabApp] zmq message arrived on closed channel
[W 18:55:33.941 LabApp] zmq message arrived on closed channel
[W 18:55:33.941 LabApp] zmq message arrived on closed channel
[W 18:55:33.942 LabApp] zmq message arrived on closed channel
[W 18:55:33.942 LabApp] zmq message arrived on closed channel
[W 18:55:33.942 LabApp] zmq message arrived on closed channel
[W 18:55:33.943 LabApp] zmq message arrived on closed channel
[W 18:55:33.943 LabApp] zmq message arrived on closed channel
[W 18:55:33.944 LabApp] zmq message arrived on closed channel
[W 18:55:33.944 LabApp] zmq message arrived on closed channel
[W 18:55:33.945 LabApp] zmq message arrived on closed channel
[W 18:55:33.945 LabApp] zmq message arrived on closed channel
[W 18:55:33.946 LabApp] zmq message arrived on closed channel
[W 18:55:33.946 LabApp] zmq message arrived on closed channel
[W 18:55:33.947 LabApp] zmq message arrived on closed channel
[W 18:55:33.947 LabApp] zmq message arrived on closed channel
[W 18:55:33.948 LabApp] zmq message arrived on closed channel
[W 18:55:33.948 LabApp] zmq message arrived on closed channel
[W 18:55:33.948 LabApp] zmq message arrived on closed channel
[W 18:55:33.949 LabApp] zmq message arrived on closed channel
[W 18:55:33.949 LabApp] zmq message arrived on closed channel
[W 18:55:33.950 LabApp] zmq message arrived on closed channel
[W 18:55:33.950 LabApp] zmq message arrived on closed channel
[W 18:55:33.951 LabApp] zmq message arrived on closed channel
[W 18:55:33.951 LabApp] zmq message arrived on closed channel
[W 18:55:33.952 LabApp] zmq message arrived on closed channel
[W 18:55:33.952 LabApp] zmq message arrived on closed channel
[W 18:55:33.953 LabApp] zmq message arrived on closed channel
[W 18:55:33.953 LabApp] zmq message arrived on closed channel
[W 18:55:33.954 LabApp] zmq message arrived on closed channel
[W 18:55:33.954 LabApp] zmq message arrived on closed channel
[W 18:55:33.954 LabApp] zmq message arrived on closed channel
[W 18:55:33.955 LabApp] zmq message arrived on closed channel
[W 18:55:33.955 LabApp] zmq message arrived on closed channel
[W 18:55:33.956 LabApp] zmq message arrived on closed channel
[W 18:55:33.956 LabApp] zmq message arrived on closed channel
[W 18:55:33.957 LabApp] zmq message arrived on closed channel
[W 18:55:33.957 LabApp] zmq message arrived on closed channel
[W 18:55:33.958 LabApp] zmq message arrived on closed channel
[W 18:55:33.958 LabApp] zmq message arrived on closed channel
[W 18:55:33.959 LabApp] zmq message arrived on closed channel
[W 18:55:33.959 LabApp] zmq message arrived on closed channel
[W 18:55:33.959 LabApp] zmq message arrived on closed channel
[W 18:55:33.960 LabApp] zmq message arrived on closed channel
[W 18:55:33.960 LabApp] zmq message arrived on closed channel
[W 18:55:33.961 LabApp] zmq message arrived on closed channel
[W 18:55:33.961 LabApp] zmq message arrived on closed channel
[W 18:55:33.962 LabApp] zmq message arrived on closed channel
[W 18:55:33.962 LabApp] zmq message arrived on closed channel
[W 18:55:33.963 LabApp] zmq message arrived on closed channel
[W 18:55:33.963 LabApp] zmq message arrived on closed channel
[W 18:55:33.964 LabApp] zmq message arrived on closed channel
[W 18:55:33.964 LabApp] zmq message arrived on closed channel
[W 18:55:33.964 LabApp] zmq message arrived on closed channel
[W 18:55:33.965 LabApp] zmq message arrived on closed channel
[W 18:55:33.965 LabApp] zmq message arrived on closed channel
[W 18:55:33.966 LabApp] zmq message arrived on closed channel
[W 18:55:33.966 LabApp] zmq message arrived on closed channel
[W 18:55:33.967 LabApp] zmq message arrived on closed channel
[W 18:55:33.967 LabApp] zmq message arrived on closed channel
[W 18:55:33.968 LabApp] zmq message arrived on closed channel
[W 18:55:33.968 LabApp] zmq message arrived on closed channel
[W 18:55:33.969 LabApp] zmq message arrived on closed channel
[W 18:55:33.969 LabApp] zmq message arrived on closed channel
[W 18:55:33.970 LabApp] zmq message arrived on closed channel
[W 18:55:33.970 LabApp] zmq message arrived on closed channel
[W 18:55:33.970 LabApp] zmq message arrived on closed channel
[W 18:55:33.971 LabApp] zmq message arrived on closed channel
[W 18:55:33.971 LabApp] zmq message arrived on closed channel
[W 18:55:33.972 LabApp] zmq message arrived on closed channel
[W 18:55:33.972 LabApp] zmq message arrived on closed channel
[W 18:55:33.973 LabApp] zmq message arrived on closed channel
[W 18:55:33.973 LabApp] zmq message arrived on closed channel
[W 18:55:33.974 LabApp] zmq message arrived on closed channel
[W 18:55:33.974 LabApp] zmq message arrived on closed channel
[W 18:55:33.975 LabApp] zmq message arrived on closed channel
[W 18:55:33.975 LabApp] zmq message arrived on closed channel
[W 18:55:33.976 LabApp] zmq message arrived on closed channel
[W 18:55:33.976 LabApp] zmq message arrived on closed channel
[W 18:55:33.976 LabApp] zmq message arrived on closed channel
[W 18:55:33.977 LabApp] zmq message arrived on closed channel
[W 18:55:33.977 LabApp] zmq message arrived on closed channel
[W 18:55:33.978 LabApp] zmq message arrived on closed channel
[W 18:55:33.978 LabApp] zmq message arrived on closed channel
[W 18:55:33.979 LabApp] zmq message arrived on closed channel
[W 18:55:33.979 LabApp] zmq message arrived on closed channel
[W 18:55:33.980 LabApp] zmq message arrived on closed channel
[W 18:55:33.980 LabApp] zmq message arrived on closed channel
[W 18:55:33.981 LabApp] zmq message arrived on closed channel
[W 18:55:33.981 LabApp] zmq message arrived on closed channel
[W 18:55:33.982 LabApp] zmq message arrived on closed channel
[W 18:55:33.982 LabApp] zmq message arrived on closed channel
[W 18:55:33.982 LabApp] zmq message arrived on closed channel
[W 18:55:33.983 LabApp] zmq message arrived on closed channel
[W 18:55:33.983 LabApp] zmq message arrived on closed channel
[W 18:55:33.984 LabApp] zmq message arrived on closed channel
[W 18:55:33.984 LabApp] zmq message arrived on closed channel
[W 18:55:33.985 LabApp] zmq message arrived on closed channel
[W 18:55:33.985 LabApp] zmq message arrived on closed channel
[W 18:55:33.986 LabApp] zmq message arrived on closed channel
[W 18:55:33.986 LabApp] zmq message arrived on closed channel
[W 18:55:33.987 LabApp] zmq message arrived on closed channel
[W 18:55:33.987 LabApp] zmq message arrived on closed channel
[W 18:55:33.988 LabApp] zmq message arrived on closed channel
[W 18:55:33.988 LabApp] zmq message arrived on closed channel
[W 18:55:33.988 LabApp] zmq message arrived on closed channel
[W 18:55:33.989 LabApp] zmq message arrived on closed channel
[W 18:55:33.989 LabApp] zmq message arrived on closed channel
[W 18:55:33.990 LabApp] zmq message arrived on closed channel
[W 18:55:33.990 LabApp] zmq message arrived on closed channel
[W 18:55:33.991 LabApp] zmq message arrived on closed channel
[W 18:55:33.991 LabApp] zmq message arrived on closed channel
[W 18:55:33.992 LabApp] zmq message arrived on closed channel
[W 18:55:33.992 LabApp] zmq message arrived on closed channel
[W 18:55:33.993 LabApp] zmq message arrived on closed channel
[W 18:55:33.993 LabApp] zmq message arrived on closed channel
[W 18:55:33.994 LabApp] zmq message arrived on closed channel
[W 18:55:33.994 LabApp] zmq message arrived on closed channel
[W 18:55:33.994 LabApp] zmq message arrived on closed channel
[W 18:55:33.995 LabApp] zmq message arrived on closed channel
[W 18:55:33.995 LabApp] zmq message arrived on closed channel
[W 18:55:33.996 LabApp] zmq message arrived on closed channel
[W 18:55:33.996 LabApp] zmq message arrived on closed channel
[W 18:55:33.997 LabApp] zmq message arrived on closed channel
[W 18:55:33.997 LabApp] zmq message arrived on closed channel
[W 18:55:33.998 LabApp] zmq message arrived on closed channel
[W 18:55:33.998 LabApp] zmq message arrived on closed channel
[W 18:55:33.999 LabApp] zmq message arrived on closed channel
[W 18:55:33.999 LabApp] zmq message arrived on closed channel
[W 18:55:34.000 LabApp] zmq message arrived on closed channel
[W 18:55:34.000 LabApp] zmq message arrived on closed channel
[W 18:55:34.000 LabApp] zmq message arrived on closed channel
[W 18:55:34.001 LabApp] zmq message arrived on closed channel
[W 18:55:34.001 LabApp] zmq message arrived on closed channel
[W 18:55:34.002 LabApp] zmq message arrived on closed channel
[W 18:55:34.002 LabApp] zmq message arrived on closed channel
[W 18:55:34.003 LabApp] zmq message arrived on closed channel
[W 18:55:34.003 LabApp] zmq message arrived on closed channel
[W 18:55:34.004 LabApp] zmq message arrived on closed channel
[W 18:55:34.004 LabApp] zmq message arrived on closed channel
[W 18:55:34.005 LabApp] zmq message arrived on closed channel
[W 18:55:34.005 LabApp] zmq message arrived on closed channel
[W 18:55:34.006 LabApp] zmq message arrived on closed channel
[W 18:55:34.006 LabApp] zmq message arrived on closed channel
[W 18:55:34.006 LabApp] zmq message arrived on closed channel
[W 18:55:34.007 LabApp] zmq message arrived on closed channel
[W 18:55:34.007 LabApp] zmq message arrived on closed channel
[W 18:55:34.008 LabApp] zmq message arrived on closed channel
[W 18:55:34.008 LabApp] zmq message arrived on closed channel
[W 18:55:34.009 LabApp] zmq message arrived on closed channel
[W 18:55:34.009 LabApp] zmq message arrived on closed channel
[W 18:55:34.010 LabApp] zmq message arrived on closed channel
[W 18:55:34.010 LabApp] zmq message arrived on closed channel
[W 18:55:34.011 LabApp] zmq message arrived on closed channel
[W 18:55:34.011 LabApp] zmq message arrived on closed channel
[W 18:55:34.012 LabApp] zmq message arrived on closed channel
[W 18:55:34.012 LabApp] zmq message arrived on closed channel
[W 18:55:34.012 LabApp] zmq message arrived on closed channel
[W 18:55:34.013 LabApp] zmq message arrived on closed channel
[W 18:55:34.013 LabApp] zmq message arrived on closed channel
[W 18:55:34.014 LabApp] zmq message arrived on closed channel
[W 18:55:34.014 LabApp] zmq message arrived on closed channel
[W 18:55:34.015 LabApp] zmq message arrived on closed channel
[W 18:55:34.015 LabApp] zmq message arrived on closed channel
[W 18:55:34.016 LabApp] zmq message arrived on closed channel
[W 18:55:34.016 LabApp] zmq message arrived on closed channel
[W 18:55:34.017 LabApp] zmq message arrived on closed channel
[W 18:55:34.017 LabApp] zmq message arrived on closed channel
[W 18:55:34.017 LabApp] zmq message arrived on closed channel
[W 18:55:34.018 LabApp] zmq message arrived on closed channel
[W 18:55:34.018 LabApp] zmq message arrived on closed channel
[W 18:55:34.019 LabApp] zmq message arrived on closed channel
[W 18:55:34.019 LabApp] zmq message arrived on closed channel
[W 18:55:34.020 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[E 18:55:34.020 LabApp] Uncaught exception GET /api/kernels/b41395eb-52e2-4a6a-bda4-d3ea858d5ff5/channels?session_id=97db3f135c8548ca8220862debe111ad (::1)
    HTTPServerRequest(protocol='http', host='localhost:8187', method='GET', uri='/api/kernels/b41395eb-52e2-4a6a-bda4-d3ea858d5ff5/channels?session_id=97db3f135c8548ca8220862debe111ad', version='HTTP/1.1', remote_ip='::1')
    Traceback (most recent call last):
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/tornado/websocket.py", line 956, in _accept_connection
        open_result = handler.open(*handler.open_args, **handler.open_kwargs)
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/notebook/services/kernels/handlers.py", line 271, in open
        self._on_zmq_reply(stream, msg_list)
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/notebook/services/kernels/handlers.py", line 385, in _on_zmq_reply
        """.format(self.iopub_msg_rate_limit, self.rate_limit_window)))
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/notebook/services/kernels/handlers.py", line 326, in write_stderr
        self.write_message(json.dumps(msg, default=date_default))
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/tornado/websocket.py", line 339, in write_message
        raise WebSocketClosedError()
    tornado.websocket.WebSocketClosedError
Task exception was never retrieved
future: <Task finished coro=<WebSocketProtocol13.write_message.<locals>.wrapper() done, defined at /home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/tornado/websocket.py:1102> exception=WebSocketClosedError()>
Traceback (most recent call last):
  File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/tornado/websocket.py", line 1104, in wrapper
    await fut
tornado.iostream.StreamClosedError: Stream is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/tornado/websocket.py", line 1106, in wrapper
    raise WebSocketClosedError()
tornado.websocket.WebSocketClosedError
[I 18:55:34.330 LabApp] KernelRestarter: restarting kernel (1/5), keep random ports
[I 18:55:34.389 LabApp] Starting buffering for 8b0a7942-bad4-4496-bf94-2db10ebceaa8:5252c64acfb6453b8c0720808d63f0c8
[I 18:55:34.391 LabApp] Kernel interrupted: b41395eb-52e2-4a6a-bda4-d3ea858d5ff5
[I 18:55:34.391 LabApp] Kernel interrupted: b41395eb-52e2-4a6a-bda4-d3ea858d5ff5
[I 18:55:34.393 LabApp] Kernel shutdown: b41395eb-52e2-4a6a-bda4-d3ea858d5ff5
[W 18:55:34.395 LabApp] Got events for closed stream None
[W 18:55:34.411 LabApp] 404 POST /api/kernels/b41395eb-52e2-4a6a-bda4-d3ea858d5ff5/interrupt (::1): Kernel does not exist: b41395eb-52e2-4a6a-bda4-d3ea858d5ff5
[W 18:55:34.411 LabApp] Kernel does not exist: b41395eb-52e2-4a6a-bda4-d3ea858d5ff5
[W 18:55:34.412 LabApp] 404 POST /api/kernels/b41395eb-52e2-4a6a-bda4-d3ea858d5ff5/interrupt (::1) 21.82ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 18:55:35.448 LabApp] Kernel restarted: 8b0a7942-bad4-4496-bf94-2db10ebceaa8
[I 18:55:35.459 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/umap-test.ipynb
[I 18:55:35.616 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/umap-test.ipynb
[I 18:55:35.767 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/umap-test.ipynb
[I 18:55:35.997 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/umap-test.ipynb
[I 18:55:40.236 LabApp] Adapting from protocol version 5.1 (kernel 8b0a7942-bad4-4496-bf94-2db10ebceaa8) to 5.3 (client).
[I 18:55:40.237 LabApp] Restoring connection for 8b0a7942-bad4-4496-bf94-2db10ebceaa8:5252c64acfb6453b8c0720808d63f0c8
[I 18:55:40.237 LabApp] Replaying 11 buffered messages
[I 18:58:16.190 LabApp] Starting buffering for 8b0a7942-bad4-4496-bf94-2db10ebceaa8:5252c64acfb6453b8c0720808d63f0c8
[I 18:58:17.224 LabApp] Kernel restarted: 8b0a7942-bad4-4496-bf94-2db10ebceaa8
[I 18:58:20.551 LabApp] Adapting from protocol version 5.1 (kernel 8b0a7942-bad4-4496-bf94-2db10ebceaa8) to 5.3 (client).
[I 18:58:20.552 LabApp] Restoring connection for 8b0a7942-bad4-4496-bf94-2db10ebceaa8:5252c64acfb6453b8c0720808d63f0c8
[I 18:58:20.552 LabApp] Replaying 6 buffered messages
[I 18:58:30.977 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 18:59:42.719 LabApp] Starting buffering for b1525541-acf6-46ec-a4c2-f05c6c9f83e5:f17fa2536e3640f68f95d7d8de63b71b
[I 18:59:45.072 LabApp] Kernel restarted: b1525541-acf6-46ec-a4c2-f05c6c9f83e5
[I 18:59:48.927 LabApp] Adapting from protocol version 5.1 (kernel b1525541-acf6-46ec-a4c2-f05c6c9f83e5) to 5.3 (client).
[I 18:59:48.928 LabApp] Restoring connection for b1525541-acf6-46ec-a4c2-f05c6c9f83e5:f17fa2536e3640f68f95d7d8de63b71b
[I 18:59:48.928 LabApp] Replaying 7 buffered messages
[I 19:00:04.580 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
2019-10-22 19:00:06.990740: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-22 19:00:12.765440: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-10-22 19:00:12.765643: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: txori
2019-10-22 19:00:12.765676: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: txori
2019-10-22 19:00:12.766464: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.79.0
2019-10-22 19:00:12.766634: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 410.79.0
2019-10-22 19:00:12.766665: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 410.79.0
2019-10-22 19:00:12.816743: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-22 19:00:12.818005: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56055ca57600 executing computations on platform Host. Devices:
2019-10-22 19:00:12.818044: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
[I 19:00:20.608 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 19:01:18.207 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 19:02:04.584 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 19:02:47.702 LabApp] Kernel interrupted: b1525541-acf6-46ec-a4c2-f05c6c9f83e5
[I 19:03:01.992 LabApp] Starting buffering for 8b0a7942-bad4-4496-bf94-2db10ebceaa8:5252c64acfb6453b8c0720808d63f0c8
[I 19:03:03.006 LabApp] Kernel shutdown: 8b0a7942-bad4-4496-bf94-2db10ebceaa8
[E 19:03:30.712 LabApp] Exception restarting kernel
    Traceback (most recent call last):
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/notebook/services/kernels/handlers.py", line 83, in post
        yield maybe_future(km.restart_kernel(kernel_id))
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/tornado/gen.py", line 735, in run
        value = future.result()
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/tornado/gen.py", line 209, in wrapper
        yielded = next(result)
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/notebook/services/kernels/kernelmanager.py", line 307, in restart_kernel
        self._check_kernel_id(kernel_id)
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/notebook/services/kernels/kernelmanager.py", line 387, in _check_kernel_id
        raise web.HTTPError(404, u'Kernel does not exist: %s' % kernel_id)
    tornado.web.HTTPError: HTTP 404: Not Found (Kernel does not exist: 8b0a7942-bad4-4496-bf94-2db10ebceaa8)
[E 19:03:30.714 LabApp] {
      "Host": "localhost:8187",
      "Connection": "keep-alive",
      "Content-Length": "0",
      "Accept": "application/json, text/javascript, */*; q=0.01",
      "Origin": "http://localhost:8187",
      "X-Requested-With": "XMLHttpRequest",
      "X-Xsrftoken": "2|2b997e67|29d4ea20755e92079558d090866cac7e|1571165215",
      "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.120 Safari/537.36",
      "Sec-Fetch-Mode": "cors",
      "Sec-Fetch-Site": "same-origin",
      "Referer": "http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/umap-test.ipynb",
      "Accept-Encoding": "gzip, deflate, br",
      "Accept-Language": "en-US,en;q=0.9,fr;q=0.8",
      "Cookie": "_ga=GA1.1.2135320950.1566148815; username-localhost-8195=\"2|1:0|10:1570831591|23:username-localhost-8195|44:Y2Q0M2Y0YjJhMDQxNDQwZThhOGNjZTdhNDFiNDNkNjI=|4fc2d73bc3298178be788038ba7812e8e7e1ca4ae1891ffcc42a6bd3445055ab\"; username-localhost-8186=\"2|1:0|10:1570831618|23:username-localhost-8186|44:OGQ0ZDZhMzA0OGU3NGJjNmE3ZWQzZTNlNjE0OTE5YTc=|c35b67c47b69b28e578cd086622671b22c440c459eb1f804d2a3d6e6da842624\"; _xsrf=2|2b997e67|29d4ea20755e92079558d090866cac7e|1571165215; username-localhost-8187=\"2|1:0|10:1571718935|23:username-localhost-8187|44:MGRhZDIxMDEzZTkyNGIxMGE1ODBmZDM0Y2YyOGU2ZjE=|e315a1d1a5e394b66f3588185d89736eb254cf8d6d700b4b37283f0fbae7d196\""
    }
[E 19:03:30.714 LabApp] 500 POST /api/kernels/8b0a7942-bad4-4496-bf94-2db10ebceaa8/restart (::1) 3.10ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/umap-test.ipynb
[W 19:03:30.956 LabApp] 404 DELETE /api/sessions/b7ba1d20-7f83-4f3f-b882-f6fd001cfbc9 (::1): Session not found: session_id='b7ba1d20-7f83-4f3f-b882-f6fd001cfbc9'
[W 19:03:30.957 LabApp] Session not found: session_id='b7ba1d20-7f83-4f3f-b882-f6fd001cfbc9'
[W 19:03:30.957 LabApp] 404 DELETE /api/sessions/b7ba1d20-7f83-4f3f-b882-f6fd001cfbc9 (::1) 2.78ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/umap-test.ipynb
[I 19:03:31.263 LabApp] Kernel started: 719a5abc-f86c-45e3-8aee-9183089df680
[I 19:03:34.337 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 19:03:35.474 LabApp] Adapting from protocol version 5.1 (kernel 719a5abc-f86c-45e3-8aee-9183089df680) to 5.3 (client).
[I 19:03:41.273 LabApp] Starting buffering for 719a5abc-f86c-45e3-8aee-9183089df680:5252c64acfb6453b8c0720808d63f0c8
[I 19:03:41.680 LabApp] Kernel shutdown: 719a5abc-f86c-45e3-8aee-9183089df680
[I 19:03:49.501 LabApp] Starting buffering for b1525541-acf6-46ec-a4c2-f05c6c9f83e5:f17fa2536e3640f68f95d7d8de63b71b
[I 19:03:51.349 LabApp] Kernel restarted: b1525541-acf6-46ec-a4c2-f05c6c9f83e5
[I 19:03:57.701 LabApp] Adapting from protocol version 5.1 (kernel b1525541-acf6-46ec-a4c2-f05c6c9f83e5) to 5.3 (client).
[I 19:03:57.703 LabApp] Restoring connection for b1525541-acf6-46ec-a4c2-f05c6c9f83e5:f17fa2536e3640f68f95d7d8de63b71b
[I 19:03:57.720 LabApp] Replaying 6 buffered messages
[I 19:04:04.646 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
2019-10-22 19:04:11.551596: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-22 19:04:15.891026: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-10-22 19:04:15.891112: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: txori
2019-10-22 19:04:15.891145: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: txori
2019-10-22 19:04:15.891560: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.79.0
2019-10-22 19:04:15.891622: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 410.79.0
2019-10-22 19:04:15.891637: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 410.79.0
2019-10-22 19:04:15.931329: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-22 19:04:15.932689: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555d646be530 executing computations on platform Host. Devices:
2019-10-22 19:04:15.932723: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
[I 19:05:15.326 LabApp] Adapting from protocol version 5.1 (kernel cdb62f00-42fe-47a1-88ee-60ee589c4fad) to 5.3 (client).
[I 19:05:15.326 LabApp] Restoring connection for cdb62f00-42fe-47a1-88ee-60ee589c4fad:69f67bf98e054e14a0ebebe149df079f
[I 19:05:55.707 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/umap-test.ipynb
[I 19:05:55.963 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 19:06:08.080 LabApp] Starting buffering for b1525541-acf6-46ec-a4c2-f05c6c9f83e5:f17fa2536e3640f68f95d7d8de63b71b
[I 19:06:10.433 LabApp] Kernel restarted: b1525541-acf6-46ec-a4c2-f05c6c9f83e5
[I 19:06:10.609 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 19:06:15.587 LabApp] Adapting from protocol version 5.1 (kernel b1525541-acf6-46ec-a4c2-f05c6c9f83e5) to 5.3 (client).
[I 19:06:15.589 LabApp] Restoring connection for b1525541-acf6-46ec-a4c2-f05c6c9f83e5:f17fa2536e3640f68f95d7d8de63b71b
[I 19:06:15.589 LabApp] Replaying 6 buffered messages
[I 19:06:27.121 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/umap-test.ipynb
[E 19:06:29.538 LabApp] Exception restarting kernel
    Traceback (most recent call last):
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/notebook/services/kernels/handlers.py", line 83, in post
        yield maybe_future(km.restart_kernel(kernel_id))
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/tornado/gen.py", line 735, in run
        value = future.result()
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/tornado/gen.py", line 209, in wrapper
        yielded = next(result)
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/notebook/services/kernels/kernelmanager.py", line 307, in restart_kernel
        self._check_kernel_id(kernel_id)
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/notebook/services/kernels/kernelmanager.py", line 387, in _check_kernel_id
        raise web.HTTPError(404, u'Kernel does not exist: %s' % kernel_id)
    tornado.web.HTTPError: HTTP 404: Not Found (Kernel does not exist: 719a5abc-f86c-45e3-8aee-9183089df680)
[E 19:06:29.539 LabApp] {
      "Host": "localhost:8187",
      "Connection": "keep-alive",
      "Content-Length": "0",
      "Accept": "application/json, text/javascript, */*; q=0.01",
      "Origin": "http://localhost:8187",
      "X-Requested-With": "XMLHttpRequest",
      "X-Xsrftoken": "2|2b997e67|29d4ea20755e92079558d090866cac7e|1571165215",
      "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.120 Safari/537.36",
      "Sec-Fetch-Mode": "cors",
      "Sec-Fetch-Site": "same-origin",
      "Referer": "http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/umap-test.ipynb",
      "Accept-Encoding": "gzip, deflate, br",
      "Accept-Language": "en-US,en;q=0.9,fr;q=0.8",
      "Cookie": "_ga=GA1.1.2135320950.1566148815; username-localhost-8195=\"2|1:0|10:1570831591|23:username-localhost-8195|44:Y2Q0M2Y0YjJhMDQxNDQwZThhOGNjZTdhNDFiNDNkNjI=|4fc2d73bc3298178be788038ba7812e8e7e1ca4ae1891ffcc42a6bd3445055ab\"; username-localhost-8186=\"2|1:0|10:1570831618|23:username-localhost-8186|44:OGQ0ZDZhMzA0OGU3NGJjNmE3ZWQzZTNlNjE0OTE5YTc=|c35b67c47b69b28e578cd086622671b22c440c459eb1f804d2a3d6e6da842624\"; _xsrf=2|2b997e67|29d4ea20755e92079558d090866cac7e|1571165215; username-localhost-8187=\"2|1:0|10:1571718935|23:username-localhost-8187|44:MGRhZDIxMDEzZTkyNGIxMGE1ODBmZDM0Y2YyOGU2ZjE=|e315a1d1a5e394b66f3588185d89736eb254cf8d6d700b4b37283f0fbae7d196\""
    }
[E 19:06:29.539 LabApp] 500 POST /api/kernels/719a5abc-f86c-45e3-8aee-9183089df680/restart (::1) 1.62ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/umap-test.ipynb
[W 19:06:29.577 LabApp] 404 DELETE /api/sessions/e5cb053b-abd9-4b1b-ac87-2f33ddd95c0c (::1): Session not found: session_id='e5cb053b-abd9-4b1b-ac87-2f33ddd95c0c'
[W 19:06:29.577 LabApp] Session not found: session_id='e5cb053b-abd9-4b1b-ac87-2f33ddd95c0c'
[W 19:06:29.577 LabApp] 404 DELETE /api/sessions/e5cb053b-abd9-4b1b-ac87-2f33ddd95c0c (::1) 1.31ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/umap-test.ipynb
[I 19:06:29.638 LabApp] Kernel started: c328fcc9-941d-4dc5-ac30-db4dc767eab3
[I 19:06:31.977 LabApp] Adapting from protocol version 5.1 (kernel c328fcc9-941d-4dc5-ac30-db4dc767eab3) to 5.3 (client).
2019-10-22 19:06:40.803143: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-22 19:06:40.804236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-22 19:06:40.804311: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-22 19:06:40.804376: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-22 19:06:40.806000: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-22 19:06:40.806069: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-22 19:06:40.806124: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-22 19:06:40.806181: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-22 19:06:40.809970: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-22 19:06:40.811563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-22 19:06:40.861121: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555db1bb45f0 executing computations on platform CUDA. Devices:
2019-10-22 19:06:40.861170: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-22 19:06:40.866830: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-22 19:06:40.870079: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555db1c8bb00 executing computations on platform Host. Devices:
2019-10-22 19:06:40.870155: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-22 19:06:40.871871: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-22 19:06:40.872006: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-22 19:06:40.872073: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-22 19:06:40.872224: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-22 19:06:40.872294: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-22 19:06:40.872360: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-22 19:06:40.872419: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-22 19:06:40.872512: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-22 19:06:40.875167: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-22 19:06:40.875295: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-22 19:06:40.875544: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-22 19:06:40.875591: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-22 19:06:40.875609: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-22 19:06:40.878003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11238 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
[I 19:06:42.439 LabApp] Starting buffering for c328fcc9-941d-4dc5-ac30-db4dc767eab3:5252c64acfb6453b8c0720808d63f0c8
[I 19:06:43.074 LabApp] Kernel restarted: c328fcc9-941d-4dc5-ac30-db4dc767eab3
[I 19:06:46.952 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 19:06:47.630 LabApp] Adapting from protocol version 5.1 (kernel c328fcc9-941d-4dc5-ac30-db4dc767eab3) to 5.3 (client).
[I 19:06:47.631 LabApp] Restoring connection for c328fcc9-941d-4dc5-ac30-db4dc767eab3:5252c64acfb6453b8c0720808d63f0c8
[I 19:06:47.631 LabApp] Replaying 6 buffered messages
[I 19:07:03.588 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/umap-test.ipynb
[I 19:07:05.691 LabApp] Starting buffering for c328fcc9-941d-4dc5-ac30-db4dc767eab3:5252c64acfb6453b8c0720808d63f0c8
[I 19:07:06.619 LabApp] Kernel restarted: c328fcc9-941d-4dc5-ac30-db4dc767eab3
[I 19:07:08.831 LabApp] Adapting from protocol version 5.1 (kernel c328fcc9-941d-4dc5-ac30-db4dc767eab3) to 5.3 (client).
[I 19:07:08.832 LabApp] Restoring connection for c328fcc9-941d-4dc5-ac30-db4dc767eab3:5252c64acfb6453b8c0720808d63f0c8
[I 19:07:08.832 LabApp] Replaying 6 buffered messages
[I 19:07:55.804 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 19:08:22.030 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 19:08:26.028 LabApp] Starting buffering for b1525541-acf6-46ec-a4c2-f05c6c9f83e5:f17fa2536e3640f68f95d7d8de63b71b
[I 19:08:32.432 LabApp] Kernel restarted: b1525541-acf6-46ec-a4c2-f05c6c9f83e5
[I 19:08:37.249 LabApp] Adapting from protocol version 5.1 (kernel b1525541-acf6-46ec-a4c2-f05c6c9f83e5) to 5.3 (client).
[I 19:08:37.251 LabApp] Restoring connection for b1525541-acf6-46ec-a4c2-f05c6c9f83e5:f17fa2536e3640f68f95d7d8de63b71b
[I 19:08:37.251 LabApp] Replaying 6 buffered messages
2019-10-22 19:08:57.663877: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-22 19:08:57.665479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-22 19:08:57.665594: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-22 19:08:57.665712: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-22 19:08:57.668009: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-22 19:08:57.668123: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-22 19:08:57.668207: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-22 19:08:57.668293: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-22 19:08:57.673765: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-22 19:08:57.676100: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-22 19:08:57.739001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56427ec1f8f0 executing computations on platform CUDA. Devices:
2019-10-22 19:08:57.739097: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-22 19:08:57.745811: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-22 19:08:57.748515: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56427ecf6dc0 executing computations on platform Host. Devices:
2019-10-22 19:08:57.748569: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-22 19:08:57.750223: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-22 19:08:57.750337: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-22 19:08:57.750404: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-22 19:08:57.750556: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-22 19:08:57.750627: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-22 19:08:57.750686: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-22 19:08:57.750743: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-22 19:08:57.750834: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-22 19:08:57.753758: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-22 19:08:57.753881: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-22 19:08:57.754152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-22 19:08:57.754207: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-22 19:08:57.754229: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-22 19:08:57.757854: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11238 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
[I 19:09:34.023 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/umap-test.ipynb
[I 19:09:35.693 LabApp] Starting buffering for c328fcc9-941d-4dc5-ac30-db4dc767eab3:5252c64acfb6453b8c0720808d63f0c8
[I 19:09:36.632 LabApp] Kernel restarted: c328fcc9-941d-4dc5-ac30-db4dc767eab3
[I 19:09:40.545 LabApp] Adapting from protocol version 5.1 (kernel c328fcc9-941d-4dc5-ac30-db4dc767eab3) to 5.3 (client).
[I 19:09:40.546 LabApp] Restoring connection for c328fcc9-941d-4dc5-ac30-db4dc767eab3:5252c64acfb6453b8c0720808d63f0c8
[I 19:09:40.546 LabApp] Replaying 6 buffered messages
[I 19:09:55.798 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 19:11:55.848 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 19:12:26.764 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/umap-test.ipynb
[I 19:12:37.263 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/umap-test.ipynb
[I 19:12:41.163 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/umap-test.ipynb
[I 19:12:45.902 LabApp] Starting buffering for c328fcc9-941d-4dc5-ac30-db4dc767eab3:5252c64acfb6453b8c0720808d63f0c8
[I 19:12:46.834 LabApp] Kernel restarted: c328fcc9-941d-4dc5-ac30-db4dc767eab3
[I 19:12:51.085 LabApp] Adapting from protocol version 5.1 (kernel c328fcc9-941d-4dc5-ac30-db4dc767eab3) to 5.3 (client).
[I 19:12:51.087 LabApp] Restoring connection for c328fcc9-941d-4dc5-ac30-db4dc767eab3:5252c64acfb6453b8c0720808d63f0c8
[I 19:12:51.087 LabApp] Replaying 6 buffered messages
[W 19:14:33.467 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.68ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/mouse-usv-PCA-projections.ipynb
[W 19:14:33.856 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 1.42ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/mouse-usv-PCA-projections.ipynb
[I 19:14:35.494 LabApp] Adapting from protocol version 5.1 (kernel 567f8b1e-f0e6-44ce-aaf6-0db2311add48) to 5.3 (client).
[I 19:14:37.596 LabApp] Starting buffering for 567f8b1e-f0e6-44ce-aaf6-0db2311add48:a1bb8f6cd93140d7be728f5e375d2a59
[I 19:14:44.192 LabApp] 302 GET /notebooks/avgn_paper/notebooks/ (::1) 0.56ms
[I 19:14:44.218 LabApp] 302 GET /notebooks/avgn_paper/notebooks (::1) 1.01ms
[W 19:14:44.789 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 1.40ms referer=http://localhost:8187/tree/avgn_paper/notebooks
[W 19:14:52.501 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 4.20ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/bf-sober-transitions-barcode.ipynb
[W 19:14:53.463 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 1.54ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/bf-sober-transitions-barcode.ipynb
[I 19:16:15.702 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap.ipynb
[I 19:16:46.630 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 19:17:10.671 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/bf-sober-transitions-barcode.ipynb
[I 19:18:46.591 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 19:19:14.419 LabApp] 302 GET /notebooks/avgn_paper/figures (::1) 2.87ms
[W 19:19:15.103 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 3.07ms referer=http://localhost:8187/tree/avgn_paper/figures
[W 19:20:44.421 LabApp] Blocking request with no referer
[W 19:20:44.421 LabApp] 403 GET /files/avgn_paper/figures/umap_seqs/bengalese_finch_sober/sober_bf-spec-lab_100.png (::1): Blocking request from unknown origin
[W 19:20:44.424 LabApp] 403 GET /files/avgn_paper/figures/umap_seqs/bengalese_finch_sober/sober_bf-spec-lab_100.png (::1) 4.31ms referer=None
[I 19:20:47.129 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 19:26:36.237 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap.ipynb
[I 19:28:26.933 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 19:32:40.174 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap.ipynb
[I 19:33:46.893 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 19:36:57.144 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap.ipynb
[I 19:39:06.918 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 19:44:26.921 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 19:47:20.206 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap.ipynb
[I 19:49:01.202 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap.ipynb
[I 19:50:39.198 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap.ipynb
[I 19:53:26.825 LabApp] Kernel interrupted: c328fcc9-941d-4dc5-ac30-db4dc767eab3
[I 19:54:03.428 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap.ipynb
[I 19:57:43.818 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap.ipynb
[I 20:00:26.980 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 20:01:31.658 LabApp] Kernel interrupted: b1525541-acf6-46ec-a4c2-f05c6c9f83e5
[I 20:02:25.913 LabApp] Kernel interrupted: b1525541-acf6-46ec-a4c2-f05c6c9f83e5
[I 20:06:12.660 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 20:06:44.504 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1053.ipynb
[I 20:06:45.348 LabApp] Copying avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1053.ipynb to /avgn_paper/notebooks/5.0-visualize-transitions
[W 20:06:49.309 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 8.27ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1053-Copy1.ipynb
[I 20:06:50.054 LabApp] Kernel started: 5ac8a8d9-eb8e-4139-b002-9956905c6930
[I 20:06:52.649 LabApp] Adapting from protocol version 5.1 (kernel 5ac8a8d9-eb8e-4139-b002-9956905c6930) to 5.3 (client).
/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/backend/semaphore_tracker.py:198: UserWarning: semaphore_tracker: There appear to be 6 leaked semaphores to clean up at shutdown
  len(cache))
[I 20:07:05.434 LabApp] KernelRestarter: restarting kernel (1/5), keep random ports
kernel b1525541-acf6-46ec-a4c2-f05c6c9f83e5 restarted
[I 20:08:50.186 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 20:08:59.769 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 20:09:10.161 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 20:09:52.195 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 20:10:14.776 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 20:12:12.341 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 20:14:22.183 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 20:15:09.974 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 20:15:12.655 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 20:15:20.360 LabApp] Starting buffering for 5ac8a8d9-eb8e-4139-b002-9956905c6930:81a6fac6a80f45bc8db89665e391a525
[I 20:15:21.945 LabApp] Kernel restarted: 5ac8a8d9-eb8e-4139-b002-9956905c6930
[I 20:15:25.691 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 20:15:26.397 LabApp] Adapting from protocol version 5.1 (kernel 5ac8a8d9-eb8e-4139-b002-9956905c6930) to 5.3 (client).
[I 20:15:26.398 LabApp] Restoring connection for 5ac8a8d9-eb8e-4139-b002-9956905c6930:81a6fac6a80f45bc8db89665e391a525
[I 20:15:26.398 LabApp] Replaying 6 buffered messages
[I 20:15:30.873 LabApp] 302 GET /notebooks/avgn_paper/notebooks/5.0-visualize-transitions/ (::1) 0.71ms
[I 20:15:30.899 LabApp] 302 GET /notebooks/avgn_paper/notebooks/5.0-visualize-transitions (::1) 1.22ms
[W 20:15:31.539 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 2.28ms referer=http://localhost:8187/tree/avgn_paper/notebooks/5.0-visualize-transitions
[W 20:15:42.020 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 1.64ms referer=http://localhost:8187/tree/avgn_paper/notebooks/1.0-custom-parsing
[W 20:15:58.325 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 4.95ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/1.0-custom-parsing/08.0-mouse-usv-custom-parsing.ipynb
[I 20:15:58.677 LabApp] Kernel started: 167b6f67-9758-4944-945d-bb06ca0a62c3
[W 20:15:58.771 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 3.07ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/1.0-custom-parsing/08.0-mouse-usv-custom-parsing.ipynb
[I 20:15:59.674 LabApp] Adapting from protocol version 5.1 (kernel 167b6f67-9758-4944-945d-bb06ca0a62c3) to 5.3 (client).
[W 20:16:32.254 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 5.83ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/0.1-data-exploration/mouse_usv/0.1-Mouse-USV-Data-Exploration-2nd-dataset.ipynb
[W 20:16:32.672 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 1.41ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/0.1-data-exploration/mouse_usv/0.1-Mouse-USV-Data-Exploration-2nd-dataset.ipynb
[I 20:16:33.321 LabApp] Kernel started: 32efcdc9-958a-4866-b649-b4719a7349ae
[I 20:16:34.472 LabApp] Adapting from protocol version 5.1 (kernel 32efcdc9-958a-4866-b649-b4719a7349ae) to 5.3 (client).
[I 20:17:40.767 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 20:17:59.343 LabApp] Saving file at /avgn_paper/notebooks/1.0-custom-parsing/08.0-mouse-usv-custom-parsing.ipynb
[I 20:18:31.921 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-umap-single-song.ipynb
[I 20:20:31.926 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-umap-single-song.ipynb
[I 20:22:31.951 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-umap-single-song.ipynb
[I 20:24:31.931 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-umap-single-song.ipynb
[I 20:25:11.467 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 20:26:31.962 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-umap-single-song.ipynb
[I 20:27:41.729 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 20:28:32.853 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-umap-single-song.ipynb
[I 20:30:35.437 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-umap-single-song.ipynb
[I 20:32:36.331 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-umap-single-song.ipynb
[I 20:32:42.968 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 20:33:50.280 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 20:34:40.631 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 20:35:16.636 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 20:37:43.658 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 20:40:13.667 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 20:42:47.750 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 20:43:16.251 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 20:43:21.664 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 20:45:16.621 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 20:47:49.047 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[W 20:47:50.328 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 3.10ms referer=http://localhost:8187/tree/avgn_paper/figures/umap_seqs/bengalese_finch_sober
[I 20:47:59.936 LabApp] 302 GET /tree/avgn_paper/ (::1) 1.11ms
[W 20:48:00.540 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 3.15ms referer=http://localhost:8187/tree/avgn_paper
[W 20:48:55.180 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 3.16ms referer=http://localhost:8187/tree/avgn_paper/notebooks/5.0-visualize-transitions
[W 20:48:59.236 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 5.83ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/bf-sober-transitions-barcode.ipynb
[W 20:49:00.546 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 3.08ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/bf-sober-transitions-barcode.ipynb
[W 20:49:07.000 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 5.28ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/transitions-bengalese-finch-sober-with-dendrogram.ipynb
[I 20:49:07.717 LabApp] Adapting from protocol version 5.1 (kernel a64a2193-19ce-4f69-9641-e19bc2fee84d) to 5.3 (client).
[W 20:49:07.792 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 3.17ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/transitions-bengalese-finch-sober-with-dendrogram.ipynb
[I 20:50:16.786 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 20:51:08.697 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/transitions-bengalese-finch-sober-with-dendrogram.ipynb
[I 20:51:17.658 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/bf-sober-transitions-barcode.ipynb
[I 20:52:47.282 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 20:55:16.841 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 20:57:47.121 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 21:00:17.178 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
2019-10-22 21:02:05.788618: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
[I 21:02:09.038 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
2019-10-22 21:02:11.539445: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-10-22 21:02:11.539522: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: txori
2019-10-22 21:02:11.539535: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: txori
2019-10-22 21:02:11.539653: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.79.0
2019-10-22 21:02:11.539702: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 410.79.0
2019-10-22 21:02:11.539715: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 410.79.0
2019-10-22 21:02:11.586301: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-22 21:02:11.587984: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56512bb39950 executing computations on platform Host. Devices:
2019-10-22 21:02:11.588033: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
[I 21:05:36.062 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 21:12:54.198 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 21:13:01.836 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 21:15:17.128 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 21:17:46.923 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 21:20:16.892 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 21:22:46.939 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 21:25:17.298 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 21:27:47.422 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 21:30:17.488 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 21:32:47.451 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 21:35:17.534 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 21:37:47.187 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 21:40:18.706 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 21:42:19.028 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 21:42:34.670 LabApp] Kernel interrupted: b1525541-acf6-46ec-a4c2-f05c6c9f83e5
[I 21:45:19.236 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 21:45:23.854 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 21:46:47.098 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 21:47:27.456 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 21:47:50.187 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 21:47:53.879 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 21:48:37.545 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 21:49:42.844 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 21:49:44.007 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 21:51:39.558 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 21:52:48.108 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 21:55:17.955 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 21:56:23.003 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 21:57:50.346 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 22:00:19.684 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 22:02:21.856 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 22:02:47.448 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 22:04:13.700 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 22:05:14.533 LabApp] Starting buffering for 5ac8a8d9-eb8e-4139-b002-9956905c6930:81a6fac6a80f45bc8db89665e391a525
[I 22:05:17.612 LabApp] Kernel restarted: 5ac8a8d9-eb8e-4139-b002-9956905c6930
[I 22:05:21.873 LabApp] Adapting from protocol version 5.1 (kernel 5ac8a8d9-eb8e-4139-b002-9956905c6930) to 5.3 (client).
[I 22:05:21.875 LabApp] Restoring connection for 5ac8a8d9-eb8e-4139-b002-9956905c6930:81a6fac6a80f45bc8db89665e391a525
[I 22:05:21.875 LabApp] Replaying 6 buffered messages
[I 22:05:24.111 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 22:05:45.486 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 22:10:17.127 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 22:12:45.972 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 22:15:16.335 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 22:15:27.421 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 22:17:46.449 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 22:18:53.370 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 22:20:16.546 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 22:22:57.129 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 22:25:33.089 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 22:26:05.118 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 22:27:14.687 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[W 22:28:06.545 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 3.31ms referer=http://localhost:8187/tree/avgn_paper/notebooks
[W 22:28:59.050 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 3.52ms referer=http://localhost:8187/tree/avgn_paper/figures/umap_seqs/bengalese_finch_sober
[I 22:29:21.072 LabApp] Starting buffering for 32efcdc9-958a-4866-b649-b4719a7349ae:97f4c053614c47708bed9ab3c8edb607
[I 22:29:25.995 LabApp] Adapting from protocol version 5.1 (kernel 32efcdc9-958a-4866-b649-b4719a7349ae) to 5.3 (client).
[I 22:31:38.488 LabApp] Starting buffering for 5e7b4be6-7cfb-4bed-be7a-1317135b8c1c:7759f7117cbb45088b23864c320e2468
[I 22:32:06.224 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 22:38:04.933 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 22:41:01.985 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 22:44:05.788 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 22:47:03.710 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 22:47:04.181 LabApp] Kernel interrupted: 5ac8a8d9-eb8e-4139-b002-9956905c6930
[I 22:49:48.942 LabApp] Kernel interrupted: 5ac8a8d9-eb8e-4139-b002-9956905c6930
[I 22:50:05.251 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 22:50:26.827 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 22:52:54.011 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 22:53:05.120 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[W 22:55:48.060 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 3.88ms referer=http://localhost:8187/tree/avgn_paper/figures/umap_seqs/european_starling_gentner_segmented
[I 23:16:53.311 LabApp] Starting buffering for a64a2193-19ce-4f69-9641-e19bc2fee84d:efedeb8803ba447891b68fcfccc31a69
[I 23:16:59.404 LabApp] Starting buffering for 5ac8a8d9-eb8e-4139-b002-9956905c6930:81a6fac6a80f45bc8db89665e391a525
[I 23:17:01.826 LabApp] Kernel shutdown: 5ac8a8d9-eb8e-4139-b002-9956905c6930
[I 23:17:10.156 LabApp] Starting buffering for c328fcc9-941d-4dc5-ac30-db4dc767eab3:5252c64acfb6453b8c0720808d63f0c8
[I 23:20:36.467 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-umap-single-song.ipynb
[I 23:22:38.828 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-umap-single-song.ipynb
[I 23:24:34.963 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-umap-single-song.ipynb
[I 23:25:45.986 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-umap-single-song.ipynb
[I 23:26:16.077 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-umap-single-song.ipynb
[I 23:26:36.850 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-umap-single-song.ipynb
[I 23:26:44.771 LabApp] 302 GET /notebooks/avgn_paper/notebooks/5.0-visualize-transitions/ (::1) 0.56ms
[I 23:26:44.823 LabApp] 302 GET /notebooks/avgn_paper/notebooks/5.0-visualize-transitions (::1) 1.37ms
[W 23:26:45.404 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 2.02ms referer=http://localhost:8187/tree/avgn_paper/notebooks/5.0-visualize-transitions
[I 23:28:37.002 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-umap-single-song.ipynb
[W 23:34:46.367 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.57ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 23:34:47.466 LabApp] Kernel started: 1300fffe-f532-4c8c-a549-35ab08e92fd7
[W 23:34:47.712 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 3.00ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 23:34:48.885 LabApp] Adapting from protocol version 5.1 (kernel 1300fffe-f532-4c8c-a549-35ab08e92fd7) to 5.3 (client).
[I 23:34:57.781 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 23:34:58.596 LabApp] Copying avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb to /avgn_paper/notebooks/5.0-visualize-transitions
[W 23:35:01.164 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 2.92ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060-Copy1.ipynb
[I 23:35:02.709 LabApp] Kernel started: 6778c2fd-8e21-4b6c-a49b-52668a46fbc6
[I 23:35:03.682 LabApp] Adapting from protocol version 5.1 (kernel 6778c2fd-8e21-4b6c-a49b-52668a46fbc6) to 5.3 (client).
[I 23:37:09.655 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap.ipynb
[I 23:38:36.858 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-umap-single-song.ipynb
[I 23:39:09.279 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap.ipynb
[I 23:40:49.499 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap.ipynb
[I 23:41:09.683 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap.ipynb
[I 23:43:09.254 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap.ipynb
[I 23:44:34.487 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-umap-single-song.ipynb
[I 23:45:08.272 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap.ipynb
[I 23:45:50.279 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap.ipynb
[I 23:46:36.449 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-umap-single-song.ipynb
[I 23:46:51.757 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap.ipynb
[I 23:50:36.355 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-umap-single-song.ipynb
[I 23:55:47.016 LabApp] Starting buffering for 6778c2fd-8e21-4b6c-a49b-52668a46fbc6:4eec9349ae194882b04ee9451c42dce2
[I 23:55:48.097 LabApp] Kernel restarted: 6778c2fd-8e21-4b6c-a49b-52668a46fbc6
[I 23:55:49.325 LabApp] Adapting from protocol version 5.1 (kernel 6778c2fd-8e21-4b6c-a49b-52668a46fbc6) to 5.3 (client).
[I 23:55:49.327 LabApp] Restoring connection for 6778c2fd-8e21-4b6c-a49b-52668a46fbc6:4eec9349ae194882b04ee9451c42dce2
[I 23:55:49.327 LabApp] Replaying 6 buffered messages
[I 23:57:02.697 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap.ipynb
[I 23:59:03.616 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap.ipynb
[I 00:00:37.466 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-umap-single-song.ipynb
[I 01:01:20.621 LabApp] Starting buffering for 1300fffe-f532-4c8c-a549-35ab08e92fd7:24d6f2d60b8445d6b48020d322011b62
[I 08:57:05.227 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap.ipynb
[I 08:59:04.021 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap.ipynb
[I 09:00:37.787 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-umap-single-song.ipynb
[I 09:01:03.982 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap.ipynb
[I 09:01:20.605 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap.ipynb
[I 09:03:04.141 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap.ipynb
[I 09:04:17.135 LabApp] Kernel interrupted: 6778c2fd-8e21-4b6c-a49b-52668a46fbc6
[I 09:05:06.154 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap.ipynb
[I 09:07:06.185 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap.ipynb
[I 09:09:06.943 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap.ipynb
[I 09:11:06.236 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap.ipynb
[I 09:13:07.733 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap.ipynb
[W 09:14:20.651 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.59ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[W 09:14:21.904 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 2.70ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 09:14:22.879 LabApp] Adapting from protocol version 5.1 (kernel 1300fffe-f532-4c8c-a549-35ab08e92fd7) to 5.3 (client).
[I 09:15:07.708 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap.ipynb
[I 09:16:29.738 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 09:17:07.737 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap.ipynb
[I 09:18:40.781 LabApp] Kernel interrupted: 6778c2fd-8e21-4b6c-a49b-52668a46fbc6
[I 09:19:06.497 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap.ipynb
[I 09:19:13.301 LabApp] Kernel interrupted: 6778c2fd-8e21-4b6c-a49b-52668a46fbc6
[I 09:19:51.782 LabApp] Kernel interrupted: 6778c2fd-8e21-4b6c-a49b-52668a46fbc6
[I 09:20:20.998 LabApp] Kernel interrupted: 6778c2fd-8e21-4b6c-a49b-52668a46fbc6
[I 09:21:08.138 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap.ipynb
[W 09:21:44.317 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 4.44ms referer=http://localhost:8187/tree/avgn_paper/figures/umap_seqs/european_starling_gentner_segmented
[W 09:21:59.259 LabApp] Notebook avgn_paper/notebooks/2.0-make-syllable_df/human-make-phones-df.ipynb is not trusted
[W 09:21:59.615 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 4.22ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/2.0-make-syllable_df/human-make-phones-df.ipynb
[W 09:22:02.082 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 3.63ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/2.0-make-syllable_df/human-make-phones-df.ipynb
[I 09:22:04.775 LabApp] Kernel started: 6e317bc5-fc1a-44c4-8e4e-56b533c98cf6
[I 09:22:08.756 LabApp] Adapting from protocol version 5.1 (kernel 6e317bc5-fc1a-44c4-8e4e-56b533c98cf6) to 5.3 (client).
[I 09:23:05.739 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap.ipynb
[I 09:24:22.651 LabApp] Saving file at /avgn_paper/notebooks/2.0-make-syllable_df/human-make-phones-df.ipynb
[W 09:24:22.654 LabApp] Notebook avgn_paper/notebooks/2.0-make-syllable_df/human-make-phones-df.ipynb is not trusted
[I 09:25:10.090 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap.ipynb
[I 09:25:45.884 LabApp] Kernel interrupted: 073e0049-65f0-4a3f-b6a4-42a203713fe6
[I 09:25:49.495 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-umap-single-song.ipynb
[I 09:25:50.313 LabApp] KernelRestarter: restarting kernel (1/5), keep random ports
kernel 073e0049-65f0-4a3f-b6a4-42a203713fe6 restarted
[I 09:25:55.290 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-umap-single-song.ipynb
[I 09:26:37.814 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-umap-single-song.ipynb
[I 09:27:27.197 LabApp] 302 GET /notebooks/avgn_paper/notebooks/5.0-visualize-transitions/ (::1) 1.85ms
[I 09:27:27.223 LabApp] 302 GET /notebooks/avgn_paper/notebooks/5.0-visualize-transitions (::1) 3.16ms
[W 09:27:27.837 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 3.15ms referer=http://localhost:8187/tree/avgn_paper/notebooks/5.0-visualize-transitions
[I 09:28:37.823 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-umap-single-song.ipynb
[I 09:31:10.090 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap.ipynb
[I 09:33:15.113 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap.ipynb
[I 09:35:32.938 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap.ipynb
[I 09:37:38.566 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap.ipynb
[I 09:39:37.326 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap.ipynb
[I 09:39:38.380 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap.ipynb
[I 09:42:04.375 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap.ipynb
[I 09:43:21.260 LabApp] Starting buffering for 6778c2fd-8e21-4b6c-a49b-52668a46fbc6:4eec9349ae194882b04ee9451c42dce2
[W 09:43:24.995 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 4.73ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap.ipynb
[I 09:43:28.043 LabApp] Adapting from protocol version 5.1 (kernel 6778c2fd-8e21-4b6c-a49b-52668a46fbc6) to 5.3 (client).
[I 09:44:13.753 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-umap-single-song.ipynb
[I 09:44:37.853 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-umap-single-song.ipynb
[I 09:46:35.514 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-umap-single-song.ipynb
[I 09:47:35.943 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap.ipynb
[I 09:47:51.032 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap.ipynb
[I 09:48:35.512 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-umap-single-song.ipynb
[I 09:49:35.940 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap.ipynb
[I 09:51:33.634 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-100.ipynb
[I 09:51:39.332 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-100.ipynb
[I 09:51:43.573 LabApp] Copying avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-100.ipynb to /avgn_paper/notebooks/5.0-visualize-transitions
[W 09:51:47.967 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 4.69ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-100-Copy1.ipynb
[I 09:51:49.421 LabApp] Kernel started: 57564d53-1477-4e98-8fd3-56514f29a2e6
[I 09:51:52.212 LabApp] Adapting from protocol version 5.1 (kernel 57564d53-1477-4e98-8fd3-56514f29a2e6) to 5.3 (client).
[I 09:52:22.834 LabApp] KernelRestarter: restarting kernel (1/5), keep random ports
[I 09:53:58.077 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-20.ipynb
[I 09:55:57.098 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-20.ipynb
[I 09:56:06.261 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-20.ipynb
[I 09:57:58.252 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-20.ipynb
[I 09:59:56.073 LabApp] Starting buffering for 57564d53-1477-4e98-8fd3-56514f29a2e6:a4c1833ee3444e67844c9273b8741415
[I 09:59:57.807 LabApp] Kernel restarted: 57564d53-1477-4e98-8fd3-56514f29a2e6
[I 09:59:58.292 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-20.ipynb
[I 09:59:59.975 LabApp] Adapting from protocol version 5.1 (kernel 57564d53-1477-4e98-8fd3-56514f29a2e6) to 5.3 (client).
[I 09:59:59.976 LabApp] Restoring connection for 57564d53-1477-4e98-8fd3-56514f29a2e6:a4c1833ee3444e67844c9273b8741415
[I 09:59:59.976 LabApp] Replaying 6 buffered messages
[I 10:00:32.520 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-umap-single-song.ipynb
[I 10:01:56.797 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-20.ipynb
[I 10:02:35.286 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-umap-single-song.ipynb
[I 10:03:58.196 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-20.ipynb
[I 10:04:35.284 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-umap-single-song.ipynb
[I 10:06:31.109 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-20.ipynb
[I 10:08:51.053 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-20.ipynb
[I 10:10:23.337 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-20.ipynb
[I 10:11:11.086 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-20.ipynb
[I 10:13:31.096 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-20.ipynb
[I 10:15:51.162 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-20.ipynb
[I 10:17:59.949 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-20.ipynb
[I 10:18:11.534 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-20.ipynb
[I 10:18:28.610 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-20.ipynb
[I 10:20:32.564 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-20.ipynb
[I 10:21:17.771 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-20.ipynb
[I 10:22:52.385 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-20.ipynb
[W 10:23:08.107 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.54ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/2.0-project-UMAP/5.0-human-phones-umap.ipynb
[I 10:23:09.967 LabApp] Kernel started: 8b37073e-8e76-4847-9454-2b5664d57513
[I 10:23:12.742 LabApp] Adapting from protocol version 5.1 (kernel 8b37073e-8e76-4847-9454-2b5664d57513) to 5.3 (client).
[I 10:24:45.670 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-20.ipynb
[I 10:25:14.437 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-20.ipynb
[I 10:25:23.912 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/5.0-human-phones-umap.ipynb
[I 10:27:32.900 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-20.ipynb
[I 10:29:53.759 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-20.ipynb
[I 10:32:13.860 LabApp] Starting buffering for 073e0049-65f0-4a3f-b6a4-42a203713fe6:24caeaec0bf64b96854aa3b4b67f6f3c
[I 10:32:15.233 LabApp] Kernel restarted: 073e0049-65f0-4a3f-b6a4-42a203713fe6
[I 10:32:19.836 LabApp] Adapting from protocol version 5.1 (kernel 073e0049-65f0-4a3f-b6a4-42a203713fe6) to 5.3 (client).
[I 10:32:19.838 LabApp] Restoring connection for 073e0049-65f0-4a3f-b6a4-42a203713fe6:24caeaec0bf64b96854aa3b4b67f6f3c
[I 10:32:19.838 LabApp] Replaying 8 buffered messages
[I 10:32:32.514 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-umap-single-song.ipynb
[I 10:32:35.870 LabApp] Copying avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-20.ipynb to /avgn_paper/notebooks/5.0-visualize-transitions
[W 10:32:38.161 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.32ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-20-Copy1.ipynb
[I 10:32:40.199 LabApp] Kernel started: 815689ab-aeb8-431f-a33f-edfc21f78e9c
[I 10:32:41.073 LabApp] Adapting from protocol version 5.1 (kernel 815689ab-aeb8-431f-a33f-edfc21f78e9c) to 5.3 (client).
[I 10:34:34.958 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-umap-single-song.ipynb
[I 10:34:51.120 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-5.ipynb
[I 10:35:42.485 LabApp] Kernel restarted: 815689ab-aeb8-431f-a33f-edfc21f78e9c
[I 10:35:42.510 LabApp] Starting buffering for 815689ab-aeb8-431f-a33f-edfc21f78e9c:7be58dcb7f3c49518608f1f626a7e7b9
[I 10:35:44.587 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-5.ipynb
[I 10:35:45.358 LabApp] Adapting from protocol version 5.1 (kernel 815689ab-aeb8-431f-a33f-edfc21f78e9c) to 5.3 (client).
[I 10:35:45.359 LabApp] Restoring connection for 815689ab-aeb8-431f-a33f-edfc21f78e9c:7be58dcb7f3c49518608f1f626a7e7b9
[I 10:35:45.359 LabApp] Replaying 4 buffered messages
[I 10:35:45.847 LabApp] Starting buffering for 57564d53-1477-4e98-8fd3-56514f29a2e6:a4c1833ee3444e67844c9273b8741415
[I 10:35:47.764 LabApp] Kernel shutdown: 57564d53-1477-4e98-8fd3-56514f29a2e6
[I 10:36:37.869 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-umap-single-song.ipynb
[I 10:36:40.126 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-5.ipynb
[I 10:38:47.174 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-5.ipynb
[I 10:39:10.416 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-5.ipynb
[I 10:40:50.083 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-5.ipynb
[I 10:42:50.882 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-5.ipynb
[I 10:43:48.729 LabApp] 301 GET /lab/workspaces/auto-B/?clone (::1) 2.51ms
[I 10:43:50.739 LabApp] Build is up to date
[I 10:43:51.337 LabApp] 302 GET /notebooks/avgn_paper/notebooks/5.0-visualize-transitions/ (::1) 5.15ms
[I 10:43:51.641 LabApp] 302 GET /notebooks/avgn_paper/notebooks/5.0-visualize-transitions (::1) 2.56ms
[I 10:43:51.882 LabApp] Adapting from protocol version 5.1 (kernel 978d9916-af35-4406-97da-0a0aa693d3c0) to 5.3 (client).
[I 10:43:52.177 LabApp] Starting buffering for 978d9916-af35-4406-97da-0a0aa693d3c0:27981e21-82d5-427c-9feb-521ed799c2f7
[I 10:43:52.366 LabApp] Adapting from protocol version 5.1 (kernel 567f8b1e-f0e6-44ce-aaf6-0db2311add48) to 5.3 (client).
[I 10:43:52.368 LabApp] Starting buffering for 567f8b1e-f0e6-44ce-aaf6-0db2311add48:9bcd0a71-bfac-4f51-b009-9dc466ad8572
[W 10:43:52.605 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 3.58ms referer=http://localhost:8187/tree/avgn_paper/notebooks/5.0-visualize-transitions
[W 10:43:57.124 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 5.86ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-100.ipynb
[I 10:43:59.005 LabApp] Adapting from protocol version 5.1 (kernel 6778c2fd-8e21-4b6c-a49b-52668a46fbc6) to 5.3 (client).
[I 10:44:51.942 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-5.ipynb
[I 10:45:39.422 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-5.ipynb
[I 10:47:12.764 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-5.ipynb
[I 10:49:23.007 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-5.ipynb
[I 10:51:33.041 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-5.ipynb
[I 10:53:43.039 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-5.ipynb
[I 10:55:53.454 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-5.ipynb
[I 10:58:03.550 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-5.ipynb
[I 11:00:13.774 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-5.ipynb
[I 11:02:29.530 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-5.ipynb
[I 11:05:47.494 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-5.ipynb
[I 11:08:47.732 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-5.ipynb
[I 11:12:27.703 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-5.ipynb
[I 11:15:47.746 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-5.ipynb
[I 11:19:07.975 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-5.ipynb
[I 12:30:44.691 LabApp] Starting buffering for 32efcdc9-958a-4866-b649-b4719a7349ae:6697e65e51be4da1b1bab093ee0e224f
[W 13:38:29.677 LabApp] WebSocket ping timeout after 119874 ms.
[I 13:38:34.679 LabApp] Starting buffering for 167b6f67-9758-4944-945d-bb06ca0a62c3:7d50aebef4a54a7e9967c0de262cc093
[W 13:38:37.253 LabApp] WebSocket ping timeout after 119873 ms.
[W 13:38:38.760 LabApp] WebSocket ping timeout after 119947 ms.
[I 13:38:42.255 LabApp] Starting buffering for b1525541-acf6-46ec-a4c2-f05c6c9f83e5:f17fa2536e3640f68f95d7d8de63b71b
[W 13:38:42.746 LabApp] WebSocket ping timeout after 119980 ms.
[I 13:38:43.762 LabApp] Starting buffering for 6e317bc5-fc1a-44c4-8e4e-56b533c98cf6:2f43d20d928a4a498ea4455fed3cd28c
[W 13:38:45.328 LabApp] WebSocket ping timeout after 119960 ms.
[W 13:38:45.360 LabApp] WebSocket ping timeout after 119976 ms.
[I 13:38:47.748 LabApp] Starting buffering for 8b37073e-8e76-4847-9454-2b5664d57513:b268f245a5414bb68f5ce1cb5c962a09
[W 13:38:49.839 LabApp] WebSocket ping timeout after 119900 ms.
[I 13:38:50.331 LabApp] Starting buffering for cdb62f00-42fe-47a1-88ee-60ee589c4fad:69f67bf98e054e14a0ebebe149df079f
[I 13:38:50.361 LabApp] Starting buffering for 815689ab-aeb8-431f-a33f-edfc21f78e9c:7be58dcb7f3c49518608f1f626a7e7b9
[W 13:38:52.881 LabApp] WebSocket ping timeout after 119935 ms.
[I 13:38:54.840 LabApp] Starting buffering for 073e0049-65f0-4a3f-b6a4-42a203713fe6:24caeaec0bf64b96854aa3b4b67f6f3c
[I 13:38:57.883 LabApp] Starting buffering for 1300fffe-f532-4c8c-a549-35ab08e92fd7:7616e9003e17425a92eac583f86be486
[W 13:38:58.045 LabApp] WebSocket ping timeout after 119979 ms.
[I 13:39:03.046 LabApp] Starting buffering for 6778c2fd-8e21-4b6c-a49b-52668a46fbc6:a65482453be249a6b797f73299753d80
[I 10:01:32.471 LabApp] 302 GET / (::1) 2.03ms
[I 10:01:35.183 LabApp] Build is up to date
[I 10:01:36.911 LabApp] Adapting from protocol version 5.1 (kernel 978d9916-af35-4406-97da-0a0aa693d3c0) to 5.3 (client).
[I 10:01:37.308 LabApp] Adapting from protocol version 5.1 (kernel 567f8b1e-f0e6-44ce-aaf6-0db2311add48) to 5.3 (client).
[I 10:01:44.673 LabApp] Adapting from protocol version 5.1 (kernel 815689ab-aeb8-431f-a33f-edfc21f78e9c) to 5.3 (client).
[I 10:01:44.777 LabApp] Starting buffering for 815689ab-aeb8-431f-a33f-edfc21f78e9c:762c6f27-d0de-44aa-9b53-bd51a9eef746
[I 10:02:15.309 LabApp] Starting buffering for 978d9916-af35-4406-97da-0a0aa693d3c0:03746b52-75a4-4fbc-941c-c37506c5041b
[I 10:02:15.312 LabApp] Starting buffering for 567f8b1e-f0e6-44ce-aaf6-0db2311add48:751fd886-553c-4f7d-ad11-4053fe682c8c
[I 10:02:15.312 LabApp] Starting buffering for 5e7b4be6-7cfb-4bed-be7a-1317135b8c1c:1c3abcf6-ef37-4949-bf52-83b59cc76ea9
[W 10:02:15.689 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 1.63ms referer=http://localhost:8187/tree
[W 10:02:22.414 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.81ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-5.ipynb
[I 10:02:25.152 LabApp] Adapting from protocol version 5.1 (kernel 815689ab-aeb8-431f-a33f-edfc21f78e9c) to 5.3 (client).
[I 10:04:42.231 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-5.ipynb
[I 10:08:10.779 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-5.ipynb
[I 10:11:21.017 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-5.ipynb
[I 10:14:30.772 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-5.ipynb
[I 10:17:40.987 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-5.ipynb
[I 10:20:50.727 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-5.ipynb
[I 10:24:01.700 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-5.ipynb
[I 10:27:11.270 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-5.ipynb
[I 10:30:20.698 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-5.ipynb
[I 10:33:31.715 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-5.ipynb
[I 10:37:55.426 LabApp] 302 GET /notebooks/avgn_paper/notebooks/5.0-visualize-transitions/ (::1) 0.95ms
[I 10:37:55.454 LabApp] 302 GET /notebooks/avgn_paper/notebooks/5.0-visualize-transitions (::1) 2.19ms
[W 10:37:56.109 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 3.00ms referer=http://localhost:8187/tree/avgn_paper/notebooks/5.0-visualize-transitions
[I 10:39:52.185 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-5.ipynb
[I 10:43:03.138 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-5.ipynb
[W 10:49:19.886 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.17ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-20.ipynb
[I 10:49:22.095 LabApp] Kernel started: b1c2494a-9db0-4c61-aa9d-b283a9718b82
[I 10:49:25.112 LabApp] Adapting from protocol version 5.1 (kernel b1c2494a-9db0-4c61-aa9d-b283a9718b82) to 5.3 (client).
[I 10:49:25.630 LabApp] Copying avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-5.ipynb to /avgn_paper/notebooks/5.0-visualize-transitions
[W 10:49:26.034 LabApp] Notebook avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-5.ipynb is not trusted
[W 10:49:26.309 LabApp] Notebook avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-5-Copy1.ipynb is not trusted
[W 10:49:28.564 LabApp] Notebook avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-5-Copy1.ipynb is not trusted
[W 10:49:29.326 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.78ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-5-Copy1.ipynb
[I 10:49:32.178 LabApp] Kernel started: 22942dd5-12a8-42a5-a386-e3060427a882
[I 10:49:34.046 LabApp] Adapting from protocol version 5.1 (kernel 22942dd5-12a8-42a5-a386-e3060427a882) to 5.3 (client).
[I 10:49:54.098 LabApp] KernelRestarter: restarting kernel (1/5), keep random ports
[W 10:49:58.232 LabApp] 409 PATCH /api/contents/avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-5-Copy1.ipynb (::1): File already exists: avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-5.ipynb
[W 10:49:58.233 LabApp] File already exists: avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-5.ipynb
[W 10:49:58.234 LabApp] 409 PATCH /api/contents/avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-5-Copy1.ipynb (::1) 3.84ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-5-Copy1.ipynb
[W 10:50:28.831 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 5.12ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-umap-single-song.ipynb
[I 10:50:30.123 LabApp] Adapting from protocol version 5.1 (kernel 073e0049-65f0-4a3f-b6a4-42a203713fe6) to 5.3 (client).
[I 10:51:33.018 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-20.ipynb
[I 10:51:51.241 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-832-5.ipynb
[W 10:51:51.245 LabApp] Notebook avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-832-5.ipynb is not trusted
[I 10:52:36.249 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-umap-make-windows.ipynb
[I 10:54:30.069 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-umap-make-windows.ipynb
[I 10:54:37.425 LabApp] Starting buffering for 22942dd5-12a8-42a5-a386-e3060427a882:b3a70e87c0be491987cb86aff4eade1a
[I 10:54:38.234 LabApp] Kernel shutdown: 22942dd5-12a8-42a5-a386-e3060427a882
[I 10:55:36.668 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-20.ipynb
[I 10:55:48.000 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-832-5.ipynb
[W 10:55:48.003 LabApp] Notebook avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-832-5.ipynb is not trusted
[I 10:56:33.071 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-umap-make-windows.ipynb
[I 10:58:29.046 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-20.ipynb
[I 11:01:09.637 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-20.ipynb
[I 11:03:49.044 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-20.ipynb
[I 11:04:53.138 LabApp] Starting buffering for b1c2494a-9db0-4c61-aa9d-b283a9718b82:a19f45a3a09448da8c9c13cfabc05382
[I 11:04:54.850 LabApp] Kernel shutdown: b1c2494a-9db0-4c61-aa9d-b283a9718b82
[W 11:07:26.490 LabApp] 404 POST /api/kernels/22942dd5-12a8-42a5-a386-e3060427a882/interrupt (::1): Kernel does not exist: 22942dd5-12a8-42a5-a386-e3060427a882
[W 11:07:26.490 LabApp] Kernel does not exist: 22942dd5-12a8-42a5-a386-e3060427a882
[W 11:07:26.491 LabApp] 404 POST /api/kernels/22942dd5-12a8-42a5-a386-e3060427a882/interrupt (::1) 3.20ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-832-5.ipynb
[W 11:07:33.526 LabApp] Notebook avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-832-5.ipynb is not trusted
[W 11:07:33.907 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.77ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-832-5.ipynb
[W 11:07:36.876 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 2.32ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-832-5.ipynb
[I 11:07:39.718 LabApp] Kernel started: c5ed7b93-0584-42f3-8420-286897a1a123
[I 11:07:43.116 LabApp] Adapting from protocol version 5.1 (kernel c5ed7b93-0584-42f3-8420-286897a1a123) to 5.3 (client).
[I 11:10:06.181 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-832-5.ipynb
[W 11:10:06.185 LabApp] Notebook avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-832-5.ipynb is not trusted
[I 11:10:13.630 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-5.ipynb
[I 11:12:30.087 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-umap-make-windows.ipynb
[I 11:14:25.176 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-5.ipynb
[I 11:14:32.843 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-umap-make-windows.ipynb
[I 11:15:00.467 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-832-5.ipynb
[W 11:15:00.471 LabApp] Notebook avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-832-5.ipynb is not trusted
[I 11:16:30.719 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-umap-make-windows.ipynb
[I 11:18:33.066 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-umap-make-windows.ipynb
[I 11:19:39.671 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-832-5.ipynb
[W 11:19:39.674 LabApp] Notebook avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-832-5.ipynb is not trusted
[I 11:22:21.451 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-832-5.ipynb
[W 11:22:21.456 LabApp] Notebook avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-832-5.ipynb is not trusted
[I 11:23:30.323 LabApp] Starting buffering for c5ed7b93-0584-42f3-8420-286897a1a123:8b5374d4141e4e8f8bcc46fae02846ee
[I 11:23:31.832 LabApp] Kernel restarted: c5ed7b93-0584-42f3-8420-286897a1a123
[I 11:23:35.411 LabApp] Adapting from protocol version 5.1 (kernel c5ed7b93-0584-42f3-8420-286897a1a123) to 5.3 (client).
[I 11:23:35.412 LabApp] Restoring connection for c5ed7b93-0584-42f3-8420-286897a1a123:8b5374d4141e4e8f8bcc46fae02846ee
[I 11:23:35.413 LabApp] Replaying 6 buffered messages
[I 11:23:45.833 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-832-5.ipynb
[W 11:23:45.837 LabApp] Notebook avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-832-5.ipynb is not trusted
[I 11:24:19.086 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-832-5.ipynb
[W 11:24:19.088 LabApp] Notebook avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-832-5.ipynb is not trusted
[I 11:29:03.459 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-832-5.ipynb
[W 11:29:03.464 LabApp] Notebook avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-832-5.ipynb is not trusted
[I 13:02:37.227 LabApp] 302 GET /notebooks/avgn_paper/notebooks/5.0-visualize-transitions/ (::1) 1.94ms
[I 13:02:37.259 LabApp] 302 GET /notebooks/avgn_paper/notebooks/5.0-visualize-transitions (::1) 3.56ms
[W 13:02:37.969 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 3.25ms referer=http://localhost:8187/tree/avgn_paper/notebooks/5.0-visualize-transitions
[W 13:03:26.684 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.83ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 13:03:28.546 LabApp] Adapting from protocol version 5.1 (kernel 1300fffe-f532-4c8c-a549-35ab08e92fd7) to 5.3 (client).
[I 13:03:55.753 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb
[I 13:03:56.442 LabApp] Copying avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060.ipynb to /avgn_paper/notebooks/5.0-visualize-transitions
[W 13:04:00.434 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.75ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060-Copy1.ipynb
[I 13:04:01.393 LabApp] Kernel started: 6487f762-3e01-4a9d-a976-01ba23998d22
[I 13:04:04.826 LabApp] Adapting from protocol version 5.1 (kernel 6487f762-3e01-4a9d-a976-01ba23998d22) to 5.3 (client).
[I 13:05:41.826 LabApp] Starting buffering for c5ed7b93-0584-42f3-8420-286897a1a123:8b5374d4141e4e8f8bcc46fae02846ee
[I 13:05:43.537 LabApp] Kernel shutdown: c5ed7b93-0584-42f3-8420-286897a1a123
[W 13:05:44.279 LabApp] 404 DELETE /api/sessions/7f62e4c5-0ecb-4924-b3ec-6af48a9af960 (::1): Session not found: session_id='7f62e4c5-0ecb-4924-b3ec-6af48a9af960'
[W 13:05:44.279 LabApp] Session not found: session_id='7f62e4c5-0ecb-4924-b3ec-6af48a9af960'
[W 13:05:44.280 LabApp] 404 DELETE /api/sessions/7f62e4c5-0ecb-4924-b3ec-6af48a9af960 (::1) 2.06ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-829-20.ipynb
[I 13:06:08.176 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060-Copy1.ipynb
[I 13:06:14.203 LabApp] Starting buffering for 6487f762-3e01-4a9d-a976-01ba23998d22:ec690f385d1848bf8992f14a57c44626
[I 13:06:15.119 LabApp] Kernel restarted: 6487f762-3e01-4a9d-a976-01ba23998d22
[I 13:06:18.233 LabApp] Adapting from protocol version 5.1 (kernel 6487f762-3e01-4a9d-a976-01ba23998d22) to 5.3 (client).
[I 13:06:18.234 LabApp] Restoring connection for 6487f762-3e01-4a9d-a976-01ba23998d22:ec690f385d1848bf8992f14a57c44626
[I 13:06:18.234 LabApp] Replaying 6 buffered messages
[W 13:07:41.483 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 1.94ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/starling-umap-projections-single-song.ipynb
[W 13:07:51.017 LabApp] 400 GET /api/contents/avgn_paper/notebooks/5.0-visualize-transitions/starling_umap_windows.npy?type=file&format=text&_=1571947662469 (::1): /home/AD/tsainbur/github_repos/avgn_paper/notebooks/5.0-visualize-transitions/starling_umap_windows.npy is not UTF-8 encoded
[W 13:07:51.017 LabApp] /home/AD/tsainbur/github_repos/avgn_paper/notebooks/5.0-visualize-transitions/starling_umap_windows.npy is not UTF-8 encoded
[W 13:07:51.018 LabApp] 400 GET /api/contents/avgn_paper/notebooks/5.0-visualize-transitions/starling_umap_windows.npy?type=file&format=text&_=1571947662469 (::1) 8482.54ms referer=http://localhost:8187/edit/avgn_paper/notebooks/5.0-visualize-transitions/starling_umap_windows.npy
[I 13:08:06.914 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060-Copy1.ipynb
[I 13:09:18.299 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060-Copy1.ipynb
[I 13:12:07.204 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060-Copy1.ipynb
[I 13:14:03.711 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060-Copy1.ipynb
[I 13:16:08.603 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060-Copy1.ipynb
[I 18:54:08.567 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060-Copy1.ipynb
[I 19:16:07.344 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060-Copy1.ipynb
[W 19:16:29.835 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 3.19ms referer=http://localhost:8187/tree
[I 19:16:35.129 LabApp] 302 GET /notebooks/avgn_paper/notebooks/5.0-visualize-transitions/ (::1) 0.91ms
[I 19:16:35.159 LabApp] 302 GET /notebooks/avgn_paper/notebooks/5.0-visualize-transitions (::1) 2.12ms
[W 19:16:35.600 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 11.23ms referer=http://localhost:8187/tree/avgn_paper/notebooks/5.0-visualize-transitions
[W 19:16:52.109 LabApp] 400 GET /api/contents/avgn_paper/notebooks/5.0-visualize-transitions/starling_umap_windows.npy?type=file&format=text&_=1571969799636 (::1): /home/AD/tsainbur/github_repos/avgn_paper/notebooks/5.0-visualize-transitions/starling_umap_windows.npy is not UTF-8 encoded
[W 19:16:52.110 LabApp] /home/AD/tsainbur/github_repos/avgn_paper/notebooks/5.0-visualize-transitions/starling_umap_windows.npy is not UTF-8 encoded
[W 19:16:52.111 LabApp] 400 GET /api/contents/avgn_paper/notebooks/5.0-visualize-transitions/starling_umap_windows.npy?type=file&format=text&_=1571969799636 (::1) 11389.18ms referer=http://localhost:8187/edit/avgn_paper/notebooks/5.0-visualize-transitions/starling_umap_windows.npy
[W 19:16:55.940 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 5.13ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 19:16:59.077 LabApp] Adapting from protocol version 5.1 (kernel b1525541-acf6-46ec-a4c2-f05c6c9f83e5) to 5.3 (client).
[I 19:18:07.585 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060-Copy1.ipynb
[I 19:19:21.386 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[W 19:19:42.013 LabApp] Notebook avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-832-5.ipynb is not trusted
[W 19:19:42.351 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.58ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-832-5.ipynb
[I 19:19:48.036 LabApp] Kernel started: 58e81f53-24fb-4915-9136-6003bddc877a
[I 19:19:53.317 LabApp] Adapting from protocol version 5.1 (kernel 58e81f53-24fb-4915-9136-6003bddc877a) to 5.3 (client).
[I 19:20:07.530 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060-Copy1.ipynb
[I 19:21:36.387 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060-Copy1.ipynb
[I 19:22:07.586 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-832-5.ipynb
[W 19:22:07.589 LabApp] Notebook avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-832-5.ipynb is not trusted
[I 19:22:10.745 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060-Copy1.ipynb
[I 19:23:59.457 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060-Copy1.ipynb
[I 19:24:00.115 LabApp] Copying avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060-Copy1.ipynb to /avgn_paper/notebooks/5.0-visualize-transitions
[W 19:24:02.382 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.45ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060-Copy2.ipynb
[I 19:24:04.566 LabApp] Kernel started: 9d47859b-9582-4cf0-a265-f04b0a927f07
[I 19:24:05.596 LabApp] Adapting from protocol version 5.1 (kernel 9d47859b-9582-4cf0-a265-f04b0a927f07) to 5.3 (client).
[I 19:26:12.845 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060-Copy1.ipynb
[I 19:26:17.030 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060-Copy2.ipynb
[I 19:27:45.913 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 19:28:36.609 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060-Copy1.ipynb
[I 19:28:39.457 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060-50.ipynb
[I 19:29:05.886 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-832-5.ipynb
[W 19:29:05.889 LabApp] Notebook avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-832-5.ipynb is not trusted
[I 19:29:50.098 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060-50.ipynb
[I 19:29:54.193 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060-50.ipynb
[I 19:31:44.829 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-PCA-projections-multiple_seqs.ipynb
[I 19:32:54.360 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060-Copy1.ipynb
[I 19:32:59.621 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060-50.ipynb
[I 19:35:01.576 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060-Copy1.ipynb
[I 19:37:16.370 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060-Copy1.ipynb
[I 19:37:18.717 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060-50.ipynb
[I 19:39:24.223 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060-50.ipynb
[I 19:40:54.090 LabApp] Starting buffering for 9d47859b-9582-4cf0-a265-f04b0a927f07:a8c268805cbb44798bc6906395f0aa36
[I 19:48:01.494 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060-recent.ipynb
[I 19:50:11.353 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/starling-project-view-umap-b1060-recent.ipynb
[I 19:55:32.190 LabApp] Starting buffering for 58e81f53-24fb-4915-9136-6003bddc877a:79175664f5ab41a18c5b5c7e5a81624a
[I 19:55:32.672 LabApp] Starting buffering for b1525541-acf6-46ec-a4c2-f05c6c9f83e5:d584ce788b254e9b966133647109b316
[I 19:55:34.408 LabApp] Starting buffering for 1300fffe-f532-4c8c-a549-35ab08e92fd7:acfde73e950c49158885e962d70ab337
[I 19:55:37.912 LabApp] Build is up to date
[I 19:55:38.622 LabApp] Starting buffering for 6487f762-3e01-4a9d-a976-01ba23998d22:ec690f385d1848bf8992f14a57c44626
[I 19:55:39.949 LabApp] Adapting from protocol version 5.1 (kernel 978d9916-af35-4406-97da-0a0aa693d3c0) to 5.3 (client).
[I 19:55:40.424 LabApp] Adapting from protocol version 5.1 (kernel 567f8b1e-f0e6-44ce-aaf6-0db2311add48) to 5.3 (client).
[I 19:55:43.824 LabApp] 302 GET / (::1) 0.90ms
[I 19:55:43.916 LabApp] Starting buffering for 073e0049-65f0-4a3f-b6a4-42a203713fe6:18d2ead0110b43299bb87ea5b4d85968
[I 19:55:44.569 LabApp] 301 GET /lab/workspaces/auto-k/?clone (::1) 1.64ms
[I 19:55:45.572 LabApp] Build is up to date
[I 19:55:47.297 LabApp] Adapting from protocol version 5.1 (kernel 978d9916-af35-4406-97da-0a0aa693d3c0) to 5.3 (client).
[I 19:55:47.880 LabApp] Adapting from protocol version 5.1 (kernel 567f8b1e-f0e6-44ce-aaf6-0db2311add48) to 5.3 (client).
[I 19:55:48.133 LabApp] Adapting from protocol version 5.1 (kernel 9d47859b-9582-4cf0-a265-f04b0a927f07) to 5.3 (client).
[I 19:55:48.238 LabApp] Starting buffering for 9d47859b-9582-4cf0-a265-f04b0a927f07:ed7fb41e-5cef-4aee-852c-d08ab9373ea8
[W 19:55:50.813 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 2.90ms referer=http://localhost:8187/tree
[I 19:55:52.829 LabApp] Starting buffering for 978d9916-af35-4406-97da-0a0aa693d3c0:f1a516cc-4073-4eef-adca-886797dd8322
[I 19:55:56.374 LabApp] Kernel shutdown: 978d9916-af35-4406-97da-0a0aa693d3c0
[I 19:55:56.381 LabApp] Starting buffering for 5e7b4be6-7cfb-4bed-be7a-1317135b8c1c:795ed6b1-929c-4ccf-8337-667ce11fa397
[I 19:55:56.381 LabApp] Starting buffering for 567f8b1e-f0e6-44ce-aaf6-0db2311add48:6fb8f5f2-8bfa-4001-ab11-169416a58f7b
Traceback (most recent call last):
  File "/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/backend/semaphore_tracker.py", line 177, in main
    cache.remove(name)
KeyError: '/loky-7495-pyn4twfa'
Traceback (most recent call last):
  File "/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/backend/semaphore_tracker.py", line 177, in main
    cache.remove(name)
KeyError: '/loky-7495-sxohu1ge'
Traceback (most recent call last):
  File "/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/backend/semaphore_tracker.py", line 177, in main
    cache.remove(name)
KeyError: '/loky-7495-wtxdcgrm'
Traceback (most recent call last):
  File "/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/backend/semaphore_tracker.py", line 177, in main
    cache.remove(name)
KeyError: '/loky-7495-qmp2re0m'
Traceback (most recent call last):
  File "/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/backend/semaphore_tracker.py", line 177, in main
    cache.remove(name)
KeyError: '/loky-7495-nic4aucr'
Traceback (most recent call last):
  File "/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/backend/semaphore_tracker.py", line 177, in main
    cache.remove(name)
KeyError: '/loky-7495-k8pykl4n'
[I 19:56:00.533 LabApp] Kernel shutdown: b0d6db59-8f03-4124-99a3-ab6c5a0f8d31
[I 19:56:05.671 LabApp] Kernel shutdown: 5e7b4be6-7cfb-4bed-be7a-1317135b8c1c
[I 19:56:06.094 LabApp] Kernel shutdown: a62ba8c7-71ba-48f9-8581-aee04b99949f
[I 19:56:06.514 LabApp] Kernel shutdown: 567f8b1e-f0e6-44ce-aaf6-0db2311add48
[I 19:56:06.923 LabApp] Kernel shutdown: 15dca1e2-311b-40a6-8455-274ab82f472d
[I 19:56:08.055 LabApp] Kernel shutdown: 737b3e2e-60ed-44d5-a20a-c7c4a02ed91a
[I 19:56:08.959 LabApp] Kernel shutdown: aaac4ddf-99c2-4d66-83ad-ef06f18a778b
[I 19:56:10.686 LabApp] Kernel shutdown: f4cb2bac-28c3-4830-b001-be6be3f23c36
[I 19:56:11.121 LabApp] Kernel shutdown: 18eabf2b-2c7e-44ff-93f7-53f289fada24
[W 19:56:11.127 LabApp] 404 DELETE /api/sessions/5b7f820e-dc8c-41f6-9374-847f420696f6?1571972156450 (::1): Session not found: session_id='5b7f820e-dc8c-41f6-9374-847f420696f6'
[W 19:56:11.128 LabApp] Session not found: session_id='5b7f820e-dc8c-41f6-9374-847f420696f6'
[W 19:56:11.128 LabApp] 404 DELETE /api/sessions/5b7f820e-dc8c-41f6-9374-847f420696f6?1571972156450 (::1) 4.29ms referer=http://localhost:8187/lab
[W 19:56:11.128 LabApp] 404 DELETE /api/sessions/7829621b-9bfa-4761-8d24-e7cc94ec821a?1571972156607 (::1): Session not found: session_id='7829621b-9bfa-4761-8d24-e7cc94ec821a'
[W 19:56:11.129 LabApp] Session not found: session_id='7829621b-9bfa-4761-8d24-e7cc94ec821a'
[W 19:56:11.129 LabApp] 404 DELETE /api/sessions/7829621b-9bfa-4761-8d24-e7cc94ec821a?1571972156607 (::1) 4.09ms referer=http://localhost:8187/lab
[W 19:56:11.129 LabApp] 404 DELETE /api/sessions/6396f408-820c-464b-a31a-280ccbedf567?1571972157034 (::1): Session not found: session_id='6396f408-820c-464b-a31a-280ccbedf567'
[W 19:56:11.129 LabApp] Session not found: session_id='6396f408-820c-464b-a31a-280ccbedf567'
[W 19:56:11.130 LabApp] 404 DELETE /api/sessions/6396f408-820c-464b-a31a-280ccbedf567?1571972157034 (::1) 4.10ms referer=http://localhost:8187/lab
[W 19:56:11.130 LabApp] 404 DELETE /api/sessions/bc0a5711-2b21-457e-a610-79c1e8f2a27f?1571972157220 (::1): Session not found: session_id='bc0a5711-2b21-457e-a610-79c1e8f2a27f'
[W 19:56:11.130 LabApp] Session not found: session_id='bc0a5711-2b21-457e-a610-79c1e8f2a27f'
[W 19:56:11.130 LabApp] 404 DELETE /api/sessions/bc0a5711-2b21-457e-a610-79c1e8f2a27f?1571972157220 (::1) 4.09ms referer=http://localhost:8187/lab
[I 19:56:11.634 LabApp] Kernel shutdown: 78035f26-95be-4e04-82aa-a7cc1f959e7a
[W 19:56:11.642 LabApp] 404 DELETE /api/sessions/40400d5f-fa0e-49f6-a43b-d6bfd02e1e2f?1571972157875 (::1): Session not found: session_id='40400d5f-fa0e-49f6-a43b-d6bfd02e1e2f'
[W 19:56:11.643 LabApp] Session not found: session_id='40400d5f-fa0e-49f6-a43b-d6bfd02e1e2f'
[W 19:56:11.643 LabApp] 404 DELETE /api/sessions/40400d5f-fa0e-49f6-a43b-d6bfd02e1e2f?1571972157875 (::1) 4.63ms referer=http://localhost:8187/lab
[W 19:56:11.663 LabApp] 404 DELETE /api/sessions/450f7891-99d6-4c83-afc5-1cf5b55319fe?1571972158045 (::1): Session not found: session_id='450f7891-99d6-4c83-afc5-1cf5b55319fe'
[W 19:56:11.663 LabApp] Session not found: session_id='450f7891-99d6-4c83-afc5-1cf5b55319fe'
[W 19:56:11.664 LabApp] 404 DELETE /api/sessions/450f7891-99d6-4c83-afc5-1cf5b55319fe?1571972158045 (::1) 22.82ms referer=http://localhost:8187/lab
[W 19:56:11.672 LabApp] 404 DELETE /api/sessions/2b803c68-e954-4dc7-bef4-b6071fa7e76e?1571972157384 (::1): Session not found: session_id='2b803c68-e954-4dc7-bef4-b6071fa7e76e'
[W 19:56:11.672 LabApp] Session not found: session_id='2b803c68-e954-4dc7-bef4-b6071fa7e76e'
[W 19:56:11.672 LabApp] 404 DELETE /api/sessions/2b803c68-e954-4dc7-bef4-b6071fa7e76e?1571972157384 (::1) 2.33ms referer=http://localhost:8187/lab
[W 19:56:11.673 LabApp] 404 DELETE /api/sessions/aced9aaa-0511-48c3-b4e8-473e1af8984d?1571972158225 (::1): Session not found: session_id='aced9aaa-0511-48c3-b4e8-473e1af8984d'
[W 19:56:11.673 LabApp] Session not found: session_id='aced9aaa-0511-48c3-b4e8-473e1af8984d'
[W 19:56:11.673 LabApp] 404 DELETE /api/sessions/aced9aaa-0511-48c3-b4e8-473e1af8984d?1571972158225 (::1) 2.26ms referer=http://localhost:8187/lab
[W 19:56:11.687 LabApp] 404 DELETE /api/sessions/6ebe9b85-3b5b-46e4-9be0-c24942332200?1571972158386 (::1): Session not found: session_id='6ebe9b85-3b5b-46e4-9be0-c24942332200'
[W 19:56:11.687 LabApp] Session not found: session_id='6ebe9b85-3b5b-46e4-9be0-c24942332200'
[W 19:56:11.688 LabApp] 404 DELETE /api/sessions/6ebe9b85-3b5b-46e4-9be0-c24942332200?1571972158386 (::1) 1.19ms referer=http://localhost:8187/lab
[W 19:56:11.767 LabApp] 404 DELETE /api/sessions/cd99ad3d-ce39-4d13-a0a1-31caa53205d2?1571972158566 (::1): Session not found: session_id='cd99ad3d-ce39-4d13-a0a1-31caa53205d2'
[W 19:56:11.768 LabApp] Session not found: session_id='cd99ad3d-ce39-4d13-a0a1-31caa53205d2'
[W 19:56:11.768 LabApp] 404 DELETE /api/sessions/cd99ad3d-ce39-4d13-a0a1-31caa53205d2?1571972158566 (::1) 1.21ms referer=http://localhost:8187/lab
[I 19:56:12.274 LabApp] Kernel shutdown: a2c77d6b-ee8a-46ce-b107-091963dc16ee
[I 19:56:12.682 LabApp] Kernel shutdown: a64a2193-19ce-4f69-9641-e19bc2fee84d
[I 19:56:15.589 LabApp] Kernel shutdown: 1a299ce2-5104-456b-ac5b-02c132cf99a5
[I 19:56:17.496 LabApp] Kernel shutdown: cdb62f00-42fe-47a1-88ee-60ee589c4fad
[I 19:56:19.803 LabApp] Kernel shutdown: 38a56180-e126-4229-8295-7902ea0386cc
[I 19:56:21.227 LabApp] Kernel shutdown: b1525541-acf6-46ec-a4c2-f05c6c9f83e5
[I 19:56:21.236 LabApp] Discarding 1 buffered messages for c328fcc9-941d-4dc5-ac30-db4dc767eab3:5252c64acfb6453b8c0720808d63f0c8
[I 19:56:21.638 LabApp] Kernel shutdown: c328fcc9-941d-4dc5-ac30-db4dc767eab3
[I 19:56:22.043 LabApp] Kernel shutdown: 167b6f67-9758-4944-945d-bb06ca0a62c3
[I 19:56:22.447 LabApp] Kernel shutdown: 32efcdc9-958a-4866-b649-b4719a7349ae
[I 19:56:23.453 LabApp] Kernel shutdown: 073e0049-65f0-4a3f-b6a4-42a203713fe6
[I 19:56:23.459 LabApp] Discarding 1 buffered messages for 6778c2fd-8e21-4b6c-a49b-52668a46fbc6:a65482453be249a6b797f73299753d80
[I 19:56:23.861 LabApp] Kernel shutdown: 6778c2fd-8e21-4b6c-a49b-52668a46fbc6
[I 19:56:24.264 LabApp] Kernel shutdown: 6e317bc5-fc1a-44c4-8e4e-56b533c98cf6
[I 19:56:24.668 LabApp] Kernel shutdown: 8b37073e-8e76-4847-9454-2b5664d57513
[I 19:56:26.576 LabApp] Kernel shutdown: 815689ab-aeb8-431f-a33f-edfc21f78e9c
[I 19:56:26.980 LabApp] Kernel shutdown: 1300fffe-f532-4c8c-a549-35ab08e92fd7
[I 19:56:28.892 LabApp] Kernel shutdown: 6487f762-3e01-4a9d-a976-01ba23998d22
[I 19:56:29.396 LabApp] Kernel shutdown: 58e81f53-24fb-4915-9136-6003bddc877a
[I 19:56:30.904 LabApp] Kernel shutdown: 9d47859b-9582-4cf0-a265-f04b0a927f07
[W 19:56:31.056 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 2.91ms referer=http://localhost:8187/tree/avgn_paper/notebooks
[W 19:56:51.307 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 4.09ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/1.0-starling-to-tfrecord.ipynb
[I 19:56:51.892 LabApp] Kernel started: de905082-d91a-4f7e-8a4c-62a2660e6c39
[W 19:56:51.932 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 1.94ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/1.0-starling-to-tfrecord.ipynb
[I 19:56:54.258 LabApp] Adapting from protocol version 5.1 (kernel de905082-d91a-4f7e-8a4c-62a2660e6c39) to 5.3 (client).
[I 19:57:12.369 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/1.0-starling-to-tfrecord.ipynb
[I 19:57:12.755 LabApp] Copying avgn_paper/notebooks/6.0-neural-networks/1.0-starling-to-tfrecord.ipynb to /avgn_paper/notebooks/6.0-neural-networks
[I 19:57:15.121 LabApp] Kernel started: 1298b219-7c76-481f-9908-3b312eaef93f
[W 19:57:15.476 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 2.05ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/1.0-starling-to-tfrecord-Copy1.ipynb
[I 19:57:16.767 LabApp] Adapting from protocol version 5.1 (kernel 1298b219-7c76-481f-9908-3b312eaef93f) to 5.3 (client).
[W 19:58:18.588 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 2.24ms referer=http://localhost:8187/tree/avgn_paper/notebooks/2.0-make-syllable_df
[W 19:58:24.660 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.93ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/2.0-make-syllable_df/starling-syllable-df-128.ipynb
[I 19:58:30.722 LabApp] Kernel started: 505e20f1-c76f-41fa-aefb-13ceae966daa
[I 19:58:33.065 LabApp] Adapting from protocol version 5.1 (kernel 505e20f1-c76f-41fa-aefb-13ceae966daa) to 5.3 (client).
[I 19:59:15.966 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/1.0-starling-to-tfrecord-32.ipynb
[I 20:00:53.027 LabApp] Saving file at /avgn_paper/notebooks/2.0-make-syllable_df/starling-syllable-df-128.ipynb
[W 20:01:44.182 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 4.01ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/2.0-make-syllable_df/canary-syllable-df.ipynb
[I 20:01:46.220 LabApp] Kernel started: 40205617-51a4-4b93-803b-794eb1770065
[I 20:01:49.336 LabApp] Adapting from protocol version 5.1 (kernel 40205617-51a4-4b93-803b-794eb1770065) to 5.3 (client).
[I 20:02:13.004 LabApp] Saving file at /avgn_paper/notebooks/2.0-make-syllable_df/canary-syllable-df.ipynb
[I 20:02:13.789 LabApp] Copying avgn_paper/notebooks/2.0-make-syllable_df/canary-syllable-df.ipynb to /avgn_paper/notebooks/2.0-make-syllable_df
[W 20:02:16.401 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.70ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/2.0-make-syllable_df/canary-syllable-df-Copy3.ipynb
[W 20:02:18.662 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 2.84ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/2.0-make-syllable_df/canary-syllable-df-Copy3.ipynb
[I 20:02:19.713 LabApp] Kernel started: 5a69de6c-04c0-4d41-b77e-fe76b01501f0
[I 20:02:22.284 LabApp] Adapting from protocol version 5.1 (kernel 5a69de6c-04c0-4d41-b77e-fe76b01501f0) to 5.3 (client).
[I 20:02:42.281 LabApp] Saving file at /avgn_paper/notebooks/2.0-make-syllable_df/canary-syllable-df-Copy3.ipynb
[I 20:02:47.844 LabApp] Starting buffering for 5a69de6c-04c0-4d41-b77e-fe76b01501f0:63e1c63492334d5386f99743580e02e0
[I 20:05:15.251 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/1.0-canary-to-tfrecord-32x24.ipynb
[W 20:06:09.080 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.83ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/2.0-make-syllable_df/canary-syllable-df.ipynb
[I 20:06:12.406 LabApp] Adapting from protocol version 5.1 (kernel 40205617-51a4-4b93-803b-794eb1770065) to 5.3 (client).
[W 20:06:24.737 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 4.11ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/2.0-project-UMAP/canary-syllable-umap.ipynb
[W 20:06:25.825 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 3.31ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/2.0-project-UMAP/canary-syllable-umap.ipynb
[I 20:06:26.386 LabApp] Kernel started: f1777420-0a47-4bcd-8590-9cb5c822e11d
[I 20:06:28.958 LabApp] Adapting from protocol version 5.1 (kernel f1777420-0a47-4bcd-8590-9cb5c822e11d) to 5.3 (client).
[I 20:07:16.413 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/1.0-canary-to-tfrecord-32x24.ipynb
2019-10-24 20:07:21.374001: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-24 20:07:21.392261: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2019-10-24 20:07:21.392345: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: txori
2019-10-24 20:07:21.392358: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: txori
2019-10-24 20:07:21.392538: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.79.0
2019-10-24 20:07:21.392585: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 410.79.0
2019-10-24 20:07:21.392598: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 410.79.0
2019-10-24 20:07:21.443534: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-24 20:07:21.444991: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e768b8b070 executing computations on platform Host. Devices:
2019-10-24 20:07:21.445025: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
[I 20:07:38.412 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/canary-syllable-umap.ipynb
[I 20:08:18.450 LabApp] Saving file at /avgn_paper/notebooks/2.0-make-syllable_df/canary-syllable-df.ipynb
[I 20:08:46.705 LabApp] Creating new directory in /avgn_paper/notebooks
[I 20:09:35.163 LabApp] Creating new notebook in /avgn_paper/notebooks/7.0-segmentation-examples
[W 20:09:36.626 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 4.14ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/7.0-segmentation-examples/Untitled.ipynb?kernel_name=python3
[I 20:09:36.816 LabApp] Kernel started: 11777ca9-05bd-4ea4-bc65-bd1bf70a0360
[W 20:09:36.855 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 1.91ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/7.0-segmentation-examples/Untitled.ipynb?kernel_name=python3
[I 20:09:39.076 LabApp] Adapting from protocol version 5.1 (kernel 11777ca9-05bd-4ea4-bc65-bd1bf70a0360) to 5.3 (client).
[I 20:10:05.405 LabApp] Starting buffering for de905082-d91a-4f7e-8a4c-62a2660e6c39:4aeab0d0b2cc40c1890924a9176e74e7
[I 20:10:09.947 LabApp] Starting buffering for 505e20f1-c76f-41fa-aefb-13ceae966daa:c553f3de129044438d58ca2e4bf65cf4
[I 20:10:10.493 LabApp] Adapting from protocol version 5.1 (kernel de905082-d91a-4f7e-8a4c-62a2660e6c39) to 5.3 (client).
[I 20:10:30.139 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/canary-syllable-umap.ipynb
[I 20:11:36.955 LabApp] Saving file at /avgn_paper/notebooks/7.0-segmentation-examples/bf-segmentation-example.ipynb
[I 20:11:52.181 LabApp] Starting buffering for f1777420-0a47-4bcd-8590-9cb5c822e11d:27d87100634e4f7688e863d3b99240a8
[I 20:11:56.601 LabApp] Kernel shutdown: f1777420-0a47-4bcd-8590-9cb5c822e11d
[I 20:12:06.034 LabApp] Starting buffering for 40205617-51a4-4b93-803b-794eb1770065:2eb5dddd3133494d844f3b88a3ef3f8c
[I 20:12:06.441 LabApp] Kernel shutdown: 40205617-51a4-4b93-803b-794eb1770065
[I 20:12:10.716 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/1.0-starling-to-tfrecord_128.ipynb
[I 20:13:15.602 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/1.0-canary-to-tfrecord-32x24.ipynb
[I 20:18:45.384 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/1.0-canary-to-tfrecord-32x24.ipynb
[I 20:19:15.314 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/1.0-canary-to-tfrecord-32x24.ipynb
[I 20:21:15.261 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/1.0-canary-to-tfrecord-32x24.ipynb
2019-10-24 20:23:34.167293: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-24 20:23:34.188114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-24 20:23:34.189285: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-24 20:23:34.190082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 2 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
2019-10-24 20:23:34.191130: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 3 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-24 20:23:34.192194: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-24 20:23:34.196728: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-24 20:23:34.897966: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-24 20:23:35.025096: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-24 20:23:35.033541: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-24 20:23:35.039767: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-24 20:23:36.124816: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-24 20:23:36.138493: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1, 2, 3
2019-10-24 20:23:36.910029: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fa3cb64f90 executing computations on platform CUDA. Devices:
2019-10-24 20:23:36.910084: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-24 20:23:36.910097: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (1): TITAN Xp, Compute Capability 6.1
2019-10-24 20:23:36.910108: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (2): Tesla K40c, Compute Capability 3.5
2019-10-24 20:23:36.910134: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (3): Tesla K40c, Compute Capability 3.5
2019-10-24 20:23:36.918906: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-24 20:23:36.920116: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fa39daf150 executing computations on platform Host. Devices:
2019-10-24 20:23:36.920176: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-24 20:23:36.922764: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-24 20:23:36.923692: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-24 20:23:36.924421: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 2 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
2019-10-24 20:23:36.925963: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 3 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-24 20:23:36.926150: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-24 20:23:36.926191: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-24 20:23:36.926226: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-24 20:23:36.926262: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-24 20:23:36.926296: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-24 20:23:36.926332: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-24 20:23:36.926369: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-24 20:23:36.933576: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1, 2, 3
2019-10-24 20:23:36.933651: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-24 20:23:36.937987: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-24 20:23:36.938010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 1 2 3 
2019-10-24 20:23:36.938022: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N Y N N 
2019-10-24 20:23:36.938031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 1:   Y N N N 
2019-10-24 20:23:36.938040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 2:   N N N Y 
2019-10-24 20:23:36.938049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 3:   N N Y N 
2019-10-24 20:23:36.943355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-24 20:23:36.944651: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 11427 MB memory) -> physical GPU (device: 1, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-24 20:23:36.946047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 232 MB memory) -> physical GPU (device: 2, name: Tesla K40c, pci bus id: 0000:02:00.0, compute capability: 3.5)
2019-10-24 20:23:36.947650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 10791 MB memory) -> physical GPU (device: 3, name: Tesla K40c, pci bus id: 0000:03:00.0, compute capability: 3.5)
[I 20:25:15.762 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/1.0-canary-to-tfrecord-32x24.ipynb
2019-10-24 20:28:44.580958: W tensorflow/core/framework/op_kernel.cc:1546] OP_REQUIRES failed at example_parsing_ops.cc:240 : Invalid argument: Key: phrase.  Data types don't match. Data type: string but expected type: int64
2019-10-24 20:28:44.581066: W tensorflow/core/framework/op_kernel.cc:1546] OP_REQUIRES failed at iterator_ops.cc:1055 : Invalid argument: Key: phrase.  Data types don't match. Data type: string but expected type: int64
	 [[{{node ParseSingleExample/ParseSingleExample}}]]
2019-10-24 20:29:05.180761: W tensorflow/core/framework/op_kernel.cc:1546] OP_REQUIRES failed at example_parsing_ops.cc:240 : Invalid argument: Key: phrase.  Data types don't match. Data type: string but expected type: int64
2019-10-24 20:29:05.180854: W tensorflow/core/framework/op_kernel.cc:1546] OP_REQUIRES failed at iterator_ops.cc:1055 : Invalid argument: Key: phrase.  Data types don't match. Data type: string but expected type: int64
	 [[{{node ParseSingleExample/ParseSingleExample}}]]
2019-10-24 20:29:08.847985: W tensorflow/core/framework/op_kernel.cc:1546] OP_REQUIRES failed at example_parsing_ops.cc:240 : Invalid argument: Key: phrase.  Data types don't match. Data type: string but expected type: int64
2019-10-24 20:29:08.848072: W tensorflow/core/framework/op_kernel.cc:1546] OP_REQUIRES failed at iterator_ops.cc:1055 : Invalid argument: Key: phrase.  Data types don't match. Data type: string but expected type: int64
	 [[{{node ParseSingleExample/ParseSingleExample}}]]
[I 20:29:15.160 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/1.0-canary-to-tfrecord-32x24.ipynb
[I 20:30:16.278 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/1.0-canary-to-tfrecord-32x24.ipynb
2019-10-24 20:33:31.350273: W tensorflow/core/framework/op_kernel.cc:1546] OP_REQUIRES failed at example_parsing_ops.cc:240 : Invalid argument: Key: phrase.  Data types don't match. Data type: string but expected type: int64
2019-10-24 20:33:31.350376: W tensorflow/core/framework/op_kernel.cc:1546] OP_REQUIRES failed at iterator_ops.cc:1055 : Invalid argument: Key: phrase.  Data types don't match. Data type: string but expected type: int64
	 [[{{node ParseSingleExample/ParseSingleExample}}]]
[I 20:35:15.162 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/1.0-canary-to-tfrecord-32x24.ipynb
2019-10-24 20:42:12.095413: W tensorflow/core/framework/op_kernel.cc:1546] OP_REQUIRES failed at example_parsing_ops.cc:240 : Invalid argument: Key: phrase.  Data types don't match. Data type: string but expected type: int64
2019-10-24 20:42:12.095594: W tensorflow/core/framework/op_kernel.cc:1546] OP_REQUIRES failed at iterator_ops.cc:1055 : Invalid argument: Key: phrase.  Data types don't match. Data type: string but expected type: int64
	 [[{{node ParseSingleExample/ParseSingleExample}}]]
2019-10-24 20:42:39.873159: W tensorflow/core/framework/op_kernel.cc:1546] OP_REQUIRES failed at example_parsing_ops.cc:240 : Invalid argument: Key: phrase.  Data types don't match. Data type: string but expected type: int64
2019-10-24 20:42:39.873253: W tensorflow/core/framework/op_kernel.cc:1546] OP_REQUIRES failed at iterator_ops.cc:1055 : Invalid argument: Key: phrase.  Data types don't match. Data type: string but expected type: int64
	 [[{{node ParseSingleExample/ParseSingleExample}}]]
[I 20:43:15.182 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/1.0-canary-to-tfrecord-32x24.ipynb
[I 20:45:15.152 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/1.0-canary-to-tfrecord-32x24.ipynb
[I 20:49:15.149 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/1.0-canary-to-tfrecord-32x24.ipynb
[W 20:49:31.670 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 5.28ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 20:49:33.253 LabApp] Kernel started: 68fe739f-0fae-442f-860e-d943da609e51
[W 20:49:33.264 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 5.20ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 20:49:35.609 LabApp] Adapting from protocol version 5.1 (kernel 68fe739f-0fae-442f-860e-d943da609e51) to 5.3 (client).
[I 20:49:35.631 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 20:49:39.024 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 20:49:39.478 LabApp] Copying avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb to /avgn_paper/notebooks/6.0-neural-networks
[I 20:49:41.115 LabApp] Starting buffering for 68fe739f-0fae-442f-860e-d943da609e51:0ca7e84cfcec469f93f57a3526ca9ca3
[W 20:49:41.118 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.94ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-AE-Copy1.ipynb
[I 20:49:43.131 LabApp] Kernel started: 58be35ac-9299-4833-a925-9817001cae5c
[W 20:49:43.190 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 5.59ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-AE-Copy1.ipynb
[I 20:49:44.740 LabApp] Adapting from protocol version 5.1 (kernel 58be35ac-9299-4833-a925-9817001cae5c) to 5.3 (client).
[I 20:50:09.119 LabApp] KernelRestarter: restarting kernel (1/5), keep random ports
kernel 1298b219-7c76-481f-9908-3b312eaef93f restarted
2019-10-24 20:50:58.204229: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-24 20:50:58.225852: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-24 20:50:58.226852: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-24 20:50:58.229161: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-24 20:50:58.231035: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-24 20:50:58.231828: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-24 20:50:58.234090: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-24 20:50:58.236078: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-24 20:50:58.240241: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-24 20:50:58.242354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-24 20:50:58.490420: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55944e742740 executing computations on platform CUDA. Devices:
2019-10-24 20:50:58.490509: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-24 20:50:58.496740: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-24 20:50:58.498772: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55944e8191d0 executing computations on platform Host. Devices:
2019-10-24 20:50:58.498822: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-24 20:50:58.500602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-24 20:50:58.500733: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-24 20:50:58.500810: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-24 20:50:58.500899: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-24 20:50:58.500972: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-24 20:50:58.501043: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-24 20:50:58.501114: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-24 20:50:58.501185: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-24 20:50:58.504061: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-24 20:50:58.504175: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-24 20:50:58.507687: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-24 20:50:58.507740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-24 20:50:58.507761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-24 20:50:58.511208: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
[I 20:51:44.218 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
2019-10-24 20:52:45.345008: W tensorflow/core/framework/op_kernel.cc:1546] OP_REQUIRES failed at iterator_ops.cc:1055 : Not found: /local/home/tsainbur/github_repos/avgn_paper/data/tfrecords/canary_32x24.tfrecords; No such file or directory
2019-10-24 20:53:21.551481: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-24 20:53:21.806911: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[W 20:53:40.474 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 4.24ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 20:53:41.491 LabApp] Adapting from protocol version 5.1 (kernel 68fe739f-0fae-442f-860e-d943da609e51) to 5.3 (client).
[W 20:53:41.506 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 1.74ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 20:53:44.794 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[I 20:55:42.937 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 20:55:44.360 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[I 20:56:27.585 LabApp] Kernel interrupted: 58be35ac-9299-4833-a925-9817001cae5c
[I 20:57:07.459 LabApp] Kernel interrupted: 58be35ac-9299-4833-a925-9817001cae5c
[I 20:57:35.584 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[I 20:57:43.638 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[I 20:58:52.267 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[I 20:59:16.005 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[I 20:59:18.699 LabApp] Kernel interrupted: 58be35ac-9299-4833-a925-9817001cae5c
[I 20:59:43.638 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[I 20:59:49.702 LabApp] Kernel interrupted: 58be35ac-9299-4833-a925-9817001cae5c
[I 21:01:43.681 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[I 21:02:54.892 LabApp] Kernel interrupted: 58be35ac-9299-4833-a925-9817001cae5c
[I 21:03:43.337 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[I 21:05:43.557 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[I 21:07:43.659 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[I 21:09:43.624 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[W 21:11:20.836 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 1.60ms referer=http://localhost:8187/tree/avgn_paper/notebooks
[I 21:11:43.988 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[W 21:12:02.217 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.61ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/2.0-project-UMAP/canary-syllable-umap.ipynb
[W 21:12:03.772 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 1.54ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/2.0-project-UMAP/canary-syllable-umap.ipynb
[I 21:12:04.370 LabApp] Kernel started: 254383e0-ee3a-4f13-8f5c-605ef4fefd29
[I 21:12:06.210 LabApp] Adapting from protocol version 5.1 (kernel 254383e0-ee3a-4f13-8f5c-605ef4fefd29) to 5.3 (client).
[I 21:13:43.685 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[I 21:13:57.050 LabApp] Kernel interrupted: 58be35ac-9299-4833-a925-9817001cae5c
[I 21:14:07.928 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/canary-syllable-umap.ipynb
[I 21:15:44.106 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[W 21:17:04.926 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 2.39ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 21:17:05.548 LabApp] Kernel started: 73df9972-e766-4753-b8c4-396d4d1c07fb
[W 21:17:05.582 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 1.73ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 21:17:07.862 LabApp] Adapting from protocol version 5.1 (kernel 73df9972-e766-4753-b8c4-396d4d1c07fb) to 5.3 (client).
[I 21:17:13.764 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 21:17:14.063 LabApp] Copying avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb to /avgn_paper/notebooks/6.0-neural-networks
[W 21:17:15.283 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 2.96ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-Copy1.ipynb
[I 21:17:15.693 LabApp] Kernel started: d9916fc0-f379-41c3-acdb-22feac30f803
[W 21:17:15.770 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 1.76ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-Copy1.ipynb
[I 21:17:17.189 LabApp] Adapting from protocol version 5.1 (kernel d9916fc0-f379-41c3-acdb-22feac30f803) to 5.3 (client).
[I 21:17:44.285 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
2019-10-24 21:18:14.261412: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-24 21:18:14.347819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-24 21:18:14.348813: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-24 21:18:14.350593: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-24 21:18:14.351953: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-24 21:18:14.352835: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-24 21:18:14.354641: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-24 21:18:14.356165: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-24 21:18:14.359549: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-24 21:18:14.361409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-24 21:18:21.751218: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5570b2a437d0 executing computations on platform CUDA. Devices:
2019-10-24 21:18:21.751274: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-24 21:18:21.754762: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-24 21:18:21.755935: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5570b2b1a220 executing computations on platform Host. Devices:
2019-10-24 21:18:21.755966: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-24 21:18:21.757107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-24 21:18:21.757193: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-24 21:18:21.757234: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-24 21:18:21.757272: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-24 21:18:21.757309: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-24 21:18:21.757346: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-24 21:18:21.757384: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-24 21:18:21.757422: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-24 21:18:21.760857: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-24 21:18:21.760920: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-24 21:18:21.763881: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-24 21:18:21.763912: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-24 21:18:21.763934: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-24 21:18:21.766288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
[I 21:19:15.864 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
2019-10-24 21:19:30.286409: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-24 21:19:36.583109: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 21:21:15.724 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 21:22:12.773 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 21:22:15.775 LabApp] Kernel interrupted: d9916fc0-f379-41c3-acdb-22feac30f803
[I 21:22:50.054 LabApp] Kernel interrupted: d9916fc0-f379-41c3-acdb-22feac30f803
[I 21:23:16.218 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 21:25:16.780 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 21:27:16.778 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 21:29:17.053 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 21:31:17.059 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 21:32:23.550 LabApp] Kernel interrupted: d9916fc0-f379-41c3-acdb-22feac30f803
[I 21:33:16.748 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 21:39:15.237 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/1.0-canary-to-tfrecord-32x24.ipynb
[I 21:39:23.225 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/1.0-canary-to-tfrecord-32x24.ipynb
[I 22:08:59.392 LabApp] Copying avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb to /avgn_paper/notebooks/6.0-neural-networks
[W 22:08:59.432 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb is not trusted
[W 22:08:59.465 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-AE-Copy1.ipynb is not trusted
[W 22:09:01.686 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-AE-Copy1.ipynb is not trusted
[I 22:09:02.627 LabApp] Kernel started: c4a93869-fff9-4616-b073-1014f8e4cd13
[W 22:09:02.671 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 1.77ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-AE-Copy1.ipynb
[I 22:09:04.800 LabApp] Adapting from protocol version 5.1 (kernel c4a93869-fff9-4616-b073-1014f8e4cd13) to 5.3 (client).
[I 22:10:38.400 LabApp] Starting buffering for 58be35ac-9299-4833-a925-9817001cae5c:1c6ab78cf46d4d5989f3df1b4911defd
[I 22:10:45.293 LabApp] Kernel shutdown: 58be35ac-9299-4833-a925-9817001cae5c
2019-10-24 22:10:59.794921: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-24 22:11:00.381846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-24 22:11:00.395180: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-24 22:11:00.397007: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-24 22:11:00.398587: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-24 22:11:00.411334: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-24 22:11:00.413241: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-24 22:11:00.414867: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-24 22:11:00.418275: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-24 22:11:00.460472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
[I 22:11:03.692 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb
[W 22:11:03.693 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb is not trusted
2019-10-24 22:11:06.844410: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5631212ecf40 executing computations on platform CUDA. Devices:
2019-10-24 22:11:06.844468: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-24 22:11:06.848079: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-24 22:11:06.849249: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5631213c39c0 executing computations on platform Host. Devices:
2019-10-24 22:11:06.849281: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-24 22:11:06.850651: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-24 22:11:06.850721: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-24 22:11:06.850757: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-24 22:11:06.850791: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-24 22:11:06.850825: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-24 22:11:06.850858: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-24 22:11:06.850892: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-24 22:11:06.850926: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-24 22:11:06.852655: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-24 22:11:06.852714: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-24 22:11:06.854764: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-24 22:11:06.854783: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-24 22:11:06.854793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-24 22:11:06.858201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
[I 22:13:03.651 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb
[W 22:13:03.652 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb is not trusted
[I 22:19:03.717 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb
[W 22:19:03.718 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb is not trusted
[I 22:19:26.933 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb
[W 22:19:26.934 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb is not trusted
[I 22:19:47.998 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb
[W 22:19:47.998 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb is not trusted
[I 22:19:52.152 LabApp] Starting buffering for c4a93869-fff9-4616-b073-1014f8e4cd13:a3d51229a10d43a8980e387ffcdb176f
[I 22:19:55.154 LabApp] Kernel restarted: c4a93869-fff9-4616-b073-1014f8e4cd13
[I 22:19:58.366 LabApp] Adapting from protocol version 5.1 (kernel c4a93869-fff9-4616-b073-1014f8e4cd13) to 5.3 (client).
[I 22:19:58.366 LabApp] Restoring connection for c4a93869-fff9-4616-b073-1014f8e4cd13:a3d51229a10d43a8980e387ffcdb176f
[I 22:19:58.366 LabApp] Replaying 6 buffered messages
[I 22:20:30.629 LabApp] Starting buffering for c4a93869-fff9-4616-b073-1014f8e4cd13:a3d51229a10d43a8980e387ffcdb176f
[I 22:20:31.087 LabApp] Kernel restarted: c4a93869-fff9-4616-b073-1014f8e4cd13
[I 22:20:32.626 LabApp] Adapting from protocol version 5.1 (kernel c4a93869-fff9-4616-b073-1014f8e4cd13) to 5.3 (client).
[I 22:20:32.627 LabApp] Restoring connection for c4a93869-fff9-4616-b073-1014f8e4cd13:a3d51229a10d43a8980e387ffcdb176f
[I 22:20:32.627 LabApp] Replaying 6 buffered messages
2019-10-24 22:20:42.789588: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-24 22:20:44.455462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-24 22:20:44.459827: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-24 22:20:44.461648: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-24 22:20:44.463037: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-24 22:20:44.466734: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-24 22:20:44.468661: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-24 22:20:44.470195: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-24 22:20:44.473609: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-24 22:20:44.541681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-24 22:20:50.697110: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56285050cff0 executing computations on platform CUDA. Devices:
2019-10-24 22:20:50.697151: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-24 22:20:50.700376: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-24 22:20:50.701695: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5628505e3a90 executing computations on platform Host. Devices:
2019-10-24 22:20:50.701724: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-24 22:20:50.762637: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-24 22:20:50.762785: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-24 22:20:50.762864: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-24 22:20:50.762935: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-24 22:20:50.763006: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-24 22:20:50.763077: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-24 22:20:50.763170: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-24 22:20:50.763246: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-24 22:20:50.766154: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-24 22:20:50.766264: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-24 22:20:52.773631: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-24 22:20:52.773692: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-24 22:20:52.773706: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-24 22:20:52.778497: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
[I 22:21:02.530 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb
[I 22:23:02.539 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb
[I 22:30:07.424 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb
[I 22:30:09.721 LabApp] Starting buffering for c4a93869-fff9-4616-b073-1014f8e4cd13:a3d51229a10d43a8980e387ffcdb176f
[I 22:30:10.938 LabApp] Kernel restarted: c4a93869-fff9-4616-b073-1014f8e4cd13
[I 22:30:13.234 LabApp] Adapting from protocol version 5.1 (kernel c4a93869-fff9-4616-b073-1014f8e4cd13) to 5.3 (client).
[I 22:30:13.234 LabApp] Restoring connection for c4a93869-fff9-4616-b073-1014f8e4cd13:a3d51229a10d43a8980e387ffcdb176f
[I 22:30:13.234 LabApp] Replaying 6 buffered messages
2019-10-24 22:30:24.980698: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-24 22:30:26.163456: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-24 22:30:26.164539: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-24 22:30:26.167441: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-24 22:30:26.169963: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-24 22:30:26.171070: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-24 22:30:26.174026: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-24 22:30:26.176540: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-24 22:30:26.182210: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-24 22:30:26.239031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-24 22:30:32.465091: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5610569e5ec0 executing computations on platform CUDA. Devices:
2019-10-24 22:30:32.465180: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-24 22:30:32.471354: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-24 22:30:32.472941: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561056abc950 executing computations on platform Host. Devices:
2019-10-24 22:30:32.472970: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-24 22:30:32.476445: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-24 22:30:32.476579: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-24 22:30:32.476620: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-24 22:30:32.476657: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-24 22:30:32.476694: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-24 22:30:32.476744: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-24 22:30:32.476782: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-24 22:30:32.476820: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-24 22:30:32.538352: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-24 22:30:32.538499: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-24 22:30:34.487540: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-24 22:30:34.487608: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-24 22:30:34.487621: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-24 22:30:34.489866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
[I 22:31:02.543 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb
2019-10-24 22:31:09.625423: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-24 22:31:15.791566: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 22:31:23.709 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb
[I 22:31:25.415 LabApp] Kernel interrupted: c4a93869-fff9-4616-b073-1014f8e4cd13
[I 22:31:34.287 LabApp] Kernel interrupted: c4a93869-fff9-4616-b073-1014f8e4cd13
[I 22:31:34.864 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb
[I 22:31:52.540 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb
[I 22:32:56.558 LabApp] Kernel interrupted: c4a93869-fff9-4616-b073-1014f8e4cd13
[I 22:32:58.168 LabApp] Starting buffering for c4a93869-fff9-4616-b073-1014f8e4cd13:a3d51229a10d43a8980e387ffcdb176f
[I 22:33:04.532 LabApp] Kernel restarted: c4a93869-fff9-4616-b073-1014f8e4cd13
[I 22:33:04.720 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb
[I 22:33:05.913 LabApp] Adapting from protocol version 5.1 (kernel c4a93869-fff9-4616-b073-1014f8e4cd13) to 5.3 (client).
[I 22:33:05.914 LabApp] Restoring connection for c4a93869-fff9-4616-b073-1014f8e4cd13:a3d51229a10d43a8980e387ffcdb176f
[I 22:33:05.914 LabApp] Replaying 13 buffered messages
2019-10-24 22:33:16.116648: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-24 22:33:17.832826: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-24 22:33:17.834333: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-24 22:33:17.836614: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-24 22:33:17.838027: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-24 22:33:17.838709: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-24 22:33:17.840562: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-24 22:33:17.842104: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-24 22:33:17.845634: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-24 22:33:17.898251: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-24 22:33:24.022029: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55960ca19f20 executing computations on platform CUDA. Devices:
2019-10-24 22:33:24.022110: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-24 22:33:24.026024: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-24 22:33:24.027148: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55960caf09a0 executing computations on platform Host. Devices:
2019-10-24 22:33:24.027182: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-24 22:33:24.083269: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-24 22:33:24.083413: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-24 22:33:24.083455: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-24 22:33:24.083493: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-24 22:33:24.083531: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-24 22:33:24.083568: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-24 22:33:24.083606: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-24 22:33:24.083644: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-24 22:33:24.085497: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-24 22:33:24.085563: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-24 22:33:26.446735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-24 22:33:26.446805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-24 22:33:26.446818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-24 22:33:26.449754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-24 22:33:47.668980: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-24 22:33:58.048794: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 22:35:02.594 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb
[I 22:37:37.451 LabApp] Starting buffering for 73df9972-e766-4753-b8c4-396d4d1c07fb:a9af4370599446818ea81fe33e8fc014
[I 22:37:39.545 LabApp] Starting buffering for de905082-d91a-4f7e-8a4c-62a2660e6c39:7750dacf4aec4b9092e6ae0c3eeda44a
[I 22:39:02.592 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb
[I 22:41:02.609 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb
[I 22:41:38.821 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb
[I 22:43:02.598 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb
[I 22:44:26.577 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb
[I 22:44:27.729 LabApp] Kernel interrupted: c4a93869-fff9-4616-b073-1014f8e4cd13
[I 22:44:29.781 LabApp] Starting buffering for c4a93869-fff9-4616-b073-1014f8e4cd13:a3d51229a10d43a8980e387ffcdb176f
[I 22:44:38.170 LabApp] Kernel restarted: c4a93869-fff9-4616-b073-1014f8e4cd13
[I 22:44:39.791 LabApp] Adapting from protocol version 5.1 (kernel c4a93869-fff9-4616-b073-1014f8e4cd13) to 5.3 (client).
[I 22:44:39.792 LabApp] Restoring connection for c4a93869-fff9-4616-b073-1014f8e4cd13:a3d51229a10d43a8980e387ffcdb176f
[I 22:44:39.792 LabApp] Replaying 7 buffered messages
2019-10-24 22:44:49.783147: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-24 22:44:51.040382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-24 22:44:51.041305: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-24 22:44:51.043249: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-24 22:44:51.044603: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-24 22:44:51.045234: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-24 22:44:51.047001: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-24 22:44:51.048535: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-24 22:44:51.051923: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-24 22:44:51.110239: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-24 22:44:57.448984: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561ff3e1d4d0 executing computations on platform CUDA. Devices:
2019-10-24 22:44:57.449042: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-24 22:44:57.453114: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-24 22:44:57.454230: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561ff3ef3f50 executing computations on platform Host. Devices:
2019-10-24 22:44:57.454258: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-24 22:44:57.514528: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-24 22:44:57.514621: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-24 22:44:57.514663: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-24 22:44:57.514701: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-24 22:44:57.514738: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-24 22:44:57.514776: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-24 22:44:57.514813: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-24 22:44:57.514851: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-24 22:44:57.516657: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-24 22:44:57.516725: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-24 22:44:58.913742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-24 22:44:58.913797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-24 22:44:58.913808: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-24 22:44:59.889680: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
[I 22:45:02.536 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb
2019-10-24 22:45:14.534492: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-24 22:45:22.444355: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 22:47:02.577 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb
[I 22:49:02.592 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb
[I 22:49:26.826 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb
[I 22:49:37.326 LabApp] Kernel interrupted: c4a93869-fff9-4616-b073-1014f8e4cd13
[I 22:49:39.030 LabApp] Starting buffering for c4a93869-fff9-4616-b073-1014f8e4cd13:a3d51229a10d43a8980e387ffcdb176f
[I 22:49:45.683 LabApp] Kernel restarted: c4a93869-fff9-4616-b073-1014f8e4cd13
[I 22:49:47.076 LabApp] Adapting from protocol version 5.1 (kernel c4a93869-fff9-4616-b073-1014f8e4cd13) to 5.3 (client).
[I 22:49:47.076 LabApp] Restoring connection for c4a93869-fff9-4616-b073-1014f8e4cd13:a3d51229a10d43a8980e387ffcdb176f
[I 22:49:47.076 LabApp] Replaying 69 buffered messages
2019-10-24 22:49:56.616674: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-24 22:49:58.218209: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-24 22:49:58.219237: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-24 22:49:58.221466: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-24 22:49:58.222907: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-24 22:49:58.223582: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-24 22:49:58.225443: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-24 22:49:58.226991: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-24 22:49:58.230371: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-24 22:49:58.232274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-24 22:50:04.730834: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e03fc55650 executing computations on platform CUDA. Devices:
2019-10-24 22:50:04.730903: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-24 22:50:04.734635: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-24 22:50:04.735544: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e03fd2c110 executing computations on platform Host. Devices:
2019-10-24 22:50:04.735572: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-24 22:50:04.737070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-24 22:50:04.737155: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-24 22:50:04.737195: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-24 22:50:04.737233: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-24 22:50:04.737271: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-24 22:50:04.737307: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-24 22:50:04.737344: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-24 22:50:04.737382: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-24 22:50:04.745266: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-24 22:50:04.745324: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-24 22:50:04.747277: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-24 22:50:04.747297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-24 22:50:04.747307: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-24 22:50:04.749322: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
[I 22:51:02.580 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb
2019-10-24 22:51:32.458265: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-24 22:51:40.865663: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 22:53:02.604 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb
[I 22:55:02.611 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb
[I 22:57:02.618 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb
[I 22:59:02.615 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb
[I 23:01:02.626 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb
[I 23:03:02.620 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb
[I 23:05:02.618 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb
[I 23:07:02.644 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb
[I 23:09:02.633 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb
[I 23:11:03.254 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb
[I 07:21:45.692 LabApp] KernelRestarter: restarting kernel (1/5), keep random ports
kernel d9916fc0-f379-41c3-acdb-22feac30f803 restarted
[W 07:21:56.137 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb is not trusted
[W 07:21:56.179 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 1.66ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 07:21:57.082 LabApp] Adapting from protocol version 5.1 (kernel d9916fc0-f379-41c3-acdb-22feac30f803) to 5.3 (client).
[W 07:21:57.192 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 1.79ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 07:22:01.928 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[W 07:22:01.929 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb is not trusted
[I 07:22:02.090 LabApp] Copying avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb to /avgn_paper/notebooks/6.0-neural-networks
[W 07:22:02.128 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb is not trusted
[W 07:22:02.160 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-VAE-Copy1.ipynb is not trusted
[W 07:22:03.191 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-VAE-Copy1.ipynb is not trusted
[W 07:22:03.233 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.02ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-VAE-Copy1.ipynb
[I 07:22:03.933 LabApp] Kernel started: b60093f0-9890-4acf-b847-f792bad7af5e
[W 07:22:03.993 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 2.12ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-VAE-Copy1.ipynb
[I 07:22:06.791 LabApp] Adapting from protocol version 5.1 (kernel b60093f0-9890-4acf-b847-f792bad7af5e) to 5.3 (client).
[I 07:23:03.203 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb
[I 07:24:05.060 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE-Copy1.ipynb
[W 07:24:05.061 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-VAE-Copy1.ipynb is not trusted
[I 07:25:03.560 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb
[I 07:27:03.145 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb
[I 07:29:03.660 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb
[I 07:31:03.205 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb
[I 07:33:03.388 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb
[I 07:35:03.178 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb
[I 07:37:03.625 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb
[I 07:39:03.343 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb
[I 07:40:05.068 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[W 07:40:05.069 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb is not trusted
2019-10-25 07:40:21.780744: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-25 07:40:22.296125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-25 07:40:22.305035: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 07:40:22.307140: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 07:40:22.308555: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 07:40:22.318803: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 07:40:22.320761: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 07:40:22.322443: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 07:40:22.325808: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 07:40:22.328857: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 07:40:22.518138: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5581a3e21190 executing computations on platform CUDA. Devices:
2019-10-25 07:40:22.518184: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-25 07:40:22.521112: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-25 07:40:22.522201: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5581a3ef7c40 executing computations on platform Host. Devices:
2019-10-25 07:40:22.522227: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-25 07:40:22.524062: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-25 07:40:22.524224: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 07:40:22.524267: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 07:40:22.524304: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 07:40:22.524342: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 07:40:22.524380: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 07:40:22.524418: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 07:40:22.524456: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 07:40:22.526335: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 07:40:22.526405: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 07:40:22.529222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-25 07:40:22.529253: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-25 07:40:22.529265: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-25 07:40:22.531367: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
[I 07:40:48.223 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[W 07:40:48.224 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb is not trusted
[I 07:41:03.279 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb
[I 07:41:23.531 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[W 07:41:23.532 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb is not trusted
[I 07:42:04.971 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[W 07:42:04.972 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb is not trusted
[I 07:43:03.171 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb
[I 07:43:11.923 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[W 07:43:11.924 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb is not trusted
[I 07:43:42.439 LabApp] Starting buffering for b60093f0-9890-4acf-b847-f792bad7af5e:0d6ed5aea79744c991ac561f3fdb7bd4
[I 07:43:44.058 LabApp] Kernel restarted: b60093f0-9890-4acf-b847-f792bad7af5e
[I 07:43:47.026 LabApp] Adapting from protocol version 5.1 (kernel b60093f0-9890-4acf-b847-f792bad7af5e) to 5.3 (client).
[I 07:43:47.027 LabApp] Restoring connection for b60093f0-9890-4acf-b847-f792bad7af5e:0d6ed5aea79744c991ac561f3fdb7bd4
[I 07:43:47.027 LabApp] Replaying 6 buffered messages
2019-10-25 07:43:59.655572: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-25 07:44:00.147938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-25 07:44:00.154073: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 07:44:00.156071: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 07:44:00.157712: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 07:44:00.158687: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 07:44:00.160578: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 07:44:00.162249: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 07:44:00.165621: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 07:44:00.167531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 07:44:00.361246: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d24bb72e60 executing computations on platform CUDA. Devices:
2019-10-25 07:44:00.361307: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-25 07:44:00.364743: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-25 07:44:00.366126: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d24bc498f0 executing computations on platform Host. Devices:
2019-10-25 07:44:00.366157: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-25 07:44:00.367237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-25 07:44:00.367323: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 07:44:00.367363: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 07:44:00.367401: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 07:44:00.367438: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 07:44:00.367475: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 07:44:00.367512: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 07:44:00.367549: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 07:44:00.369315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 07:44:00.369379: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 07:44:00.372090: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-25 07:44:00.372112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-25 07:44:00.372123: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-25 07:44:00.374212: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-25 07:44:03.579291: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 07:44:03.962 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
2019-10-25 07:44:04.451030: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
[I 07:44:55.472 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 07:44:55.695 LabApp] Copying avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb to /avgn_paper/notebooks/6.0-neural-networks
[W 07:44:57.811 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 2.00ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN-Copy1.ipynb
[I 07:44:58.363 LabApp] Kernel started: 12515917-ab73-46e0-87bf-02273f875e74
[W 07:44:58.374 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 4.08ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN-Copy1.ipynb
[I 07:45:01.026 LabApp] Adapting from protocol version 5.1 (kernel 12515917-ab73-46e0-87bf-02273f875e74) to 5.3 (client).
[I 07:45:03.832 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb
[I 07:45:33.683 LabApp] KernelRestarter: restarting kernel (1/5), keep random ports
kernel c4a93869-fff9-4616-b073-1014f8e4cd13 restarted
[W 07:46:11.812 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb is not trusted
[W 07:46:11.871 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 4.63ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[I 07:46:12.985 LabApp] Kernel started: 1c23d551-7d11-4d02-ac6c-999284268760
[W 07:46:13.004 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 5.27ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[I 07:46:16.247 LabApp] Adapting from protocol version 5.1 (kernel 1c23d551-7d11-4d02-ac6c-999284268760) to 5.3 (client).
[I 07:46:59.452 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[W 07:46:59.455 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb is not trusted
[I 07:47:03.180 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb
[I 07:48:03.991 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 07:48:14.464 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[W 07:48:14.466 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb is not trusted
[I 07:48:42.722 LabApp] Starting buffering for 12515917-ab73-46e0-87bf-02273f875e74:930dbc8dc4fa4aa8bca7abe1b7acfc52
[I 07:48:43.443 LabApp] Kernel restarted: 12515917-ab73-46e0-87bf-02273f875e74
[I 07:48:46.332 LabApp] Adapting from protocol version 5.1 (kernel 12515917-ab73-46e0-87bf-02273f875e74) to 5.3 (client).
[I 07:48:46.333 LabApp] Restoring connection for 12515917-ab73-46e0-87bf-02273f875e74:930dbc8dc4fa4aa8bca7abe1b7acfc52
[I 07:48:46.334 LabApp] Replaying 6 buffered messages
[I 07:48:58.317 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
2019-10-25 07:49:01.274445: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-25 07:49:01.862541: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-25 07:49:01.864494: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 07:49:01.866783: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 07:49:01.869580: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 07:49:01.870759: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 07:49:01.874587: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 07:49:01.877880: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 07:49:01.884993: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 07:49:01.888394: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 07:49:02.174289: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5559fda06e50 executing computations on platform CUDA. Devices:
2019-10-25 07:49:02.174390: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-25 07:49:02.181397: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-25 07:49:02.182745: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5559fdadd8e0 executing computations on platform Host. Devices:
2019-10-25 07:49:02.182776: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-25 07:49:02.183875: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-25 07:49:02.183977: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 07:49:02.184018: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 07:49:02.184056: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 07:49:02.184093: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 07:49:02.184130: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 07:49:02.184167: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 07:49:02.184206: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 07:49:02.186042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 07:49:02.186106: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 07:49:02.188248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-25 07:49:02.188270: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-25 07:49:02.188282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-25 07:49:02.190383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-25 07:49:22.931022: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 07:49:23.168756: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 07:49:49.669411: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:502] constant folding failed: Invalid argument: Unsupported type: 21
2019-10-25 07:49:50.059716: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:502] constant folding failed: Invalid argument: Unsupported type: 21
[I 07:50:59.164 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 07:52:59.163 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 07:54:59.178 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 07:56:59.163 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 07:58:59.165 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 08:00:43.377 LabApp] Kernel interrupted: 12515917-ab73-46e0-87bf-02273f875e74
[I 08:00:59.236 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 08:01:40.488 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 08:01:42.530 LabApp] Starting buffering for 12515917-ab73-46e0-87bf-02273f875e74:930dbc8dc4fa4aa8bca7abe1b7acfc52
[I 08:01:46.169 LabApp] Kernel restarted: 12515917-ab73-46e0-87bf-02273f875e74
[I 08:01:49.625 LabApp] Adapting from protocol version 5.1 (kernel 12515917-ab73-46e0-87bf-02273f875e74) to 5.3 (client).
[I 08:01:49.626 LabApp] Restoring connection for 12515917-ab73-46e0-87bf-02273f875e74:930dbc8dc4fa4aa8bca7abe1b7acfc52
[I 08:01:49.627 LabApp] Replaying 8 buffered messages
2019-10-25 08:02:06.243307: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-25 08:02:06.855809: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-25 08:02:06.867064: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 08:02:06.870708: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 08:02:06.873374: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 08:02:06.904234: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 08:02:06.908170: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 08:02:06.911772: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 08:02:06.919904: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 08:02:06.923384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 08:02:07.253239: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f9326bdc00 executing computations on platform CUDA. Devices:
2019-10-25 08:02:07.253299: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-25 08:02:07.257765: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-25 08:02:07.259916: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f932794690 executing computations on platform Host. Devices:
2019-10-25 08:02:07.260003: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-25 08:02:07.261421: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-25 08:02:07.261616: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 08:02:07.261715: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 08:02:07.261806: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 08:02:07.261922: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 08:02:07.261970: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 08:02:07.262016: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 08:02:07.262063: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 08:02:07.264927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 08:02:07.265065: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 08:02:07.268566: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-25 08:02:07.268589: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-25 08:02:07.268602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-25 08:02:07.271832: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-25 08:02:10.968458: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 08:02:11.190425: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 08:02:36.982430: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:502] constant folding failed: Invalid argument: Unsupported type: 21
2019-10-25 08:02:37.421578: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:502] constant folding failed: Invalid argument: Unsupported type: 21
[I 08:02:59.143 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 08:03:10.898 LabApp] Kernel interrupted: 12515917-ab73-46e0-87bf-02273f875e74
[I 08:03:33.187 LabApp] Kernel interrupted: 12515917-ab73-46e0-87bf-02273f875e74
[I 08:04:03.956 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 08:04:37.943 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 08:06:04.086 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 08:06:58.351 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 08:07:31.075 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 08:07:33.319 LabApp] Starting buffering for 12515917-ab73-46e0-87bf-02273f875e74:930dbc8dc4fa4aa8bca7abe1b7acfc52
[I 08:07:37.001 LabApp] Kernel restarted: 12515917-ab73-46e0-87bf-02273f875e74
[I 08:07:40.088 LabApp] Adapting from protocol version 5.1 (kernel 12515917-ab73-46e0-87bf-02273f875e74) to 5.3 (client).
[I 08:07:40.089 LabApp] Restoring connection for 12515917-ab73-46e0-87bf-02273f875e74:930dbc8dc4fa4aa8bca7abe1b7acfc52
[I 08:07:40.089 LabApp] Replaying 8 buffered messages
2019-10-25 08:07:51.637371: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-25 08:07:52.219168: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-25 08:07:52.221093: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 08:07:52.224224: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 08:07:52.226710: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 08:07:52.228382: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 08:07:52.231547: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 08:07:52.234133: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 08:07:52.239607: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 08:07:52.242618: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 08:07:52.497921: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e0cc661e00 executing computations on platform CUDA. Devices:
2019-10-25 08:07:52.497991: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-25 08:07:52.502333: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-25 08:07:52.503992: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e0cc738890 executing computations on platform Host. Devices:
2019-10-25 08:07:52.504034: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-25 08:07:52.505645: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-25 08:07:52.505759: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 08:07:52.505819: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 08:07:52.505874: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 08:07:52.505930: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 08:07:52.505985: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 08:07:52.506050: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 08:07:52.506107: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 08:07:52.508276: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 08:07:52.508352: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 08:07:52.510709: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-25 08:07:52.510732: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-25 08:07:52.510745: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-25 08:07:52.513072: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-25 08:07:55.956477: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 08:07:56.186848: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 08:08:05.391706: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:502] constant folding failed: Invalid argument: Unsupported type: 21
2019-10-25 08:08:05.754852: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:502] constant folding failed: Invalid argument: Unsupported type: 21
[I 08:08:58.442 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 08:09:07.500 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 08:10:05.531 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 08:10:20.336 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 08:10:23.435 LabApp] Starting buffering for 12515917-ab73-46e0-87bf-02273f875e74:930dbc8dc4fa4aa8bca7abe1b7acfc52
[I 08:10:29.223 LabApp] Kernel restarted: 12515917-ab73-46e0-87bf-02273f875e74
[I 08:10:32.784 LabApp] Adapting from protocol version 5.1 (kernel 12515917-ab73-46e0-87bf-02273f875e74) to 5.3 (client).
[I 08:10:32.785 LabApp] Restoring connection for 12515917-ab73-46e0-87bf-02273f875e74:930dbc8dc4fa4aa8bca7abe1b7acfc52
[I 08:10:32.785 LabApp] Replaying 107 buffered messages
[I 08:10:45.394 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 08:10:46.464 LabApp] Kernel interrupted: 12515917-ab73-46e0-87bf-02273f875e74
[I 08:10:51.780 LabApp] Starting buffering for 12515917-ab73-46e0-87bf-02273f875e74:930dbc8dc4fa4aa8bca7abe1b7acfc52
[I 08:10:53.043 LabApp] Kernel restarted: 12515917-ab73-46e0-87bf-02273f875e74
[I 08:10:55.611 LabApp] Adapting from protocol version 5.1 (kernel 12515917-ab73-46e0-87bf-02273f875e74) to 5.3 (client).
[I 08:10:55.612 LabApp] Restoring connection for 12515917-ab73-46e0-87bf-02273f875e74:930dbc8dc4fa4aa8bca7abe1b7acfc52
[I 08:10:55.612 LabApp] Replaying 6 buffered messages
[I 08:10:58.319 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
2019-10-25 08:11:05.826811: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-25 08:11:06.344516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-25 08:11:06.345699: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 08:11:06.347726: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 08:11:06.349318: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 08:11:06.350317: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 08:11:06.352424: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 08:11:06.354174: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 08:11:06.357991: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 08:11:06.359928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 08:11:06.572681: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564b0a07e930 executing computations on platform CUDA. Devices:
2019-10-25 08:11:06.572756: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-25 08:11:06.578053: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-25 08:11:06.579334: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564b0a1553e0 executing computations on platform Host. Devices:
2019-10-25 08:11:06.579366: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-25 08:11:06.580483: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-25 08:11:06.580566: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 08:11:06.580605: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 08:11:06.580642: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 08:11:06.580678: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 08:11:06.580714: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 08:11:06.580752: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 08:11:06.580789: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 08:11:06.582560: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 08:11:06.582623: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 08:11:06.584747: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-25 08:11:06.584771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-25 08:11:06.584783: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-25 08:11:06.587789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-25 08:11:19.695293: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 08:11:19.908168: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 08:11:28.396894: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:502] constant folding failed: Invalid argument: Unsupported type: 21
2019-10-25 08:11:28.761865: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:502] constant folding failed: Invalid argument: Unsupported type: 21
[I 08:11:55.955 LabApp] Kernel interrupted: 12515917-ab73-46e0-87bf-02273f875e74
[I 08:12:05.090 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 08:12:58.425 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 08:14:05.073 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 08:14:58.426 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 08:16:09.054 LabApp] Copying avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb to /avgn_paper/notebooks/6.0-neural-networks
[W 08:16:09.112 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb is not trusted
[W 08:16:09.150 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-AE-Copy1.ipynb is not trusted
[W 08:16:10.511 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-AE-Copy1.ipynb is not trusted
[W 08:16:10.571 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 5.33ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-AE-Copy1.ipynb
[I 08:16:11.615 LabApp] Kernel started: 4fc82f8c-c0b7-436a-aa4a-b0f06a645448
[W 08:16:11.634 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 6.75ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-AE-Copy1.ipynb
[I 08:16:14.365 LabApp] Adapting from protocol version 5.1 (kernel 4fc82f8c-c0b7-436a-aa4a-b0f06a645448) to 5.3 (client).
[I 08:16:28.439 LabApp] Kernel interrupted: b60093f0-9890-4acf-b847-f792bad7af5e
[I 08:16:59.051 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 08:17:41.848 LabApp] Starting buffering for b60093f0-9890-4acf-b847-f792bad7af5e:0d6ed5aea79744c991ac561f3fdb7bd4
[I 08:17:44.767 LabApp] Kernel shutdown: b60093f0-9890-4acf-b847-f792bad7af5e
[I 08:18:05.493 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 08:18:12.675 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
[W 08:18:12.676 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb is not trusted
[I 08:18:59.044 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
2019-10-25 08:19:40.294117: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-25 08:19:40.885929: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-25 08:19:40.887030: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 08:19:40.889471: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 08:19:40.891388: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 08:19:40.892266: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 08:19:40.894478: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 08:19:40.896385: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 08:19:40.901231: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 08:19:40.903634: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 08:19:41.134071: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562f96742b90 executing computations on platform CUDA. Devices:
2019-10-25 08:19:41.134128: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-25 08:19:41.139671: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-25 08:19:41.141235: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562f96819610 executing computations on platform Host. Devices:
2019-10-25 08:19:41.141273: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-25 08:19:41.142545: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-25 08:19:41.142662: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 08:19:41.142715: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 08:19:41.142780: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 08:19:41.142830: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 08:19:41.142878: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 08:19:41.142927: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 08:19:41.142975: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 08:19:41.144812: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 08:19:41.144883: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 08:19:41.146979: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-25 08:19:41.146999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-25 08:19:41.147011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-25 08:19:41.149171: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
[I 08:20:12.654 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
[W 08:20:12.656 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb is not trusted
[I 08:20:59.072 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 08:21:15.574 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
[W 08:21:15.574 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb is not trusted
[I 08:21:41.908 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
[W 08:21:41.909 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb is not trusted
[I 08:22:20.588 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
[W 08:22:20.590 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb is not trusted
[I 08:22:28.910 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
[W 08:22:28.911 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb is not trusted
[I 08:22:35.142 LabApp] Starting buffering for 4fc82f8c-c0b7-436a-aa4a-b0f06a645448:883498b9d537425e9791b6e9a48aff81
[I 08:22:36.598 LabApp] Kernel restarted: 4fc82f8c-c0b7-436a-aa4a-b0f06a645448
[I 08:22:40.217 LabApp] Adapting from protocol version 5.1 (kernel 4fc82f8c-c0b7-436a-aa4a-b0f06a645448) to 5.3 (client).
[I 08:22:40.218 LabApp] Restoring connection for 4fc82f8c-c0b7-436a-aa4a-b0f06a645448:883498b9d537425e9791b6e9a48aff81
[I 08:22:40.218 LabApp] Replaying 6 buffered messages
2019-10-25 08:22:54.011139: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-25 08:22:54.583640: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-25 08:22:54.603559: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 08:22:54.605730: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 08:22:54.607362: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 08:22:54.608339: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 08:22:54.610391: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 08:22:54.612204: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 08:22:54.616034: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 08:22:54.618139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 08:22:54.870584: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a8958246d0 executing computations on platform CUDA. Devices:
2019-10-25 08:22:54.870648: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-25 08:22:54.874214: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-25 08:22:54.875257: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a8958fb140 executing computations on platform Host. Devices:
2019-10-25 08:22:54.875282: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-25 08:22:54.876424: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-25 08:22:54.876515: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 08:22:54.876556: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 08:22:54.876593: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 08:22:54.876631: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 08:22:54.876668: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 08:22:54.876706: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 08:22:54.876745: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 08:22:54.878565: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 08:22:54.878624: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 08:22:54.881102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-25 08:22:54.881131: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-25 08:22:54.881150: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-25 08:22:54.883856: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
[I 08:22:58.420 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 08:24:11.556 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
2019-10-25 08:24:30.608021: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-25 08:24:30.649687: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 08:24:30.892128: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 08:24:57.863 LabApp] Starting buffering for 4fc82f8c-c0b7-436a-aa4a-b0f06a645448:883498b9d537425e9791b6e9a48aff81
[I 08:25:00.630 LabApp] Kernel restarted: 4fc82f8c-c0b7-436a-aa4a-b0f06a645448
[I 08:25:00.846 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 08:25:03.361 LabApp] Adapting from protocol version 5.1 (kernel 4fc82f8c-c0b7-436a-aa4a-b0f06a645448) to 5.3 (client).
[I 08:25:03.362 LabApp] Restoring connection for 4fc82f8c-c0b7-436a-aa4a-b0f06a645448:883498b9d537425e9791b6e9a48aff81
[I 08:25:03.362 LabApp] Replaying 8 buffered messages
2019-10-25 08:25:14.389277: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-25 08:25:14.921142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-25 08:25:14.936139: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 08:25:14.938115: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 08:25:14.939783: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 08:25:14.946559: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 08:25:14.948659: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 08:25:14.950358: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 08:25:14.954164: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 08:25:14.956210: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 08:25:15.162859: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562e531d9a30 executing computations on platform CUDA. Devices:
2019-10-25 08:25:15.162925: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-25 08:25:15.166714: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-25 08:25:15.167920: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562e532b04e0 executing computations on platform Host. Devices:
2019-10-25 08:25:15.167954: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-25 08:25:15.169039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-25 08:25:15.169130: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 08:25:15.169171: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 08:25:15.169208: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 08:25:15.169246: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 08:25:15.169283: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 08:25:15.169321: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 08:25:15.169376: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 08:25:15.171134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 08:25:15.171201: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 08:25:15.173423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-25 08:25:15.173457: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-25 08:25:15.173469: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-25 08:25:15.175637: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-25 08:25:20.741147: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-25 08:25:20.778519: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 08:25:21.000342: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 08:26:12.695 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
[I 08:26:55.913 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
[I 08:26:58.867 LabApp] Starting buffering for 4fc82f8c-c0b7-436a-aa4a-b0f06a645448:883498b9d537425e9791b6e9a48aff81
[I 08:27:02.424 LabApp] Kernel restarted: 4fc82f8c-c0b7-436a-aa4a-b0f06a645448
[I 08:27:02.606 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 08:27:04.803 LabApp] Adapting from protocol version 5.1 (kernel 4fc82f8c-c0b7-436a-aa4a-b0f06a645448) to 5.3 (client).
[I 08:27:04.804 LabApp] Restoring connection for 4fc82f8c-c0b7-436a-aa4a-b0f06a645448:883498b9d537425e9791b6e9a48aff81
[I 08:27:04.804 LabApp] Replaying 6 buffered messages
2019-10-25 08:27:18.020875: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-25 08:27:18.534799: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-25 08:27:18.536228: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 08:27:18.538175: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 08:27:18.539792: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 08:27:18.540775: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 08:27:18.542771: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 08:27:18.544512: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 08:27:18.548220: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 08:27:18.551522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 08:27:18.753241: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e49bd49530 executing computations on platform CUDA. Devices:
2019-10-25 08:27:18.753316: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-25 08:27:18.759941: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-25 08:27:18.761874: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e49be1ffc0 executing computations on platform Host. Devices:
2019-10-25 08:27:18.761905: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-25 08:27:18.762994: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-25 08:27:18.763071: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 08:27:18.763124: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 08:27:18.763164: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 08:27:18.763201: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 08:27:18.763238: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 08:27:18.763276: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 08:27:18.763315: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 08:27:18.765087: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 08:27:18.765150: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 08:27:18.767233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-25 08:27:18.767254: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-25 08:27:18.767266: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-25 08:27:18.769430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-25 08:27:24.179164: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-25 08:27:24.212054: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 08:27:24.414188: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 08:28:12.069 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
[I 08:28:59.077 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 08:30:11.593 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
[I 08:30:59.081 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 08:32:11.643 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
[I 08:32:59.079 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 08:34:11.629 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
[I 08:34:59.069 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 08:36:11.643 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
[I 08:36:59.064 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 08:38:11.630 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
[I 08:38:30.393 LabApp] Kernel interrupted: 4fc82f8c-c0b7-436a-aa4a-b0f06a645448
[I 08:38:59.002 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 08:40:11.643 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
[I 08:40:59.055 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 08:41:14.137 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
[I 08:41:54.643 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
[I 08:41:57.403 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
[I 08:42:07.848 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
[I 08:42:10.020 LabApp] Starting buffering for 4fc82f8c-c0b7-436a-aa4a-b0f06a645448:883498b9d537425e9791b6e9a48aff81
[I 08:42:13.465 LabApp] Kernel restarted: 4fc82f8c-c0b7-436a-aa4a-b0f06a645448
[I 08:42:17.585 LabApp] Adapting from protocol version 5.1 (kernel 4fc82f8c-c0b7-436a-aa4a-b0f06a645448) to 5.3 (client).
[I 08:42:17.586 LabApp] Restoring connection for 4fc82f8c-c0b7-436a-aa4a-b0f06a645448:883498b9d537425e9791b6e9a48aff81
[I 08:42:17.586 LabApp] Replaying 8 buffered messages
2019-10-25 08:42:30.976578: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-25 08:42:31.506081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-25 08:42:31.508275: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 08:42:31.511211: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 08:42:31.514070: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 08:42:31.516076: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 08:42:31.518707: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 08:42:31.521918: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 08:42:31.525710: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 08:42:31.527639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 08:42:31.726031: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55989e1cfbe0 executing computations on platform CUDA. Devices:
2019-10-25 08:42:31.726100: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-25 08:42:31.732265: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-25 08:42:31.733860: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55989e2a6670 executing computations on platform Host. Devices:
2019-10-25 08:42:31.733918: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-25 08:42:31.735888: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-25 08:42:31.736065: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 08:42:31.736153: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 08:42:31.736234: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 08:42:31.736315: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 08:42:31.736396: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 08:42:31.736476: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 08:42:31.736558: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 08:42:31.739758: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 08:42:31.739869: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 08:42:31.743521: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-25 08:42:31.743560: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-25 08:42:31.743580: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-25 08:42:31.747011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-25 08:42:37.128519: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-25 08:42:37.166767: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 08:42:37.409299: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 08:42:59.073 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 08:44:12.024 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
[I 08:44:59.077 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 08:46:12.669 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
[I 08:46:59.081 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 08:48:12.581 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
[I 08:48:59.073 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 08:50:12.187 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
[I 08:50:59.105 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 08:52:12.172 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
[I 08:52:59.076 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 08:54:12.216 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
[I 08:54:59.065 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 08:56:12.233 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
[I 08:56:59.080 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 08:58:12.199 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
[I 08:58:59.148 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 09:00:12.236 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
[I 09:00:59.073 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 09:02:12.219 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
[I 09:02:59.094 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 09:04:12.242 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
[I 09:04:59.071 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 09:06:13.069 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
[I 09:06:59.124 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 09:08:12.419 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
[I 09:08:59.121 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 09:10:12.251 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
[I 09:10:59.089 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 09:12:12.256 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
[I 09:12:59.094 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 09:14:12.216 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
[I 09:14:59.090 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 09:16:12.240 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
[I 09:16:59.094 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 09:18:12.244 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
[I 09:18:59.085 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 09:20:12.784 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
[I 09:20:59.104 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 09:22:12.398 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
[I 09:22:59.099 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 09:24:12.411 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
[I 09:24:59.121 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 09:26:12.227 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
[I 09:26:59.100 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 09:27:22.885 LabApp] Kernel interrupted: 12515917-ab73-46e0-87bf-02273f875e74
[I 09:28:12.260 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
[I 09:28:59.177 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 09:30:12.280 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
[I 09:30:59.223 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 09:32:12.246 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
[I 09:32:59.214 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 09:34:12.249 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
[I 09:34:37.756 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
[I 09:34:47.187 LabApp] Starting buffering for 12515917-ab73-46e0-87bf-02273f875e74:930dbc8dc4fa4aa8bca7abe1b7acfc52
[I 09:34:52.970 LabApp] Kernel shutdown: 12515917-ab73-46e0-87bf-02273f875e74
[I 09:34:53.273 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
[I 09:34:53.531 LabApp] Copying avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb to /avgn_paper/notebooks/6.0-neural-networks
[I 09:34:55.968 LabApp] Kernel started: 0120207d-d5dc-4388-b6a9-1756f0b374b7
[W 09:34:56.035 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 4.85ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA-Copy1.ipynb
[W 09:34:56.241 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 2.16ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA-Copy1.ipynb
[I 09:34:58.460 LabApp] Adapting from protocol version 5.1 (kernel 0120207d-d5dc-4388-b6a9-1756f0b374b7) to 5.3 (client).
[I 09:34:59.753 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 09:36:01.117 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA2.ipynb
[I 09:36:09.269 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA2.ipynb
[I 09:36:12.400 LabApp] Starting buffering for 0120207d-d5dc-4388-b6a9-1756f0b374b7:50d5768e074d49ba93ddd24648fbdf8c
[I 09:36:13.017 LabApp] Kernel restarted: 0120207d-d5dc-4388-b6a9-1756f0b374b7
[I 09:36:15.882 LabApp] Adapting from protocol version 5.1 (kernel 0120207d-d5dc-4388-b6a9-1756f0b374b7) to 5.3 (client).
[I 09:36:15.883 LabApp] Restoring connection for 0120207d-d5dc-4388-b6a9-1756f0b374b7:50d5768e074d49ba93ddd24648fbdf8c
[I 09:36:15.883 LabApp] Replaying 6 buffered messages
2019-10-25 09:36:29.562270: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-25 09:36:30.115331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-25 09:36:30.127958: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 09:36:30.130177: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 09:36:30.131764: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 09:36:30.132731: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 09:36:30.134809: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 09:36:30.136550: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 09:36:30.140410: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 09:36:30.142444: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 09:36:30.372767: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5647d1b827e0 executing computations on platform CUDA. Devices:
2019-10-25 09:36:30.372820: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-25 09:36:30.376077: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-25 09:36:30.377263: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5647d1c59290 executing computations on platform Host. Devices:
2019-10-25 09:36:30.377293: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-25 09:36:30.378313: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-25 09:36:30.378418: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 09:36:30.378463: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 09:36:30.378505: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 09:36:30.378547: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 09:36:30.378587: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 09:36:30.378629: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 09:36:30.378671: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 09:36:30.380465: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 09:36:30.380535: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 09:36:30.382644: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-25 09:36:30.382664: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-25 09:36:30.382674: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-25 09:36:30.384832: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
[I 09:36:55.926 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA2.ipynb
[I 09:38:12.357 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
2019-10-25 09:38:15.622151: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-25 09:38:15.662489: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 09:38:15.894774: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 09:38:56.031 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA2.ipynb
[I 09:39:00.889 LabApp] Kernel interrupted: 0120207d-d5dc-4388-b6a9-1756f0b374b7
[I 09:39:04.503 LabApp] Starting buffering for 0120207d-d5dc-4388-b6a9-1756f0b374b7:50d5768e074d49ba93ddd24648fbdf8c
[I 09:39:06.908 LabApp] Kernel restarted: 0120207d-d5dc-4388-b6a9-1756f0b374b7
[I 09:39:09.703 LabApp] Adapting from protocol version 5.1 (kernel 0120207d-d5dc-4388-b6a9-1756f0b374b7) to 5.3 (client).
[I 09:39:09.704 LabApp] Restoring connection for 0120207d-d5dc-4388-b6a9-1756f0b374b7:50d5768e074d49ba93ddd24648fbdf8c
[I 09:39:09.704 LabApp] Replaying 6 buffered messages
2019-10-25 09:39:22.363610: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-25 09:39:22.913026: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-25 09:39:22.914102: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 09:39:22.916296: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 09:39:22.917866: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 09:39:22.918587: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 09:39:22.920639: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 09:39:22.922370: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 09:39:22.926227: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 09:39:22.928280: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 09:39:23.178491: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b50ff167d0 executing computations on platform CUDA. Devices:
2019-10-25 09:39:23.178613: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-25 09:39:23.185689: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-25 09:39:23.187658: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b50ffed220 executing computations on platform Host. Devices:
2019-10-25 09:39:23.187710: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-25 09:39:23.189215: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-25 09:39:23.189343: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 09:39:23.189408: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 09:39:23.189468: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 09:39:23.189529: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 09:39:23.189589: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 09:39:23.189650: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 09:39:23.189711: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 09:39:23.192224: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 09:39:23.192326: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 09:39:23.204532: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-25 09:39:23.204572: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-25 09:39:23.204590: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-25 09:39:23.207519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-25 09:39:29.420047: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-25 09:39:29.452649: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 09:39:29.724570: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 09:40:12.263 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
[I 09:40:23.927 LabApp] Starting buffering for 0120207d-d5dc-4388-b6a9-1756f0b374b7:50d5768e074d49ba93ddd24648fbdf8c
[I 09:40:26.822 LabApp] Kernel restarted: 0120207d-d5dc-4388-b6a9-1756f0b374b7
[I 09:40:30.502 LabApp] Adapting from protocol version 5.1 (kernel 0120207d-d5dc-4388-b6a9-1756f0b374b7) to 5.3 (client).
[I 09:40:30.503 LabApp] Restoring connection for 0120207d-d5dc-4388-b6a9-1756f0b374b7:50d5768e074d49ba93ddd24648fbdf8c
[I 09:40:30.503 LabApp] Replaying 6 buffered messages
2019-10-25 09:40:45.631756: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-25 09:40:46.188083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-25 09:40:46.189194: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 09:40:46.191543: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 09:40:46.193255: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 09:40:46.194035: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 09:40:46.196350: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 09:40:46.198235: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 09:40:46.202139: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 09:40:46.204155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 09:40:46.452077: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555af87b7110 executing computations on platform CUDA. Devices:
2019-10-25 09:40:46.452155: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-25 09:40:46.458448: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-25 09:40:46.460971: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555af888dbc0 executing computations on platform Host. Devices:
2019-10-25 09:40:46.461044: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-25 09:40:46.462379: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-25 09:40:46.462496: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 09:40:46.462553: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 09:40:46.462607: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 09:40:46.462661: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 09:40:46.462714: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 09:40:46.462787: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 09:40:46.462844: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 09:40:46.471625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 09:40:46.471733: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 09:40:46.474610: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-25 09:40:46.474641: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-25 09:40:46.474656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-25 09:40:46.477499: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-25 09:40:52.488717: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-25 09:40:52.525659: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 09:40:52.750373: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 09:40:55.908 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA2.ipynb
[I 09:42:12.258 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
[I 09:42:55.985 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA2.ipynb
[I 09:43:46.530 LabApp] Starting buffering for 0120207d-d5dc-4388-b6a9-1756f0b374b7:50d5768e074d49ba93ddd24648fbdf8c
[I 09:43:49.562 LabApp] Kernel restarted: 0120207d-d5dc-4388-b6a9-1756f0b374b7
[I 09:43:53.118 LabApp] Adapting from protocol version 5.1 (kernel 0120207d-d5dc-4388-b6a9-1756f0b374b7) to 5.3 (client).
[I 09:43:53.119 LabApp] Restoring connection for 0120207d-d5dc-4388-b6a9-1756f0b374b7:50d5768e074d49ba93ddd24648fbdf8c
[I 09:43:53.119 LabApp] Replaying 6 buffered messages
2019-10-25 09:44:08.358130: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-25 09:44:09.050518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-25 09:44:09.059610: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 09:44:09.061806: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 09:44:09.063452: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 09:44:09.072072: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 09:44:09.074152: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 09:44:09.076041: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 09:44:09.080038: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 09:44:09.084477: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 09:44:09.351556: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d2710f3700 executing computations on platform CUDA. Devices:
2019-10-25 09:44:09.351621: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-25 09:44:09.355138: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-25 09:44:09.356683: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d2711ca170 executing computations on platform Host. Devices:
2019-10-25 09:44:09.356715: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-25 09:44:09.357865: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-25 09:44:09.357944: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 09:44:09.357985: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 09:44:09.358022: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 09:44:09.358060: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 09:44:09.358097: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 09:44:09.358135: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 09:44:09.358174: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 09:44:09.360003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 09:44:09.360068: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 09:44:09.362251: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-25 09:44:09.362272: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-25 09:44:09.362283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-25 09:44:09.364486: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
[I 09:44:12.385 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
2019-10-25 09:44:16.151162: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-25 09:44:16.196130: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 09:44:16.459961: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 09:44:55.980 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA2.ipynb
[I 09:46:12.071 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
[I 09:46:56.101 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA2.ipynb
[I 09:48:11.838 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
[I 09:48:56.149 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA2.ipynb
[I 09:50:12.267 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
[I 09:50:56.169 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA2.ipynb
[I 09:50:58.419 LabApp] Kernel interrupted: 4fc82f8c-c0b7-436a-aa4a-b0f06a645448
[I 09:51:03.438 LabApp] Copying avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA2.ipynb to /avgn_paper/notebooks/6.0-neural-networks
[I 09:51:06.041 LabApp] Kernel started: b8fca378-ada2-4f42-90db-abdd3770459b
[W 09:51:06.089 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 2.98ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA2-Copy1.ipynb
[I 09:51:08.259 LabApp] Starting buffering for 4fc82f8c-c0b7-436a-aa4a-b0f06a645448:883498b9d537425e9791b6e9a48aff81
[I 09:51:10.988 LabApp] Kernel shutdown: 4fc82f8c-c0b7-436a-aa4a-b0f06a645448
[I 09:51:10.993 LabApp] Adapting from protocol version 5.1 (kernel b8fca378-ada2-4f42-90db-abdd3770459b) to 5.3 (client).
[I 09:51:26.836 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA2-Copy1.ipynb
[I 09:51:36.683 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA2-Copy1.ipynb
[I 09:51:40.388 LabApp] Starting buffering for b8fca378-ada2-4f42-90db-abdd3770459b:07ac4ea6cb4f4a09885b5b052c1e97d5
[I 09:51:40.877 LabApp] Kernel restarted: b8fca378-ada2-4f42-90db-abdd3770459b
[I 09:51:43.360 LabApp] Adapting from protocol version 5.1 (kernel b8fca378-ada2-4f42-90db-abdd3770459b) to 5.3 (client).
[I 09:51:43.360 LabApp] Restoring connection for b8fca378-ada2-4f42-90db-abdd3770459b:07ac4ea6cb4f4a09885b5b052c1e97d5
[I 09:51:43.361 LabApp] Replaying 6 buffered messages
[I 09:51:47.195 LabApp] Kernel interrupted: b8fca378-ada2-4f42-90db-abdd3770459b
[I 09:51:56.224 LabApp] Starting buffering for b8fca378-ada2-4f42-90db-abdd3770459b:07ac4ea6cb4f4a09885b5b052c1e97d5
[I 09:51:56.798 LabApp] Kernel restarted: b8fca378-ada2-4f42-90db-abdd3770459b
[I 09:51:59.124 LabApp] Adapting from protocol version 5.1 (kernel b8fca378-ada2-4f42-90db-abdd3770459b) to 5.3 (client).
[I 09:51:59.125 LabApp] Restoring connection for b8fca378-ada2-4f42-90db-abdd3770459b:07ac4ea6cb4f4a09885b5b052c1e97d5
[I 09:51:59.125 LabApp] Replaying 6 buffered messages
[I 09:52:03.028 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.ipynb
[I 09:52:12.305 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
2019-10-25 09:52:14.223793: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-25 09:52:14.785680: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-25 09:52:14.799459: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 09:52:14.801778: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 09:52:14.803413: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 09:52:14.811334: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 09:52:14.813433: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 09:52:14.815201: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 09:52:14.819088: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 09:52:14.821124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 09:52:15.036867: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e7edea2ed0 executing computations on platform CUDA. Devices:
2019-10-25 09:52:15.036921: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-25 09:52:15.040602: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-25 09:52:15.042362: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e7edf79960 executing computations on platform Host. Devices:
2019-10-25 09:52:15.042401: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-25 09:52:15.043416: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-25 09:52:15.043507: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 09:52:15.043548: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 09:52:15.043586: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 09:52:15.043623: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 09:52:15.043661: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 09:52:15.043699: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 09:52:15.043738: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 09:52:15.045584: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 09:52:15.045653: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 09:52:15.047761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-25 09:52:15.047783: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-25 09:52:15.047794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-25 09:52:15.049946: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-25 09:52:20.879486: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-25 09:52:20.917136: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 09:52:21.141974: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 09:52:56.268 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA2.ipynb
[I 09:53:03.205 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.ipynb
[I 09:53:09.099 LabApp] Kernel interrupted: b8fca378-ada2-4f42-90db-abdd3770459b
[I 09:53:24.133 LabApp] Starting buffering for b8fca378-ada2-4f42-90db-abdd3770459b:07ac4ea6cb4f4a09885b5b052c1e97d5
[I 09:53:26.684 LabApp] Kernel restarted: b8fca378-ada2-4f42-90db-abdd3770459b
[I 09:53:29.520 LabApp] Adapting from protocol version 5.1 (kernel b8fca378-ada2-4f42-90db-abdd3770459b) to 5.3 (client).
[I 09:53:29.521 LabApp] Restoring connection for b8fca378-ada2-4f42-90db-abdd3770459b:07ac4ea6cb4f4a09885b5b052c1e97d5
[I 09:53:29.521 LabApp] Replaying 7 buffered messages
[I 09:53:35.502 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 09:53:39.382 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
2019-10-25 09:53:42.619746: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
[I 09:53:43.087 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA.ipynb
2019-10-25 09:53:43.181553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-25 09:53:43.182851: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 09:53:43.185062: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 09:53:43.186599: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 09:53:43.187619: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 09:53:43.189695: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 09:53:43.191474: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 09:53:43.195312: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 09:53:43.212548: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 09:53:43.466696: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556dc6037cc0 executing computations on platform CUDA. Devices:
2019-10-25 09:53:43.466744: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-25 09:53:43.470918: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-25 09:53:43.472613: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556dc610e720 executing computations on platform Host. Devices:
2019-10-25 09:53:43.472653: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-25 09:53:43.474006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-25 09:53:43.474106: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 09:53:43.474156: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 09:53:43.474203: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 09:53:43.474250: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 09:53:43.474297: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 09:53:43.474344: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 09:53:43.474392: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 09:53:43.476448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 09:53:43.476539: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 09:53:43.479066: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-25 09:53:43.479091: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-25 09:53:43.479114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-25 09:53:43.481562: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-25 09:53:50.178062: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-25 09:53:50.221830: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 09:53:50.475972: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 09:54:56.289 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA2.ipynb
[I 09:55:05.987 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.ipynb
[I 09:57:06.902 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.ipynb
[I 09:57:41.451 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.ipynb
[I 09:58:56.302 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA2.ipynb
[I 09:59:06.423 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.ipynb
[W 10:02:29.522 LabApp] WebSocket ping timeout after 119964 ms.
[W 10:02:29.606 LabApp] zmq message arrived on closed channel
[W 10:02:29.608 LabApp] zmq message arrived on closed channel
[W 10:02:29.862 LabApp] zmq message arrived on closed channel
[W 10:02:29.863 LabApp] zmq message arrived on closed channel
[W 10:02:30.123 LabApp] zmq message arrived on closed channel
[W 10:02:30.123 LabApp] zmq message arrived on closed channel
[W 10:02:30.383 LabApp] zmq message arrived on closed channel
[W 10:02:30.385 LabApp] zmq message arrived on closed channel
[W 10:02:30.646 LabApp] zmq message arrived on closed channel
[W 10:02:30.647 LabApp] zmq message arrived on closed channel
[W 10:02:30.898 LabApp] zmq message arrived on closed channel
[W 10:02:30.899 LabApp] zmq message arrived on closed channel
[W 10:02:31.153 LabApp] zmq message arrived on closed channel
[W 10:02:31.154 LabApp] zmq message arrived on closed channel
[W 10:02:31.410 LabApp] zmq message arrived on closed channel
[W 10:02:31.411 LabApp] zmq message arrived on closed channel
[W 10:02:31.665 LabApp] zmq message arrived on closed channel
[W 10:02:31.666 LabApp] zmq message arrived on closed channel
[W 10:02:31.919 LabApp] zmq message arrived on closed channel
[W 10:02:31.920 LabApp] zmq message arrived on closed channel
[W 10:02:32.181 LabApp] zmq message arrived on closed channel
[W 10:02:32.182 LabApp] zmq message arrived on closed channel
[W 10:02:32.440 LabApp] zmq message arrived on closed channel
[W 10:02:32.441 LabApp] zmq message arrived on closed channel
[W 10:02:32.703 LabApp] zmq message arrived on closed channel
[W 10:02:32.705 LabApp] zmq message arrived on closed channel
[W 10:02:32.965 LabApp] zmq message arrived on closed channel
[W 10:02:32.966 LabApp] zmq message arrived on closed channel
[W 10:02:33.233 LabApp] zmq message arrived on closed channel
[W 10:02:33.233 LabApp] zmq message arrived on closed channel
[W 10:02:33.495 LabApp] zmq message arrived on closed channel
[W 10:02:33.496 LabApp] zmq message arrived on closed channel
[W 10:02:33.765 LabApp] zmq message arrived on closed channel
[W 10:02:33.766 LabApp] zmq message arrived on closed channel
[W 10:02:34.041 LabApp] zmq message arrived on closed channel
[W 10:02:34.043 LabApp] zmq message arrived on closed channel
[W 10:02:34.313 LabApp] zmq message arrived on closed channel
[W 10:02:34.314 LabApp] zmq message arrived on closed channel
[I 10:02:34.525 LabApp] Starting buffering for b8fca378-ada2-4f42-90db-abdd3770459b:07ac4ea6cb4f4a09885b5b052c1e97d5
[W 10:02:36.213 LabApp] WebSocket ping timeout after 119977 ms.
[W 10:02:39.078 LabApp] WebSocket ping timeout after 119980 ms.
[I 10:02:40.641 LabApp] Starting buffering for c4a93869-fff9-4616-b073-1014f8e4cd13:a3d51229a10d43a8980e387ffcdb176f
[I 10:02:40.641 LabApp] Starting buffering for 0120207d-d5dc-4388-b6a9-1756f0b374b7:50d5768e074d49ba93ddd24648fbdf8c
[I 10:02:40.641 LabApp] Starting buffering for 1c23d551-7d11-4d02-ac6c-999284268760:ded3610e09c94dc985d01d40f70073dc
[I 10:02:40.643 LabApp] Starting buffering for d9916fc0-f379-41c3-acdb-22feac30f803:2c23f5cfecfc44feaa109e849ba63311
[I 10:02:40.643 LabApp] Starting buffering for 68fe739f-0fae-442f-860e-d943da609e51:b02f1c1780c8406785dc66b0ffa544f6
[I 10:02:40.643 LabApp] Starting buffering for 254383e0-ee3a-4f13-8f5c-605ef4fefd29:0b75ce0926b8496c84aceb4f24ffb5b6
[I 10:02:40.644 LabApp] Starting buffering for 1298b219-7c76-481f-9908-3b312eaef93f:e9d516f66aa54f1dbb6458bc0e9a0623
[I 10:02:40.644 LabApp] Starting buffering for 11777ca9-05bd-4ea4-bc65-bd1bf70a0360:07552191011d4f5a8da9f495dae8b7a8
[I 12:40:40.170 LabApp] Adapting from protocol version 5.1 (kernel b8fca378-ada2-4f42-90db-abdd3770459b) to 5.3 (client).
[I 12:40:40.171 LabApp] Restoring connection for b8fca378-ada2-4f42-90db-abdd3770459b:07ac4ea6cb4f4a09885b5b052c1e97d5
[I 12:40:40.171 LabApp] Replaying 71961 buffered messages
[W 12:40:42.137 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 12:40:43.587 LabApp] iopub messages resumed
[W 12:40:45.586 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 12:40:47.007 LabApp] iopub messages resumed
[W 12:40:49.441 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 12:40:50.875 LabApp] iopub messages resumed
[W 12:40:52.652 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 12:40:54.250 LabApp] iopub messages resumed
[W 12:40:56.075 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 12:40:57.598 LabApp] iopub messages resumed
[W 12:40:59.502 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 12:41:00.976 LabApp] iopub messages resumed
[W 12:41:02.901 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 12:41:04.362 LabApp] iopub messages resumed
[W 12:41:06.353 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 12:41:07.748 LabApp] iopub messages resumed
[W 12:41:10.320 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 12:41:11.173 LabApp] iopub messages resumed
[W 12:41:11.756 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 12:41:12.310 LabApp] iopub messages resumed
[W 12:41:13.718 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 12:41:14.569 LabApp] iopub messages resumed
[W 12:41:15.132 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 12:41:15.689 LabApp] iopub messages resumed
[W 12:41:17.158 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 12:41:17.953 LabApp] iopub messages resumed
[W 12:41:18.523 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 12:41:19.087 LabApp] iopub messages resumed
[W 12:41:20.479 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 12:41:21.352 LabApp] iopub messages resumed
[I 12:41:33.888 LabApp] Kernel interrupted: b8fca378-ada2-4f42-90db-abdd3770459b
[I 12:41:38.414 LabApp] Kernel interrupted: b8fca378-ada2-4f42-90db-abdd3770459b
[I 12:42:27.595 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA2.ipynb
[I 12:42:37.619 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.ipynb
[I 12:42:39.937 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.ipynb
[I 12:43:10.223 LabApp] Starting buffering for b8fca378-ada2-4f42-90db-abdd3770459b:07ac4ea6cb4f4a09885b5b052c1e97d5
[I 12:43:13.539 LabApp] Kernel restarted: b8fca378-ada2-4f42-90db-abdd3770459b
[I 12:43:19.609 LabApp] Adapting from protocol version 5.1 (kernel b8fca378-ada2-4f42-90db-abdd3770459b) to 5.3 (client).
[I 12:43:19.610 LabApp] Restoring connection for b8fca378-ada2-4f42-90db-abdd3770459b:07ac4ea6cb4f4a09885b5b052c1e97d5
[I 12:43:19.610 LabApp] Replaying 8 buffered messages
[I 12:43:29.523 LabApp] Adapting from protocol version 5.1 (kernel 0120207d-d5dc-4388-b6a9-1756f0b374b7) to 5.3 (client).
[I 12:43:29.523 LabApp] Restoring connection for 0120207d-d5dc-4388-b6a9-1756f0b374b7:50d5768e074d49ba93ddd24648fbdf8c
[I 12:43:29.524 LabApp] Replaying 80919 buffered messages
[W 12:43:31.324 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 12:43:32.875 LabApp] iopub messages resumed
2019-10-25 12:43:33.661377: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-25 12:43:34.183230: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-25 12:43:34.184338: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 12:43:34.186253: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 12:43:34.187706: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 12:43:34.193580: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 12:43:34.195505: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 12:43:34.197092: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 12:43:34.200601: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 12:43:34.202428: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 12:43:34.408573: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f8d7982f50 executing computations on platform CUDA. Devices:
2019-10-25 12:43:34.408671: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-25 12:43:34.418221: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-25 12:43:34.419624: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f8d7a599d0 executing computations on platform Host. Devices:
2019-10-25 12:43:34.419675: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-25 12:43:34.421026: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-25 12:43:34.421144: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 12:43:34.421207: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 12:43:34.421259: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 12:43:34.421310: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 12:43:34.421361: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 12:43:34.421413: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 12:43:34.421467: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 12:43:34.424360: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 12:43:34.424447: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 12:43:34.427070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-25 12:43:34.427096: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-25 12:43:34.427125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-25 12:43:34.429577: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
[W 12:43:34.614 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 12:43:36.212 LabApp] iopub messages resumed
[W 12:43:37.921 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 12:43:39.559 LabApp] iopub messages resumed
2019-10-25 12:43:39.990167: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-25 12:43:40.032229: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 12:43:40.252766: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[W 12:43:41.313 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 12:43:42.922 LabApp] iopub messages resumed
[W 12:43:45.047 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 12:43:46.692 LabApp] iopub messages resumed
[W 12:43:48.418 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 12:43:50.038 LabApp] iopub messages resumed
[W 12:43:51.756 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 12:43:53.388 LabApp] iopub messages resumed
[W 12:43:55.108 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 12:43:56.730 LabApp] iopub messages resumed
[W 12:43:58.504 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 12:44:00.096 LabApp] iopub messages resumed
[W 12:44:02.396 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 12:44:03.465 LabApp] iopub messages resumed
[W 12:44:05.129 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 12:44:06.699 LabApp] iopub messages resumed
[W 12:44:08.487 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 12:44:10.046 LabApp] iopub messages resumed
[I 12:44:19.981 LabApp] Kernel interrupted: 0120207d-d5dc-4388-b6a9-1756f0b374b7
[I 12:44:27.709 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA2.ipynb
[I 12:44:37.331 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.ipynb
[I 12:46:10.692 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.ipynb
[I 12:46:19.956 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.ipynb
[I 12:48:07.718 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.ipynb
[I 12:48:07.956 LabApp] Copying avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.ipynb to /avgn_paper/notebooks/6.0-neural-networks
[I 12:48:11.350 LabApp] Kernel started: e39dead4-688b-49f3-857a-813763382e79
[W 12:48:11.397 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 2.03ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3-Copy1.ipynb
[W 12:48:12.547 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 1.81ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3-Copy1.ipynb
[I 12:48:14.072 LabApp] Adapting from protocol version 5.1 (kernel e39dead4-688b-49f3-857a-813763382e79) to 5.3 (client).
[I 12:48:16.184 LabApp] Starting buffering for 0120207d-d5dc-4388-b6a9-1756f0b374b7:50d5768e074d49ba93ddd24648fbdf8c
[I 12:48:19.030 LabApp] Kernel shutdown: 0120207d-d5dc-4388-b6a9-1756f0b374b7
[I 12:50:11.532 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3-Copy1.ipynb
[I 12:50:37.570 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.ipynb
[I 12:52:37.491 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.ipynb
[I 12:53:41.676 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.1.ipynb
[I 12:53:49.452 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.1.ipynb
[I 12:53:50.910 LabApp] Starting buffering for e39dead4-688b-49f3-857a-813763382e79:dd4f04dcddc5478287a5039c17ee8cdd
[I 12:53:51.665 LabApp] Kernel restarted: e39dead4-688b-49f3-857a-813763382e79
[I 12:53:57.182 LabApp] Adapting from protocol version 5.1 (kernel e39dead4-688b-49f3-857a-813763382e79) to 5.3 (client).
[I 12:53:57.183 LabApp] Restoring connection for e39dead4-688b-49f3-857a-813763382e79:dd4f04dcddc5478287a5039c17ee8cdd
[I 12:53:57.183 LabApp] Replaying 6 buffered messages
2019-10-25 12:54:08.984062: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-25 12:54:09.499144: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-25 12:54:09.517727: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 12:54:09.519671: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 12:54:09.521216: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 12:54:09.532400: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 12:54:09.534430: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 12:54:09.536212: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 12:54:09.540022: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 12:54:09.546830: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 12:54:09.780013: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5599ddcdedc0 executing computations on platform CUDA. Devices:
2019-10-25 12:54:09.780067: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-25 12:54:09.783248: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-25 12:54:09.784149: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5599dddb5840 executing computations on platform Host. Devices:
2019-10-25 12:54:09.784173: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-25 12:54:09.785250: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-25 12:54:09.785325: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 12:54:09.785365: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 12:54:09.785403: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 12:54:09.785441: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 12:54:09.785480: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 12:54:09.785517: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 12:54:09.785556: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 12:54:09.787381: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 12:54:09.787440: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 12:54:09.789524: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-25 12:54:09.789545: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-25 12:54:09.789556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-25 12:54:09.791676: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
[I 12:54:11.317 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.1.ipynb
2019-10-25 12:54:16.336611: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-25 12:54:16.383574: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 12:54:16.645929: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 12:56:11.257 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.1.ipynb
[I 12:56:37.500 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.ipynb
[I 12:57:36.877 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 12:57:52.650 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 12:57:55.045 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 12:58:03.596 LabApp] Creating new notebook in /avgn_paper/notebooks/6.0-neural-networks
[W 12:58:05.436 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 2.93ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Untitled.ipynb?kernel_name=python3
[I 12:58:05.682 LabApp] Kernel started: e4f39541-c636-4e93-9820-1a4ae1520340
[W 12:58:05.692 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 4.45ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Untitled.ipynb?kernel_name=python3
[I 12:58:08.750 LabApp] Adapting from protocol version 5.1 (kernel e4f39541-c636-4e93-9820-1a4ae1520340) to 5.3 (client).
[I 12:58:11.377 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.1.ipynb
[I 12:58:13.872 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 12:58:17.443 LabApp] Starting buffering for e4f39541-c636-4e93-9820-1a4ae1520340:98fb7f0da09145ed8c6fe2c7d020decf
[I 12:58:17.913 LabApp] Kernel restarted: e4f39541-c636-4e93-9820-1a4ae1520340
[I 12:58:20.036 LabApp] Adapting from protocol version 5.1 (kernel e4f39541-c636-4e93-9820-1a4ae1520340) to 5.3 (client).
[I 12:58:20.038 LabApp] Restoring connection for e4f39541-c636-4e93-9820-1a4ae1520340:98fb7f0da09145ed8c6fe2c7d020decf
[I 12:58:20.038 LabApp] Replaying 6 buffered messages
2019-10-25 12:58:31.128060: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-25 12:58:33.833020: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-25 12:58:33.842179: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 12:58:33.843932: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 12:58:33.845360: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 12:58:33.850454: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 12:58:33.852280: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 12:58:33.853823: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 12:58:33.857198: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 12:58:33.862827: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 12:58:34.052395: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5601b598f400 executing computations on platform CUDA. Devices:
2019-10-25 12:58:34.052498: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K40c, Compute Capability 3.5
2019-10-25 12:58:34.057961: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-25 12:58:34.059133: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5601b5a65e60 executing computations on platform Host. Devices:
2019-10-25 12:58:34.059158: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-25 12:58:34.060185: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-25 12:58:34.060270: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 12:58:34.060311: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 12:58:34.060352: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 12:58:34.060391: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 12:58:34.060429: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 12:58:34.060472: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 12:58:34.060530: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 12:58:34.062381: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 12:58:34.062445: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 12:58:34.070037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-25 12:58:34.070059: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-25 12:58:34.070071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-25 12:58:34.072200: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10794 MB memory) -> physical GPU (device: 0, name: Tesla K40c, pci bus id: 0000:03:00.0, compute capability: 3.5)
[I 12:58:37.570 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.ipynb
[I 12:59:22.066 LabApp] Kernel interrupted: e39dead4-688b-49f3-857a-813763382e79
[I 13:00:05.545 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Untitled.ipynb
[I 13:00:11.607 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.1.ipynb
[I 13:00:37.494 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.ipynb
[I 13:02:05.559 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Untitled.ipynb
[I 13:02:11.575 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.1.ipynb
[I 13:02:37.603 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.ipynb
[I 13:03:11.834 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.1.ipynb
[I 13:03:13.729 LabApp] Kernel interrupted: e39dead4-688b-49f3-857a-813763382e79
[I 13:03:16.960 LabApp] Starting buffering for e39dead4-688b-49f3-857a-813763382e79:dd4f04dcddc5478287a5039c17ee8cdd
[I 13:03:19.560 LabApp] Kernel restarted: e39dead4-688b-49f3-857a-813763382e79
[I 13:03:24.538 LabApp] Adapting from protocol version 5.1 (kernel e39dead4-688b-49f3-857a-813763382e79) to 5.3 (client).
[I 13:03:24.539 LabApp] Restoring connection for e39dead4-688b-49f3-857a-813763382e79:dd4f04dcddc5478287a5039c17ee8cdd
[I 13:03:24.539 LabApp] Replaying 7 buffered messages
[I 13:03:36.513 LabApp] Adapting from protocol version 5.1 (kernel 11777ca9-05bd-4ea4-bc65-bd1bf70a0360) to 5.3 (client).
[I 13:03:36.514 LabApp] Restoring connection for 11777ca9-05bd-4ea4-bc65-bd1bf70a0360:07552191011d4f5a8da9f495dae8b7a8
2019-10-25 13:03:38.188194: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-25 13:03:38.766324: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-25 13:03:38.773913: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 13:03:38.775990: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 13:03:38.777550: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 13:03:38.778464: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 13:03:38.780522: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 13:03:38.782232: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 13:03:38.786049: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 13:03:38.789913: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 13:03:39.034359: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a7141a30f0 executing computations on platform CUDA. Devices:
2019-10-25 13:03:39.034423: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-25 13:03:39.038208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-25 13:03:39.040035: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a714279ba0 executing computations on platform Host. Devices:
2019-10-25 13:03:39.040078: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-25 13:03:39.041277: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-25 13:03:39.041356: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 13:03:39.041396: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 13:03:39.041433: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 13:03:39.041471: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 13:03:39.041508: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 13:03:39.041545: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 13:03:39.041582: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 13:03:39.043397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 13:03:39.043457: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 13:03:39.045564: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-25 13:03:39.045585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-25 13:03:39.045596: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-25 13:03:39.047744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-25 13:03:46.003543: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-25 13:03:46.053899: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 13:03:46.296907: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 13:04:11.392 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.1.ipynb
[I 13:04:37.614 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.ipynb
[I 13:05:09.247 LabApp] Saving file at /avgn_paper/notebooks/7.0-segmentation-examples/bf-segmentation-example.ipynb
[I 13:06:11.604 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.1.ipynb
[I 13:06:37.642 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.ipynb
[I 13:07:11.064 LabApp] Saving file at /avgn_paper/notebooks/7.0-segmentation-examples/bf-segmentation-example.ipynb
[I 13:07:42.192 LabApp] Kernel interrupted: e39dead4-688b-49f3-857a-813763382e79
[I 13:08:11.517 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.1.ipynb
[I 13:08:37.704 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.ipynb
[I 13:09:11.619 LabApp] Saving file at /avgn_paper/notebooks/7.0-segmentation-examples/bf-segmentation-example.ipynb
[I 13:09:24.726 LabApp] Kernel interrupted: b8fca378-ada2-4f42-90db-abdd3770459b
[I 13:09:28.318 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.1.ipynb
[I 13:09:28.692 LabApp] Copying avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.1.ipynb to /avgn_paper/notebooks/6.0-neural-networks
[I 13:09:31.463 LabApp] Kernel started: 7cffdb85-7fdd-4123-8aae-99174ab1c8b9
[W 13:09:31.518 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 2.15ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.1-Copy1.ipynb
[I 13:09:35.684 LabApp] Adapting from protocol version 5.1 (kernel 7cffdb85-7fdd-4123-8aae-99174ab1c8b9) to 5.3 (client).
[I 13:10:11.522 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.1.ipynb
[I 13:10:37.638 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.ipynb
[I 13:11:31.164 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.1-Copy1.ipynb
[I 13:11:31.790 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.1-Copy1.ipynb
[I 13:11:33.155 LabApp] Starting buffering for 7cffdb85-7fdd-4123-8aae-99174ab1c8b9:43203f7e385846428ddb1d2573e04fef
[I 13:11:33.774 LabApp] Kernel restarted: 7cffdb85-7fdd-4123-8aae-99174ab1c8b9
[I 13:11:41.398 LabApp] Adapting from protocol version 5.1 (kernel 7cffdb85-7fdd-4123-8aae-99174ab1c8b9) to 5.3 (client).
[I 13:11:41.400 LabApp] Restoring connection for 7cffdb85-7fdd-4123-8aae-99174ab1c8b9:43203f7e385846428ddb1d2573e04fef
[I 13:11:41.400 LabApp] Replaying 6 buffered messages
2019-10-25 13:11:54.237982: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-25 13:11:54.260289: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-25 13:11:54.261267: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 13:11:54.263259: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 13:11:54.264936: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 13:11:54.266095: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 13:11:54.268276: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 13:11:54.270094: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 13:11:54.274193: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 13:11:54.276558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 13:11:54.534765: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ca07a96bd0 executing computations on platform CUDA. Devices:
2019-10-25 13:11:54.534881: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-25 13:11:54.541582: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-25 13:11:54.544204: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ca07b6d660 executing computations on platform Host. Devices:
2019-10-25 13:11:54.544275: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-25 13:11:54.546008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-25 13:11:54.546148: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 13:11:54.546233: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 13:11:54.546312: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 13:11:54.546391: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 13:11:54.546470: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 13:11:54.546549: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 13:11:54.546634: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 13:11:54.548965: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 13:11:54.549081: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 13:11:54.552265: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-25 13:11:54.552303: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-25 13:11:54.552323: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-25 13:11:54.554778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 206 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-25 13:11:55.684061: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 206.06M (216072192 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2019-10-25 13:11:55.797155: F tensorflow/stream_executor/cuda/cuda_driver.cc:175] Check failed: err == cudaSuccess || err == cudaErrorInvalidValue Unexpected CUDA error: out of memory
[I 13:11:57.775 LabApp] KernelRestarter: restarting kernel (1/5), keep random ports
kernel 7cffdb85-7fdd-4123-8aae-99174ab1c8b9 restarted
[I 13:12:11.612 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.1.ipynb
[I 13:12:44.601 LabApp] Starting buffering for b8fca378-ada2-4f42-90db-abdd3770459b:07ac4ea6cb4f4a09885b5b052c1e97d5
[I 13:12:48.483 LabApp] Kernel shutdown: b8fca378-ada2-4f42-90db-abdd3770459b
[I 13:12:48.486 LabApp] Starting buffering for e39dead4-688b-49f3-857a-813763382e79:dd4f04dcddc5478287a5039c17ee8cdd
[I 13:12:51.495 LabApp] Kernel shutdown: e39dead4-688b-49f3-857a-813763382e79
[I 13:12:54.747 LabApp] Starting buffering for 7cffdb85-7fdd-4123-8aae-99174ab1c8b9:43203f7e385846428ddb1d2573e04fef
[I 13:12:55.340 LabApp] Kernel restarted: 7cffdb85-7fdd-4123-8aae-99174ab1c8b9
[I 13:13:02.467 LabApp] Adapting from protocol version 5.1 (kernel 7cffdb85-7fdd-4123-8aae-99174ab1c8b9) to 5.3 (client).
[I 13:13:02.468 LabApp] Restoring connection for 7cffdb85-7fdd-4123-8aae-99174ab1c8b9:43203f7e385846428ddb1d2573e04fef
[I 13:13:02.468 LabApp] Replaying 6 buffered messages
2019-10-25 13:13:17.177535: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-25 13:13:18.213612: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-25 13:13:18.229961: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 13:13:18.232390: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 13:13:18.234304: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 13:13:18.235420: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 13:13:18.237879: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 13:13:18.239937: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 13:13:18.244665: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 13:13:18.246881: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 13:13:18.501221: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556ed3e421e0 executing computations on platform CUDA. Devices:
2019-10-25 13:13:18.501313: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-25 13:13:18.506791: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-25 13:13:18.508783: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556ed3f18c90 executing computations on platform Host. Devices:
2019-10-25 13:13:18.508837: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-25 13:13:18.510432: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-25 13:13:18.510562: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 13:13:18.510636: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 13:13:18.510704: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 13:13:18.510774: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 13:13:18.510841: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 13:13:18.510909: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 13:13:18.510978: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 13:13:18.513314: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 13:13:18.513416: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 13:13:18.516416: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-25 13:13:18.516449: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-25 13:13:18.516468: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-25 13:13:18.519312: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-25 13:13:26.699487: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-25 13:13:26.740080: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 13:13:27.006974: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 13:13:32.380 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.2.ipynb
[I 13:15:10.872 LabApp] Saving file at /avgn_paper/notebooks/7.0-segmentation-examples/bf-segmentation-example.ipynb
[I 13:15:32.814 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.2.ipynb
[I 13:17:10.536 LabApp] Saving file at /avgn_paper/notebooks/7.0-segmentation-examples/bf-segmentation-example.ipynb
[I 13:17:31.688 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.2.ipynb
[I 13:19:11.080 LabApp] Saving file at /avgn_paper/notebooks/7.0-segmentation-examples/bf-segmentation-example.ipynb
[I 13:19:31.683 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.2.ipynb
[I 13:20:56.548 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.2.ipynb
[I 13:21:05.829 LabApp] Copying avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.2.ipynb to /avgn_paper/notebooks/6.0-neural-networks
[I 13:21:09.511 LabApp] Kernel started: e2d8d2c5-7ca7-4cba-b58d-a6681cac1d41
[W 13:21:09.572 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 2.39ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.2-Copy1.ipynb
[I 13:21:11.830 LabApp] Saving file at /avgn_paper/notebooks/7.0-segmentation-examples/bf-segmentation-example.ipynb
[I 13:21:13.359 LabApp] Adapting from protocol version 5.1 (kernel e2d8d2c5-7ca7-4cba-b58d-a6681cac1d41) to 5.3 (client).
[I 13:21:31.440 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.2.ipynb
[I 13:23:06.424 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.2-Copy1.ipynb
[I 13:23:31.738 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.2.ipynb
[I 13:23:49.916 LabApp] Starting buffering for e2d8d2c5-7ca7-4cba-b58d-a6681cac1d41:d036a0a2545645839e61853d82557fe9
[I 13:23:50.578 LabApp] Kernel restarted: e2d8d2c5-7ca7-4cba-b58d-a6681cac1d41
[I 13:23:56.329 LabApp] Adapting from protocol version 5.1 (kernel e2d8d2c5-7ca7-4cba-b58d-a6681cac1d41) to 5.3 (client).
[I 13:23:56.330 LabApp] Restoring connection for e2d8d2c5-7ca7-4cba-b58d-a6681cac1d41:d036a0a2545645839e61853d82557fe9
[I 13:23:56.330 LabApp] Replaying 6 buffered messages
2019-10-25 13:24:07.892221: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-25 13:24:08.375923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-25 13:24:08.394011: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 13:24:08.395965: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 13:24:08.397410: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 13:24:08.406526: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 13:24:08.408486: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 13:24:08.410094: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 13:24:08.413607: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 13:24:08.415544: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 13:24:08.612158: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f289d7d600 executing computations on platform CUDA. Devices:
2019-10-25 13:24:08.612215: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-25 13:24:08.615658: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-25 13:24:08.616586: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f289e540e0 executing computations on platform Host. Devices:
2019-10-25 13:24:08.616617: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-25 13:24:08.617648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-25 13:24:08.617729: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 13:24:08.617769: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 13:24:08.617806: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 13:24:08.617842: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 13:24:08.617879: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 13:24:08.617916: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 13:24:08.617953: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 13:24:08.619726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 13:24:08.619788: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 13:24:08.621901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-25 13:24:08.621922: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-25 13:24:08.621933: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-25 13:24:08.624008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-25 13:24:15.161465: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-25 13:24:15.210843: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 13:24:15.441756: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 13:25:09.478 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.3.ipynb
[I 13:25:31.732 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.2.ipynb
[I 13:25:53.416 LabApp] Kernel interrupted: e2d8d2c5-7ca7-4cba-b58d-a6681cac1d41
[I 13:27:09.454 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.3.ipynb
[I 13:27:32.663 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.2.ipynb
[I 13:29:32.595 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.2.ipynb
[I 13:31:32.594 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.2.ipynb
[I 13:33:09.455 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.3.ipynb
[I 13:33:32.594 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.2.ipynb
[I 13:35:31.630 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.2.ipynb
[I 13:36:36.951 LabApp] Kernel interrupted: e2d8d2c5-7ca7-4cba-b58d-a6681cac1d41
[I 13:36:44.709 LabApp] Starting buffering for e2d8d2c5-7ca7-4cba-b58d-a6681cac1d41:d036a0a2545645839e61853d82557fe9
[I 13:36:47.647 LabApp] Kernel restarted: e2d8d2c5-7ca7-4cba-b58d-a6681cac1d41
[I 13:36:55.857 LabApp] Adapting from protocol version 5.1 (kernel e2d8d2c5-7ca7-4cba-b58d-a6681cac1d41) to 5.3 (client).
[I 13:36:55.858 LabApp] Restoring connection for e2d8d2c5-7ca7-4cba-b58d-a6681cac1d41:d036a0a2545645839e61853d82557fe9
[I 13:36:55.858 LabApp] Replaying 7 buffered messages
2019-10-25 13:37:09.161348: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
[I 13:37:09.312 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.3.ipynb
2019-10-25 13:37:09.714716: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-25 13:37:09.724621: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 13:37:09.726939: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 13:37:09.728590: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 13:37:09.729535: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 13:37:09.731677: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 13:37:09.733416: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 13:37:09.737456: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 13:37:09.739537: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 13:37:09.991448: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563969643580 executing computations on platform CUDA. Devices:
2019-10-25 13:37:09.991510: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-25 13:37:09.995614: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-25 13:37:09.997188: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56396971a020 executing computations on platform Host. Devices:
2019-10-25 13:37:09.997219: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-25 13:37:10.002424: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-25 13:37:10.002525: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 13:37:10.002585: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 13:37:10.002626: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 13:37:10.002666: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 13:37:10.002706: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 13:37:10.002746: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 13:37:10.002786: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 13:37:10.004704: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 13:37:10.004775: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 13:37:10.007020: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-25 13:37:10.007043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-25 13:37:10.007055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-25 13:37:10.009373: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-25 13:37:16.917101: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-25 13:37:16.969390: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 13:37:17.212521: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 13:37:31.638 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.2.ipynb
[I 13:37:53.422 LabApp] Kernel interrupted: e2d8d2c5-7ca7-4cba-b58d-a6681cac1d41
[I 13:38:07.807 LabApp] Kernel interrupted: 7cffdb85-7fdd-4123-8aae-99174ab1c8b9
[I 13:38:34.602 LabApp] Kernel interrupted: e2d8d2c5-7ca7-4cba-b58d-a6681cac1d41
[I 13:39:08.410 LabApp] Starting buffering for e2d8d2c5-7ca7-4cba-b58d-a6681cac1d41:d036a0a2545645839e61853d82557fe9
[I 13:39:10.985 LabApp] Kernel restarted: e2d8d2c5-7ca7-4cba-b58d-a6681cac1d41
[I 13:39:11.175 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.3.ipynb
[I 13:39:17.658 LabApp] Adapting from protocol version 5.1 (kernel e2d8d2c5-7ca7-4cba-b58d-a6681cac1d41) to 5.3 (client).
[I 13:39:17.659 LabApp] Restoring connection for e2d8d2c5-7ca7-4cba-b58d-a6681cac1d41:d036a0a2545645839e61853d82557fe9
[I 13:39:17.659 LabApp] Replaying 6 buffered messages
2019-10-25 13:39:30.188595: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-25 13:39:30.770128: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-25 13:39:30.774049: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 13:39:30.776149: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 13:39:30.777774: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 13:39:30.802023: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 13:39:30.804165: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 13:39:30.805845: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 13:39:30.809651: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 13:39:30.811859: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 13:39:31.094103: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55569d9b6540 executing computations on platform CUDA. Devices:
2019-10-25 13:39:31.094210: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-25 13:39:31.100015: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-25 13:39:31.101739: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55569da8cfd0 executing computations on platform Host. Devices:
2019-10-25 13:39:31.101793: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-25 13:39:31.103441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-25 13:39:31.103590: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 13:39:31.103666: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 13:39:31.103736: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 13:39:31.103805: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 13:39:31.103874: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 13:39:31.103943: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 13:39:31.104013: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 13:39:31.106838: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 13:39:31.106951: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 13:39:31.110131: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-25 13:39:31.110168: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-25 13:39:31.110186: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-25 13:39:31.113351: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
[I 13:39:31.756 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.2.ipynb
2019-10-25 13:39:37.728424: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-25 13:39:37.771388: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 13:39:38.000885: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 13:41:08.300 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.3.ipynb
[I 13:43:09.595 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.3.ipynb
[I 13:43:31.700 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.2.ipynb
[I 13:43:47.545 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.3.ipynb
[I 13:43:47.997 LabApp] Copying avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.3.ipynb to /avgn_paper/notebooks/6.0-neural-networks
[I 13:43:50.544 LabApp] Kernel started: b6811db2-2831-444b-823c-785f07a7fbfd
[W 13:43:50.592 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.76ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.3-Copy1.ipynb
[I 13:43:54.189 LabApp] Starting buffering for 7cffdb85-7fdd-4123-8aae-99174ab1c8b9:43203f7e385846428ddb1d2573e04fef
[I 13:43:57.224 LabApp] Kernel shutdown: 7cffdb85-7fdd-4123-8aae-99174ab1c8b9
[I 13:43:57.252 LabApp] Adapting from protocol version 5.1 (kernel b6811db2-2831-444b-823c-785f07a7fbfd) to 5.3 (client).
[I 13:44:57.162 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA4.ipynb
[I 13:45:01.981 LabApp] Starting buffering for b6811db2-2831-444b-823c-785f07a7fbfd:dc5fb0a9867445adaa4a9da4c85dd120
[I 13:45:02.737 LabApp] Kernel restarted: b6811db2-2831-444b-823c-785f07a7fbfd
[I 13:45:09.697 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.3.ipynb
[I 13:45:10.192 LabApp] Adapting from protocol version 5.1 (kernel b6811db2-2831-444b-823c-785f07a7fbfd) to 5.3 (client).
[I 13:45:10.193 LabApp] Restoring connection for b6811db2-2831-444b-823c-785f07a7fbfd:dc5fb0a9867445adaa4a9da4c85dd120
[I 13:45:10.193 LabApp] Replaying 6 buffered messages
2019-10-25 13:45:22.185169: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-25 13:45:25.119468: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-25 13:45:25.139778: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 13:45:25.143386: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 13:45:25.145650: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 13:45:25.166824: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 13:45:25.169570: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 13:45:25.171892: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 13:45:25.177022: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 13:45:25.190096: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 13:45:25.420674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a7e6f5baa0 executing computations on platform CUDA. Devices:
2019-10-25 13:45:25.420752: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-25 13:45:25.426082: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-25 13:45:25.428316: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a7e7032530 executing computations on platform Host. Devices:
2019-10-25 13:45:25.428362: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-25 13:45:25.430003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-25 13:45:25.430138: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 13:45:25.430222: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 13:45:25.430302: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 13:45:25.430380: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 13:45:25.430458: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 13:45:25.430537: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 13:45:25.430617: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 13:45:25.433650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 13:45:25.433789: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 13:45:25.436584: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-25 13:45:25.436606: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-25 13:45:25.436617: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-25 13:45:25.438637: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-25 13:45:32.102642: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-25 13:45:32.144635: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 13:45:32.360475: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 13:45:50.433 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA4.ipynb
[I 13:47:09.681 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.3.ipynb
[I 13:47:50.614 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA4.ipynb
[I 13:48:38.122 LabApp] Kernel interrupted: b6811db2-2831-444b-823c-785f07a7fbfd
[I 13:48:40.895 LabApp] Starting buffering for b6811db2-2831-444b-823c-785f07a7fbfd:dc5fb0a9867445adaa4a9da4c85dd120
[I 13:48:46.898 LabApp] Kernel restarted: b6811db2-2831-444b-823c-785f07a7fbfd
[I 13:48:53.422 LabApp] Adapting from protocol version 5.1 (kernel b6811db2-2831-444b-823c-785f07a7fbfd) to 5.3 (client).
[I 13:48:53.424 LabApp] Restoring connection for b6811db2-2831-444b-823c-785f07a7fbfd:dc5fb0a9867445adaa4a9da4c85dd120
[I 13:48:53.424 LabApp] Replaying 90 buffered messages
2019-10-25 13:49:05.499392: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-25 13:49:08.605954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-25 13:49:08.630028: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 13:49:08.632084: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 13:49:08.633601: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 13:49:08.648715: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 13:49:08.650713: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 13:49:08.652399: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 13:49:08.656144: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 13:49:08.657973: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 13:49:08.879482: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561f44e1a540 executing computations on platform CUDA. Devices:
2019-10-25 13:49:08.879557: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-25 13:49:08.884070: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-25 13:49:08.885049: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561f44ef0fd0 executing computations on platform Host. Devices:
2019-10-25 13:49:08.885077: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-25 13:49:08.886012: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-25 13:49:08.886100: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 13:49:08.886145: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 13:49:08.886186: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 13:49:08.886228: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 13:49:08.886270: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 13:49:08.886312: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 13:49:08.886355: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 13:49:08.888462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 13:49:08.888569: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 13:49:08.891803: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-25 13:49:08.891849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-25 13:49:08.891872: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-25 13:49:08.895461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
[I 13:49:09.370 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.3.ipynb
2019-10-25 13:49:15.497114: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-25 13:49:15.537569: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 13:49:15.774589: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 13:49:50.583 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA4.ipynb
[I 13:51:09.645 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.3.ipynb
[I 13:51:50.362 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA4.ipynb
[I 13:53:09.658 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.3.ipynb
[I 13:53:31.587 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA4.ipynb
[I 13:53:31.819 LabApp] Copying avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA4.ipynb to /avgn_paper/notebooks/6.0-neural-networks
[W 13:53:33.324 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 1.85ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA4-Copy1.ipynb
[I 13:53:34.198 LabApp] Kernel started: 51463314-8cca-433e-b358-f12c09c7c165
[W 13:53:34.212 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 5.74ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA4-Copy1.ipynb
[I 13:53:38.435 LabApp] Adapting from protocol version 5.1 (kernel 51463314-8cca-433e-b358-f12c09c7c165) to 5.3 (client).
[I 13:53:39.686 LabApp] Starting buffering for e2d8d2c5-7ca7-4cba-b58d-a6681cac1d41:d036a0a2545645839e61853d82557fe9
[I 13:53:45.357 LabApp] Kernel shutdown: e2d8d2c5-7ca7-4cba-b58d-a6681cac1d41
[I 13:53:50.428 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA4.ipynb
[I 13:54:26.014 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA4-Copy1.ipynb
[I 13:54:34.179 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 13:54:36.339 LabApp] Starting buffering for 51463314-8cca-433e-b358-f12c09c7c165:4b33e997f6f346ad8a9485d4574ca938
[I 13:54:36.791 LabApp] Kernel restarted: 51463314-8cca-433e-b358-f12c09c7c165
[I 13:54:42.453 LabApp] Adapting from protocol version 5.1 (kernel 51463314-8cca-433e-b358-f12c09c7c165) to 5.3 (client).
[I 13:54:42.455 LabApp] Restoring connection for 51463314-8cca-433e-b358-f12c09c7c165:4b33e997f6f346ad8a9485d4574ca938
[I 13:54:42.455 LabApp] Replaying 6 buffered messages
2019-10-25 13:54:54.240394: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-25 13:54:54.747112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-25 13:54:54.762037: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 13:54:54.764539: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 13:54:54.766395: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 13:54:54.780240: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 13:54:54.782545: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 13:54:54.784482: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 13:54:54.788645: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 13:54:54.790561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 13:54:55.008927: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564f0e703c60 executing computations on platform CUDA. Devices:
2019-10-25 13:54:55.008997: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-25 13:54:55.012760: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-25 13:54:55.013925: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564f0e7da6e0 executing computations on platform Host. Devices:
2019-10-25 13:54:55.013954: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-25 13:54:55.015016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-25 13:54:55.015113: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 13:54:55.015157: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 13:54:55.015195: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 13:54:55.015233: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 13:54:55.015271: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 13:54:55.015308: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 13:54:55.015348: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 13:54:55.017116: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 13:54:55.017181: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 13:54:55.019416: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-25 13:54:55.019465: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-25 13:54:55.019478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-25 13:54:55.021647: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-25 13:55:01.575305: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-25 13:55:01.621608: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 13:55:01.854819: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 13:55:09.702 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.3.ipynb
[I 13:55:34.079 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 13:55:50.432 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA4.ipynb
[I 13:55:53.404 LabApp] Kernel interrupted: 51463314-8cca-433e-b358-f12c09c7c165
[I 13:56:00.123 LabApp] Starting buffering for 51463314-8cca-433e-b358-f12c09c7c165:4b33e997f6f346ad8a9485d4574ca938
[I 13:56:02.507 LabApp] Kernel restarted: 51463314-8cca-433e-b358-f12c09c7c165
[I 13:56:06.854 LabApp] Adapting from protocol version 5.1 (kernel 51463314-8cca-433e-b358-f12c09c7c165) to 5.3 (client).
[I 13:56:06.855 LabApp] Restoring connection for 51463314-8cca-433e-b358-f12c09c7c165:4b33e997f6f346ad8a9485d4574ca938
[I 13:56:06.855 LabApp] Replaying 6 buffered messages
2019-10-25 13:56:16.709991: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-25 13:56:17.184180: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-25 13:56:17.185271: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 13:56:17.187149: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 13:56:17.188518: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 13:56:17.189378: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 13:56:17.191188: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 13:56:17.192707: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 13:56:17.196083: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 13:56:17.197859: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 13:56:17.380097: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55cdca09faf0 executing computations on platform CUDA. Devices:
2019-10-25 13:56:17.380158: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-25 13:56:17.383674: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-25 13:56:17.384781: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55cdca176580 executing computations on platform Host. Devices:
2019-10-25 13:56:17.384810: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-25 13:56:17.385800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-25 13:56:17.385889: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 13:56:17.385930: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 13:56:17.385969: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 13:56:17.386008: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 13:56:17.386045: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 13:56:17.386098: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 13:56:17.386138: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 13:56:17.387859: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 13:56:17.387929: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 13:56:17.390027: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-25 13:56:17.390048: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-25 13:56:17.390059: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-25 13:56:17.392201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-25 13:56:23.460334: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-25 13:56:23.502159: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 13:56:23.717998: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 13:57:34.214 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 13:57:50.642 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA4.ipynb
[I 13:59:34.058 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 13:59:50.649 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA4.ipynb
[I 14:01:34.222 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 14:01:50.656 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA4.ipynb
[I 14:02:45.736 LabApp] Kernel interrupted: 51463314-8cca-433e-b358-f12c09c7c165
[I 14:02:48.723 LabApp] Starting buffering for 51463314-8cca-433e-b358-f12c09c7c165:4b33e997f6f346ad8a9485d4574ca938
[I 14:02:54.404 LabApp] Kernel restarted: 51463314-8cca-433e-b358-f12c09c7c165
[I 14:02:58.634 LabApp] Adapting from protocol version 5.1 (kernel 51463314-8cca-433e-b358-f12c09c7c165) to 5.3 (client).
[I 14:02:58.635 LabApp] Restoring connection for 51463314-8cca-433e-b358-f12c09c7c165:4b33e997f6f346ad8a9485d4574ca938
[I 14:02:58.635 LabApp] Replaying 80 buffered messages
2019-10-25 14:03:09.997329: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-25 14:03:10.510029: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-25 14:03:10.518120: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 14:03:10.519933: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 14:03:10.521306: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 14:03:10.527498: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 14:03:10.529290: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 14:03:10.530822: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 14:03:10.534526: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 14:03:10.536368: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 14:03:10.744632: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555a47d343b0 executing computations on platform CUDA. Devices:
2019-10-25 14:03:10.744695: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-25 14:03:10.748346: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-25 14:03:10.749505: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555a47e0ae10 executing computations on platform Host. Devices:
2019-10-25 14:03:10.749534: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-25 14:03:10.750530: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-25 14:03:10.750635: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 14:03:10.750679: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 14:03:10.750720: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 14:03:10.750761: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 14:03:10.750802: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 14:03:10.750844: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 14:03:10.750886: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 14:03:10.755294: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 14:03:10.755366: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 14:03:10.757386: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-25 14:03:10.757407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-25 14:03:10.757418: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-25 14:03:10.760602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
[I 14:03:34.006 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 14:03:50.653 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA4.ipynb
[I 14:05:50.676 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA4.ipynb
[I 14:06:55.106 LabApp] Saving file at /avgn_paper/notebooks/7.0-segmentation-examples/bf-segmentation-example.ipynb
[I 14:07:09.945 LabApp] Saving file at /avgn_paper/notebooks/7.0-segmentation-examples/bf-segmentation-example.ipynb
[I 14:07:34.405 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 14:07:50.732 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA4.ipynb
[I 14:08:33.727 LabApp] Saving file at /avgn_paper/notebooks/7.0-segmentation-examples/bf-segmentation-example.ipynb
[I 14:08:36.311 LabApp] Saving file at /avgn_paper/notebooks/7.0-segmentation-examples/bf-segmentation-example.ipynb
2019-10-25 14:08:55.484778: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-25 14:08:55.526055: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 14:08:55.734272: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 14:09:10.871 LabApp] Saving file at /avgn_paper/notebooks/7.0-segmentation-examples/bf-segmentation-example.ipynb
[I 14:09:35.026 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 14:09:50.449 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA4.ipynb
[I 14:11:12.404 LabApp] Saving file at /avgn_paper/notebooks/7.0-segmentation-examples/bf-segmentation-example.ipynb
[I 14:11:34.727 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 14:11:50.621 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA4.ipynb
[I 14:13:09.429 LabApp] Kernel interrupted: 51463314-8cca-433e-b358-f12c09c7c165
[I 14:13:34.225 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 14:13:48.626 LabApp] Starting buffering for 51463314-8cca-433e-b358-f12c09c7c165:4b33e997f6f346ad8a9485d4574ca938
[I 14:13:51.609 LabApp] Kernel restarted: 51463314-8cca-433e-b358-f12c09c7c165
[I 14:13:51.890 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA4.ipynb
[I 14:13:53.413 LabApp] Kernel interrupted: b6811db2-2831-444b-823c-785f07a7fbfd
[I 14:13:58.102 LabApp] Adapting from protocol version 5.1 (kernel 51463314-8cca-433e-b358-f12c09c7c165) to 5.3 (client).
[I 14:13:58.103 LabApp] Restoring connection for 51463314-8cca-433e-b358-f12c09c7c165:4b33e997f6f346ad8a9485d4574ca938
[I 14:13:58.103 LabApp] Replaying 6 buffered messages
2019-10-25 14:14:08.996790: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-25 14:14:09.507210: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-25 14:14:09.508903: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 14:14:09.512066: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 14:14:09.514647: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 14:14:09.515456: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 14:14:09.519093: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 14:14:09.521496: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 14:14:09.527202: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 14:14:09.529884: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 14:14:09.714939: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562a861329c0 executing computations on platform CUDA. Devices:
2019-10-25 14:14:09.715008: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-25 14:14:09.719495: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-25 14:14:09.720783: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562a86209460 executing computations on platform Host. Devices:
2019-10-25 14:14:09.720812: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-25 14:14:09.721814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-25 14:14:09.721898: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 14:14:09.721937: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 14:14:09.721973: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 14:14:09.722009: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 14:14:09.722046: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 14:14:09.722082: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 14:14:09.722119: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 14:14:09.723931: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 14:14:09.723995: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 14:14:09.726081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-25 14:14:09.726101: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-25 14:14:09.726112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-25 14:14:09.728341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-25 14:14:16.889052: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-25 14:14:16.930624: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 14:14:17.138796: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 14:15:03.960 LabApp] Copying avgn_paper/notebooks/7.0-segmentation-examples/bf-seg-continuousexample.ipynb to /avgn_paper/notebooks/7.0-segmentation-examples
[W 14:15:05.918 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.18ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/7.0-segmentation-examples/bf-seg-continuousexample-Copy1.ipynb
[I 14:15:06.355 LabApp] Kernel started: d849356d-faa3-448d-b20c-12997f49ba94
[I 14:15:07.903 LabApp] Adapting from protocol version 5.1 (kernel d849356d-faa3-448d-b20c-12997f49ba94) to 5.3 (client).
[I 14:15:34.629 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 14:15:50.627 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA4.ipynb
[I 14:17:08.371 LabApp] Saving file at /avgn_paper/notebooks/7.0-segmentation-examples/mose-seg-con-sexample.ipynb
[I 14:17:34.917 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 14:19:13.094 LabApp] Saving file at /avgn_paper/notebooks/7.0-segmentation-examples/mose-seg-con-sexample.ipynb
[I 14:19:34.694 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 14:21:07.398 LabApp] Saving file at /avgn_paper/notebooks/7.0-segmentation-examples/mose-seg-con-sexample.ipynb
[I 14:21:34.636 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 14:23:08.040 LabApp] Saving file at /avgn_paper/notebooks/7.0-segmentation-examples/mose-seg-con-sexample.ipynb
[I 14:23:34.909 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 14:25:34.258 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 14:27:34.291 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 14:28:42.335 LabApp] Starting buffering for b6811db2-2831-444b-823c-785f07a7fbfd:dc5fb0a9867445adaa4a9da4c85dd120
[I 14:28:45.266 LabApp] Kernel shutdown: b6811db2-2831-444b-823c-785f07a7fbfd
[W 14:28:45.884 LabApp] 404 DELETE /api/sessions/1afc31b9-c37a-4ab2-b9e6-84cadb6517e5 (::1): Session not found: session_id='1afc31b9-c37a-4ab2-b9e6-84cadb6517e5'
[W 14:28:45.885 LabApp] Session not found: session_id='1afc31b9-c37a-4ab2-b9e6-84cadb6517e5'
[W 14:28:45.885 LabApp] 404 DELETE /api/sessions/1afc31b9-c37a-4ab2-b9e6-84cadb6517e5 (::1) 1.53ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA3.2.ipynb
[I 14:29:34.430 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 14:31:34.729 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 14:33:34.757 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 14:35:34.672 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 14:37:34.696 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 14:39:34.737 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 14:41:34.475 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 14:43:34.750 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 14:45:34.687 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 14:47:34.300 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 14:49:34.402 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 14:51:34.058 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 14:53:34.311 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 14:55:34.297 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 14:57:34.695 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 14:59:34.671 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 15:01:34.676 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 15:03:34.679 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 15:05:34.668 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 15:07:34.707 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 15:09:34.700 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 15:11:34.620 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 15:13:34.649 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 15:15:34.480 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 15:17:34.652 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 15:19:34.638 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 15:21:34.693 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 15:23:34.648 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 15:25:34.522 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 15:27:34.678 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 15:29:34.677 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 15:31:34.806 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 15:33:34.678 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 15:35:34.689 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 15:37:34.892 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 15:39:34.895 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 15:41:34.709 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 15:43:34.891 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 15:45:34.657 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 15:47:34.697 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 15:49:34.834 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 15:51:34.757 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 15:53:34.689 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 15:55:34.774 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 15:57:34.660 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 15:59:34.987 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 17:24:36.919 LabApp] Kernel interrupted: 51463314-8cca-433e-b358-f12c09c7c165
[I 17:25:34.388 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 17:25:44.694 LabApp] Starting buffering for 51463314-8cca-433e-b358-f12c09c7c165:4b33e997f6f346ad8a9485d4574ca938
[I 17:25:48.234 LabApp] Kernel restarted: 51463314-8cca-433e-b358-f12c09c7c165
[I 17:25:52.966 LabApp] Adapting from protocol version 5.1 (kernel 51463314-8cca-433e-b358-f12c09c7c165) to 5.3 (client).
[I 17:25:52.968 LabApp] Restoring connection for 51463314-8cca-433e-b358-f12c09c7c165:4b33e997f6f346ad8a9485d4574ca938
[I 17:25:52.968 LabApp] Replaying 6 buffered messages
2019-10-25 17:26:05.517826: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-25 17:26:06.526107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-25 17:26:06.530656: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 17:26:06.533655: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 17:26:06.535213: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 17:26:06.535887: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 17:26:06.537918: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 17:26:06.539648: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 17:26:06.543453: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 17:26:06.545304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 17:26:06.780618: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e9f087d0e0 executing computations on platform CUDA. Devices:
2019-10-25 17:26:06.780709: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-25 17:26:06.788107: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-25 17:26:06.790044: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e9f0953b80 executing computations on platform Host. Devices:
2019-10-25 17:26:06.790080: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-25 17:26:06.791094: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-25 17:26:06.791219: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 17:26:06.791261: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 17:26:06.791299: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 17:26:06.791336: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 17:26:06.791373: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 17:26:06.791410: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 17:26:06.791448: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-25 17:26:06.793106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-25 17:26:06.793173: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 17:26:06.795454: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-25 17:26:06.795480: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-25 17:26:06.795493: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-25 17:26:06.797676: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-25 17:26:13.441937: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-25 17:26:13.488395: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 17:26:13.712846: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 17:27:34.379 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 17:29:34.383 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 17:31:34.392 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 17:33:34.420 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 17:35:34.412 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 17:37:34.456 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 17:39:34.442 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 17:41:34.437 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 17:43:34.377 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 17:45:34.193 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 17:47:34.663 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 17:49:35.280 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb
[I 10:32:54.862 LabApp] Copying avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb to /avgn_paper/notebooks/6.0-neural-networks
[W 10:32:57.502 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.77ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5-Copy1.ipynb
[I 10:32:58.494 LabApp] Kernel started: 2392fde6-7f84-4084-9f30-2f7e876a3598
[W 10:32:58.507 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 3.91ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5-Copy1.ipynb
[I 10:33:02.301 LabApp] Adapting from protocol version 5.1 (kernel 2392fde6-7f84-4084-9f30-2f7e876a3598) to 5.3 (client).
[I 10:33:12.464 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5-Copy1.ipynb
[I 10:33:21.050 LabApp] Starting buffering for 2392fde6-7f84-4084-9f30-2f7e876a3598:76da145f00d94d588006e293c5179f28
[I 10:33:21.530 LabApp] Kernel restarted: 2392fde6-7f84-4084-9f30-2f7e876a3598
[I 10:33:28.787 LabApp] Adapting from protocol version 5.1 (kernel 2392fde6-7f84-4084-9f30-2f7e876a3598) to 5.3 (client).
[I 10:33:28.789 LabApp] Restoring connection for 2392fde6-7f84-4084-9f30-2f7e876a3598:76da145f00d94d588006e293c5179f28
[I 10:33:28.799 LabApp] Replaying 6 buffered messages
2019-10-26 10:33:43.734660: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 10:33:44.337079: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-26 10:33:44.338042: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 10:33:44.340307: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 10:33:44.342176: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 10:33:44.343020: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 10:33:44.345460: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 10:33:44.347715: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 10:33:44.351617: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 10:33:44.353746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 10:33:44.608101: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556a81ad6cb0 executing computations on platform CUDA. Devices:
2019-10-26 10:33:44.608181: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-26 10:33:44.613312: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 10:33:44.615683: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556a81bad730 executing computations on platform Host. Devices:
2019-10-26 10:33:44.615737: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 10:33:44.616928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-26 10:33:44.617056: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 10:33:44.617112: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 10:33:44.617166: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 10:33:44.617220: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 10:33:44.617273: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 10:33:44.617327: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 10:33:44.617382: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 10:33:44.618999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 10:33:44.619091: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 10:33:44.621758: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 10:33:44.621790: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 10:33:44.621807: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 10:33:44.624086: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 204 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-26 10:33:46.136180: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 204.75M (214695936 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2019-10-26 10:33:46.227071: F tensorflow/stream_executor/cuda/cuda_driver.cc:175] Check failed: err == cudaSuccess || err == cudaErrorInvalidValue Unexpected CUDA error: out of memory
[I 10:33:48.531 LabApp] KernelRestarter: restarting kernel (1/5), keep random ports
kernel 2392fde6-7f84-4084-9f30-2f7e876a3598 restarted
[I 10:34:58.666 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5-2D.ipynb
[I 12:04:22.427 LabApp] Starting buffering for 2392fde6-7f84-4084-9f30-2f7e876a3598:76da145f00d94d588006e293c5179f28
[I 12:04:23.050 LabApp] Kernel restarted: 2392fde6-7f84-4084-9f30-2f7e876a3598
[I 12:04:29.185 LabApp] Adapting from protocol version 5.1 (kernel 2392fde6-7f84-4084-9f30-2f7e876a3598) to 5.3 (client).
[I 12:04:29.186 LabApp] Restoring connection for 2392fde6-7f84-4084-9f30-2f7e876a3598:76da145f00d94d588006e293c5179f28
[I 12:04:29.186 LabApp] Replaying 6 buffered messages
[W 12:04:38.649 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb is not trusted
[W 12:04:38.696 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.39ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 12:04:39.439 LabApp] Adapting from protocol version 5.1 (kernel d9916fc0-f379-41c3-acdb-22feac30f803) to 5.3 (client).
[W 12:04:39.517 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 2.18ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
2019-10-26 12:04:46.722207: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 12:04:47.311934: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-26 12:04:47.312982: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 12:04:47.315022: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 12:04:47.316656: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 12:04:47.317683: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 12:04:47.319698: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 12:04:47.321542: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 12:04:47.325294: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 12:04:47.327411: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 12:04:47.539542: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c160193400 executing computations on platform CUDA. Devices:
2019-10-26 12:04:47.539667: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-26 12:04:47.547162: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 12:04:47.550072: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c160269e60 executing computations on platform Host. Devices:
2019-10-26 12:04:47.550126: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 12:04:47.550919: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-26 12:04:47.551006: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 12:04:47.551047: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 12:04:47.551084: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 12:04:47.551138: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 12:04:47.551178: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 12:04:47.551216: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 12:04:47.551254: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 12:04:47.552565: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 12:04:47.552625: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 12:04:47.554431: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 12:04:47.554452: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 12:04:47.554474: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 12:04:47.556039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 204 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-26 12:04:48.925099: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 204.75M (214695936 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2019-10-26 12:04:49.018390: F tensorflow/stream_executor/cuda/cuda_driver.cc:175] Check failed: err == cudaSuccess || err == cudaErrorInvalidValue Unexpected CUDA error: out of memory
[I 12:04:50.050 LabApp] KernelRestarter: restarting kernel (1/5), keep random ports
kernel 2392fde6-7f84-4084-9f30-2f7e876a3598 restarted
[I 12:04:56.497 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5-2D.ipynb
[I 12:04:59.182 LabApp] Starting buffering for 2392fde6-7f84-4084-9f30-2f7e876a3598:76da145f00d94d588006e293c5179f28
[I 12:04:59.651 LabApp] Kernel restarted: 2392fde6-7f84-4084-9f30-2f7e876a3598
[I 12:05:03.585 LabApp] Adapting from protocol version 5.1 (kernel 2392fde6-7f84-4084-9f30-2f7e876a3598) to 5.3 (client).
[I 12:05:03.587 LabApp] Restoring connection for 2392fde6-7f84-4084-9f30-2f7e876a3598:76da145f00d94d588006e293c5179f28
[I 12:05:03.587 LabApp] Replaying 6 buffered messages
2019-10-26 12:05:16.070411: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 12:05:16.659777: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 12:05:16.660760: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 12:05:16.663828: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 12:05:16.666022: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 12:05:16.667469: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 12:05:16.670577: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 12:05:16.673113: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 12:05:16.679389: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 12:05:16.683798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 12:05:16.952842: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x557c88844c60 executing computations on platform CUDA. Devices:
2019-10-26 12:05:16.952916: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-26 12:05:16.959830: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 12:05:16.962851: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x557c8891b6e0 executing computations on platform Host. Devices:
2019-10-26 12:05:16.962921: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 12:05:16.965075: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 12:05:16.965217: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 12:05:16.965302: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 12:05:16.965404: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 12:05:16.965486: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 12:05:16.965566: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 12:05:16.965646: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 12:05:16.965728: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 12:05:16.969113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 12:05:16.969241: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 12:05:16.973471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 12:05:16.973516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 12:05:16.973538: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 12:05:16.977504: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-26 12:05:23.086563: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-26 12:05:23.126667: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 12:05:23.336576: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 12:06:41.281 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[W 12:06:41.282 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb is not trusted
[I 12:06:58.713 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5-2D.ipynb
[I 12:08:28.740 LabApp] Kernel interrupted: 2392fde6-7f84-4084-9f30-2f7e876a3598
[I 12:08:59.400 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5-2D.ipynb
[I 12:10:59.932 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5-2D.ipynb
[I 12:13:00.151 LabApp] Starting buffering for 51463314-8cca-433e-b358-f12c09c7c165:4b33e997f6f346ad8a9485d4574ca938
[I 12:13:03.215 LabApp] Kernel shutdown: 51463314-8cca-433e-b358-f12c09c7c165
[I 12:13:03.219 LabApp] Copying avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5.ipynb to /avgn_paper/notebooks/6.0-neural-networks
[W 12:13:05.447 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.64ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5-Copy1.ipynb
[I 12:13:06.216 LabApp] Kernel started: 5ffe4de3-4588-4f02-bdea-140007678a54
[W 12:13:06.264 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 4.14ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-GAIA5-Copy1.ipynb
[I 12:13:08.983 LabApp] Adapting from protocol version 5.1 (kernel 5ffe4de3-4588-4f02-bdea-140007678a54) to 5.3 (client).
[W 12:13:48.504 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 4.39ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 12:13:49.320 LabApp] Adapting from protocol version 5.1 (kernel 68fe739f-0fae-442f-860e-d943da609e51) to 5.3 (client).
[W 12:13:49.332 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 1.75ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 12:15:06.625 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 12:15:50.874 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 12:17:07.026 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 12:19:06.624 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 12:57:30.577 LabApp] Starting buffering for 5ffe4de3-4588-4f02-bdea-140007678a54:87436897cbf044af8e92b442487ce937
[I 12:57:31.269 LabApp] Kernel restarted: 5ffe4de3-4588-4f02-bdea-140007678a54
[I 12:57:38.240 LabApp] Adapting from protocol version 5.1 (kernel 5ffe4de3-4588-4f02-bdea-140007678a54) to 5.3 (client).
[I 12:57:38.241 LabApp] Restoring connection for 5ffe4de3-4588-4f02-bdea-140007678a54:87436897cbf044af8e92b442487ce937
[I 12:57:38.241 LabApp] Replaying 6 buffered messages
2019-10-26 12:57:50.726642: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 12:57:51.372198: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-26 12:57:51.373526: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 12:57:51.377667: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 12:57:51.381018: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 12:57:51.382849: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 12:57:51.386858: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 12:57:51.390012: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 12:57:51.397089: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 12:57:51.400405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 12:57:51.692590: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55bae11855c0 executing computations on platform CUDA. Devices:
2019-10-26 12:57:51.692697: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-26 12:57:51.700243: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 12:57:51.702471: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55bae125c060 executing computations on platform Host. Devices:
2019-10-26 12:57:51.702535: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 12:57:51.707664: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-26 12:57:51.707783: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 12:57:51.707827: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 12:57:51.707867: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 12:57:51.707924: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 12:57:51.707966: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 12:57:51.708005: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 12:57:51.708046: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 12:57:51.709869: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 12:57:51.709941: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 12:57:51.712078: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 12:57:51.712102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 12:57:51.712115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 12:57:51.714302: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-26 12:58:46.993689: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-26 12:58:47.042861: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 12:58:47.239410: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 12:59:06.647 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 13:01:06.980 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 13:02:07.990 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 13:02:12.528 LabApp] Kernel interrupted: 5ffe4de3-4588-4f02-bdea-140007678a54
[I 13:02:15.434 LabApp] Starting buffering for 5ffe4de3-4588-4f02-bdea-140007678a54:87436897cbf044af8e92b442487ce937
[I 13:02:18.091 LabApp] Kernel restarted: 5ffe4de3-4588-4f02-bdea-140007678a54
[I 13:02:24.574 LabApp] Adapting from protocol version 5.1 (kernel 5ffe4de3-4588-4f02-bdea-140007678a54) to 5.3 (client).
[I 13:02:24.575 LabApp] Restoring connection for 5ffe4de3-4588-4f02-bdea-140007678a54:87436897cbf044af8e92b442487ce937
[I 13:02:24.576 LabApp] Replaying 7 buffered messages
2019-10-26 13:02:39.505704: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 13:02:40.107592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-26 13:02:40.108874: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 13:02:40.112802: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 13:02:40.116464: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 13:02:40.119079: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 13:02:40.122908: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 13:02:40.125771: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 13:02:40.132293: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 13:02:40.135307: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 13:02:40.428349: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558768f83b20 executing computations on platform CUDA. Devices:
2019-10-26 13:02:40.428439: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-26 13:02:40.433579: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 13:02:40.436893: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55876905a5b0 executing computations on platform Host. Devices:
2019-10-26 13:02:40.436964: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 13:02:40.438961: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-26 13:02:40.439180: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 13:02:40.439253: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 13:02:40.439314: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 13:02:40.439376: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 13:02:40.439483: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 13:02:40.439569: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 13:02:40.439651: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 13:02:40.446814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 13:02:40.446995: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 13:02:40.451246: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 13:02:40.451298: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 13:02:40.451322: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 13:02:40.455441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-26 13:02:48.263094: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-26 13:02:48.321865: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 13:02:48.567781: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[W 13:02:55.495 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 1.83ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 13:02:55.505 LabApp] Adapting from protocol version 5.1 (kernel 68fe739f-0fae-442f-860e-d943da609e51) to 5.3 (client).
[W 13:02:59.623 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb is not trusted
[W 13:02:59.669 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 2.78ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[W 13:03:00.887 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 4.36ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[I 13:03:01.106 LabApp] Adapting from protocol version 5.1 (kernel 1c23d551-7d11-4d02-ac6c-999284268760) to 5.3 (client).
[I 13:03:07.220 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 13:03:14.913 LabApp] KernelRestarter: restarting kernel (1/5), keep random ports
kernel e4f39541-c636-4e93-9820-1a4ae1520340 restarted
[I 13:03:19.175 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[W 13:03:19.178 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb is not trusted
[I 13:03:19.403 LabApp] Copying avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb to /avgn_paper/notebooks/6.0-neural-networks
[W 13:03:19.448 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb is not trusted
[W 13:03:19.485 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-AE-Copy1.ipynb is not trusted
[W 13:03:20.285 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-AE-Copy1.ipynb is not trusted
[W 13:03:20.534 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 2.30ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-AE-Copy1.ipynb
[I 13:03:20.978 LabApp] Kernel started: 0285bf89-571b-47ee-8381-e564b9e597e2
[W 13:03:21.096 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 3.23ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-AE-Copy1.ipynb
[I 13:03:22.939 LabApp] Adapting from protocol version 5.1 (kernel 0285bf89-571b-47ee-8381-e564b9e597e2) to 5.3 (client).
[I 13:04:35.418 LabApp] Kernel interrupted: 5ffe4de3-4588-4f02-bdea-140007678a54
[I 13:04:47.804 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 13:04:50.628 LabApp] Starting buffering for 5ffe4de3-4588-4f02-bdea-140007678a54:87436897cbf044af8e92b442487ce937
[I 13:04:53.488 LabApp] Kernel restarted: 5ffe4de3-4588-4f02-bdea-140007678a54
[I 13:04:58.810 LabApp] Adapting from protocol version 5.1 (kernel 5ffe4de3-4588-4f02-bdea-140007678a54) to 5.3 (client).
[I 13:04:58.811 LabApp] Restoring connection for 5ffe4de3-4588-4f02-bdea-140007678a54:87436897cbf044af8e92b442487ce937
[I 13:04:58.811 LabApp] Replaying 6 buffered messages
[I 13:05:06.144 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
2019-10-26 13:05:09.628605: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 13:05:12.162555: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-26 13:05:12.163452: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 13:05:12.165330: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 13:05:12.166752: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 13:05:12.167391: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 13:05:12.169257: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 13:05:12.170841: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 13:05:12.174246: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 13:05:12.178869: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 13:05:12.459421: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559e9043ccc0 executing computations on platform CUDA. Devices:
2019-10-26 13:05:12.459509: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-26 13:05:12.464455: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 13:05:12.465864: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559e90513720 executing computations on platform Host. Devices:
2019-10-26 13:05:12.465890: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 13:05:12.466814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-26 13:05:12.466885: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 13:05:12.466921: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 13:05:12.466955: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 13:05:12.466989: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 13:05:12.467022: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 13:05:12.467056: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 13:05:12.467090: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 13:05:12.468696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 13:05:12.468752: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 13:05:12.471603: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 13:05:12.471632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 13:05:12.471646: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 13:05:12.474256: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-26 13:05:18.647528: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-26 13:05:18.696447: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 13:05:18.890321: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 13:05:22.085 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[W 13:05:22.085 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb is not trusted
[I 13:05:49.405 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[W 13:05:49.406 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb is not trusted
[I 13:07:06.954 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[W 13:08:11.379 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 5.65ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[W 13:08:13.085 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 2.55ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 13:08:13.130 LabApp] Adapting from protocol version 5.1 (kernel 68fe739f-0fae-442f-860e-d943da609e51) to 5.3 (client).
[I 13:08:14.945 LabApp] Starting buffering for 1c23d551-7d11-4d02-ac6c-999284268760:7f92e1c799c0447388587a3c8118cea6
[I 13:08:21.046 LabApp] Starting buffering for d9916fc0-f379-41c3-acdb-22feac30f803:659b95cae7ed4b9d8874fe4145593240
[I 13:09:07.494 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 13:09:14.203 LabApp] Starting buffering for 2392fde6-7f84-4084-9f30-2f7e876a3598:76da145f00d94d588006e293c5179f28
[I 13:09:17.016 LabApp] Kernel shutdown: 2392fde6-7f84-4084-9f30-2f7e876a3598
[I 13:09:19.824 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 13:09:20.105 LabApp] Copying avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb to /avgn_paper/notebooks/6.0-neural-networks
[W 13:09:22.482 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.69ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 13:09:23.519 LabApp] Kernel started: e85ec2b3-3c7e-4b03-b4e6-e80a17805233
[W 13:09:23.719 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 3.00ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 13:09:28.315 LabApp] Adapting from protocol version 5.1 (kernel e85ec2b3-3c7e-4b03-b4e6-e80a17805233) to 5.3 (client).
[I 13:09:54.952 LabApp] Starting buffering for e85ec2b3-3c7e-4b03-b4e6-e80a17805233:17e9ca8f0f4e4172a2723d8b67616285
[I 13:09:55.425 LabApp] Kernel restarted: e85ec2b3-3c7e-4b03-b4e6-e80a17805233
[I 13:10:00.123 LabApp] Adapting from protocol version 5.1 (kernel e85ec2b3-3c7e-4b03-b4e6-e80a17805233) to 5.3 (client).
[I 13:10:00.124 LabApp] Restoring connection for e85ec2b3-3c7e-4b03-b4e6-e80a17805233:17e9ca8f0f4e4172a2723d8b67616285
[I 13:10:00.124 LabApp] Replaying 6 buffered messages
2019-10-26 13:10:08.513628: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 13:10:11.175924: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 13:10:11.176954: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 13:10:11.179625: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 13:10:11.181465: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 13:10:11.182304: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 13:10:11.184497: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 13:10:11.186314: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 13:10:11.190385: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 13:10:11.192271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 13:10:11.405108: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ae923577e0 executing computations on platform CUDA. Devices:
2019-10-26 13:10:11.405163: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-26 13:10:11.408809: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 13:10:11.410264: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ae9242e230 executing computations on platform Host. Devices:
2019-10-26 13:10:11.410296: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 13:10:11.412052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 13:10:11.412138: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 13:10:11.412179: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 13:10:11.412216: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 13:10:11.412253: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 13:10:11.412290: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 13:10:11.412327: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 13:10:11.412366: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 13:10:11.413952: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 13:10:11.414023: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 13:10:11.416048: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 13:10:11.416071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 13:10:11.416082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 13:10:11.418032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
[I 13:10:14.041 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 13:11:07.080 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
2019-10-26 13:11:14.673140: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-26 13:11:14.732548: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 13:11:14.969493: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 13:11:24.023 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-faster.ipynb
[I 13:13:06.997 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 13:13:24.315 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-faster.ipynb
[I 13:14:48.222 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-faster.ipynb
[I 13:14:52.213 LabApp] Starting buffering for e85ec2b3-3c7e-4b03-b4e6-e80a17805233:17e9ca8f0f4e4172a2723d8b67616285
[I 13:14:57.879 LabApp] Kernel restarted: e85ec2b3-3c7e-4b03-b4e6-e80a17805233
[I 13:15:03.732 LabApp] Adapting from protocol version 5.1 (kernel e85ec2b3-3c7e-4b03-b4e6-e80a17805233) to 5.3 (client).
[I 13:15:03.733 LabApp] Restoring connection for e85ec2b3-3c7e-4b03-b4e6-e80a17805233:17e9ca8f0f4e4172a2723d8b67616285
[I 13:15:03.733 LabApp] Replaying 81 buffered messages
[I 13:15:06.971 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
2019-10-26 13:15:11.798676: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 13:15:14.401796: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 13:15:14.402484: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 13:15:14.404454: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 13:15:14.405908: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 13:15:14.406745: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 13:15:14.408581: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 13:15:14.410144: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 13:15:14.413512: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 13:15:14.415153: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 13:15:14.608761: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56054712cf60 executing computations on platform CUDA. Devices:
2019-10-26 13:15:14.608819: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-26 13:15:14.612290: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 13:15:14.613584: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5605472039e0 executing computations on platform Host. Devices:
2019-10-26 13:15:14.613628: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 13:15:14.614556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 13:15:14.614649: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 13:15:14.614689: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 13:15:14.614727: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 13:15:14.614764: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 13:15:14.614817: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 13:15:14.614856: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 13:15:14.614893: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 13:15:14.616478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 13:15:14.616544: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 13:15:14.618539: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 13:15:14.618560: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 13:15:14.618571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 13:15:14.620541: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
[I 13:15:23.597 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-faster.ipynb
[I 13:16:58.448 LabApp] Starting buffering for e85ec2b3-3c7e-4b03-b4e6-e80a17805233:17e9ca8f0f4e4172a2723d8b67616285
[I 13:17:00.901 LabApp] Kernel restarted: e85ec2b3-3c7e-4b03-b4e6-e80a17805233
[I 13:17:04.361 LabApp] Adapting from protocol version 5.1 (kernel e85ec2b3-3c7e-4b03-b4e6-e80a17805233) to 5.3 (client).
[I 13:17:04.362 LabApp] Restoring connection for e85ec2b3-3c7e-4b03-b4e6-e80a17805233:17e9ca8f0f4e4172a2723d8b67616285
[I 13:17:04.362 LabApp] Replaying 6 buffered messages
[I 13:17:07.083 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
2019-10-26 13:17:12.484250: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 13:17:15.143019: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 13:17:15.144034: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 13:17:15.145987: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 13:17:15.147606: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 13:17:15.148295: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 13:17:15.150259: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 13:17:15.151974: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 13:17:15.155817: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 13:17:15.157759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 13:17:15.371129: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fe449a0b90 executing computations on platform CUDA. Devices:
2019-10-26 13:17:15.371228: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-26 13:17:15.377488: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 13:17:15.379364: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fe44a77610 executing computations on platform Host. Devices:
2019-10-26 13:17:15.379411: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 13:17:15.380532: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 13:17:15.380624: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 13:17:15.380669: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 13:17:15.380710: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 13:17:15.380751: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 13:17:15.380793: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 13:17:15.380835: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 13:17:15.380878: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 13:17:15.382584: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 13:17:15.382648: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 13:17:15.384681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 13:17:15.384703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 13:17:15.384714: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 13:17:15.386724: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-26 13:17:22.705079: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-26 13:17:22.754494: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 13:17:22.952272: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 13:17:23.606 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-faster.ipynb
[I 13:19:06.967 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 13:19:24.329 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-faster.ipynb
[I 13:21:07.120 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 13:21:24.933 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 13:21:25.634 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-faster.ipynb
[I 13:21:26.456 LabApp] Starting buffering for 5ffe4de3-4588-4f02-bdea-140007678a54:87436897cbf044af8e92b442487ce937
[I 13:21:32.167 LabApp] Kernel restarted: 5ffe4de3-4588-4f02-bdea-140007678a54
[I 13:21:36.869 LabApp] Adapting from protocol version 5.1 (kernel 5ffe4de3-4588-4f02-bdea-140007678a54) to 5.3 (client).
[I 13:21:36.870 LabApp] Restoring connection for 5ffe4de3-4588-4f02-bdea-140007678a54:87436897cbf044af8e92b442487ce937
[I 13:21:36.870 LabApp] Replaying 79 buffered messages
2019-10-26 13:21:47.770379: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
[I 13:21:48.590 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[W 13:21:48.594 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb is not trusted
2019-10-26 13:21:50.374722: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-26 13:21:50.375556: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 13:21:50.377651: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 13:21:50.379218: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 13:21:50.379900: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 13:21:50.381916: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 13:21:50.383634: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 13:21:50.387392: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 13:21:50.389179: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 13:21:50.614640: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5589955c9450 executing computations on platform CUDA. Devices:
2019-10-26 13:21:50.614697: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-26 13:21:50.618127: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 13:21:50.619421: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55899569ff30 executing computations on platform Host. Devices:
2019-10-26 13:21:50.619474: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 13:21:50.620541: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-26 13:21:50.620639: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 13:21:50.620679: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 13:21:50.620717: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 13:21:50.620754: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 13:21:50.620792: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 13:21:50.620829: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 13:21:50.620867: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 13:21:50.622474: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 13:21:50.622535: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 13:21:50.626304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 13:21:50.626401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 13:21:50.626429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 13:21:50.630457: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
[I 13:22:17.635 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[W 13:22:17.637 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb is not trusted
[I 13:22:20.044 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[W 13:22:20.045 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb is not trusted
[I 13:22:21.036 LabApp] Starting buffering for 0285bf89-571b-47ee-8381-e564b9e597e2:e8e96eeef0304e3e82e4909db55ccdb1
[I 13:22:21.481 LabApp] Kernel restarted: 0285bf89-571b-47ee-8381-e564b9e597e2
[I 13:22:22.705 LabApp] Adapting from protocol version 5.1 (kernel 0285bf89-571b-47ee-8381-e564b9e597e2) to 5.3 (client).
[I 13:22:22.705 LabApp] Restoring connection for 0285bf89-571b-47ee-8381-e564b9e597e2:e8e96eeef0304e3e82e4909db55ccdb1
[I 13:22:22.705 LabApp] Replaying 6 buffered messages
2019-10-26 13:22:29.783791: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 13:22:32.500355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-26 13:22:32.501425: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 13:22:32.503804: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 13:22:32.505599: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 13:22:32.506275: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 13:22:32.508667: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 13:22:32.510639: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 13:22:32.515373: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 13:22:32.517610: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 13:22:32.671531: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560e0eececc0 executing computations on platform CUDA. Devices:
2019-10-26 13:22:32.671590: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K40c, Compute Capability 3.5
2019-10-26 13:22:32.675124: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 13:22:32.676325: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560e0efa5720 executing computations on platform Host. Devices:
2019-10-26 13:22:32.676354: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 13:22:32.677413: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-26 13:22:32.677505: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 13:22:32.677546: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 13:22:32.677584: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 13:22:32.677638: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 13:22:32.677677: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 13:22:32.677715: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 13:22:32.677759: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 13:22:32.679688: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 13:22:32.679753: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 13:22:32.681948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 13:22:32.681968: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 13:22:32.681979: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 13:22:32.684090: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10794 MB memory) -> physical GPU (device: 0, name: Tesla K40c, pci bus id: 0000:03:00.0, compute capability: 3.5)
2019-10-26 13:22:34.532049: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 13:22:34.700536: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-26 13:22:34.757820: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 13:22:34.965491: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 13:22:35.254790: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 13:23:06.661 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 13:23:21.221 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 13:23:25.083 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-faster.ipynb
[I 13:25:07.375 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 13:25:21.371 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 13:25:25.054 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-faster.ipynb
[I 13:27:07.311 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 13:27:21.375 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 13:27:25.093 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-faster.ipynb
[I 13:29:07.537 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 13:29:21.427 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 13:29:25.157 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-faster.ipynb
[I 13:31:07.102 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 13:31:21.363 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 13:31:25.066 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-faster.ipynb
[I 13:33:07.091 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 13:33:21.352 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 13:33:25.208 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-faster.ipynb
[I 13:35:07.070 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 13:35:21.370 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 13:35:25.141 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-faster.ipynb
[I 13:37:07.073 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 13:37:21.364 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 13:37:25.177 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-faster.ipynb
[I 13:39:07.102 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 13:39:21.381 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 13:39:25.121 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-faster.ipynb
[I 13:41:07.081 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 13:41:21.401 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 13:41:25.147 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-faster.ipynb
[I 13:43:07.100 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 13:43:21.422 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 13:43:25.469 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-faster.ipynb
[I 13:45:07.250 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 13:45:21.411 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 13:45:25.046 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-faster.ipynb
[I 13:47:07.081 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 13:47:21.393 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 13:47:25.050 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-faster.ipynb
[I 13:49:07.158 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 13:49:21.378 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 13:49:25.091 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-faster.ipynb
[I 13:51:07.090 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 13:51:21.368 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 13:51:25.110 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-faster.ipynb
[I 13:53:07.098 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 13:53:21.384 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 13:53:25.176 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-faster.ipynb
[I 13:55:07.084 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 13:55:21.396 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 13:55:24.652 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-faster.ipynb
[I 13:57:07.126 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 13:57:21.463 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 13:57:25.051 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-faster.ipynb
[I 13:59:07.155 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 13:59:21.431 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 13:59:25.060 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-faster.ipynb
[I 14:01:07.168 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 14:01:21.096 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 14:01:24.700 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-faster.ipynb
[I 14:02:56.317 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 14:02:57.399 LabApp] Kernel interrupted: 0285bf89-571b-47ee-8381-e564b9e597e2
[I 14:02:59.133 LabApp] Starting buffering for 0285bf89-571b-47ee-8381-e564b9e597e2:e8e96eeef0304e3e82e4909db55ccdb1
[I 14:03:05.584 LabApp] Kernel restarted: 0285bf89-571b-47ee-8381-e564b9e597e2
[I 14:03:07.116 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 14:03:07.473 LabApp] Adapting from protocol version 5.1 (kernel 0285bf89-571b-47ee-8381-e564b9e597e2) to 5.3 (client).
[I 14:03:07.474 LabApp] Restoring connection for 0285bf89-571b-47ee-8381-e564b9e597e2:e8e96eeef0304e3e82e4909db55ccdb1
[I 14:03:07.474 LabApp] Replaying 69 buffered messages
[I 14:03:10.375 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-faster.ipynb
[I 14:03:15.889 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-faster.ipynb
2019-10-26 14:03:17.800336: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 14:03:20.220053: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-26 14:03:20.228339: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 14:03:20.230222: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 14:03:20.231736: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 14:03:20.242702: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 14:03:20.244583: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 14:03:20.246165: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 14:03:20.249576: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 14:03:20.251265: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 14:03:20.407722: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e110492ca0 executing computations on platform CUDA. Devices:
2019-10-26 14:03:20.407769: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K40c, Compute Capability 3.5
2019-10-26 14:03:20.410781: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 14:03:20.413327: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e110569720 executing computations on platform Host. Devices:
2019-10-26 14:03:20.413372: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 14:03:20.414852: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-26 14:03:20.414940: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 14:03:20.414978: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 14:03:20.415014: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 14:03:20.415050: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 14:03:20.415085: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 14:03:20.415130: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 14:03:20.415168: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 14:03:20.416830: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 14:03:20.416883: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 14:03:20.418773: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 14:03:20.418790: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 14:03:20.418800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 14:03:20.420793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10794 MB memory) -> physical GPU (device: 0, name: Tesla K40c, pci bus id: 0000:03:00.0, compute capability: 3.5)
[I 14:03:21.013 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 14:03:24.298 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-faster.ipynb
[W 14:04:37.623 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 6.03ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/1.0-starling-to-tfrecord_128.ipynb
[I 14:04:38.135 LabApp] Adapting from protocol version 5.1 (kernel de905082-d91a-4f7e-8a4c-62a2660e6c39) to 5.3 (client).
[W 14:04:38.147 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 1.74ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/1.0-starling-to-tfrecord_128.ipynb
[I 14:04:42.092 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/1.0-starling-to-tfrecord_128.ipynb
[I 14:04:42.450 LabApp] Copying avgn_paper/notebooks/6.0-neural-networks/1.0-starling-to-tfrecord_128.ipynb to /avgn_paper/notebooks/6.0-neural-networks
[W 14:04:43.609 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 4.35ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/1.0-starling-to-tfrecord_128-Copy1.ipynb
[I 14:04:44.035 LabApp] Kernel started: 45fdaabd-cd04-44ae-b12b-197e86cc5654
[W 14:04:44.136 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 1.73ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/1.0-starling-to-tfrecord_128-Copy1.ipynb
[I 14:04:45.818 LabApp] Adapting from protocol version 5.1 (kernel 45fdaabd-cd04-44ae-b12b-197e86cc5654) to 5.3 (client).
[I 14:05:07.079 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 14:05:21.315 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 14:05:23.842 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-faster.ipynb
[I 14:05:24.904 LabApp] Kernel interrupted: 45fdaabd-cd04-44ae-b12b-197e86cc5654
[W 14:06:38.843 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 6.34ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/2.0-make-syllable_df/starling-syllable-df-128.ipynb
[W 14:06:42.079 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 2.34ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/2.0-make-syllable_df/starling-syllable-df-128.ipynb
[I 14:06:45.456 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/1.0-starling-to-tfrecord_32.ipynb
[I 14:06:45.686 LabApp] Adapting from protocol version 5.1 (kernel 505e20f1-c76f-41fa-aefb-13ceae966daa) to 5.3 (client).
[I 14:07:07.101 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 14:07:24.302 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-faster.ipynb
[I 14:07:24.650 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 14:07:26.676 LabApp] Starting buffering for 0285bf89-571b-47ee-8381-e564b9e597e2:e8e96eeef0304e3e82e4909db55ccdb1
[I 14:07:27.827 LabApp] Kernel restarted: 0285bf89-571b-47ee-8381-e564b9e597e2
[I 14:07:29.274 LabApp] Adapting from protocol version 5.1 (kernel 0285bf89-571b-47ee-8381-e564b9e597e2) to 5.3 (client).
[I 14:07:29.275 LabApp] Restoring connection for 0285bf89-571b-47ee-8381-e564b9e597e2:e8e96eeef0304e3e82e4909db55ccdb1
[I 14:07:29.275 LabApp] Replaying 6 buffered messages
2019-10-26 14:07:37.778551: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 14:07:40.231616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-26 14:07:40.232485: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 14:07:40.234354: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 14:07:40.235860: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 14:07:40.236657: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 14:07:40.238507: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 14:07:40.240112: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 14:07:40.243550: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 14:07:40.245249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 14:07:40.413647: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56114660feb0 executing computations on platform CUDA. Devices:
2019-10-26 14:07:40.413710: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K40c, Compute Capability 3.5
2019-10-26 14:07:40.417129: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 14:07:40.418201: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5611466e6940 executing computations on platform Host. Devices:
2019-10-26 14:07:40.418230: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 14:07:40.419303: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-26 14:07:40.419375: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 14:07:40.419411: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 14:07:40.419458: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 14:07:40.419492: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 14:07:40.419525: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 14:07:40.419558: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 14:07:40.419591: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 14:07:40.421330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 14:07:40.421386: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 14:07:40.426235: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 14:07:40.426283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 14:07:40.426296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 14:07:40.428541: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10794 MB memory) -> physical GPU (device: 0, name: Tesla K40c, pci bus id: 0000:03:00.0, compute capability: 3.5)
2019-10-26 14:07:42.564529: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 14:07:42.758860: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 14:08:15.143 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/1.0-starling-to-tfrecord_32.ipynb
[I 14:08:44.036 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/1.0-starling-to-tfrecord_32.ipynb
[I 14:09:06.477 LabApp] Saving file at /avgn_paper/notebooks/2.0-make-syllable_df/starling-syllable-df-128.ipynb
[I 14:09:08.494 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 14:09:21.615 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 14:09:22.381 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-faster.ipynb
[I 14:09:32.509 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-faster.ipynb
[I 14:09:32.815 LabApp] Copying avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-faster.ipynb to /avgn_paper/notebooks/6.0-neural-networks
[W 14:09:34.332 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 1.63ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-faster-Copy1.ipynb
[I 14:09:35.034 LabApp] Kernel started: 43cf827e-ce45-4069-9480-663293f6d5b5
[W 14:09:35.259 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 1.76ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-faster-Copy1.ipynb
2019-10-26 14:09:36.106623: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 14:09:36.123207: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-26 14:09:36.123928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 14:09:36.124683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 2 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
2019-10-26 14:09:36.125354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 3 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-26 14:09:36.126088: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 14:09:36.127776: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 14:09:36.129363: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 14:09:36.130122: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 14:09:36.132033: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 14:09:36.133756: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 14:09:36.137238: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 14:09:36.144094: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1, 2, 3
2019-10-26 14:09:36.688687: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5574acdcc630 executing computations on platform CUDA. Devices:
2019-10-26 14:09:36.688756: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-26 14:09:36.688768: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (1): TITAN Xp, Compute Capability 6.1
2019-10-26 14:09:36.688778: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (2): Tesla K40c, Compute Capability 3.5
2019-10-26 14:09:36.688787: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (3): Tesla K40c, Compute Capability 3.5
2019-10-26 14:09:36.694248: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 14:09:36.695776: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x557517d5d150 executing computations on platform Host. Devices:
2019-10-26 14:09:36.695822: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 14:09:36.698111: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-26 14:09:36.698812: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 14:09:36.699492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 2 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
2019-10-26 14:09:36.700154: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 3 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-26 14:09:36.700224: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 14:09:36.700261: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 14:09:36.700295: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 14:09:36.700330: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 14:09:36.700365: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 14:09:36.700400: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 14:09:36.700446: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 14:09:36.706408: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1, 2, 3
2019-10-26 14:09:36.706467: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 14:09:36.710186: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 14:09:36.710206: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 1 2 3 
2019-10-26 14:09:36.710218: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N Y N N 
2019-10-26 14:09:36.710226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 1:   Y N N N 
2019-10-26 14:09:36.710234: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 2:   N N N Y 
2019-10-26 14:09:36.710242: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 3:   N N Y N 
2019-10-26 14:09:36.714145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 204 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-26 14:09:36.715368: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 206 MB memory) -> physical GPU (device: 1, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-26 14:09:36.717123: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 232 MB memory) -> physical GPU (device: 2, name: Tesla K40c, pci bus id: 0000:02:00.0, compute capability: 3.5)
2019-10-26 14:09:36.718231: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 126 MB memory) -> physical GPU (device: 3, name: Tesla K40c, pci bus id: 0000:03:00.0, compute capability: 3.5)
[I 14:09:39.864 LabApp] Adapting from protocol version 5.1 (kernel 43cf827e-ce45-4069-9480-663293f6d5b5) to 5.3 (client).
2019-10-26 14:10:03.261666: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 14:10:03.281375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 14:10:03.281849: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 14:10:03.283588: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 14:10:03.284958: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 14:10:03.285536: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 14:10:03.287401: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 14:10:03.288975: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 14:10:03.292693: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 14:10:03.294305: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 14:10:03.522651: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x557c43287160 executing computations on platform CUDA. Devices:
2019-10-26 14:10:03.522713: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-26 14:10:03.526015: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 14:10:03.527124: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x557c4335dc10 executing computations on platform Host. Devices:
2019-10-26 14:10:03.527154: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 14:10:03.528090: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 14:10:03.528183: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 14:10:03.528227: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 14:10:03.528267: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 14:10:03.528309: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 14:10:03.528349: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 14:10:03.528389: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 14:10:03.528431: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 14:10:03.530763: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 14:10:03.530828: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 14:10:03.532750: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 14:10:03.532770: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 14:10:03.532781: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 14:10:03.534362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 49 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-26 14:10:16.961447: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 49.06M (51445760 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2019-10-26 14:10:16.966054: F tensorflow/stream_executor/cuda/cuda_driver.cc:175] Check failed: err == cudaSuccess || err == cudaErrorInvalidValue Unexpected CUDA error: out of memory
[I 14:10:20.033 LabApp] KernelRestarter: restarting kernel (1/5), keep random ports
kernel 43cf827e-ce45-4069-9480-663293f6d5b5 restarted
[I 14:10:21.165 LabApp] Starting buffering for 68fe739f-0fae-442f-860e-d943da609e51:cdf2a09fa89f4ceea2bc48c473269f8a
[I 14:10:25.327 LabApp] Starting buffering for 5ffe4de3-4588-4f02-bdea-140007678a54:87436897cbf044af8e92b442487ce937
[I 14:10:30.617 LabApp] Kernel shutdown: 5ffe4de3-4588-4f02-bdea-140007678a54
[I 14:10:30.622 LabApp] Starting buffering for e85ec2b3-3c7e-4b03-b4e6-e80a17805233:17e9ca8f0f4e4172a2723d8b67616285
[I 14:10:30.625 LabApp] Discarding 4 buffered messages for e85ec2b3-3c7e-4b03-b4e6-e80a17805233:17e9ca8f0f4e4172a2723d8b67616285
[I 14:10:35.874 LabApp] Kernel shutdown: e85ec2b3-3c7e-4b03-b4e6-e80a17805233
[W 14:10:35.884 LabApp] Got events for closed stream None
[W 14:10:35.897 LabApp] Got events for closed stream None
[W 14:10:35.898 LabApp] Got events for closed stream None
[I 14:10:37.204 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA.ipynb
[I 14:10:38.310 LabApp] Starting buffering for 43cf827e-ce45-4069-9480-663293f6d5b5:cc3e7f9a89b74c979d34c0f5a6798bd4
[I 14:10:38.780 LabApp] Kernel restarted: 43cf827e-ce45-4069-9480-663293f6d5b5
[I 14:10:42.527 LabApp] Adapting from protocol version 5.1 (kernel 43cf827e-ce45-4069-9480-663293f6d5b5) to 5.3 (client).
[I 14:10:42.529 LabApp] Restoring connection for 43cf827e-ce45-4069-9480-663293f6d5b5:cc3e7f9a89b74c979d34c0f5a6798bd4
[I 14:10:42.529 LabApp] Replaying 6 buffered messages
[I 14:10:44.052 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/1.0-starling-to-tfrecord_32.ipynb
[I 14:10:45.386 LabApp] Starting buffering for 45fdaabd-cd04-44ae-b12b-197e86cc5654:1cb1c595dbd546aaa9029b3f724b01e5
[I 14:10:47.553 LabApp] Starting buffering for de905082-d91a-4f7e-8a4c-62a2660e6c39:09cc29aa5f6045f28b6044b96faaa51d
2019-10-26 14:10:49.879410: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 14:10:49.905585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 14:10:49.906841: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 14:10:49.909074: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 14:10:49.910751: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 14:10:49.911712: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 14:10:49.913921: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 14:10:49.915803: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 14:10:49.920085: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 14:10:49.922945: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 14:10:50.195675: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5584650a74d0 executing computations on platform CUDA. Devices:
2019-10-26 14:10:50.195754: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-26 14:10:50.202735: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 14:10:50.205062: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55846517df50 executing computations on platform Host. Devices:
2019-10-26 14:10:50.205115: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 14:10:50.206316: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 14:10:50.206409: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 14:10:50.206454: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 14:10:50.206497: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 14:10:50.206539: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 14:10:50.206580: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 14:10:50.206621: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 14:10:50.206663: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 14:10:50.209889: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 14:10:50.209960: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 14:10:50.212139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 14:10:50.212162: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 14:10:50.212173: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 14:10:50.214441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11278 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
[I 14:11:06.841 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 14:11:25.063 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-faster.ipynb
[I 14:11:35.135 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA.ipynb
[I 14:12:36.859 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 14:13:21.044 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 14:14:03.298 LabApp] Starting buffering for 0285bf89-571b-47ee-8381-e564b9e597e2:e8e96eeef0304e3e82e4909db55ccdb1
[I 14:14:04.858 LabApp] Kernel restarted: 0285bf89-571b-47ee-8381-e564b9e597e2
[I 14:14:06.293 LabApp] Adapting from protocol version 5.1 (kernel 0285bf89-571b-47ee-8381-e564b9e597e2) to 5.3 (client).
[I 14:14:06.294 LabApp] Restoring connection for 0285bf89-571b-47ee-8381-e564b9e597e2:e8e96eeef0304e3e82e4909db55ccdb1
[I 14:14:06.294 LabApp] Replaying 6 buffered messages
2019-10-26 14:14:14.370316: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 14:14:14.395353: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-26 14:14:14.396590: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 14:14:14.398517: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 14:14:14.401018: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 14:14:14.402390: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 14:14:14.406107: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 14:14:14.408861: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 14:14:14.415233: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 14:14:14.418115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 14:14:14.610500: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55642477f8f0 executing computations on platform CUDA. Devices:
2019-10-26 14:14:14.610554: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K40c, Compute Capability 3.5
2019-10-26 14:14:14.614339: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 14:14:14.616297: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5564248563a0 executing computations on platform Host. Devices:
2019-10-26 14:14:14.616331: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 14:14:14.617390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-26 14:14:14.617482: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 14:14:14.617522: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 14:14:14.617558: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 14:14:14.617594: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 14:14:14.617630: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 14:14:14.617666: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 14:14:14.617703: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 14:14:14.619544: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 14:14:14.619611: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 14:14:14.621747: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 14:14:14.621767: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 14:14:14.621778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 14:14:14.624010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10726 MB memory) -> physical GPU (device: 0, name: Tesla K40c, pci bus id: 0000:03:00.0, compute capability: 3.5)
2019-10-26 14:14:16.912024: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 14:14:17.138453: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 14:14:58.247 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA.ipynb
[I 14:14:59.230 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA.ipynb
[I 14:15:02.176 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA.ipynb
2019-10-26 14:15:08.977174: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-26 14:15:09.016093: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 14:15:09.266403: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 14:15:21.668 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 14:15:35.128 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA.ipynb
[I 14:16:00.644 LabApp] Starting buffering for 0285bf89-571b-47ee-8381-e564b9e597e2:e8e96eeef0304e3e82e4909db55ccdb1
[I 14:16:04.056 LabApp] Adapting from protocol version 5.1 (kernel 0285bf89-571b-47ee-8381-e564b9e597e2) to 5.3 (client).
[I 14:17:35.114 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA.ipynb
[I 14:18:04.086 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
2019-10-26 14:19:23.874382: W tensorflow/core/framework/op_kernel.cc:1546] OP_REQUIRES failed at reduction_ops_common.h:155 : Invalid argument: Invalid reduction dimension (2 for input with 2 dimension(s)
[I 14:20:04.098 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 14:22:04.093 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 14:24:04.108 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 14:24:16.494 LabApp] Starting buffering for 0285bf89-571b-47ee-8381-e564b9e597e2:c4a763956ede491c98b574600c86bac1
[I 14:24:18.271 LabApp] Kernel restarted: 0285bf89-571b-47ee-8381-e564b9e597e2
[I 14:24:19.573 LabApp] Adapting from protocol version 5.1 (kernel 0285bf89-571b-47ee-8381-e564b9e597e2) to 5.3 (client).
[I 14:24:19.574 LabApp] Restoring connection for 0285bf89-571b-47ee-8381-e564b9e597e2:c4a763956ede491c98b574600c86bac1
[I 14:24:19.574 LabApp] Replaying 6 buffered messages
2019-10-26 14:24:29.402593: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 14:24:29.424063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-26 14:24:29.424962: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 14:24:29.427247: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 14:24:29.428987: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 14:24:29.429812: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 14:24:29.432003: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 14:24:29.434997: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 14:24:29.441050: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 14:24:29.444794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 14:24:29.637393: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5572c0140b40 executing computations on platform CUDA. Devices:
2019-10-26 14:24:29.637515: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K40c, Compute Capability 3.5
2019-10-26 14:24:29.643312: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 14:24:29.644575: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5572c02175d0 executing computations on platform Host. Devices:
2019-10-26 14:24:29.644606: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 14:24:29.645741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-26 14:24:29.645838: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 14:24:29.645885: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 14:24:29.645928: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 14:24:29.645969: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 14:24:29.646012: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 14:24:29.646069: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 14:24:29.646113: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 14:24:29.647918: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 14:24:29.647994: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 14:24:29.650213: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 14:24:29.650233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 14:24:29.650245: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 14:24:29.653045: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10726 MB memory) -> physical GPU (device: 0, name: Tesla K40c, pci bus id: 0000:03:00.0, compute capability: 3.5)
2019-10-26 14:24:32.325727: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 14:24:32.508337: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 14:25:35.133 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA.ipynb
[I 14:25:47.518 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA.ipynb
[I 14:26:04.071 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 14:26:09.228 LabApp] Kernel interrupted: 43cf827e-ce45-4069-9480-663293f6d5b5
[I 14:26:12.539 LabApp] Starting buffering for 43cf827e-ce45-4069-9480-663293f6d5b5:cc3e7f9a89b74c979d34c0f5a6798bd4
[I 14:26:14.504 LabApp] Kernel restarted: 43cf827e-ce45-4069-9480-663293f6d5b5
[I 14:26:15.697 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA.ipynb
[I 14:26:16.069 LabApp] Copying avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA.ipynb to /avgn_paper/notebooks/6.0-neural-networks
[I 14:26:18.417 LabApp] Kernel started: 9a78cd76-1eeb-470a-9dcd-07782bac77a8
[W 14:26:18.608 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 2.47ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA-Copy1.ipynb
[I 14:26:20.793 LabApp] Adapting from protocol version 5.1 (kernel 9a78cd76-1eeb-470a-9dcd-07782bac77a8) to 5.3 (client).
[I 14:26:20.985 LabApp] Adapting from protocol version 5.1 (kernel 43cf827e-ce45-4069-9480-663293f6d5b5) to 5.3 (client).
[I 14:26:20.986 LabApp] Restoring connection for 43cf827e-ce45-4069-9480-663293f6d5b5:cc3e7f9a89b74c979d34c0f5a6798bd4
[I 14:26:20.986 LabApp] Replaying 7 buffered messages
2019-10-26 14:26:29.183812: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 14:26:29.208516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 14:26:29.209552: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 14:26:29.211686: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 14:26:29.214290: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 14:26:29.215197: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 14:26:29.217248: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 14:26:29.219033: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 14:26:29.222897: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 14:26:29.225569: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 14:26:29.515405: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f8a281cf20 executing computations on platform CUDA. Devices:
2019-10-26 14:26:29.515504: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-26 14:26:29.522132: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 14:26:29.524520: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f8a28f39a0 executing computations on platform Host. Devices:
2019-10-26 14:26:29.524596: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 14:26:29.526703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 14:26:29.526851: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 14:26:29.526937: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 14:26:29.527017: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 14:26:29.527096: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 14:26:29.527201: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 14:26:29.527258: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 14:26:29.527315: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 14:26:29.531227: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 14:26:29.531328: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 14:26:29.535421: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 14:26:29.535468: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 14:26:29.535492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 14:26:29.539488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11278 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
[I 14:26:32.716 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA-Copy1.ipynb
[I 14:26:35.191 LabApp] Starting buffering for 9a78cd76-1eeb-470a-9dcd-07782bac77a8:3cbc60977d8443028566687e2ac4e838
2019-10-26 14:26:35.565003: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-26 14:26:35.614546: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
[I 14:26:35.756 LabApp] Kernel restarted: 9a78cd76-1eeb-470a-9dcd-07782bac77a8
2019-10-26 14:26:35.868017: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 14:26:40.066 LabApp] Adapting from protocol version 5.1 (kernel 9a78cd76-1eeb-470a-9dcd-07782bac77a8) to 5.3 (client).
[I 14:26:40.066 LabApp] Restoring connection for 9a78cd76-1eeb-470a-9dcd-07782bac77a8:3cbc60977d8443028566687e2ac4e838
[I 14:26:40.067 LabApp] Replaying 6 buffered messages
2019-10-26 14:26:46.748974: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 14:26:46.771480: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-26 14:26:46.772195: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 14:26:46.773839: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 14:26:46.775134: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 14:26:46.775598: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 14:26:46.777281: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 14:26:46.778760: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 14:26:46.782188: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 14:26:46.784725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 14:26:47.008587: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fc84387d10 executing computations on platform CUDA. Devices:
2019-10-26 14:26:47.008649: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-26 14:26:47.012112: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 14:26:47.013229: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fc8445e780 executing computations on platform Host. Devices:
2019-10-26 14:26:47.013259: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 14:26:47.014261: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-26 14:26:47.014344: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 14:26:47.014386: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 14:26:47.014424: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 14:26:47.014462: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 14:26:47.014500: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 14:26:47.014537: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 14:26:47.014577: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 14:26:47.016393: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 14:26:47.016461: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 14:26:47.018731: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 14:26:47.018753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 14:26:47.018765: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 14:26:47.021075: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11277 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-26 14:26:52.923794: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-26 14:26:52.976553: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 14:26:53.236393: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 14:27:29.417 LabApp] Starting buffering for 0285bf89-571b-47ee-8381-e564b9e597e2:c4a763956ede491c98b574600c86bac1
[I 14:27:30.882 LabApp] Kernel restarted: 0285bf89-571b-47ee-8381-e564b9e597e2
[I 14:27:32.116 LabApp] Adapting from protocol version 5.1 (kernel 0285bf89-571b-47ee-8381-e564b9e597e2) to 5.3 (client).
[I 14:27:32.116 LabApp] Restoring connection for 0285bf89-571b-47ee-8381-e564b9e597e2:c4a763956ede491c98b574600c86bac1
[I 14:27:32.117 LabApp] Replaying 6 buffered messages
[I 14:27:35.712 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA.ipynb
2019-10-26 14:27:39.870184: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 14:27:39.888521: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-26 14:27:39.889238: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 14:27:39.891212: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 14:27:39.892802: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 14:27:39.893532: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 14:27:39.895575: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 14:27:39.897294: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 14:27:39.901182: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 14:27:39.904941: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 14:27:40.130152: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563a064587e0 executing computations on platform CUDA. Devices:
2019-10-26 14:27:40.130235: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K40c, Compute Capability 3.5
2019-10-26 14:27:40.136101: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 14:27:40.137876: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563a0652f290 executing computations on platform Host. Devices:
2019-10-26 14:27:40.137930: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 14:27:40.139327: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-26 14:27:40.139449: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 14:27:40.139510: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 14:27:40.139568: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 14:27:40.139625: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 14:27:40.139682: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 14:27:40.139740: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 14:27:40.139798: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 14:27:40.142021: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 14:27:40.142113: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 14:27:40.147344: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 14:27:40.147396: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 14:27:40.147409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 14:27:40.156163: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10726 MB memory) -> physical GPU (device: 0, name: Tesla K40c, pci bus id: 0000:03:00.0, compute capability: 3.5)
[I 14:28:04.052 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
2019-10-26 14:28:13.180769: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 14:28:13.394846: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 14:28:18.455 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA-Copy1.ipynb
[I 14:29:24.848 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA-Copy1.ipynb
[I 14:29:25.359 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA-Copy1.ipynb
[I 14:29:31.781 LabApp] Kernel interrupted: 9a78cd76-1eeb-470a-9dcd-07782bac77a8
[I 14:29:34.308 LabApp] Starting buffering for 9a78cd76-1eeb-470a-9dcd-07782bac77a8:3cbc60977d8443028566687e2ac4e838
[I 14:29:39.540 LabApp] Kernel restarted: 9a78cd76-1eeb-470a-9dcd-07782bac77a8
[I 14:29:39.985 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA.ipynb
[I 14:29:45.447 LabApp] Adapting from protocol version 5.1 (kernel 9a78cd76-1eeb-470a-9dcd-07782bac77a8) to 5.3 (client).
[I 14:29:45.448 LabApp] Restoring connection for 9a78cd76-1eeb-470a-9dcd-07782bac77a8:3cbc60977d8443028566687e2ac4e838
[I 14:29:45.457 LabApp] Replaying 96 buffered messages
2019-10-26 14:29:53.383643: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 14:29:53.408677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-26 14:29:53.653531: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 14:29:53.657938: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 14:29:53.659742: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 14:29:53.660558: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 14:29:53.662682: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 14:29:53.665438: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 14:29:53.669191: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 14:29:53.671860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 14:29:53.909871: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56136a830f60 executing computations on platform CUDA. Devices:
2019-10-26 14:29:53.909922: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-26 14:29:53.913340: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 14:29:53.914684: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56136a9079e0 executing computations on platform Host. Devices:
2019-10-26 14:29:53.914729: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 14:29:53.916671: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-26 14:29:53.916760: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 14:29:53.916800: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 14:29:53.916839: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 14:29:53.916876: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 14:29:53.916913: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 14:29:53.916951: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 14:29:53.916989: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 14:29:53.918792: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 14:29:53.918852: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 14:29:53.920913: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 14:29:53.920934: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 14:29:53.920945: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 14:29:53.929023: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11277 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-26 14:30:00.177019: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-26 14:30:00.228893: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 14:30:00.497850: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 14:30:04.092 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 14:30:18.472 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA-d_prop-05-gprop-025.ipynb
[I 14:31:12.223 LabApp] Kernel interrupted: 0285bf89-571b-47ee-8381-e564b9e597e2
[I 14:31:36.172 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA.ipynb
[I 14:32:05.072 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 14:32:18.683 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA-d_prop-025-gprop-05.ipynb
[I 14:32:49.698 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 14:32:49.947 LabApp] Kernel interrupted: 0285bf89-571b-47ee-8381-e564b9e597e2
[I 14:32:51.883 LabApp] KernelRestarter: restarting kernel (1/5), keep random ports
kernel 0285bf89-571b-47ee-8381-e564b9e597e2 restarted
[I 14:32:55.541 LabApp] Starting buffering for 0285bf89-571b-47ee-8381-e564b9e597e2:c4a763956ede491c98b574600c86bac1
[I 14:33:00.981 LabApp] Kernel restarted: 0285bf89-571b-47ee-8381-e564b9e597e2
[I 14:33:35.721 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA.ipynb
[W 14:34:00.983 LabApp] Timeout waiting for kernel_info_reply: 0285bf89-571b-47ee-8381-e564b9e597e2
[E 14:34:00.983 LabApp] Exception restarting kernel
    Traceback (most recent call last):
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/notebook/services/kernels/handlers.py", line 83, in post
        yield maybe_future(km.restart_kernel(kernel_id))
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/tornado/gen.py", line 735, in run
        value = future.result()
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/tornado/gen.py", line 742, in run
        yielded = self.gen.throw(*exc_info)  # type: ignore
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/notebook/services/kernels/kernelmanager.py", line 345, in restart_kernel
        yield future
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/tornado/gen.py", line 735, in run
        value = future.result()
    tornado.util.TimeoutError: Timeout waiting for restart
[E 14:34:00.985 LabApp] {
      "Host": "localhost:8187",
      "Connection": "keep-alive",
      "Content-Length": "0",
      "Accept": "application/json, text/javascript, */*; q=0.01",
      "Origin": "http://localhost:8187",
      "X-Requested-With": "XMLHttpRequest",
      "X-Xsrftoken": "2|2b997e67|29d4ea20755e92079558d090866cac7e|1571165215",
      "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.120 Safari/537.36",
      "Sec-Fetch-Mode": "cors",
      "Sec-Fetch-Site": "same-origin",
      "Referer": "http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb",
      "Accept-Encoding": "gzip, deflate, br",
      "Accept-Language": "en-US,en;q=0.9,fr;q=0.8",
      "Cookie": "_ga=GA1.1.2135320950.1566148815; username-localhost-8195=\"2|1:0|10:1570831591|23:username-localhost-8195|44:Y2Q0M2Y0YjJhMDQxNDQwZThhOGNjZTdhNDFiNDNkNjI=|4fc2d73bc3298178be788038ba7812e8e7e1ca4ae1891ffcc42a6bd3445055ab\"; _xsrf=2|2b997e67|29d4ea20755e92079558d090866cac7e|1571165215; username-localhost-8187=\"2|1:0|10:1571972576|23:username-localhost-8187|44:MGIyNmM0MzhlMTcxNDQ2OGJlNTczNjAwZDNlZjQ1NGE=|909460f83df7fd5d2e23ab9cf52e046079d5caccf76ccde023e9d50b06ebbeb1\"; username-localhost-8186=\"2|1:0|10:1572021258|23:username-localhost-8186|44:MTc4MTJjZWEwOTk3NDczMjkxNGE1MzNhYTVjYjAwOTI=|cba0fbd07d9368c13f1b3c575d3620ffa64e225e03effea9bb49e964131868b7\""
    }
[E 14:34:00.985 LabApp] 500 POST /api/kernels/0285bf89-571b-47ee-8381-e564b9e597e2/restart (::1) 65440.47ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 14:34:05.646 LabApp] Kernel shutdown: 0285bf89-571b-47ee-8381-e564b9e597e2
[I 14:34:05.845 LabApp] Kernel started: 00cb76cf-9ff9-45d7-bf9b-ca5e71a3b40a
[I 14:34:06.506 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 14:34:06.959 LabApp] Adapting from protocol version 5.1 (kernel 00cb76cf-9ff9-45d7-bf9b-ca5e71a3b40a) to 5.3 (client).
[I 14:34:19.608 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA-d_prop-025-gprop-05.ipynb
[I 14:34:32.656 LabApp] Starting buffering for 43cf827e-ce45-4069-9480-663293f6d5b5:cc3e7f9a89b74c979d34c0f5a6798bd4
[I 14:34:37.921 LabApp] Kernel restarted: 43cf827e-ce45-4069-9480-663293f6d5b5
[I 14:34:40.843 LabApp] Adapting from protocol version 5.1 (kernel 43cf827e-ce45-4069-9480-663293f6d5b5) to 5.3 (client).
[I 14:34:40.844 LabApp] Restoring connection for 43cf827e-ce45-4069-9480-663293f6d5b5:cc3e7f9a89b74c979d34c0f5a6798bd4
[I 14:34:40.844 LabApp] Replaying 67 buffered messages
[I 14:34:42.030 LabApp] Starting buffering for 00cb76cf-9ff9-45d7-bf9b-ca5e71a3b40a:c4a763956ede491c98b574600c86bac1
[I 14:34:42.476 LabApp] Kernel restarted: 00cb76cf-9ff9-45d7-bf9b-ca5e71a3b40a
[I 14:34:43.521 LabApp] Adapting from protocol version 5.1 (kernel 00cb76cf-9ff9-45d7-bf9b-ca5e71a3b40a) to 5.3 (client).
[I 14:34:43.522 LabApp] Restoring connection for 00cb76cf-9ff9-45d7-bf9b-ca5e71a3b40a:c4a763956ede491c98b574600c86bac1
[I 14:34:43.522 LabApp] Replaying 6 buffered messages
2019-10-26 14:34:49.766874: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 14:34:49.789053: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 14:34:49.789908: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 14:34:49.791798: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 14:34:49.795620: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 14:34:49.796379: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 14:34:49.798388: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 14:34:49.800208: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 14:34:49.803931: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 14:34:49.805917: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 14:34:50.040238: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558fd606e0f0 executing computations on platform CUDA. Devices:
2019-10-26 14:34:50.040288: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-26 14:34:50.043988: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 14:34:50.047340: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558fd6144ba0 executing computations on platform Host. Devices:
2019-10-26 14:34:50.047375: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 14:34:50.048385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 14:34:50.048493: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 14:34:50.048534: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 14:34:50.048572: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 14:34:50.048609: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 14:34:50.048646: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 14:34:50.048684: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 14:34:50.048722: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 14:34:50.050468: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 14:34:50.050532: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 14:34:50.052618: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 14:34:50.052639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 14:34:50.052650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 14:34:50.057744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11278 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-26 14:34:50.266742: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 14:34:50.284478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-26 14:34:50.285108: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 14:34:50.286866: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 14:34:50.288243: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 14:34:50.288874: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 14:34:50.291018: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 14:34:50.292762: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 14:34:50.296548: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 14:34:50.298381: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 14:34:50.481364: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c7a32be5e0 executing computations on platform CUDA. Devices:
2019-10-26 14:34:50.481412: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K40c, Compute Capability 3.5
2019-10-26 14:34:50.484697: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 14:34:50.485851: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c7a3395090 executing computations on platform Host. Devices:
2019-10-26 14:34:50.485880: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 14:34:50.487122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-26 14:34:50.487232: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 14:34:50.487278: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 14:34:50.487318: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 14:34:50.487360: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 14:34:50.487401: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 14:34:50.487442: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 14:34:50.487484: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 14:34:50.489359: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 14:34:50.489428: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 14:34:50.491512: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 14:34:50.491534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 14:34:50.491545: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 14:34:50.493683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10726 MB memory) -> physical GPU (device: 0, name: Tesla K40c, pci bus id: 0000:03:00.0, compute capability: 3.5)
2019-10-26 14:34:53.536657: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 14:34:53.719741: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 14:34:57.327797: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-26 14:34:57.375887: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 14:34:57.608049: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 14:35:35.853 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA.ipynb
[I 14:36:04.077 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 14:36:19.833 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA-d_prop-025-gprop-05.ipynb
[I 14:37:35.336 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA.ipynb
[I 14:38:04.126 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 14:38:19.678 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA-d_prop-025-gprop-05.ipynb
[I 14:38:22.370 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA-d_prop-025-gprop-05.ipynb
[I 14:38:23.651 LabApp] Kernel interrupted: 9a78cd76-1eeb-470a-9dcd-07782bac77a8
[I 14:38:26.317 LabApp] Starting buffering for 9a78cd76-1eeb-470a-9dcd-07782bac77a8:3cbc60977d8443028566687e2ac4e838
[I 14:38:28.168 LabApp] Kernel restarted: 9a78cd76-1eeb-470a-9dcd-07782bac77a8
[I 14:38:30.569 LabApp] Adapting from protocol version 5.1 (kernel 9a78cd76-1eeb-470a-9dcd-07782bac77a8) to 5.3 (client).
[I 14:38:30.570 LabApp] Restoring connection for 9a78cd76-1eeb-470a-9dcd-07782bac77a8:3cbc60977d8443028566687e2ac4e838
[I 14:38:30.570 LabApp] Replaying 6 buffered messages
2019-10-26 14:38:38.232336: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 14:38:38.249939: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-26 14:38:38.250678: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 14:38:38.252758: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 14:38:38.254243: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 14:38:38.254955: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 14:38:38.257014: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 14:38:38.258713: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 14:38:38.262520: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 14:38:38.264606: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 14:38:38.456206: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5561b9be27e0 executing computations on platform CUDA. Devices:
2019-10-26 14:38:38.456269: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-26 14:38:38.459885: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 14:38:38.460897: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5561b9cb9290 executing computations on platform Host. Devices:
2019-10-26 14:38:38.460925: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 14:38:38.461898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-26 14:38:38.462002: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 14:38:38.462048: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 14:38:38.462089: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 14:38:38.462132: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 14:38:38.462174: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 14:38:38.462216: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 14:38:38.462258: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 14:38:38.464467: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 14:38:38.464594: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 14:38:38.468063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 14:38:38.468103: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 14:38:38.468124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 14:38:38.471455: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11277 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-26 14:38:44.773109: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-26 14:38:44.820036: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 14:38:45.040160: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 14:39:36.135 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA.ipynb
[I 14:40:04.157 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 14:40:18.883 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA-d_prop-075-gprop-75.ipynb
[I 14:41:35.648 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA.ipynb
[I 14:42:04.175 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 14:42:18.530 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA-d_prop-075-gprop-75.ipynb
[I 14:43:35.405 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA.ipynb
[I 14:44:04.146 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 14:44:20.544 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA-d_prop-075-gprop-75.ipynb
[I 14:45:36.055 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA.ipynb
[I 14:46:04.155 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 14:46:20.027 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA-d_prop-075-gprop-75.ipynb
[I 14:47:35.493 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA.ipynb
[I 14:48:04.154 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 14:48:19.422 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA-d_prop-075-gprop-75.ipynb
[I 14:49:35.369 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA.ipynb
[I 14:50:04.148 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 14:50:19.649 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA-d_prop-075-gprop-75.ipynb
[I 14:51:36.130 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA.ipynb
[I 14:52:04.179 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 14:52:19.795 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA-d_prop-075-gprop-75.ipynb
[I 14:53:35.406 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA.ipynb
[I 14:54:04.130 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 14:54:18.481 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA-d_prop-075-gprop-75.ipynb
[I 14:55:35.418 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA.ipynb
[I 14:56:04.139 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 14:56:19.472 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA-d_prop-075-gprop-75.ipynb
[I 14:57:35.828 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA.ipynb
[I 14:58:04.158 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 14:58:18.839 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA-d_prop-075-gprop-75.ipynb
[I 14:59:35.552 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA.ipynb
[I 15:00:04.161 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 15:00:19.432 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA-d_prop-075-gprop-75.ipynb
[I 15:01:35.836 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA.ipynb
[I 15:02:04.167 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 15:02:19.735 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA-d_prop-075-gprop-75.ipynb
[I 15:04:04.160 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 15:04:19.704 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA-d_prop-075-gprop-75.ipynb
[I 15:06:04.144 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 15:06:20.107 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA-d_prop-075-gprop-75.ipynb
[I 15:08:04.178 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 15:10:04.456 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 15:12:04.431 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 15:14:04.435 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 15:16:04.466 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 15:18:04.516 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 15:20:04.467 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 15:22:04.449 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 15:24:04.442 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 15:26:04.520 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 15:28:04.484 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 15:30:04.472 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 15:32:04.455 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 15:34:04.489 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 15:36:04.447 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 15:38:04.461 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 15:40:04.483 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 15:42:04.464 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 15:44:04.473 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 15:46:04.470 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 15:48:04.509 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 15:50:04.473 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 15:52:04.518 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 15:54:04.479 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 15:56:04.489 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 15:58:04.475 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 16:00:04.473 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 16:02:04.541 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 16:04:04.506 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 16:06:04.489 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 16:08:04.475 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 16:10:04.494 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 16:12:04.528 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 16:14:04.502 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 16:16:04.480 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 16:18:04.523 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 16:20:04.477 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 16:22:04.490 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 16:24:04.528 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 16:26:04.507 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 16:28:04.484 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 16:30:04.521 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 16:32:04.495 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 16:34:04.504 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 16:36:04.510 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 16:38:04.529 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 16:40:04.521 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 16:42:04.539 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 16:44:04.511 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 16:46:04.507 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 16:48:04.569 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 16:50:04.503 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 16:51:50.238 LabApp] Kernel interrupted: 00cb76cf-9ff9-45d7-bf9b-ca5e71a3b40a
[I 16:52:04.781 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 16:53:36.191 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA.ipynb
[I 16:54:05.750 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 16:54:19.287 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA-d_prop-075-gprop-75.ipynb
[W 16:57:33.925 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 1.58ms referer=http://localhost:8187/tree/avgn_paper/notebooks/2.0-project-UMAP
[I 16:58:05.780 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[W 16:58:38.614 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 4.14ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/2.0-project-UMAP/canary-syllable-umap.ipynb
[W 16:58:39.464 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 3.13ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/2.0-project-UMAP/canary-syllable-umap.ipynb
[I 16:58:40.042 LabApp] Adapting from protocol version 5.1 (kernel 254383e0-ee3a-4f13-8f5c-605ef4fefd29) to 5.3 (client).
[I 17:00:05.277 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 17:00:43.602 LabApp] Saving file at /avgn_paper/notebooks/2.0-project-UMAP/canary-syllable-umap.ipynb
[I 17:02:05.888 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 17:04:05.869 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 17:04:44.018 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 17:05:40.092 LabApp] 302 GET /notebooks/avgn_paper/notebooks/6.0-neural-networks/ (::1) 0.98ms
[I 17:05:40.135 LabApp] 302 GET /notebooks/avgn_paper/notebooks/6.0-neural-networks (::1) 1.72ms
[W 17:05:40.740 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 1.58ms referer=http://localhost:8187/tree/avgn_paper/notebooks/6.0-neural-networks
[W 17:05:45.547 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.43ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 17:05:46.378 LabApp] Kernel started: 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24
[W 17:05:46.428 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 1.85ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 17:05:48.064 LabApp] Adapting from protocol version 5.1 (kernel 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24) to 5.3 (client).
[I 17:06:03.088 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 17:06:05.118 LabApp] Starting buffering for 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24:d11a9635afb642ada62c41550c5fbd49
[I 17:06:05.585 LabApp] Kernel restarted: 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24
[I 17:06:06.164 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 17:06:06.673 LabApp] Adapting from protocol version 5.1 (kernel 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24) to 5.3 (client).
[I 17:06:06.673 LabApp] Restoring connection for 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24:d11a9635afb642ada62c41550c5fbd49
[I 17:06:06.673 LabApp] Replaying 6 buffered messages
[I 17:06:07.519 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 17:06:07.762 LabApp] Copying avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb to /avgn_paper/notebooks/6.0-neural-networks
[I 17:06:10.238 LabApp] Kernel started: 7d92a0c8-94f8-47ee-afb2-3d39108cabb1
[W 17:06:10.461 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 2.48ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 17:06:11.221 LabApp] Adapting from protocol version 5.1 (kernel 7d92a0c8-94f8-47ee-afb2-3d39108cabb1) to 5.3 (client).
2019-10-26 17:06:16.351298: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 17:06:16.378680: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-26 17:06:16.379691: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 17:06:16.381693: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 17:06:16.383359: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 17:06:16.384361: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 17:06:16.387327: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 17:06:16.389770: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 17:06:16.395355: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 17:06:16.398079: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 17:06:16.687881: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559f0e8b49f0 executing computations on platform CUDA. Devices:
2019-10-26 17:06:16.687993: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-26 17:06:16.694862: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 17:06:16.697525: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559f0e98b4b0 executing computations on platform Host. Devices:
2019-10-26 17:06:16.697588: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 17:06:16.699120: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-26 17:06:16.699288: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 17:06:16.699366: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 17:06:16.699464: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 17:06:16.699544: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 17:06:16.699622: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 17:06:16.699703: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 17:06:16.699783: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 17:06:16.702247: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 17:06:16.702381: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 17:06:16.706185: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 17:06:16.706231: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 17:06:16.706254: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 17:06:16.709187: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 197 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-26 17:06:17.849795: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 197.75M (207355904 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2019-10-26 17:06:17.938528: F tensorflow/stream_executor/cuda/cuda_driver.cc:175] Check failed: err == cudaSuccess || err == cudaErrorInvalidValue Unexpected CUDA error: out of memory
[I 17:06:20.585 LabApp] KernelRestarter: restarting kernel (1/5), keep random ports
kernel 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24 restarted
[I 17:06:21.385 LabApp] Starting buffering for 43cf827e-ce45-4069-9480-663293f6d5b5:cc3e7f9a89b74c979d34c0f5a6798bd4
[I 17:06:23.732 LabApp] Kernel shutdown: 43cf827e-ce45-4069-9480-663293f6d5b5
[I 17:06:25.104 LabApp] Starting buffering for 9a78cd76-1eeb-470a-9dcd-07782bac77a8:3cbc60977d8443028566687e2ac4e838
[I 17:06:27.235 LabApp] Kernel shutdown: 9a78cd76-1eeb-470a-9dcd-07782bac77a8
[I 17:06:29.684 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 17:06:38.628 LabApp] Starting buffering for 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24:d11a9635afb642ada62c41550c5fbd49
[I 17:06:39.101 LabApp] Kernel restarted: 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24
[I 17:06:40.228 LabApp] Adapting from protocol version 5.1 (kernel 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24) to 5.3 (client).
[I 17:06:40.230 LabApp] Restoring connection for 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24:d11a9635afb642ada62c41550c5fbd49
[I 17:06:40.230 LabApp] Replaying 6 buffered messages
[I 17:06:41.893 LabApp] Starting buffering for 7d92a0c8-94f8-47ee-afb2-3d39108cabb1:903ac617a20b44ac8174ad2dbd028f9f
[I 17:06:42.338 LabApp] Kernel restarted: 7d92a0c8-94f8-47ee-afb2-3d39108cabb1
[I 17:06:43.389 LabApp] Adapting from protocol version 5.1 (kernel 7d92a0c8-94f8-47ee-afb2-3d39108cabb1) to 5.3 (client).
[I 17:06:43.390 LabApp] Restoring connection for 7d92a0c8-94f8-47ee-afb2-3d39108cabb1:903ac617a20b44ac8174ad2dbd028f9f
[I 17:06:43.390 LabApp] Replaying 6 buffered messages
2019-10-26 17:06:47.738713: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 17:06:47.764100: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 17:06:47.764919: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 17:06:47.768025: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 17:06:47.770582: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 17:06:47.771438: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 17:06:47.774905: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 17:06:47.777490: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 17:06:47.784222: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 17:06:47.787434: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 17:06:48.049745: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5575391b06f0 executing computations on platform CUDA. Devices:
2019-10-26 17:06:48.049810: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-26 17:06:48.054459: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 17:06:48.055721: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x557539287160 executing computations on platform Host. Devices:
2019-10-26 17:06:48.055780: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 17:06:48.056982: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 17:06:48.057069: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 17:06:48.057110: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 17:06:48.057147: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 17:06:48.057184: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 17:06:48.057222: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 17:06:48.057271: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 17:06:48.057310: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 17:06:48.059205: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 17:06:48.059271: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 17:06:48.061406: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 17:06:48.061427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 17:06:48.061438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 17:06:48.063590: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11278 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-26 17:06:50.187881: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 17:06:50.205134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-26 17:06:50.205728: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 17:06:50.207321: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 17:06:50.208606: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 17:06:50.209150: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 17:06:50.210875: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 17:06:50.212280: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 17:06:50.215492: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 17:06:50.220362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 17:06:50.448137: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55db922f6710 executing computations on platform CUDA. Devices:
2019-10-26 17:06:50.448195: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-26 17:06:50.451584: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 17:06:50.453135: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55db923cd160 executing computations on platform Host. Devices:
2019-10-26 17:06:50.453162: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 17:06:50.454239: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-26 17:06:50.454322: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 17:06:50.454357: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 17:06:50.454390: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 17:06:50.454423: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 17:06:50.454465: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 17:06:50.454499: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 17:06:50.454532: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 17:06:50.456956: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 17:06:50.457014: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 17:06:50.458904: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 17:06:50.458922: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 17:06:50.458931: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 17:06:50.460885: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11277 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-26 17:06:55.088752: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-26 17:06:55.139486: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 17:06:55.342701: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 17:06:57.552885: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-26 17:06:57.613391: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 17:06:57.842472: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 17:07:46.814 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 17:08:11.240 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 17:09:47.148 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 17:10:11.173 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 17:11:47.259 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 17:12:11.165 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 17:13:47.378 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 17:14:11.264 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 17:15:47.254 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 17:16:11.303 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 17:17:47.284 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 17:18:11.216 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 17:19:47.320 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 17:20:11.311 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 17:21:47.653 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 17:22:11.270 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 17:24:08.288 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 17:24:29.480 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 17:28:08.100 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 17:28:16.503 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 17:31:32.275 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 17:32:11.443 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 17:35:02.274 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 17:36:11.372 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 17:38:32.282 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 17:40:11.335 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 17:42:02.279 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 17:44:10.798 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 17:45:32.279 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 17:48:11.427 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 17:49:02.283 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 17:52:11.350 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 17:52:32.308 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 17:56:02.279 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 17:56:11.355 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 17:59:32.315 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 18:00:11.544 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 18:03:02.312 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 18:04:11.772 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 18:06:32.296 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 18:08:11.188 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 18:10:02.295 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 18:12:11.186 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 18:13:32.299 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 18:16:11.201 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 18:17:02.364 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 18:20:11.605 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 18:20:32.323 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 18:24:03.060 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 20:47:35.121 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 20:47:35.748 LabApp] Starting buffering for 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24:d11a9635afb642ada62c41550c5fbd49
[I 20:47:38.262 LabApp] Kernel restarted: 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24
[I 20:47:41.332 LabApp] Adapting from protocol version 5.1 (kernel 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24) to 5.3 (client).
[I 20:47:41.334 LabApp] Restoring connection for 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24:d11a9635afb642ada62c41550c5fbd49
[I 20:47:41.334 LabApp] Replaying 6 buffered messages
2019-10-26 20:47:53.242002: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 20:47:53.268331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 20:47:53.269562: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 20:47:53.271530: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 20:47:53.273098: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 20:47:53.273792: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 20:47:53.275862: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 20:47:53.277747: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 20:47:53.281708: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 20:47:53.283924: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 20:47:53.593250: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55aa394ebff0 executing computations on platform CUDA. Devices:
2019-10-26 20:47:53.593327: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-26 20:47:53.598453: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 20:47:53.600514: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55aa395c2a90 executing computations on platform Host. Devices:
2019-10-26 20:47:53.600603: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 20:47:53.602433: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 20:47:53.602598: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 20:47:53.602697: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 20:47:53.602789: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 20:47:53.602879: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 20:47:53.602971: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 20:47:53.603062: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 20:47:53.603177: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 20:47:53.606003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 20:47:53.606141: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 20:47:53.609734: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 20:47:53.609782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 20:47:53.609806: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 20:47:53.613196: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11278 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-26 20:48:00.850136: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-26 20:48:00.904189: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 20:48:01.115816: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 20:48:10.537 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 20:48:25.637 LabApp] Starting buffering for 7d92a0c8-94f8-47ee-afb2-3d39108cabb1:903ac617a20b44ac8174ad2dbd028f9f
[I 20:48:28.099 LabApp] Kernel restarted: 7d92a0c8-94f8-47ee-afb2-3d39108cabb1
[I 20:48:29.030 LabApp] Adapting from protocol version 5.1 (kernel 7d92a0c8-94f8-47ee-afb2-3d39108cabb1) to 5.3 (client).
[I 20:48:29.031 LabApp] Restoring connection for 7d92a0c8-94f8-47ee-afb2-3d39108cabb1:903ac617a20b44ac8174ad2dbd028f9f
[I 20:48:29.031 LabApp] Replaying 6 buffered messages
2019-10-26 20:48:35.062929: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 20:48:35.086908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-26 20:48:35.087655: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 20:48:35.089430: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 20:48:35.090776: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 20:48:35.091250: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 20:48:35.093215: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 20:48:35.094781: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 20:48:35.098702: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 20:48:35.100865: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 20:48:35.332112: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56207aca1f50 executing computations on platform CUDA. Devices:
2019-10-26 20:48:35.332177: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-26 20:48:35.337149: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 20:48:35.338450: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56207ad789d0 executing computations on platform Host. Devices:
2019-10-26 20:48:35.338498: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 20:48:35.339537: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-26 20:48:35.339650: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 20:48:35.339694: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 20:48:35.339736: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 20:48:35.339777: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 20:48:35.339818: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 20:48:35.339860: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 20:48:35.339902: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 20:48:35.342104: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 20:48:35.342219: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 20:48:35.344392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 20:48:35.344415: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 20:48:35.344427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 20:48:35.346542: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11277 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-26 20:48:42.682407: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-26 20:48:42.740716: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 20:48:42.970451: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 20:51:02.450 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 20:52:11.488 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 20:54:32.346 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 20:56:11.363 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 20:58:02.625 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 21:00:11.342 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 21:01:31.784 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 21:02:15.455 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 21:02:16.287 LabApp] Kernel interrupted: 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24
[I 21:02:18.318 LabApp] Starting buffering for 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24:d11a9635afb642ada62c41550c5fbd49
[I 21:02:20.571 LabApp] Kernel restarted: 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24
[I 21:02:21.727 LabApp] Adapting from protocol version 5.1 (kernel 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24) to 5.3 (client).
[I 21:02:21.727 LabApp] Restoring connection for 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24:d11a9635afb642ada62c41550c5fbd49
[I 21:02:21.728 LabApp] Replaying 7 buffered messages
2019-10-26 21:02:28.659039: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 21:02:28.676168: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 21:02:28.676899: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 21:02:28.678891: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 21:02:28.680536: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 21:02:28.681216: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 21:02:28.683212: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 21:02:28.684910: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 21:02:28.688739: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 21:02:28.690667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 21:02:28.938963: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564bc61b8600 executing computations on platform CUDA. Devices:
2019-10-26 21:02:28.939035: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-26 21:02:28.943478: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 21:02:28.945722: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564bc628f0e0 executing computations on platform Host. Devices:
2019-10-26 21:02:28.945786: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 21:02:28.946974: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 21:02:28.947061: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 21:02:28.947113: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 21:02:28.947152: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 21:02:28.947189: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 21:02:28.947226: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 21:02:28.947268: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 21:02:28.947306: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 21:02:28.949091: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 21:02:28.949153: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 21:02:28.951229: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 21:02:28.951261: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 21:02:28.951273: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 21:02:28.953410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11278 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-26 21:02:35.809066: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-26 21:02:35.867325: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 21:02:36.125018: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 21:04:11.432 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 21:05:02.577 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 21:08:11.338 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 21:08:32.350 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 21:12:03.115 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 21:12:11.335 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 21:15:32.464 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 21:16:11.858 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 21:19:02.845 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 21:20:11.590 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 21:22:33.180 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 21:24:11.584 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 21:26:03.368 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 21:28:11.718 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 21:29:32.601 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 21:32:11.622 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 21:33:02.376 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 21:36:12.402 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 21:36:32.615 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 21:40:02.451 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 21:40:11.647 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 21:43:32.775 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 21:44:11.674 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 21:47:02.439 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 21:48:12.962 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 21:50:32.583 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 21:52:11.593 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 21:54:03.016 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 21:56:11.591 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 21:57:32.772 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 22:00:10.760 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 22:00:24.510 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 22:00:25.876 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 22:00:31.400 LabApp] Kernel interrupted: 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24
[I 22:00:33.560 LabApp] Starting buffering for 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24:d11a9635afb642ada62c41550c5fbd49
[I 22:00:38.878 LabApp] Kernel restarted: 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24
[I 22:00:40.497 LabApp] Adapting from protocol version 5.1 (kernel 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24) to 5.3 (client).
[I 22:00:40.497 LabApp] Restoring connection for 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24:d11a9635afb642ada62c41550c5fbd49
[I 22:00:40.498 LabApp] Replaying 85 buffered messages
2019-10-26 22:00:50.479280: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 22:00:50.501321: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 22:00:50.502223: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 22:00:50.504168: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 22:00:50.505813: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 22:00:50.506469: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 22:00:50.508517: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 22:00:50.510220: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 22:00:50.514139: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 22:00:50.516367: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 22:00:50.808698: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560836383440 executing computations on platform CUDA. Devices:
2019-10-26 22:00:50.808780: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-26 22:00:50.813954: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 22:00:50.816280: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560836459ea0 executing computations on platform Host. Devices:
2019-10-26 22:00:50.816311: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 22:00:50.817749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 22:00:50.817861: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 22:00:50.817915: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 22:00:50.817966: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 22:00:50.818035: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 22:00:50.818088: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 22:00:50.818139: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 22:00:50.818193: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 22:00:50.820591: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 22:00:50.820671: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 22:00:50.823384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 22:00:50.823413: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 22:00:50.823429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 22:00:50.826130: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11278 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-26 22:00:58.149363: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-26 22:00:58.207074: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 22:00:58.481837: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 22:01:02.280 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 22:04:11.438 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 22:04:32.353 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 22:08:11.601 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 22:12:11.448 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 22:16:10.982 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 22:20:10.608 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 22:23:24.945 LabApp] Kernel interrupted: 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24
[I 22:23:30.199 LabApp] Starting buffering for 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24:d11a9635afb642ada62c41550c5fbd49
[I 22:23:32.258 LabApp] Kernel restarted: 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24
[I 22:23:33.740 LabApp] Adapting from protocol version 5.1 (kernel 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24) to 5.3 (client).
[I 22:23:33.741 LabApp] Restoring connection for 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24:d11a9635afb642ada62c41550c5fbd49
[I 22:23:33.741 LabApp] Replaying 7 buffered messages
2019-10-26 22:23:41.681887: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 22:23:41.708399: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 22:23:41.709781: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 22:23:41.713196: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 22:23:41.715744: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 22:23:41.717106: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 22:23:41.720612: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 22:23:41.723729: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 22:23:41.729562: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 22:23:41.732775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 22:23:42.022070: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x557ba9fdfe20 executing computations on platform CUDA. Devices:
2019-10-26 22:23:42.022152: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-26 22:23:42.027282: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 22:23:42.029104: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x557baa0b68b0 executing computations on platform Host. Devices:
2019-10-26 22:23:42.029163: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 22:23:42.030777: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 22:23:42.030944: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 22:23:42.031030: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 22:23:42.031131: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 22:23:42.031194: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 22:23:42.031268: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 22:23:42.031326: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 22:23:42.031393: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 22:23:42.034239: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 22:23:42.034373: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 22:23:42.037906: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 22:23:42.037930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 22:23:42.037942: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 22:23:42.041393: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11278 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-26 22:23:48.809436: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-26 22:23:48.868734: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 22:23:49.173491: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 22:23:50.473 LabApp] Kernel interrupted: 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24
[I 22:23:53.070 LabApp] Starting buffering for 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24:d11a9635afb642ada62c41550c5fbd49
[I 22:23:58.295 LabApp] Kernel restarted: 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24
[I 22:23:59.359 LabApp] Adapting from protocol version 5.1 (kernel 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24) to 5.3 (client).
[I 22:23:59.360 LabApp] Restoring connection for 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24:d11a9635afb642ada62c41550c5fbd49
[I 22:23:59.360 LabApp] Replaying 38 buffered messages
[I 22:24:06.117 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
2019-10-26 22:24:06.603640: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 22:24:06.625639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 22:24:06.626348: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 22:24:06.628042: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 22:24:06.629444: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 22:24:06.629948: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 22:24:06.631761: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 22:24:06.633267: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 22:24:06.636776: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 22:24:06.638640: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 22:24:06.896245: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e67a3c87c0 executing computations on platform CUDA. Devices:
2019-10-26 22:24:06.896315: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-26 22:24:06.900486: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 22:24:06.901827: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e67a49f270 executing computations on platform Host. Devices:
2019-10-26 22:24:06.901863: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 22:24:06.903505: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 22:24:06.903655: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 22:24:06.903741: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 22:24:06.903821: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 22:24:06.903901: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 22:24:06.903980: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 22:24:06.904085: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 22:24:06.904168: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 22:24:06.907400: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 22:24:06.907534: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 22:24:06.911612: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 22:24:06.911646: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 22:24:06.911663: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 22:24:06.914769: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11278 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
[I 22:24:09.883 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
2019-10-26 22:24:13.967155: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-26 22:24:14.017290: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 22:24:14.208931: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 22:26:06.696 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 22:26:40.631 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 22:26:41.001 LabApp] Kernel interrupted: 7d92a0c8-94f8-47ee-afb2-3d39108cabb1
[I 22:26:42.844 LabApp] Starting buffering for 7d92a0c8-94f8-47ee-afb2-3d39108cabb1:903ac617a20b44ac8174ad2dbd028f9f
[I 22:26:45.111 LabApp] Kernel restarted: 7d92a0c8-94f8-47ee-afb2-3d39108cabb1
[I 22:26:46.520 LabApp] Adapting from protocol version 5.1 (kernel 7d92a0c8-94f8-47ee-afb2-3d39108cabb1) to 5.3 (client).
[I 22:26:46.522 LabApp] Restoring connection for 7d92a0c8-94f8-47ee-afb2-3d39108cabb1:903ac617a20b44ac8174ad2dbd028f9f
[I 22:26:46.522 LabApp] Replaying 6 buffered messages
2019-10-26 22:26:54.765584: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 22:26:54.784333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-26 22:26:54.785595: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 22:26:54.788561: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 22:26:54.791270: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 22:26:54.791973: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 22:26:54.793991: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 22:26:54.796750: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 22:26:54.802360: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 22:26:54.804981: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 22:26:55.042166: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556045e8c1f0 executing computations on platform CUDA. Devices:
2019-10-26 22:26:55.042238: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-26 22:26:55.046695: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 22:26:55.048130: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556045f62ca0 executing computations on platform Host. Devices:
2019-10-26 22:26:55.048165: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 22:26:55.051012: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-26 22:26:55.051096: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 22:26:55.051165: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 22:26:55.051211: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 22:26:55.051256: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 22:26:55.051301: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 22:26:55.051345: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 22:26:55.051390: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 22:26:55.053502: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 22:26:55.053575: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 22:26:55.055979: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 22:26:55.056006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 22:26:55.056020: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 22:26:55.058833: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11277 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
[I 22:26:57.321 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
2019-10-26 22:27:01.714947: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-26 22:27:01.762627: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
[I 22:27:01.892 LabApp] Kernel interrupted: 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24
2019-10-26 22:27:01.953275: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 22:27:04.375 LabApp] Starting buffering for 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24:d11a9635afb642ada62c41550c5fbd49
[I 22:27:06.331 LabApp] Kernel restarted: 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24
[I 22:27:07.586 LabApp] Adapting from protocol version 5.1 (kernel 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24) to 5.3 (client).
[I 22:27:07.587 LabApp] Restoring connection for 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24:d11a9635afb642ada62c41550c5fbd49
[I 22:27:07.587 LabApp] Replaying 7 buffered messages
2019-10-26 22:27:14.523127: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 22:27:14.543178: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 22:27:14.543895: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 22:27:14.545556: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 22:27:14.546905: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 22:27:14.547453: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 22:27:14.549184: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 22:27:14.550598: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 22:27:14.554026: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 22:27:14.556122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 22:27:14.797770: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558648992f60 executing computations on platform CUDA. Devices:
2019-10-26 22:27:14.797831: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-26 22:27:14.801174: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 22:27:14.802279: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558648a699e0 executing computations on platform Host. Devices:
2019-10-26 22:27:14.802310: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 22:27:14.803383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 22:27:14.803480: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 22:27:14.803527: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 22:27:14.803564: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 22:27:14.803600: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 22:27:14.803637: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 22:27:14.803674: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 22:27:14.803711: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 22:27:14.805435: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 22:27:14.805498: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 22:27:14.807759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 22:27:14.807824: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 22:27:14.807850: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 22:27:14.811517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11278 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-26 22:27:21.783022: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-26 22:27:21.835836: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 22:27:22.077724: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 22:28:11.505 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 22:29:02.168 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 22:32:11.537 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 22:32:32.310 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 22:36:02.564 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 22:36:11.873 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 22:38:48.332 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 22:38:55.235 LabApp] Kernel interrupted: 7d92a0c8-94f8-47ee-afb2-3d39108cabb1
[I 22:39:31.411 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 22:40:11.544 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 22:40:12.669 LabApp] Kernel interrupted: 7d92a0c8-94f8-47ee-afb2-3d39108cabb1
[I 22:43:02.138 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 22:43:03.162 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 22:43:51.584 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 22:43:51.864 LabApp] Kernel interrupted: 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24
[I 22:43:54.513 LabApp] Starting buffering for 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24:d11a9635afb642ada62c41550c5fbd49
[I 22:43:56.681 LabApp] Kernel restarted: 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24
[I 22:43:57.988 LabApp] Adapting from protocol version 5.1 (kernel 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24) to 5.3 (client).
[I 22:43:57.989 LabApp] Restoring connection for 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24:d11a9635afb642ada62c41550c5fbd49
[I 22:43:57.989 LabApp] Replaying 6 buffered messages
2019-10-26 22:44:05.254782: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 22:44:05.271571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 22:44:05.272279: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 22:44:05.274220: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 22:44:05.275856: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 22:44:05.276509: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 22:44:05.278531: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 22:44:05.280265: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 22:44:05.284078: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 22:44:05.286002: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 22:44:05.555183: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562154492f50 executing computations on platform CUDA. Devices:
2019-10-26 22:44:05.555237: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-26 22:44:05.559282: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 22:44:05.561736: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5621545699d0 executing computations on platform Host. Devices:
2019-10-26 22:44:05.561791: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 22:44:05.563761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 22:44:05.563943: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 22:44:05.564037: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 22:44:05.564125: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 22:44:05.564216: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 22:44:05.564303: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 22:44:05.564391: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 22:44:05.564481: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 22:44:05.567654: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 22:44:05.567800: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 22:44:05.571843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 22:44:05.571888: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 22:44:05.571911: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 22:44:05.576847: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11278 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
[I 22:44:09.890 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
2019-10-26 22:44:13.113772: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-26 22:44:13.172028: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 22:44:13.395774: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 22:46:21.743 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 22:46:32.524 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 22:47:28.935 LabApp] Starting buffering for 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24:d11a9635afb642ada62c41550c5fbd49
[I 22:47:34.248 LabApp] Kernel restarted: 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24
[I 22:47:35.520 LabApp] Adapting from protocol version 5.1 (kernel 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24) to 5.3 (client).
[I 22:47:35.521 LabApp] Restoring connection for 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24:d11a9635afb642ada62c41550c5fbd49
[I 22:47:35.521 LabApp] Replaying 31 buffered messages
2019-10-26 22:47:43.853923: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 22:47:43.875984: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 22:47:43.876974: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 22:47:43.878956: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 22:47:43.880521: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 22:47:43.881270: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 22:47:43.883386: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 22:47:43.885273: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 22:47:43.889146: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 22:47:43.891381: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 22:47:44.128772: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a009960740 executing computations on platform CUDA. Devices:
2019-10-26 22:47:44.128839: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-26 22:47:44.133120: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 22:47:44.134670: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a009a371d0 executing computations on platform Host. Devices:
2019-10-26 22:47:44.134702: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 22:47:44.135873: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 22:47:44.135969: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 22:47:44.136015: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 22:47:44.136056: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 22:47:44.136097: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 22:47:44.136138: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 22:47:44.136191: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 22:47:44.136234: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 22:47:44.137999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 22:47:44.138066: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 22:47:44.140179: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 22:47:44.140200: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 22:47:44.140212: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 22:47:44.142396: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11278 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-26 22:47:51.439914: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-26 22:47:51.498943: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 22:47:51.736223: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 22:48:11.470 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 22:49:52.837 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 22:50:01.944 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 22:52:05.280 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 22:52:11.865 LabApp] Starting buffering for 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24:d11a9635afb642ada62c41550c5fbd49
[I 22:52:17.182 LabApp] Kernel restarted: 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24
[I 22:52:19.635 LabApp] Adapting from protocol version 5.1 (kernel 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24) to 5.3 (client).
[I 22:52:19.637 LabApp] Restoring connection for 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24:d11a9635afb642ada62c41550c5fbd49
[I 22:52:19.637 LabApp] Replaying 81 buffered messages
2019-10-26 22:52:31.081272: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 22:52:31.101974: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 22:52:31.102916: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 22:52:31.104849: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 22:52:31.106411: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 22:52:31.107142: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 22:52:31.109144: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 22:52:31.110862: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 22:52:31.114692: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 22:52:31.117899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 22:52:31.388923: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5579acc1e9b0 executing computations on platform CUDA. Devices:
2019-10-26 22:52:31.389033: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-26 22:52:31.395556: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 22:52:31.397802: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5579accf5450 executing computations on platform Host. Devices:
2019-10-26 22:52:31.397855: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 22:52:31.401350: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 22:52:31.401555: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 22:52:31.401653: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 22:52:31.401745: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 22:52:31.401833: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 22:52:31.401924: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 22:52:31.402025: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 22:52:31.402107: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 22:52:31.405443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 22:52:31.405590: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 22:52:31.409812: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 22:52:31.409858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 22:52:31.409881: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 22:52:31.413667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11278 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-26 22:52:38.775541: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-26 22:52:38.834373: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 22:52:39.069255: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 22:53:04.608 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 22:53:32.696 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 22:53:55.965 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 22:53:57.077 LabApp] Starting buffering for 7d92a0c8-94f8-47ee-afb2-3d39108cabb1:903ac617a20b44ac8174ad2dbd028f9f
[I 22:54:02.406 LabApp] Kernel restarted: 7d92a0c8-94f8-47ee-afb2-3d39108cabb1
[I 22:54:03.655 LabApp] Adapting from protocol version 5.1 (kernel 7d92a0c8-94f8-47ee-afb2-3d39108cabb1) to 5.3 (client).
[I 22:54:03.657 LabApp] Restoring connection for 7d92a0c8-94f8-47ee-afb2-3d39108cabb1:903ac617a20b44ac8174ad2dbd028f9f
[I 22:54:03.657 LabApp] Replaying 21 buffered messages
2019-10-26 22:54:12.173778: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 22:54:12.192910: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-26 22:54:12.193790: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 22:54:12.195879: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 22:54:12.198513: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 22:54:12.199669: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 22:54:12.203557: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 22:54:12.206955: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 22:54:12.212612: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 22:54:12.215484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 22:54:12.467836: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559cdfffc1a0 executing computations on platform CUDA. Devices:
2019-10-26 22:54:12.467904: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-26 22:54:12.472057: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 22:54:12.473374: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559ce00d2c50 executing computations on platform Host. Devices:
2019-10-26 22:54:12.473414: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 22:54:12.474678: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-26 22:54:12.474797: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 22:54:12.474858: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 22:54:12.474916: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 22:54:12.474975: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 22:54:12.475031: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 22:54:12.475089: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 22:54:12.475164: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 22:54:12.477318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 22:54:12.477406: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 22:54:12.480069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 22:54:12.480107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 22:54:12.480123: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 22:54:12.482727: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11277 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-26 22:54:19.904235: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-26 22:54:19.967034: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 22:54:20.236782: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[W 22:55:57.950 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 1.83ms referer=http://localhost:8187/tree/avgn_paper/notebooks/6.0-neural-networks
[W 22:56:07.196 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 1.99ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA.ipynb
[I 22:56:07.974 LabApp] Kernel started: c7c5f677-671e-4d0c-96a1-7e75dc661e86
[W 22:56:08.158 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 2.08ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA.ipynb
[I 22:56:09.010 LabApp] Adapting from protocol version 5.1 (kernel c7c5f677-671e-4d0c-96a1-7e75dc661e86) to 5.3 (client).
[I 22:56:11.601 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 22:56:12.219 LabApp] Copying avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA.ipynb to /avgn_paper/notebooks/6.0-neural-networks
[W 22:56:13.976 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 2.86ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA-Copy1.ipynb
[I 22:56:14.797 LabApp] Kernel started: 83e248ec-5177-47a1-b407-613b592bb354
[I 22:56:15.352 LabApp] Starting buffering for c7c5f677-671e-4d0c-96a1-7e75dc661e86:3e4b7c132898400c8ac9af207b356551
[I 22:56:15.745 LabApp] Adapting from protocol version 5.1 (kernel 83e248ec-5177-47a1-b407-613b592bb354) to 5.3 (client).
[I 22:57:02.604 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 22:57:53.884 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA-add_gx_loss_to_D.ipynb
[I 22:58:15.135 LabApp] Kernel interrupted: 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24
[I 22:58:17.181 LabApp] Starting buffering for 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24:d11a9635afb642ada62c41550c5fbd49
[I 22:58:19.512 LabApp] Kernel shutdown: 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24
[I 22:58:27.070 LabApp] Starting buffering for 83e248ec-5177-47a1-b407-613b592bb354:083a49f75f914da58d5ce3115d465482
[I 22:58:27.527 LabApp] Kernel restarted: 83e248ec-5177-47a1-b407-613b592bb354
[I 22:58:28.695 LabApp] Adapting from protocol version 5.1 (kernel 83e248ec-5177-47a1-b407-613b592bb354) to 5.3 (client).
[I 22:58:28.696 LabApp] Restoring connection for 83e248ec-5177-47a1-b407-613b592bb354:083a49f75f914da58d5ce3115d465482
[I 22:58:28.696 LabApp] Replaying 6 buffered messages
2019-10-26 22:58:35.828466: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 22:58:35.858572: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-26 22:58:35.859438: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 22:58:35.861311: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 22:58:35.862848: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 22:58:35.863464: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 22:58:35.865353: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 22:58:35.866915: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 22:58:35.870518: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 22:58:35.874178: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 22:58:36.155579: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564f515b6110 executing computations on platform CUDA. Devices:
2019-10-26 22:58:36.155635: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-26 22:58:36.159774: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 22:58:36.161843: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564f5168cbc0 executing computations on platform Host. Devices:
2019-10-26 22:58:36.161900: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 22:58:36.163343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-26 22:58:36.163478: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 22:58:36.163549: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 22:58:36.163616: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 22:58:36.163684: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 22:58:36.163751: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 22:58:36.163821: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 22:58:36.163894: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 22:58:36.166041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 22:58:36.166156: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 22:58:36.169960: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 22:58:36.170006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 22:58:36.170030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 22:58:36.173835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 197 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-26 22:58:37.469591: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 197.75M (207355904 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2019-10-26 22:58:37.673621: F tensorflow/stream_executor/cuda/cuda_driver.cc:175] Check failed: err == cudaSuccess || err == cudaErrorInvalidValue Unexpected CUDA error: out of memory
[I 22:58:39.527 LabApp] KernelRestarter: restarting kernel (1/5), keep random ports
kernel 83e248ec-5177-47a1-b407-613b592bb354 restarted
[I 22:59:08.034 LabApp] KernelRestarter: restarting kernel (1/5), keep random ports
[I 22:59:20.407 LabApp] KernelRestarter: restarting kernel (1/5), keep random ports
kernel 7d92a0c8-94f8-47ee-afb2-3d39108cabb1 restarted
[I 22:59:24.773 LabApp] Starting buffering for 83e248ec-5177-47a1-b407-613b592bb354:083a49f75f914da58d5ce3115d465482
[I 22:59:25.349 LabApp] Kernel restarted: 83e248ec-5177-47a1-b407-613b592bb354
[I 22:59:26.612 LabApp] Adapting from protocol version 5.1 (kernel 83e248ec-5177-47a1-b407-613b592bb354) to 5.3 (client).
[I 22:59:26.614 LabApp] Restoring connection for 83e248ec-5177-47a1-b407-613b592bb354:083a49f75f914da58d5ce3115d465482
[I 22:59:26.614 LabApp] Replaying 6 buffered messages
2019-10-26 22:59:33.741745: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 22:59:34.772726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-26 22:59:34.773441: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 22:59:34.775262: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 22:59:34.776652: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 22:59:34.777189: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 22:59:34.779069: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 22:59:34.780658: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 22:59:34.784461: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 22:59:34.786293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 22:59:35.011049: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a1dbcb25c0 executing computations on platform CUDA. Devices:
2019-10-26 22:59:35.011151: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-26 22:59:35.015671: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 22:59:35.017688: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a1dbd890a0 executing computations on platform Host. Devices:
2019-10-26 22:59:35.017723: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 22:59:35.018699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-26 22:59:35.018798: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 22:59:35.018840: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 22:59:35.018879: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 22:59:35.018932: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 22:59:35.018972: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 22:59:35.019011: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 22:59:35.019051: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 22:59:35.020716: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 22:59:35.020784: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 22:59:35.022866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 22:59:35.022887: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 22:59:35.022899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 22:59:35.025225: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-26 22:59:41.089861: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-26 22:59:41.129591: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 22:59:41.325378: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 23:00:11.081 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[E 23:00:12.444 LabApp] Exception restarting kernel
    Traceback (most recent call last):
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/notebook/services/kernels/handlers.py", line 83, in post
        yield maybe_future(km.restart_kernel(kernel_id))
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/tornado/gen.py", line 735, in run
        value = future.result()
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/tornado/gen.py", line 209, in wrapper
        yielded = next(result)
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/notebook/services/kernels/kernelmanager.py", line 307, in restart_kernel
        self._check_kernel_id(kernel_id)
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/notebook/services/kernels/kernelmanager.py", line 387, in _check_kernel_id
        raise web.HTTPError(404, u'Kernel does not exist: %s' % kernel_id)
    tornado.web.HTTPError: HTTP 404: Not Found (Kernel does not exist: 7dc8c56d-98ee-4747-93b7-6b92fc8f3e24)
[E 23:00:12.445 LabApp] {
      "Host": "localhost:8187",
      "Connection": "keep-alive",
      "Content-Length": "0",
      "Accept": "application/json, text/javascript, */*; q=0.01",
      "Origin": "http://localhost:8187",
      "X-Requested-With": "XMLHttpRequest",
      "X-Xsrftoken": "2|2b997e67|29d4ea20755e92079558d090866cac7e|1571165215",
      "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.120 Safari/537.36",
      "Sec-Fetch-Mode": "cors",
      "Sec-Fetch-Site": "same-origin",
      "Referer": "http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb",
      "Accept-Encoding": "gzip, deflate, br",
      "Accept-Language": "en-US,en;q=0.9,fr;q=0.8",
      "Cookie": "_ga=GA1.1.2135320950.1566148815; username-localhost-8195=\"2|1:0|10:1570831591|23:username-localhost-8195|44:Y2Q0M2Y0YjJhMDQxNDQwZThhOGNjZTdhNDFiNDNkNjI=|4fc2d73bc3298178be788038ba7812e8e7e1ca4ae1891ffcc42a6bd3445055ab\"; _xsrf=2|2b997e67|29d4ea20755e92079558d090866cac7e|1571165215; username-localhost-8187=\"2|1:0|10:1571972576|23:username-localhost-8187|44:MGIyNmM0MzhlMTcxNDQ2OGJlNTczNjAwZDNlZjQ1NGE=|909460f83df7fd5d2e23ab9cf52e046079d5caccf76ccde023e9d50b06ebbeb1\"; username-localhost-8186=\"2|1:0|10:1572148972|23:username-localhost-8186|44:MjAwMmFlOWIxYTRhNDc4ZmFiNDAzOTg3ODBmYzEyOTQ=|c0f3007a6fdd6628418763a8293ba019d9531ba148601913203f1e0121fd51ea\""
    }
[E 23:00:12.445 LabApp] 500 POST /api/kernels/7dc8c56d-98ee-4747-93b7-6b92fc8f3e24/restart (::1) 1.81ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[W 23:00:12.482 LabApp] 404 DELETE /api/sessions/4d888a8c-741c-4f77-8869-e51c7c7daf77 (::1): Session not found: session_id='4d888a8c-741c-4f77-8869-e51c7c7daf77'
[W 23:00:12.482 LabApp] Session not found: session_id='4d888a8c-741c-4f77-8869-e51c7c7daf77'
[W 23:00:12.483 LabApp] 404 DELETE /api/sessions/4d888a8c-741c-4f77-8869-e51c7c7daf77 (::1) 1.38ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 23:00:12.573 LabApp] Kernel started: ee49669b-a43a-4d24-bcc6-256b78cb108e
[I 23:00:13.543 LabApp] Adapting from protocol version 5.1 (kernel ee49669b-a43a-4d24-bcc6-256b78cb108e) to 5.3 (client).
[I 23:00:15.005 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA-add_gx_loss_to_D.ipynb
[I 23:00:33.582 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy1.ipynb
[I 23:02:15.915 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA-add_gx_loss_to_D.ipynb
[I 23:04:11.715 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 23:04:14.909 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA-add_gx_loss_to_D.ipynb
[I 23:04:24.315 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 23:04:27.748 LabApp] Starting buffering for ee49669b-a43a-4d24-bcc6-256b78cb108e:d11a9635afb642ada62c41550c5fbd49
[I 23:04:28.302 LabApp] Kernel restarted: ee49669b-a43a-4d24-bcc6-256b78cb108e
[I 23:04:29.522 LabApp] Adapting from protocol version 5.1 (kernel ee49669b-a43a-4d24-bcc6-256b78cb108e) to 5.3 (client).
[I 23:04:29.523 LabApp] Restoring connection for ee49669b-a43a-4d24-bcc6-256b78cb108e:d11a9635afb642ada62c41550c5fbd49
[I 23:04:29.523 LabApp] Replaying 6 buffered messages
2019-10-26 23:04:37.553257: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 23:04:38.099024: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 23:04:38.100091: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 23:04:38.102923: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 23:04:38.105167: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 23:04:38.106100: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 23:04:38.109394: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 23:04:38.111738: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 23:04:38.117056: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 23:04:38.119591: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 23:04:38.349995: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560fa9a04220 executing computations on platform CUDA. Devices:
2019-10-26 23:04:38.350043: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-26 23:04:38.353561: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 23:04:38.355889: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560fa9adacb0 executing computations on platform Host. Devices:
2019-10-26 23:04:38.355946: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 23:04:38.358000: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 23:04:38.358145: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 23:04:38.358229: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 23:04:38.358308: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 23:04:38.358387: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 23:04:38.358465: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 23:04:38.358543: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 23:04:38.358624: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 23:04:38.361887: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 23:04:38.362031: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 23:04:38.365937: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 23:04:38.365984: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 23:04:38.366007: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 23:04:38.369938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-26 23:04:45.880512: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-26 23:04:45.943439: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 23:04:46.230080: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 23:06:16.106 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA-add_gx_loss_to_D.ipynb
[I 23:08:11.281 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 23:08:15.041 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA-add_gx_loss_to_D.ipynb
[I 23:10:15.392 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 23:10:15.648 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA-add_gx_loss_to_D.ipynb
[W 23:10:25.668 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 6.14ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/1.0-starling-to-tfrecord_32.ipynb
[I 23:10:26.170 LabApp] Adapting from protocol version 5.1 (kernel 45fdaabd-cd04-44ae-b12b-197e86cc5654) to 5.3 (client).
[I 23:10:26.171 LabApp] Discarding 1 buffered messages for 45fdaabd-cd04-44ae-b12b-197e86cc5654:1cb1c595dbd546aaa9029b3f724b01e5
[W 23:10:26.221 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 1.50ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/1.0-starling-to-tfrecord_32.ipynb
[I 23:10:42.032 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/1.0-starling-to-tfrecord_32.ipynb
[I 23:10:46.948 LabApp] Starting buffering for 45fdaabd-cd04-44ae-b12b-197e86cc5654:2e35447528ae4421896831aefeb4a559
[I 23:10:47.428 LabApp] Kernel restarted: 45fdaabd-cd04-44ae-b12b-197e86cc5654
[I 23:10:49.197 LabApp] Adapting from protocol version 5.1 (kernel 45fdaabd-cd04-44ae-b12b-197e86cc5654) to 5.3 (client).
[I 23:10:49.198 LabApp] Restoring connection for 45fdaabd-cd04-44ae-b12b-197e86cc5654:2e35447528ae4421896831aefeb4a559
[I 23:10:49.198 LabApp] Replaying 6 buffered messages
[I 23:10:52.719 LabApp] Starting buffering for 7d92a0c8-94f8-47ee-afb2-3d39108cabb1:903ac617a20b44ac8174ad2dbd028f9f
[I 23:11:02.961 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 23:11:03.239 LabApp] Copying avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb to /avgn_paper/notebooks/6.0-neural-networks
[W 23:11:04.578 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 6.30ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy2.ipynb
[I 23:11:05.659 LabApp] Kernel started: 1c36c4a1-33a5-4c99-9b37-4a0b14744a92
[W 23:11:05.685 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 1.97ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy2.ipynb
[I 23:11:06.548 LabApp] Adapting from protocol version 5.1 (kernel 1c36c4a1-33a5-4c99-9b37-4a0b14744a92) to 5.3 (client).
[I 23:11:37.627 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA.ipynb
[I 23:11:50.179 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA.ipynb
[I 23:12:11.542 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 23:12:14.923 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA-add_gx_loss_to_D.ipynb
[I 23:12:26.672 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/1.0-starling-to-tfrecord_32.ipynb
2019-10-26 23:12:28.970343: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 23:12:28.991397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-26 23:12:28.992222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 23:12:28.993064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 2 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
2019-10-26 23:12:28.993894: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 3 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-26 23:12:28.994803: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 23:12:28.996733: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 23:12:28.998381: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 23:12:28.999097: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 23:12:29.001234: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 23:12:29.002997: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 23:12:29.006835: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 23:12:29.015439: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1, 2, 3
2019-10-26 23:12:29.578052: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55706382aa30 executing computations on platform CUDA. Devices:
2019-10-26 23:12:29.578114: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-26 23:12:29.578125: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (1): TITAN Xp, Compute Capability 6.1
2019-10-26 23:12:29.578134: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (2): Tesla K40c, Compute Capability 3.5
2019-10-26 23:12:29.578142: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (3): Tesla K40c, Compute Capability 3.5
2019-10-26 23:12:29.583046: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 23:12:29.583968: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5570645ce130 executing computations on platform Host. Devices:
2019-10-26 23:12:29.583995: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 23:12:29.586326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-26 23:12:29.586980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 23:12:29.587739: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 2 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
2019-10-26 23:12:29.588443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 3 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-26 23:12:29.588542: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 23:12:29.588583: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 23:12:29.588621: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 23:12:29.588659: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 23:12:29.588697: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 23:12:29.588734: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 23:12:29.588772: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 23:12:29.594778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1, 2, 3
2019-10-26 23:12:29.594844: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 23:12:29.598580: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 23:12:29.598601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 1 2 3 
2019-10-26 23:12:29.598613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N Y N N 
2019-10-26 23:12:29.598621: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 1:   Y N N N 
2019-10-26 23:12:29.598629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 2:   N N N Y 
2019-10-26 23:12:29.598637: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 3:   N N Y N 
2019-10-26 23:12:29.602318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 204 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-26 23:12:29.603265: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 206 MB memory) -> physical GPU (device: 1, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-26 23:12:29.604273: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 232 MB memory) -> physical GPU (device: 2, name: Tesla K40c, pci bus id: 0000:02:00.0, compute capability: 3.5)
2019-10-26 23:12:29.605212: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 192 MB memory) -> physical GPU (device: 3, name: Tesla K40c, pci bus id: 0000:03:00.0, compute capability: 3.5)
[I 23:12:48.014 LabApp] Starting buffering for 1c36c4a1-33a5-4c99-9b37-4a0b14744a92:5d0e2d1ac93a46308a271d4311c18ce0
[I 23:12:48.465 LabApp] Kernel restarted: 1c36c4a1-33a5-4c99-9b37-4a0b14744a92
[I 23:12:50.465 LabApp] Adapting from protocol version 5.1 (kernel 1c36c4a1-33a5-4c99-9b37-4a0b14744a92) to 5.3 (client).
[I 23:12:50.466 LabApp] Restoring connection for 1c36c4a1-33a5-4c99-9b37-4a0b14744a92:5d0e2d1ac93a46308a271d4311c18ce0
[I 23:12:50.466 LabApp] Replaying 6 buffered messages
[I 23:13:00.029 LabApp] Kernel interrupted: ee49669b-a43a-4d24-bcc6-256b78cb108e
2019-10-26 23:13:00.566417: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 23:13:00.582345: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 23:13:00.582828: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 23:13:00.584423: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 23:13:00.585717: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 23:13:00.586287: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 23:13:00.588025: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 23:13:00.589477: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 23:13:00.592786: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 23:13:00.594201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 23:13:00.774104: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558ced9a9190 executing computations on platform CUDA. Devices:
2019-10-26 23:13:00.774158: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-26 23:13:00.777112: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 23:13:00.777885: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558ceda7fc40 executing computations on platform Host. Devices:
2019-10-26 23:13:00.777911: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 23:13:00.778862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 23:13:00.778930: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 23:13:00.778965: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 23:13:00.778997: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 23:13:00.779029: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 23:13:00.779061: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 23:13:00.779117: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 23:13:00.779154: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 23:13:00.780552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 23:13:00.780604: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 23:13:00.782321: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 23:13:00.782338: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 23:13:00.782347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 23:13:00.783810: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 49 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
[I 23:13:04.971 LabApp] Starting buffering for ee49669b-a43a-4d24-bcc6-256b78cb108e:d11a9635afb642ada62c41550c5fbd49
[I 23:13:06.985 LabApp] Kernel shutdown: ee49669b-a43a-4d24-bcc6-256b78cb108e
[I 23:13:09.002 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA.ipynb
[I 23:13:10.554 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 23:13:11.980 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 23:13:15.488 LabApp] Starting buffering for 1c36c4a1-33a5-4c99-9b37-4a0b14744a92:5d0e2d1ac93a46308a271d4311c18ce0
[I 23:13:16.548 LabApp] Kernel restarted: 1c36c4a1-33a5-4c99-9b37-4a0b14744a92
[I 23:13:17.826 LabApp] Adapting from protocol version 5.1 (kernel 1c36c4a1-33a5-4c99-9b37-4a0b14744a92) to 5.3 (client).
[I 23:13:17.827 LabApp] Restoring connection for 1c36c4a1-33a5-4c99-9b37-4a0b14744a92:5d0e2d1ac93a46308a271d4311c18ce0
[I 23:13:17.827 LabApp] Replaying 6 buffered messages
2019-10-26 23:13:25.216627: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 23:13:25.236380: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 23:13:25.237022: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 23:13:25.239343: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 23:13:25.241032: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 23:13:25.241739: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 23:13:25.243672: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 23:13:25.245259: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 23:13:25.249138: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 23:13:25.251231: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 23:13:25.466166: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e1eb4a50c0 executing computations on platform CUDA. Devices:
2019-10-26 23:13:25.466234: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-26 23:13:25.472370: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 23:13:25.474326: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e1eb57bb60 executing computations on platform Host. Devices:
2019-10-26 23:13:25.474403: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 23:13:25.475798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 23:13:25.475923: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 23:13:25.476012: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 23:13:25.476093: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 23:13:25.476174: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 23:13:25.476254: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 23:13:25.476335: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 23:13:25.476419: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 23:13:25.479323: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 23:13:25.479447: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 23:13:25.482981: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 23:13:25.483025: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 23:13:25.483049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 23:13:25.487262: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11278 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
[I 23:13:47.891 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA.ipynb
[I 23:13:51.186 LabApp] Starting buffering for 1c36c4a1-33a5-4c99-9b37-4a0b14744a92:5d0e2d1ac93a46308a271d4311c18ce0
[I 23:13:52.448 LabApp] Kernel restarted: 1c36c4a1-33a5-4c99-9b37-4a0b14744a92
[I 23:13:53.945 LabApp] Adapting from protocol version 5.1 (kernel 1c36c4a1-33a5-4c99-9b37-4a0b14744a92) to 5.3 (client).
[I 23:13:53.946 LabApp] Restoring connection for 1c36c4a1-33a5-4c99-9b37-4a0b14744a92:5d0e2d1ac93a46308a271d4311c18ce0
[I 23:13:53.946 LabApp] Replaying 6 buffered messages
2019-10-26 23:14:02.799088: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 23:14:02.821731: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 23:14:02.822740: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 23:14:02.824734: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 23:14:02.826320: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 23:14:02.826989: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 23:14:02.829013: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 23:14:02.830703: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 23:14:02.834491: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 23:14:02.836673: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 23:14:03.039078: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55cfd06bbe30 executing computations on platform CUDA. Devices:
2019-10-26 23:14:03.039153: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-26 23:14:03.042899: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 23:14:03.043963: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55cfd07928c0 executing computations on platform Host. Devices:
2019-10-26 23:14:03.043994: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 23:14:03.045452: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 23:14:03.045606: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 23:14:03.045692: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 23:14:03.045757: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 23:14:03.045795: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 23:14:03.045832: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 23:14:03.045869: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 23:14:03.045908: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 23:14:03.048538: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 23:14:03.048665: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 23:14:03.051857: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 23:14:03.051879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 23:14:03.051890: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 23:14:03.053982: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11278 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-26 23:14:09.385179: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-26 23:14:09.438167: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 23:14:09.706760: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 23:14:16.075 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA-add_gx_loss_to_D.ipynb
[I 23:14:26.739 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/1.0-starling-to-tfrecord_32.ipynb
[I 23:15:06.624 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA.ipynb
[I 23:16:16.189 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA-add_gx_loss_to_D.ipynb
[I 23:17:06.612 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA.ipynb
[I 23:18:15.051 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA-add_gx_loss_to_D.ipynb
[I 23:19:06.351 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA.ipynb
[I 23:20:14.885 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA-add_gx_loss_to_D.ipynb
[I 23:20:39.569 LabApp] Kernel interrupted: 83e248ec-5177-47a1-b407-613b592bb354
[I 23:20:43.770 LabApp] Starting buffering for 83e248ec-5177-47a1-b407-613b592bb354:083a49f75f914da58d5ce3115d465482
[I 23:20:49.046 LabApp] Kernel shutdown: 83e248ec-5177-47a1-b407-613b592bb354
[I 23:21:01.178 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA.ipynb
[I 23:21:01.508 LabApp] Copying avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA.ipynb to /avgn_paper/notebooks/6.0-neural-networks
[W 23:21:03.353 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 4.80ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA-Copy1.ipynb
[I 23:21:04.427 LabApp] Kernel started: b6894d96-8bb4-481e-b283-e46995a13c20
[W 23:21:04.441 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 4.59ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA-Copy1.ipynb
[I 23:21:06.169 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA.ipynb
[I 23:21:07.276 LabApp] Adapting from protocol version 5.1 (kernel b6894d96-8bb4-481e-b283-e46995a13c20) to 5.3 (client).
[I 23:21:15.487 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA-Copy1.ipynb
[I 23:21:22.234 LabApp] Starting buffering for b6894d96-8bb4-481e-b283-e46995a13c20:d31a6ca15f5b4762afbb1d4d9c0f0627
[I 23:21:22.697 LabApp] Kernel restarted: b6894d96-8bb4-481e-b283-e46995a13c20
[I 23:21:24.403 LabApp] Adapting from protocol version 5.1 (kernel b6894d96-8bb4-481e-b283-e46995a13c20) to 5.3 (client).
[I 23:21:24.404 LabApp] Restoring connection for b6894d96-8bb4-481e-b283-e46995a13c20:d31a6ca15f5b4762afbb1d4d9c0f0627
[I 23:21:24.404 LabApp] Replaying 6 buffered messages
2019-10-26 23:21:36.766713: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 23:21:36.787144: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 23:21:36.788048: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 23:21:36.790170: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 23:21:36.791881: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 23:21:36.792670: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 23:21:36.794657: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 23:21:36.796401: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 23:21:36.800161: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 23:21:36.801799: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 23:21:37.038896: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a2daacb6c0 executing computations on platform CUDA. Devices:
2019-10-26 23:21:37.038989: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-26 23:21:37.045597: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 23:21:37.047780: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a2daba2130 executing computations on platform Host. Devices:
2019-10-26 23:21:37.047828: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 23:21:37.049107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 23:21:37.049217: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 23:21:37.049281: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 23:21:37.049340: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 23:21:37.049399: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 23:21:37.049458: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 23:21:37.049517: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 23:21:37.049576: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 23:21:37.051614: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 23:21:37.051716: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 23:21:37.054771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 23:21:37.054807: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 23:21:37.054826: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 23:21:37.057318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 197 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-26 23:21:38.382794: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 197.06M (206635008 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2019-10-26 23:21:38.553704: F tensorflow/stream_executor/cuda/cuda_driver.cc:175] Check failed: err == cudaSuccess || err == cudaErrorInvalidValue Unexpected CUDA error: out of memory
[I 23:21:40.699 LabApp] KernelRestarter: restarting kernel (1/5), keep random ports
kernel b6894d96-8bb4-481e-b283-e46995a13c20 restarted
[I 23:21:59.429 LabApp] KernelRestarter: restarting kernel (1/5), keep random ports
kernel 45fdaabd-cd04-44ae-b12b-197e86cc5654 restarted
[I 23:22:03.505 LabApp] Starting buffering for b6894d96-8bb4-481e-b283-e46995a13c20:d31a6ca15f5b4762afbb1d4d9c0f0627
[I 23:22:03.972 LabApp] Kernel restarted: b6894d96-8bb4-481e-b283-e46995a13c20
[I 23:22:05.078 LabApp] Adapting from protocol version 5.1 (kernel b6894d96-8bb4-481e-b283-e46995a13c20) to 5.3 (client).
[I 23:22:05.079 LabApp] Restoring connection for b6894d96-8bb4-481e-b283-e46995a13c20:d31a6ca15f5b4762afbb1d4d9c0f0627
[I 23:22:05.080 LabApp] Replaying 6 buffered messages
[I 23:22:09.814 LabApp] Kernel interrupted: 1c36c4a1-33a5-4c99-9b37-4a0b14744a92
2019-10-26 23:22:14.438942: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 23:22:14.996237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 23:22:14.997479: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 23:22:14.999337: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 23:22:15.000700: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 23:22:15.001221: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 23:22:15.003081: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 23:22:15.004600: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 23:22:15.008382: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 23:22:15.009866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 23:22:15.198002: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x565199b50cc0 executing computations on platform CUDA. Devices:
2019-10-26 23:22:15.198058: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-26 23:22:15.201748: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 23:22:15.203228: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x565199c27720 executing computations on platform Host. Devices:
2019-10-26 23:22:15.203260: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 23:22:15.204036: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 23:22:15.204121: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 23:22:15.204162: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 23:22:15.204211: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 23:22:15.204249: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 23:22:15.204286: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 23:22:15.204324: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 23:22:15.204362: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 23:22:15.205706: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 23:22:15.205770: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 23:22:15.207610: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 23:22:15.207632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 23:22:15.207644: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 23:22:15.209255: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 129 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
[I 23:22:15.218 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA-add_gx_loss_to_D.ipynb
2019-10-26 23:22:21.409049: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-26 23:22:21.450607: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 23:22:21.650758: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 23:22:22.458201: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2019-10-26 23:22:22.470204: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2019-10-26 23:22:22.470298: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[{{node StatefulPartitionedCall/sequential/conv2d/Conv2D}}]]
2019-10-26 23:22:22.474443: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2019-10-26 23:22:22.477513: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
[I 23:22:24.175 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA.ipynb
[I 23:23:04.369 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA-Copy1.ipynb
[I 23:23:24.208 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA.ipynb
[I 23:23:25.352 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA.ipynb
[I 23:23:27.437 LabApp] Starting buffering for 1c36c4a1-33a5-4c99-9b37-4a0b14744a92:5d0e2d1ac93a46308a271d4311c18ce0
[I 23:23:29.658 LabApp] Kernel restarted: 1c36c4a1-33a5-4c99-9b37-4a0b14744a92
[I 23:23:34.003 LabApp] Adapting from protocol version 5.1 (kernel 1c36c4a1-33a5-4c99-9b37-4a0b14744a92) to 5.3 (client).
[I 23:23:34.004 LabApp] Restoring connection for 1c36c4a1-33a5-4c99-9b37-4a0b14744a92:5d0e2d1ac93a46308a271d4311c18ce0
[I 23:23:34.004 LabApp] Replaying 6 buffered messages
2019-10-26 23:23:48.017867: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 23:23:48.592281: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 23:23:48.605547: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 23:23:48.607401: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 23:23:48.609002: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 23:23:48.623818: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 23:23:48.625772: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 23:23:48.627492: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 23:23:48.631245: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 23:23:48.633268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 23:23:48.857777: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d8461e3f60 executing computations on platform CUDA. Devices:
2019-10-26 23:23:48.857840: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-26 23:23:48.863369: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 23:23:48.865175: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d8462baa70 executing computations on platform Host. Devices:
2019-10-26 23:23:48.865210: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 23:23:48.866304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 23:23:48.866386: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 23:23:48.866425: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 23:23:48.866461: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 23:23:48.866505: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 23:23:48.866541: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 23:23:48.866578: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 23:23:48.866616: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 23:23:48.868278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 23:23:48.868342: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 23:23:48.870310: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 23:23:48.870342: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 23:23:48.870355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 23:23:48.872369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10944 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
[I 23:23:51.066 LabApp] Starting buffering for b6894d96-8bb4-481e-b283-e46995a13c20:d31a6ca15f5b4762afbb1d4d9c0f0627
[I 23:23:52.521 LabApp] Kernel restarted: b6894d96-8bb4-481e-b283-e46995a13c20
[I 23:23:54.014 LabApp] Adapting from protocol version 5.1 (kernel b6894d96-8bb4-481e-b283-e46995a13c20) to 5.3 (client).
[I 23:23:54.015 LabApp] Restoring connection for b6894d96-8bb4-481e-b283-e46995a13c20:d31a6ca15f5b4762afbb1d4d9c0f0627
[I 23:23:54.015 LabApp] Replaying 6 buffered messages
2019-10-26 23:23:55.127249: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-26 23:23:55.169999: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 23:23:55.445746: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 23:24:03.607464: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 23:24:04.121225: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-26 23:24:04.122156: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 23:24:04.124108: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 23:24:04.125442: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 23:24:04.126002: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 23:24:04.127804: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 23:24:04.129297: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 23:24:04.132748: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 23:24:04.134599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 23:24:04.381125: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555a21686220 executing computations on platform CUDA. Devices:
2019-10-26 23:24:04.381221: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-26 23:24:04.387250: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 23:24:04.388882: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555a2175ccb0 executing computations on platform Host. Devices:
2019-10-26 23:24:04.388917: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 23:24:04.390226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-26 23:24:04.390398: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 23:24:04.390434: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 23:24:04.390466: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 23:24:04.390498: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 23:24:04.390530: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 23:24:04.390562: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 23:24:04.390595: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 23:24:04.392485: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 23:24:04.392549: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 23:24:04.394383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 23:24:04.394401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 23:24:04.394411: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 23:24:04.396436: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-26 23:24:10.748111: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-26 23:24:10.789420: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 23:24:11.024351: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 23:25:04.785 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA-Copy1.ipynb
[I 23:25:05.804 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA.ipynb
[I 23:27:04.720 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA-Copy1.ipynb
[I 23:27:06.090 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA.ipynb
[I 23:29:04.731 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA-Copy1.ipynb
[I 23:29:06.074 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA.ipynb
[I 23:29:32.222 LabApp] Starting buffering for 1c36c4a1-33a5-4c99-9b37-4a0b14744a92:5d0e2d1ac93a46308a271d4311c18ce0
[I 23:29:37.996 LabApp] Kernel restarted: 1c36c4a1-33a5-4c99-9b37-4a0b14744a92
[I 23:29:40.723 LabApp] Adapting from protocol version 5.1 (kernel 1c36c4a1-33a5-4c99-9b37-4a0b14744a92) to 5.3 (client).
[I 23:29:40.724 LabApp] Restoring connection for 1c36c4a1-33a5-4c99-9b37-4a0b14744a92:5d0e2d1ac93a46308a271d4311c18ce0
[I 23:29:40.724 LabApp] Replaying 29 buffered messages
2019-10-26 23:29:53.916058: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 23:29:54.448316: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 23:29:54.449519: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 23:29:54.452307: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 23:29:54.454410: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 23:29:54.455432: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 23:29:54.458260: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 23:29:54.460822: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 23:29:54.466083: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 23:29:54.468615: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 23:29:54.708020: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564341fdae70 executing computations on platform CUDA. Devices:
2019-10-26 23:29:54.708079: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-26 23:29:54.711655: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 23:29:54.712834: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5643420b1900 executing computations on platform Host. Devices:
2019-10-26 23:29:54.712865: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 23:29:54.713934: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 23:29:54.714016: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 23:29:54.714058: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 23:29:54.714098: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 23:29:54.714137: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 23:29:54.714176: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 23:29:54.714218: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 23:29:54.714257: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 23:29:54.716677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 23:29:54.716790: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 23:29:54.720319: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 23:29:54.720343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 23:29:54.720355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 23:29:54.724181: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-26 23:30:00.716661: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-26 23:30:00.759461: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 23:30:00.960138: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 23:31:03.860 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA.ipynb
[I 23:31:04.798 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA-Copy1.ipynb
[I 23:31:05.865 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA.ipynb
[I 23:32:00.653 LabApp] Kernel interrupted: b6894d96-8bb4-481e-b283-e46995a13c20
[I 23:32:02.700 LabApp] Kernel interrupted: b6894d96-8bb4-481e-b283-e46995a13c20
[I 23:32:04.621 LabApp] Starting buffering for b6894d96-8bb4-481e-b283-e46995a13c20:d31a6ca15f5b4762afbb1d4d9c0f0627
[I 23:32:07.577 LabApp] Kernel restarted: b6894d96-8bb4-481e-b283-e46995a13c20
[I 23:32:10.142 LabApp] Adapting from protocol version 5.1 (kernel b6894d96-8bb4-481e-b283-e46995a13c20) to 5.3 (client).
[I 23:32:10.143 LabApp] Restoring connection for b6894d96-8bb4-481e-b283-e46995a13c20:d31a6ca15f5b4762afbb1d4d9c0f0627
[I 23:32:10.143 LabApp] Replaying 6 buffered messages
[I 23:32:20.268 LabApp] Kernel interrupted: b6894d96-8bb4-481e-b283-e46995a13c20
[I 23:32:24.086 LabApp] Starting buffering for b6894d96-8bb4-481e-b283-e46995a13c20:d31a6ca15f5b4762afbb1d4d9c0f0627
[I 23:32:25.104 LabApp] Kernel shutdown: b6894d96-8bb4-481e-b283-e46995a13c20
[E 23:32:35.708 LabApp] Exception restarting kernel
    Traceback (most recent call last):
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/notebook/services/kernels/handlers.py", line 83, in post
        yield maybe_future(km.restart_kernel(kernel_id))
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/tornado/gen.py", line 735, in run
        value = future.result()
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/tornado/gen.py", line 209, in wrapper
        yielded = next(result)
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/notebook/services/kernels/kernelmanager.py", line 307, in restart_kernel
        self._check_kernel_id(kernel_id)
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/notebook/services/kernels/kernelmanager.py", line 387, in _check_kernel_id
        raise web.HTTPError(404, u'Kernel does not exist: %s' % kernel_id)
    tornado.web.HTTPError: HTTP 404: Not Found (Kernel does not exist: 83e248ec-5177-47a1-b407-613b592bb354)
[E 23:32:35.709 LabApp] {
      "Host": "localhost:8187",
      "Connection": "keep-alive",
      "Content-Length": "0",
      "Accept": "application/json, text/javascript, */*; q=0.01",
      "Origin": "http://localhost:8187",
      "X-Requested-With": "XMLHttpRequest",
      "X-Xsrftoken": "2|2b997e67|29d4ea20755e92079558d090866cac7e|1571165215",
      "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.120 Safari/537.36",
      "Sec-Fetch-Mode": "cors",
      "Sec-Fetch-Site": "same-origin",
      "Referer": "http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA-add_gx_loss_to_D.ipynb",
      "Accept-Encoding": "gzip, deflate, br",
      "Accept-Language": "en-US,en;q=0.9,fr;q=0.8",
      "Cookie": "_ga=GA1.1.2135320950.1566148815; username-localhost-8195=\"2|1:0|10:1570831591|23:username-localhost-8195|44:Y2Q0M2Y0YjJhMDQxNDQwZThhOGNjZTdhNDFiNDNkNjI=|4fc2d73bc3298178be788038ba7812e8e7e1ca4ae1891ffcc42a6bd3445055ab\"; _xsrf=2|2b997e67|29d4ea20755e92079558d090866cac7e|1571165215; username-localhost-8187=\"2|1:0|10:1571972576|23:username-localhost-8187|44:MGIyNmM0MzhlMTcxNDQ2OGJlNTczNjAwZDNlZjQ1NGE=|909460f83df7fd5d2e23ab9cf52e046079d5caccf76ccde023e9d50b06ebbeb1\"; username-localhost-8186=\"2|1:0|10:1572148972|23:username-localhost-8186|44:MjAwMmFlOWIxYTRhNDc4ZmFiNDAzOTg3ODBmYzEyOTQ=|c0f3007a6fdd6628418763a8293ba019d9531ba148601913203f1e0121fd51ea\""
    }
[E 23:32:35.709 LabApp] 500 POST /api/kernels/83e248ec-5177-47a1-b407-613b592bb354/restart (::1) 2.62ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA-add_gx_loss_to_D.ipynb
[W 23:32:35.739 LabApp] 404 DELETE /api/sessions/04fd186c-c2f6-421d-a911-edae8bb19493 (::1): Session not found: session_id='04fd186c-c2f6-421d-a911-edae8bb19493'
[W 23:32:35.739 LabApp] Session not found: session_id='04fd186c-c2f6-421d-a911-edae8bb19493'
[W 23:32:35.740 LabApp] 404 DELETE /api/sessions/04fd186c-c2f6-421d-a911-edae8bb19493 (::1) 1.76ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA-add_gx_loss_to_D.ipynb
[I 23:32:35.830 LabApp] Kernel started: 169f16af-256c-438c-b9dc-bc02c0661fed
[I 23:32:37.678 LabApp] Adapting from protocol version 5.1 (kernel 169f16af-256c-438c-b9dc-bc02c0661fed) to 5.3 (client).
[I 23:33:04.777 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA-Copy1.ipynb
[I 23:33:06.173 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA.ipynb
[I 23:33:20.038 LabApp] Starting buffering for 169f16af-256c-438c-b9dc-bc02c0661fed:083a49f75f914da58d5ce3115d465482
[I 23:33:20.678 LabApp] Kernel restarted: 169f16af-256c-438c-b9dc-bc02c0661fed
[I 23:33:23.494 LabApp] Adapting from protocol version 5.1 (kernel 169f16af-256c-438c-b9dc-bc02c0661fed) to 5.3 (client).
[I 23:33:23.494 LabApp] Restoring connection for 169f16af-256c-438c-b9dc-bc02c0661fed:083a49f75f914da58d5ce3115d465482
[I 23:33:23.495 LabApp] Replaying 6 buffered messages
2019-10-26 23:33:36.655754: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 23:33:37.204926: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-26 23:33:37.206149: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 23:33:37.209301: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 23:33:37.211862: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 23:33:37.213078: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 23:33:37.216038: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 23:33:37.218518: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 23:33:37.223837: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 23:33:37.226387: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 23:33:37.512673: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5630922721a0 executing computations on platform CUDA. Devices:
2019-10-26 23:33:37.512736: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-26 23:33:37.516852: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 23:33:37.518633: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563092348c50 executing computations on platform Host. Devices:
2019-10-26 23:33:37.518695: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 23:33:37.520544: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-26 23:33:37.520709: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 23:33:37.520802: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 23:33:37.520891: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 23:33:37.520976: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 23:33:37.521061: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 23:33:37.521147: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 23:33:37.521234: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 23:33:37.524541: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 23:33:37.524686: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 23:33:37.528692: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 23:33:37.528738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 23:33:37.528760: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 23:33:37.532571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-26 23:33:43.905801: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-26 23:33:43.953349: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 23:33:44.176643: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 23:34:14.941 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA-add_gx_loss_to_D.ipynb
[I 23:35:06.084 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA.ipynb
[I 23:36:14.892 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA-add_gx_loss_to_D.ipynb
[I 23:36:21.675 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA-add_gx_loss_to_D.ipynb
[I 23:36:22.050 LabApp] Copying avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA-add_gx_loss_to_D.ipynb to /avgn_paper/notebooks/6.0-neural-networks
[W 23:36:23.413 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 4.24ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA-add_gx_loss_to_D-Copy1.ipynb
[I 23:36:24.332 LabApp] Kernel started: c8cbfe0d-cc14-43e1-96fb-366ef8f9ffcd
[W 23:36:24.349 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 6.02ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA-add_gx_loss_to_D-Copy1.ipynb
[I 23:36:27.077 LabApp] Adapting from protocol version 5.1 (kernel c8cbfe0d-cc14-43e1-96fb-366ef8f9ffcd) to 5.3 (client).
[I 23:36:38.399 LabApp] Starting buffering for 169f16af-256c-438c-b9dc-bc02c0661fed:083a49f75f914da58d5ce3115d465482
[I 23:36:44.025 LabApp] Kernel shutdown: 169f16af-256c-438c-b9dc-bc02c0661fed
[I 23:37:06.560 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA.ipynb
[I 23:37:59.293 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA3.ipynb
[I 23:38:16.109 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA-add_gx_loss_to_D.ipynb
[I 23:38:18.345 LabApp] Starting buffering for c8cbfe0d-cc14-43e1-96fb-366ef8f9ffcd:af18d9913af2484f8d3bf3820ea5cc5b
[I 23:38:18.906 LabApp] Kernel restarted: c8cbfe0d-cc14-43e1-96fb-366ef8f9ffcd
[I 23:38:21.741 LabApp] Adapting from protocol version 5.1 (kernel c8cbfe0d-cc14-43e1-96fb-366ef8f9ffcd) to 5.3 (client).
[I 23:38:21.742 LabApp] Restoring connection for c8cbfe0d-cc14-43e1-96fb-366ef8f9ffcd:af18d9913af2484f8d3bf3820ea5cc5b
[I 23:38:21.742 LabApp] Replaying 6 buffered messages
[I 23:38:24.207 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA3.ipynb
2019-10-26 23:38:35.639510: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 23:38:36.213447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-26 23:38:36.239942: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 23:38:36.242127: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 23:38:36.243815: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 23:38:36.264353: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 23:38:36.266479: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 23:38:36.269479: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 23:38:36.276772: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 23:38:36.279718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 23:38:36.564434: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558646a17d90 executing computations on platform CUDA. Devices:
2019-10-26 23:38:36.564498: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-26 23:38:36.567932: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 23:38:36.568863: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558646aee830 executing computations on platform Host. Devices:
2019-10-26 23:38:36.568892: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 23:38:36.570008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-26 23:38:36.570090: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 23:38:36.570130: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 23:38:36.570167: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 23:38:36.570204: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 23:38:36.570256: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 23:38:36.570295: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 23:38:36.570332: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 23:38:36.572090: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 23:38:36.572153: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 23:38:36.574220: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 23:38:36.574240: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 23:38:36.574251: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 23:38:36.576426: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
[I 23:39:06.169 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA2.ipynb
2019-10-26 23:39:36.905669: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-26 23:39:36.954528: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 23:39:37.268023: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 23:40:24.266 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA3.ipynb
[I 23:41:06.173 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA2.ipynb
[I 23:41:47.507 LabApp] Starting buffering for c8cbfe0d-cc14-43e1-96fb-366ef8f9ffcd:af18d9913af2484f8d3bf3820ea5cc5b
[I 23:41:50.730 LabApp] Kernel restarted: c8cbfe0d-cc14-43e1-96fb-366ef8f9ffcd
[I 23:41:54.717 LabApp] Adapting from protocol version 5.1 (kernel c8cbfe0d-cc14-43e1-96fb-366ef8f9ffcd) to 5.3 (client).
[I 23:41:54.718 LabApp] Restoring connection for c8cbfe0d-cc14-43e1-96fb-366ef8f9ffcd:af18d9913af2484f8d3bf3820ea5cc5b
[I 23:41:54.718 LabApp] Replaying 6 buffered messages
2019-10-26 23:42:11.195777: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 23:42:11.807566: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-26 23:42:11.815353: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 23:42:11.818134: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 23:42:11.820482: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 23:42:11.821891: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 23:42:11.824718: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 23:42:11.827285: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 23:42:11.832590: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 23:42:11.834959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 23:42:12.136510: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b6e75da330 executing computations on platform CUDA. Devices:
2019-10-26 23:42:12.136568: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-26 23:42:12.142761: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 23:42:12.144708: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b6e76b0dc0 executing computations on platform Host. Devices:
2019-10-26 23:42:12.144776: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 23:42:12.146379: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-26 23:42:12.146503: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 23:42:12.146577: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 23:42:12.146645: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 23:42:12.146714: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 23:42:12.146781: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 23:42:12.146848: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 23:42:12.146915: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 23:42:12.149710: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 23:42:12.149826: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 23:42:12.153023: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 23:42:12.153057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 23:42:12.153075: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 23:42:12.156174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-26 23:42:18.801946: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-26 23:42:18.850451: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 23:42:19.073772: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 23:42:24.979 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA3.ipynb
[I 23:43:06.230 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA2.ipynb
[I 23:44:05.021 LabApp] Kernel interrupted: c8cbfe0d-cc14-43e1-96fb-366ef8f9ffcd
[I 23:44:24.270 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA3.ipynb
[I 23:45:06.557 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA2.ipynb
[I 23:46:24.544 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA3.ipynb
[I 23:47:06.186 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA2.ipynb
[I 23:47:25.941 LabApp] Copying avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA2.ipynb to /avgn_paper/notebooks/6.0-neural-networks
[I 23:47:28.813 LabApp] Kernel started: 3c2e0bdf-b9cf-4a9c-a9d1-957063cc6003
[W 23:47:28.865 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 2.25ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA2-Copy1.ipynb
[I 23:47:31.596 LabApp] Adapting from protocol version 5.1 (kernel 3c2e0bdf-b9cf-4a9c-a9d1-957063cc6003) to 5.3 (client).
[I 23:47:44.858 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA2-Copy1.ipynb
[I 23:47:50.767 LabApp] Starting buffering for 1c36c4a1-33a5-4c99-9b37-4a0b14744a92:5d0e2d1ac93a46308a271d4311c18ce0
[I 23:47:56.470 LabApp] Kernel shutdown: 1c36c4a1-33a5-4c99-9b37-4a0b14744a92
[I 23:47:56.484 LabApp] Starting buffering for 3c2e0bdf-b9cf-4a9c-a9d1-957063cc6003:f0ac3f23d7f049ed84231143ffb02602
[I 23:47:56.962 LabApp] Kernel restarted: 3c2e0bdf-b9cf-4a9c-a9d1-957063cc6003
[I 23:47:59.688 LabApp] Adapting from protocol version 5.1 (kernel 3c2e0bdf-b9cf-4a9c-a9d1-957063cc6003) to 5.3 (client).
[I 23:47:59.690 LabApp] Restoring connection for 3c2e0bdf-b9cf-4a9c-a9d1-957063cc6003:f0ac3f23d7f049ed84231143ffb02602
[I 23:47:59.690 LabApp] Replaying 6 buffered messages
2019-10-26 23:48:12.245591: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 23:48:12.824947: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 23:48:12.826044: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 23:48:12.829405: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 23:48:12.832317: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 23:48:12.833501: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 23:48:12.837400: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 23:48:12.840435: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 23:48:12.847327: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 23:48:12.850652: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 23:48:13.076190: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559e5dba6940 executing computations on platform CUDA. Devices:
2019-10-26 23:48:13.076264: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-26 23:48:13.080254: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 23:48:13.082755: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559e5dc7d3f0 executing computations on platform Host. Devices:
2019-10-26 23:48:13.082788: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 23:48:13.086761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-26 23:48:13.086867: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 23:48:13.086910: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 23:48:13.086947: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 23:48:13.086983: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 23:48:13.087020: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 23:48:13.087058: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 23:48:13.087096: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 23:48:13.088881: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 23:48:13.088945: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 23:48:13.091005: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 23:48:13.091028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 23:48:13.091039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 23:48:13.093170: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
[I 23:48:24.337 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA3.ipynb
[I 23:49:06.174 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA2.ipynb
[I 23:49:28.770 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA2-Copy1.ipynb
[I 23:50:24.545 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA3.ipynb
2019-10-26 23:50:35.633814: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-26 23:50:35.687464: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 23:50:35.930922: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 23:51:09.089 LabApp] Kernel interrupted: c8cbfe0d-cc14-43e1-96fb-366ef8f9ffcd
[I 23:51:28.912 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA2-Copy1.ipynb
[I 23:52:24.568 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA3.ipynb
[I 23:52:34.657 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA3.ipynb
[I 23:52:36.516 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA3.ipynb
[I 23:52:37.539 LabApp] Starting buffering for c8cbfe0d-cc14-43e1-96fb-366ef8f9ffcd:af18d9913af2484f8d3bf3820ea5cc5b
[I 23:52:37.586 LabApp] Adapting from protocol version 5.1 (kernel c8cbfe0d-cc14-43e1-96fb-366ef8f9ffcd) to 5.3 (client).
[I 23:52:37.587 LabApp] Restoring connection for c8cbfe0d-cc14-43e1-96fb-366ef8f9ffcd:af18d9913af2484f8d3bf3820ea5cc5b
[I 23:52:40.415 LabApp] Starting buffering for c8cbfe0d-cc14-43e1-96fb-366ef8f9ffcd:af18d9913af2484f8d3bf3820ea5cc5b
[I 23:52:46.117 LabApp] Kernel restarted: c8cbfe0d-cc14-43e1-96fb-366ef8f9ffcd
[I 23:52:48.717 LabApp] Adapting from protocol version 5.1 (kernel c8cbfe0d-cc14-43e1-96fb-366ef8f9ffcd) to 5.3 (client).
[I 23:52:48.718 LabApp] Restoring connection for c8cbfe0d-cc14-43e1-96fb-366ef8f9ffcd:af18d9913af2484f8d3bf3820ea5cc5b
[I 23:52:48.718 LabApp] Replaying 20 buffered messages
2019-10-26 23:53:00.461666: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 23:53:01.015730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-26 23:53:01.016824: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 23:53:01.019585: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 23:53:01.021862: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 23:53:01.022873: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 23:53:01.025739: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 23:53:01.028062: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 23:53:01.033133: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 23:53:01.036427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 23:53:01.269426: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556d1252f160 executing computations on platform CUDA. Devices:
2019-10-26 23:53:01.269507: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-26 23:53:01.275307: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 23:53:01.277610: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556d12605c10 executing computations on platform Host. Devices:
2019-10-26 23:53:01.277668: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 23:53:01.279402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-26 23:53:01.279547: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 23:53:01.279627: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 23:53:01.279700: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 23:53:01.279774: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 23:53:01.279847: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 23:53:01.279923: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 23:53:01.279998: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 23:53:01.282759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 23:53:01.282881: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 23:53:01.286129: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 23:53:01.286166: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 23:53:01.286185: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 23:53:01.289503: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-26 23:53:07.450517: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-26 23:53:07.491656: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 23:53:07.682886: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 23:53:29.250 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA2-Copy1.ipynb
[I 23:54:24.973 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA3.ipynb
[I 23:55:29.251 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA2-Copy1.ipynb
[I 23:56:24.249 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA3.ipynb
[I 23:57:29.221 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA2-Copy1.ipynb
[I 23:57:59.656 LabApp] Starting buffering for c8cbfe0d-cc14-43e1-96fb-366ef8f9ffcd:af18d9913af2484f8d3bf3820ea5cc5b
[I 23:58:05.442 LabApp] Kernel restarted: c8cbfe0d-cc14-43e1-96fb-366ef8f9ffcd
[I 23:58:08.234 LabApp] Adapting from protocol version 5.1 (kernel c8cbfe0d-cc14-43e1-96fb-366ef8f9ffcd) to 5.3 (client).
[I 23:58:08.235 LabApp] Restoring connection for c8cbfe0d-cc14-43e1-96fb-366ef8f9ffcd:af18d9913af2484f8d3bf3820ea5cc5b
[I 23:58:08.236 LabApp] Replaying 63 buffered messages
2019-10-26 23:58:21.137047: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-26 23:58:21.666017: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-26 23:58:21.674788: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 23:58:21.677618: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 23:58:21.679799: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 23:58:21.690789: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 23:58:21.693623: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 23:58:21.696023: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 23:58:21.701364: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 23:58:21.703967: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 23:58:21.949668: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558cb4182410 executing computations on platform CUDA. Devices:
2019-10-26 23:58:21.949785: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-26 23:58:21.955844: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-26 23:58:21.957320: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558cb4258e70 executing computations on platform Host. Devices:
2019-10-26 23:58:21.957349: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-26 23:58:21.959064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-26 23:58:21.959227: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 23:58:21.959270: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 23:58:21.959307: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-26 23:58:21.959344: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-26 23:58:21.959381: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-26 23:58:21.959418: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-26 23:58:21.959475: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-26 23:58:21.961514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-26 23:58:21.961587: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-26 23:58:21.963973: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-26 23:58:21.963998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-26 23:58:21.964011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-26 23:58:21.969701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
[I 23:58:24.208 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA3.ipynb
2019-10-26 23:58:28.264503: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-26 23:58:28.305208: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-26 23:58:28.540713: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 23:59:29.639 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA2-Copy1.ipynb
[I 00:00:02.096 LabApp] Starting buffering for 3c2e0bdf-b9cf-4a9c-a9d1-957063cc6003:f0ac3f23d7f049ed84231143ffb02602
[I 00:00:07.915 LabApp] Kernel restarted: 3c2e0bdf-b9cf-4a9c-a9d1-957063cc6003
[I 00:00:11.074 LabApp] Adapting from protocol version 5.1 (kernel 3c2e0bdf-b9cf-4a9c-a9d1-957063cc6003) to 5.3 (client).
[I 00:00:11.075 LabApp] Restoring connection for 3c2e0bdf-b9cf-4a9c-a9d1-957063cc6003:f0ac3f23d7f049ed84231143ffb02602
[I 00:00:11.076 LabApp] Replaying 26 buffered messages
2019-10-27 00:00:23.397487: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-27 00:00:23.899196: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-27 00:00:23.907772: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 00:00:23.909630: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 00:00:23.911080: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 00:00:23.924705: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 00:00:23.926633: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 00:00:23.928285: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 00:00:23.931853: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 00:00:23.933721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 00:00:24.192280: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5614324b5d80 executing computations on platform CUDA. Devices:
2019-10-27 00:00:24.192346: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-27 00:00:24.198616: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-27 00:00:24.200001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56143258c820 executing computations on platform Host. Devices:
2019-10-27 00:00:24.200050: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-27 00:00:24.203821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-27 00:00:24.203979: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 00:00:24.204066: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 00:00:24.204147: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 00:00:24.204228: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 00:00:24.204307: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 00:00:24.204388: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 00:00:24.204469: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 00:00:24.207571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 00:00:24.207666: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 00:00:24.214249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-27 00:00:24.214280: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-27 00:00:24.214292: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-27 00:00:24.216336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
[I 00:00:24.466 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA3.ipynb
2019-10-27 00:00:30.939888: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-27 00:00:30.984639: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 00:00:31.208418: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 00:01:29.584 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA2-Copy1.ipynb
[I 00:02:24.712 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA3.ipynb
[I 00:03:29.334 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA2-Copy1.ipynb
[I 00:04:24.627 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA3.ipynb
[I 00:05:29.320 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA2-Copy1.ipynb
[I 00:06:24.375 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA3.ipynb
[I 00:07:29.819 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA2-Copy1.ipynb
[I 00:08:24.843 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA3.ipynb
[I 00:09:28.895 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA2-Copy1.ipynb
[I 00:10:24.661 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA3.ipynb
[I 00:11:29.312 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA2-Copy1.ipynb
[I 00:12:24.509 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA3.ipynb
[I 00:13:29.241 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA2-Copy1.ipynb
[I 00:14:24.741 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA3.ipynb
[I 00:15:29.376 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA2-Copy1.ipynb
[I 00:16:24.281 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA3.ipynb
[I 00:16:43.207 LabApp] Kernel interrupted: c8cbfe0d-cc14-43e1-96fb-366ef8f9ffcd
[I 00:16:48.766 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA3.ipynb
[I 00:16:49.038 LabApp] Copying avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA3.ipynb to /avgn_paper/notebooks/6.0-neural-networks
[I 00:16:51.829 LabApp] Kernel started: 3cabfaaf-ce23-48f7-881d-a7a4751f11a6
[W 00:16:51.880 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 2.43ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA3-Copy1.ipynb
[I 00:16:54.542 LabApp] Adapting from protocol version 5.1 (kernel 3cabfaaf-ce23-48f7-881d-a7a4751f11a6) to 5.3 (client).
[I 00:17:14.866 LabApp] Starting buffering for c8cbfe0d-cc14-43e1-96fb-366ef8f9ffcd:af18d9913af2484f8d3bf3820ea5cc5b
[I 00:17:17.298 LabApp] Kernel shutdown: c8cbfe0d-cc14-43e1-96fb-366ef8f9ffcd
[I 00:17:24.724 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA5.ipynb
[I 00:17:26.557 LabApp] Starting buffering for 3cabfaaf-ce23-48f7-881d-a7a4751f11a6:e6a9c580d4424f5d8ec3c8e17613ec10
[I 00:17:27.024 LabApp] Kernel restarted: 3cabfaaf-ce23-48f7-881d-a7a4751f11a6
[I 00:17:28.880 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA4.ipynb
[I 00:17:29.710 LabApp] Adapting from protocol version 5.1 (kernel 3cabfaaf-ce23-48f7-881d-a7a4751f11a6) to 5.3 (client).
[I 00:17:29.711 LabApp] Restoring connection for 3cabfaaf-ce23-48f7-881d-a7a4751f11a6:e6a9c580d4424f5d8ec3c8e17613ec10
[I 00:17:29.711 LabApp] Replaying 6 buffered messages
2019-10-27 00:17:40.288453: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-27 00:17:40.826881: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-27 00:17:40.827680: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 00:17:40.829681: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 00:17:40.831558: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 00:17:40.832278: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 00:17:40.834376: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 00:17:40.836187: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 00:17:40.840140: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 00:17:40.842152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 00:17:41.113386: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55dad2b0adc0 executing computations on platform CUDA. Devices:
2019-10-27 00:17:41.113486: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-27 00:17:41.119608: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-27 00:17:41.121671: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55dad2be1840 executing computations on platform Host. Devices:
2019-10-27 00:17:41.121733: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-27 00:17:41.123512: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-27 00:17:41.123671: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 00:17:41.123756: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 00:17:41.123835: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 00:17:41.123913: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 00:17:41.123992: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 00:17:41.124071: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 00:17:41.124150: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 00:17:41.127351: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 00:17:41.127476: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 00:17:41.132172: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-27 00:17:41.132230: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-27 00:17:41.132253: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-27 00:17:41.135727: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
[I 00:18:51.771 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA5.ipynb
[I 00:19:29.371 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA4.ipynb
[I 00:19:45.516 LabApp] Kernel interrupted: 3c2e0bdf-b9cf-4a9c-a9d1-957063cc6003
[I 00:19:52.997 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA4.ipynb
[I 00:19:53.270 LabApp] Kernel interrupted: 3c2e0bdf-b9cf-4a9c-a9d1-957063cc6003
[I 00:19:55.317 LabApp] Starting buffering for 3c2e0bdf-b9cf-4a9c-a9d1-957063cc6003:f0ac3f23d7f049ed84231143ffb02602
[I 00:19:57.738 LabApp] Kernel restarted: 3c2e0bdf-b9cf-4a9c-a9d1-957063cc6003
[I 00:20:00.860 LabApp] Adapting from protocol version 5.1 (kernel 3c2e0bdf-b9cf-4a9c-a9d1-957063cc6003) to 5.3 (client).
[I 00:20:00.861 LabApp] Restoring connection for 3c2e0bdf-b9cf-4a9c-a9d1-957063cc6003:f0ac3f23d7f049ed84231143ffb02602
[I 00:20:00.862 LabApp] Replaying 6 buffered messages
2019-10-27 00:20:13.242056: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-27 00:20:13.296240: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 00:20:13.552039: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 00:20:13.587699: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-27 00:20:14.107284: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-27 00:20:14.108551: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 00:20:14.112214: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 00:20:14.114727: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 00:20:14.115759: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 00:20:14.118825: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 00:20:14.121382: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 00:20:14.127312: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 00:20:14.130267: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 00:20:14.400763: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5622cf760700 executing computations on platform CUDA. Devices:
2019-10-27 00:20:14.400828: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-27 00:20:14.405039: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-27 00:20:14.406729: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5622cf837190 executing computations on platform Host. Devices:
2019-10-27 00:20:14.406768: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-27 00:20:14.408025: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-27 00:20:14.408140: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 00:20:14.408201: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 00:20:14.408257: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 00:20:14.408312: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 00:20:14.408367: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 00:20:14.408424: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 00:20:14.408480: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 00:20:14.410937: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 00:20:14.411029: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 00:20:14.413715: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-27 00:20:14.413745: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-27 00:20:14.413760: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-27 00:20:14.416223: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-27 00:20:20.947936: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-27 00:20:20.990905: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 00:20:21.191831: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 00:20:26.211 LabApp] Starting buffering for 3c2e0bdf-b9cf-4a9c-a9d1-957063cc6003:f0ac3f23d7f049ed84231143ffb02602
[I 00:20:34.197 LabApp] Adapting from protocol version 5.1 (kernel 3c2e0bdf-b9cf-4a9c-a9d1-957063cc6003) to 5.3 (client).
[I 00:20:34.198 LabApp] Discarding 20 buffered messages for 3c2e0bdf-b9cf-4a9c-a9d1-957063cc6003:f0ac3f23d7f049ed84231143ffb02602
[W 00:20:34.219 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 2.13ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA4.ipynb
[I 00:20:35.525 LabApp] Starting buffering for 45fdaabd-cd04-44ae-b12b-197e86cc5654:2e35447528ae4421896831aefeb4a559
[I 00:20:37.993 LabApp] Starting buffering for 254383e0-ee3a-4f13-8f5c-605ef4fefd29:f03137fda1d34d27bad1d9d15d8756c2
[I 00:20:39.219 LabApp] Starting buffering for 505e20f1-c76f-41fa-aefb-13ceae966daa:0db8afbac1c04be987dc16ede350fcda
[I 00:20:42.631 LabApp] Kernel interrupted: 3c2e0bdf-b9cf-4a9c-a9d1-957063cc6003
[I 00:20:46.421 LabApp] Starting buffering for 3c2e0bdf-b9cf-4a9c-a9d1-957063cc6003:25e1b94c36384b47817a4917c3fec724
[I 00:20:48.774 LabApp] Kernel restarted: 3c2e0bdf-b9cf-4a9c-a9d1-957063cc6003
[I 00:20:50.877 LabApp] Adapting from protocol version 5.1 (kernel 3c2e0bdf-b9cf-4a9c-a9d1-957063cc6003) to 5.3 (client).
[I 00:20:50.878 LabApp] Restoring connection for 3c2e0bdf-b9cf-4a9c-a9d1-957063cc6003:25e1b94c36384b47817a4917c3fec724
[I 00:20:50.878 LabApp] Replaying 7 buffered messages
[I 00:20:52.309 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA5.ipynb
2019-10-27 00:21:00.109142: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-27 00:21:00.674740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-27 00:21:00.683834: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 00:21:00.685648: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 00:21:00.686902: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 00:21:00.692574: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 00:21:00.694292: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 00:21:00.695780: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 00:21:00.699214: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 00:21:00.707851: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 00:21:00.957924: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x557cd7c494d0 executing computations on platform CUDA. Devices:
2019-10-27 00:21:00.957981: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-27 00:21:00.962057: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-27 00:21:00.963833: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x557cd7d1ff50 executing computations on platform Host. Devices:
2019-10-27 00:21:00.963865: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-27 00:21:00.964860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-27 00:21:00.964970: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 00:21:00.965015: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 00:21:00.965057: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 00:21:00.965099: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 00:21:00.965141: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 00:21:00.965183: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 00:21:00.965225: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 00:21:00.967616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 00:21:00.967690: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 00:21:00.969773: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-27 00:21:00.969795: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-27 00:21:00.969806: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-27 00:21:00.971984: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-27 00:21:07.629904: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-27 00:21:07.680684: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 00:21:07.920814: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 00:21:49.054 LabApp] Kernel interrupted: 3cabfaaf-ce23-48f7-881d-a7a4751f11a6
[I 00:21:52.167 LabApp] Starting buffering for 3cabfaaf-ce23-48f7-881d-a7a4751f11a6:e6a9c580d4424f5d8ec3c8e17613ec10
[I 00:21:54.648 LabApp] Kernel restarted: 3cabfaaf-ce23-48f7-881d-a7a4751f11a6
[I 00:21:57.095 LabApp] Adapting from protocol version 5.1 (kernel 3cabfaaf-ce23-48f7-881d-a7a4751f11a6) to 5.3 (client).
[I 00:21:57.097 LabApp] Restoring connection for 3cabfaaf-ce23-48f7-881d-a7a4751f11a6:e6a9c580d4424f5d8ec3c8e17613ec10
[I 00:21:57.097 LabApp] Replaying 6 buffered messages
2019-10-27 00:22:11.314498: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-27 00:22:11.840241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-27 00:22:11.851083: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 00:22:11.853240: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 00:22:11.854929: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 00:22:11.868397: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 00:22:11.870530: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 00:22:11.872348: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 00:22:11.876305: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 00:22:11.878307: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 00:22:12.080420: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a751e2d420 executing computations on platform CUDA. Devices:
2019-10-27 00:22:12.080477: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-27 00:22:12.083864: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-27 00:22:12.084930: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a751f03e80 executing computations on platform Host. Devices:
2019-10-27 00:22:12.084960: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-27 00:22:12.085952: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-27 00:22:12.086031: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 00:22:12.086071: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 00:22:12.086108: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 00:22:12.086145: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 00:22:12.086182: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 00:22:12.086219: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 00:22:12.086256: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 00:22:12.088041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 00:22:12.088104: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 00:22:12.090136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-27 00:22:12.090156: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-27 00:22:12.090167: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-27 00:22:12.095292: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-27 00:22:18.048407: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-27 00:22:18.089479: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 00:22:18.288351: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 00:22:34.347 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA4.ipynb
[I 00:22:51.957 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA5.ipynb
[I 00:24:34.694 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA4.ipynb
[I 00:24:52.148 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA5.ipynb
[I 00:26:34.276 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA4.ipynb
[I 00:26:52.326 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA5.ipynb
[I 00:28:34.411 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA4.ipynb
[I 00:28:52.021 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA5.ipynb
[I 00:30:03.232 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA4.ipynb
[I 00:30:03.560 LabApp] Copying avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA4.ipynb to /avgn_paper/notebooks/6.0-neural-networks
[I 00:30:06.905 LabApp] Kernel started: 73bd2d05-c649-4c32-93bc-470b87b39b26
[W 00:30:06.976 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 1.83ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA4-Copy1.ipynb
[I 00:30:09.546 LabApp] Adapting from protocol version 5.1 (kernel 73bd2d05-c649-4c32-93bc-470b87b39b26) to 5.3 (client).
[I 00:30:19.567 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA5.ipynb
[I 00:30:50.131 LabApp] Starting buffering for 3c2e0bdf-b9cf-4a9c-a9d1-957063cc6003:25e1b94c36384b47817a4917c3fec724
[I 00:30:55.869 LabApp] Kernel shutdown: 3c2e0bdf-b9cf-4a9c-a9d1-957063cc6003
[I 00:30:56.483 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA5.ipynb
[I 00:30:56.719 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA5.ipynb
[I 00:30:57.124 LabApp] Copying avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA5.ipynb to /avgn_paper/notebooks/6.0-neural-networks
[W 00:30:58.786 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.43ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA5-Copy1.ipynb
[I 00:30:59.542 LabApp] Kernel started: eabf855a-0412-47ae-8bae-ae76b127b6e9
[W 00:30:59.635 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 2.50ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA5-Copy1.ipynb
[I 00:31:02.192 LabApp] Adapting from protocol version 5.1 (kernel eabf855a-0412-47ae-8bae-ae76b127b6e9) to 5.3 (client).
[I 00:31:55.320 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA6.ipynb
[I 00:31:56.409 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA6.ipynb
[I 00:31:59.205 LabApp] Starting buffering for eabf855a-0412-47ae-8bae-ae76b127b6e9:db1679a8048d4d38838dd7f4574e6f2a
[I 00:31:59.789 LabApp] Kernel restarted: eabf855a-0412-47ae-8bae-ae76b127b6e9
[I 00:32:03.029 LabApp] Adapting from protocol version 5.1 (kernel eabf855a-0412-47ae-8bae-ae76b127b6e9) to 5.3 (client).
[I 00:32:03.030 LabApp] Restoring connection for eabf855a-0412-47ae-8bae-ae76b127b6e9:db1679a8048d4d38838dd7f4574e6f2a
[I 00:32:03.030 LabApp] Replaying 6 buffered messages
[I 00:32:07.786 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA4-Copy1.ipynb
2019-10-27 00:32:16.833858: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-27 00:32:17.424188: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-27 00:32:17.425218: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 00:32:17.427750: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 00:32:17.429185: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 00:32:17.429838: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 00:32:17.431707: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 00:32:17.433287: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 00:32:17.436768: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 00:32:17.438103: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 00:32:17.692757: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5631c2d84530 executing computations on platform CUDA. Devices:
2019-10-27 00:32:17.692807: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-27 00:32:17.696383: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-27 00:32:17.698458: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5631c2e5afc0 executing computations on platform Host. Devices:
2019-10-27 00:32:17.698522: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-27 00:32:17.700592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-27 00:32:17.700699: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 00:32:17.700751: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 00:32:17.700799: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 00:32:17.700847: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 00:32:17.700895: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 00:32:17.700944: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 00:32:17.700993: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 00:32:17.702517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 00:32:17.702601: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 00:32:17.704873: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-27 00:32:17.704901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-27 00:32:17.704916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-27 00:32:17.706629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 204 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-27 00:32:30.746439: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 204.75M (214695936 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2019-10-27 00:32:30.903693: F tensorflow/stream_executor/cuda/cuda_driver.cc:175] Check failed: err == cudaSuccess || err == cudaErrorInvalidValue Unexpected CUDA error: out of memory
[I 00:32:32.789 LabApp] KernelRestarter: restarting kernel (1/5), keep random ports
kernel eabf855a-0412-47ae-8bae-ae76b127b6e9 restarted
[I 00:32:42.968 LabApp] Starting buffering for 73bd2d05-c649-4c32-93bc-470b87b39b26:b6716fab69294654ad1108bec3328aeb
[I 00:32:43.374 LabApp] Kernel shutdown: 73bd2d05-c649-4c32-93bc-470b87b39b26
[I 00:32:49.948 LabApp] Starting buffering for eabf855a-0412-47ae-8bae-ae76b127b6e9:db1679a8048d4d38838dd7f4574e6f2a
[I 00:32:50.429 LabApp] Kernel restarted: eabf855a-0412-47ae-8bae-ae76b127b6e9
[I 00:32:52.031 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA5.ipynb
[I 00:32:53.492 LabApp] Adapting from protocol version 5.1 (kernel eabf855a-0412-47ae-8bae-ae76b127b6e9) to 5.3 (client).
[I 00:32:53.493 LabApp] Restoring connection for eabf855a-0412-47ae-8bae-ae76b127b6e9:db1679a8048d4d38838dd7f4574e6f2a
[I 00:32:53.493 LabApp] Replaying 6 buffered messages
[I 00:32:59.526 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA6.ipynb
2019-10-27 00:33:04.992641: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-27 00:33:05.536637: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-27 00:33:05.537165: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 00:33:05.538823: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 00:33:05.540169: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 00:33:05.540725: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 00:33:05.542443: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 00:33:05.543934: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 00:33:05.547399: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 00:33:05.551903: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 00:33:05.809022: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562181b72f80 executing computations on platform CUDA. Devices:
2019-10-27 00:33:05.809073: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-27 00:33:05.812713: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-27 00:33:05.813743: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562181c49a10 executing computations on platform Host. Devices:
2019-10-27 00:33:05.813773: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-27 00:33:05.814931: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-27 00:33:05.815020: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 00:33:05.815059: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 00:33:05.815096: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 00:33:05.815155: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 00:33:05.815192: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 00:33:05.815231: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 00:33:05.815270: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 00:33:05.817035: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 00:33:05.817098: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 00:33:05.819959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-27 00:33:05.819981: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-27 00:33:05.819991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-27 00:33:05.821992: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-27 00:33:12.735689: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-27 00:33:12.786171: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 00:33:13.030623: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 00:34:51.894 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA5.ipynb
[I 00:34:59.695 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA6.ipynb
[I 00:36:52.015 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA5.ipynb
[I 00:36:59.835 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA6.ipynb
[I 00:38:51.796 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA5.ipynb
[I 00:39:00.075 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA6.ipynb
[I 00:40:52.010 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA5.ipynb
[I 00:40:59.612 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA6.ipynb
[I 00:42:52.997 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA5.ipynb
[I 00:42:59.763 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA6.ipynb
[I 00:44:52.399 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA5.ipynb
[I 00:44:59.745 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA6.ipynb
[I 00:46:52.356 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA5.ipynb
[I 00:46:59.742 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA6.ipynb
[I 00:48:52.430 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA5.ipynb
[I 00:48:59.891 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA6.ipynb
[I 00:50:15.422 LabApp] Starting buffering for eabf855a-0412-47ae-8bae-ae76b127b6e9:db1679a8048d4d38838dd7f4574e6f2a
[I 00:50:21.238 LabApp] Kernel restarted: eabf855a-0412-47ae-8bae-ae76b127b6e9
[I 00:50:25.132 LabApp] Adapting from protocol version 5.1 (kernel eabf855a-0412-47ae-8bae-ae76b127b6e9) to 5.3 (client).
[I 00:50:25.134 LabApp] Restoring connection for eabf855a-0412-47ae-8bae-ae76b127b6e9:db1679a8048d4d38838dd7f4574e6f2a
[I 00:50:25.134 LabApp] Replaying 38 buffered messages
2019-10-27 00:50:39.894567: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-27 00:50:40.440362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-27 00:50:40.442511: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 00:50:40.446383: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 00:50:40.448460: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 00:50:40.449669: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 00:50:40.453225: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 00:50:40.460050: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 00:50:40.465016: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 00:50:40.467650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 00:50:40.754434: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c971f57370 executing computations on platform CUDA. Devices:
2019-10-27 00:50:40.754514: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-27 00:50:40.760723: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-27 00:50:40.763156: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c97202dde0 executing computations on platform Host. Devices:
2019-10-27 00:50:40.763187: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-27 00:50:40.765291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-27 00:50:40.765461: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 00:50:40.765548: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 00:50:40.765628: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 00:50:40.765707: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 00:50:40.765786: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 00:50:40.765867: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 00:50:40.765947: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 00:50:40.769261: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 00:50:40.769398: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 00:50:40.774442: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-27 00:50:40.774505: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-27 00:50:40.774531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-27 00:50:40.778359: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-27 00:50:47.193053: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-27 00:50:47.238086: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 00:50:47.506688: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 00:50:52.260 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA5.ipynb
[I 00:50:59.617 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA6.ipynb
[I 00:53:00.388 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA6.ipynb
[I 00:55:00.003 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA6.ipynb
[I 00:56:31.684 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA5.ipynb
[I 00:56:47.148 LabApp] Kernel interrupted: eabf855a-0412-47ae-8bae-ae76b127b6e9
[I 00:57:00.005 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA6.ipynb
[I 00:57:29.702 LabApp] Starting buffering for eabf855a-0412-47ae-8bae-ae76b127b6e9:db1679a8048d4d38838dd7f4574e6f2a
[I 00:57:33.093 LabApp] Kernel restarted: eabf855a-0412-47ae-8bae-ae76b127b6e9
[I 00:57:35.928 LabApp] Adapting from protocol version 5.1 (kernel eabf855a-0412-47ae-8bae-ae76b127b6e9) to 5.3 (client).
[I 00:57:35.929 LabApp] Restoring connection for eabf855a-0412-47ae-8bae-ae76b127b6e9:db1679a8048d4d38838dd7f4574e6f2a
[I 00:57:35.929 LabApp] Replaying 6 buffered messages
[I 00:57:46.582 LabApp] Starting buffering for 3cabfaaf-ce23-48f7-881d-a7a4751f11a6:e6a9c580d4424f5d8ec3c8e17613ec10
2019-10-27 00:57:49.698251: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
[I 00:57:49.705 LabApp] Kernel shutdown: 3cabfaaf-ce23-48f7-881d-a7a4751f11a6
2019-10-27 00:57:50.741241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-27 00:57:50.995079: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 00:57:50.998172: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 00:57:51.000301: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 00:57:51.001282: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 00:57:51.003758: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 00:57:51.005615: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 00:57:51.009494: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 00:57:51.011326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 00:57:51.294713: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560521df9730 executing computations on platform CUDA. Devices:
2019-10-27 00:57:51.294795: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-27 00:57:51.301170: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-27 00:57:51.303876: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560521ed0180 executing computations on platform Host. Devices:
2019-10-27 00:57:51.303927: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-27 00:57:51.305301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-27 00:57:51.305436: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 00:57:51.305500: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 00:57:51.305580: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 00:57:51.305642: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 00:57:51.305703: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 00:57:51.305763: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 00:57:51.305825: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 00:57:51.308578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 00:57:51.308707: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 00:57:51.311361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-27 00:57:51.311397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-27 00:57:51.311412: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-27 00:57:51.314010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-27 00:57:59.469504: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-27 00:57:59.513521: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 00:57:59.765429: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[W 00:58:01.697 LabApp] 404 PATCH /api/sessions/3cc21959-7473-4402-8777-2ea8109df191 (::1): Session not found: session_id='3cc21959-7473-4402-8777-2ea8109df191'
[W 00:58:01.698 LabApp] Session not found: session_id='3cc21959-7473-4402-8777-2ea8109df191'
[W 00:58:01.698 LabApp] 404 PATCH /api/sessions/3cc21959-7473-4402-8777-2ea8109df191 (::1) 1.27ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA5.ipynb
[E 00:58:03.942 LabApp] Exception restarting kernel
    Traceback (most recent call last):
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/notebook/services/kernels/handlers.py", line 83, in post
        yield maybe_future(km.restart_kernel(kernel_id))
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/tornado/gen.py", line 735, in run
        value = future.result()
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/tornado/gen.py", line 209, in wrapper
        yielded = next(result)
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/notebook/services/kernels/kernelmanager.py", line 307, in restart_kernel
        self._check_kernel_id(kernel_id)
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/notebook/services/kernels/kernelmanager.py", line 387, in _check_kernel_id
        raise web.HTTPError(404, u'Kernel does not exist: %s' % kernel_id)
    tornado.web.HTTPError: HTTP 404: Not Found (Kernel does not exist: 3c2e0bdf-b9cf-4a9c-a9d1-957063cc6003)
[E 00:58:03.947 LabApp] {
      "Host": "localhost:8187",
      "Connection": "keep-alive",
      "Content-Length": "0",
      "Accept": "application/json, text/javascript, */*; q=0.01",
      "Origin": "http://localhost:8187",
      "X-Requested-With": "XMLHttpRequest",
      "X-Xsrftoken": "2|2b997e67|29d4ea20755e92079558d090866cac7e|1571165215",
      "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.120 Safari/537.36",
      "Sec-Fetch-Mode": "cors",
      "Sec-Fetch-Site": "same-origin",
      "Referer": "http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb",
      "Accept-Encoding": "gzip, deflate, br",
      "Accept-Language": "en-US,en;q=0.9,fr;q=0.8",
      "Cookie": "_ga=GA1.1.2135320950.1566148815; username-localhost-8195=\"2|1:0|10:1570831591|23:username-localhost-8195|44:Y2Q0M2Y0YjJhMDQxNDQwZThhOGNjZTdhNDFiNDNkNjI=|4fc2d73bc3298178be788038ba7812e8e7e1ca4ae1891ffcc42a6bd3445055ab\"; _xsrf=2|2b997e67|29d4ea20755e92079558d090866cac7e|1571165215; username-localhost-8187=\"2|1:0|10:1571972576|23:username-localhost-8187|44:MGIyNmM0MzhlMTcxNDQ2OGJlNTczNjAwZDNlZjQ1NGE=|909460f83df7fd5d2e23ab9cf52e046079d5caccf76ccde023e9d50b06ebbeb1\"; username-localhost-8186=\"2|1:0|10:1572148972|23:username-localhost-8186|44:MjAwMmFlOWIxYTRhNDc4ZmFiNDAzOTg3ODBmYzEyOTQ=|c0f3007a6fdd6628418763a8293ba019d9531ba148601913203f1e0121fd51ea\""
    }
[E 00:58:03.947 LabApp] 500 POST /api/kernels/3c2e0bdf-b9cf-4a9c-a9d1-957063cc6003/restart (::1) 6.05ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[W 00:58:03.978 LabApp] 404 DELETE /api/sessions/3cc21959-7473-4402-8777-2ea8109df191 (::1): Session not found: session_id='3cc21959-7473-4402-8777-2ea8109df191'
[W 00:58:03.979 LabApp] Session not found: session_id='3cc21959-7473-4402-8777-2ea8109df191'
[W 00:58:03.979 LabApp] 404 DELETE /api/sessions/3cc21959-7473-4402-8777-2ea8109df191 (::1) 3.91ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 00:58:04.121 LabApp] Kernel started: 778e73e2-db3f-47df-9c6f-d4384a6751b2
[I 00:58:06.941 LabApp] Adapting from protocol version 5.1 (kernel 778e73e2-db3f-47df-9c6f-d4384a6751b2) to 5.3 (client).
[I 00:58:16.618 LabApp] Starting buffering for 778e73e2-db3f-47df-9c6f-d4384a6751b2:25e1b94c36384b47817a4917c3fec724
[I 00:58:17.098 LabApp] Kernel restarted: 778e73e2-db3f-47df-9c6f-d4384a6751b2
[I 00:58:18.789 LabApp] Adapting from protocol version 5.1 (kernel 778e73e2-db3f-47df-9c6f-d4384a6751b2) to 5.3 (client).
[I 00:58:18.790 LabApp] Restoring connection for 778e73e2-db3f-47df-9c6f-d4384a6751b2:25e1b94c36384b47817a4917c3fec724
[I 00:58:18.790 LabApp] Replaying 6 buffered messages
2019-10-27 00:58:28.346096: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-27 00:58:28.923686: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-27 00:58:28.936369: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 00:58:28.938346: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 00:58:28.939790: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 00:58:28.940566: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 00:58:28.942426: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 00:58:28.944000: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 00:58:28.947911: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 00:58:28.949904: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 00:58:29.201760: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b1f66ce7f0 executing computations on platform CUDA. Devices:
2019-10-27 00:58:29.201815: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-27 00:58:29.205725: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-27 00:58:29.207322: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b1f67a52b0 executing computations on platform Host. Devices:
2019-10-27 00:58:29.207354: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-27 00:58:29.208483: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-27 00:58:29.208576: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 00:58:29.208616: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 00:58:29.208654: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 00:58:29.208690: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 00:58:29.208727: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 00:58:29.208764: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 00:58:29.208802: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 00:58:29.210533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 00:58:29.210597: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 00:58:29.213241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-27 00:58:29.213264: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-27 00:58:29.213275: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-27 00:58:29.221850: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
[I 00:58:33.896 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 00:58:59.800 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA6.ipynb
2019-10-27 00:59:13.862385: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-27 00:59:13.911569: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 00:59:14.201109: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 01:00:34.416 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 01:00:59.618 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA6.ipynb
[I 01:02:34.361 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 01:02:59.812 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA6.ipynb
[I 01:04:34.299 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 01:04:59.832 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA6.ipynb
[I 01:06:34.357 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 01:06:59.641 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA6.ipynb
[I 01:08:34.338 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 01:08:59.815 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA6.ipynb
[I 01:10:34.393 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 01:10:59.764 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA6.ipynb
[I 01:12:35.274 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 01:13:00.530 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA6.ipynb
[I 01:14:35.347 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 01:15:00.488 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA6.ipynb
[I 01:16:35.319 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 01:16:59.999 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA6.ipynb
[I 01:18:35.271 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 01:19:00.128 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA6.ipynb
[I 01:20:35.318 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 01:21:00.069 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA6.ipynb
[I 01:22:35.295 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 01:23:00.096 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA6.ipynb
[I 01:24:35.375 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 01:25:00.553 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA6.ipynb
[I 01:26:35.282 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 01:28:35.320 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 01:30:35.262 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 01:32:35.315 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 01:34:35.287 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 01:36:35.851 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 01:38:35.333 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 01:40:35.282 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 01:42:35.293 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 01:44:35.710 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 01:46:35.321 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 01:48:35.351 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 01:50:35.315 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 01:52:35.301 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 01:54:35.180 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 01:56:35.372 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 01:58:35.298 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[W 02:01:48.791 LabApp] WebSocket ping timeout after 119905 ms.
[W 02:01:49.290 LabApp] zmq message arrived on closed channel
[W 02:01:49.291 LabApp] zmq message arrived on closed channel
[W 02:01:49.619 LabApp] zmq message arrived on closed channel
[W 02:01:49.620 LabApp] zmq message arrived on closed channel
[W 02:01:49.968 LabApp] zmq message arrived on closed channel
[W 02:01:49.968 LabApp] zmq message arrived on closed channel
[W 02:01:50.306 LabApp] zmq message arrived on closed channel
[W 02:01:50.308 LabApp] zmq message arrived on closed channel
[W 02:01:50.649 LabApp] zmq message arrived on closed channel
[W 02:01:50.649 LabApp] zmq message arrived on closed channel
[W 02:01:50.995 LabApp] zmq message arrived on closed channel
[W 02:01:50.996 LabApp] zmq message arrived on closed channel
[W 02:01:51.337 LabApp] zmq message arrived on closed channel
[W 02:01:51.337 LabApp] zmq message arrived on closed channel
[W 02:01:51.679 LabApp] zmq message arrived on closed channel
[W 02:01:51.680 LabApp] zmq message arrived on closed channel
[W 02:01:52.026 LabApp] zmq message arrived on closed channel
[W 02:01:52.027 LabApp] zmq message arrived on closed channel
[W 02:01:52.358 LabApp] zmq message arrived on closed channel
[W 02:01:52.358 LabApp] zmq message arrived on closed channel
[W 02:01:52.698 LabApp] zmq message arrived on closed channel
[W 02:01:52.699 LabApp] zmq message arrived on closed channel
[W 02:01:53.048 LabApp] zmq message arrived on closed channel
[W 02:01:53.049 LabApp] zmq message arrived on closed channel
[W 02:01:53.393 LabApp] zmq message arrived on closed channel
[W 02:01:53.393 LabApp] zmq message arrived on closed channel
[W 02:01:53.728 LabApp] zmq message arrived on closed channel
[W 02:01:53.728 LabApp] zmq message arrived on closed channel
[I 02:01:53.792 LabApp] Starting buffering for 778e73e2-db3f-47df-9c6f-d4384a6751b2:25e1b94c36384b47817a4917c3fec724
[I 10:35:15.506 LabApp] Starting buffering for d849356d-faa3-448d-b20c-12997f49ba94:dcf4d8f8f5d64133930dbf8089bec6a7
[I 10:35:15.507 LabApp] Starting buffering for e4f39541-c636-4e93-9820-1a4ae1520340:98fb7f0da09145ed8c6fe2c7d020decf
[I 10:35:15.509 LabApp] Starting buffering for eabf855a-0412-47ae-8bae-ae76b127b6e9:db1679a8048d4d38838dd7f4574e6f2a
[I 10:35:15.509 LabApp] Starting buffering for 11777ca9-05bd-4ea4-bc65-bd1bf70a0360:07552191011d4f5a8da9f495dae8b7a8
[I 10:35:15.510 LabApp] Starting buffering for 00cb76cf-9ff9-45d7-bf9b-ca5e71a3b40a:c4a763956ede491c98b574600c86bac1
[I 10:35:20.268 LabApp] Adapting from protocol version 5.1 (kernel 00cb76cf-9ff9-45d7-bf9b-ca5e71a3b40a) to 5.3 (client).
[I 10:35:20.270 LabApp] Restoring connection for 00cb76cf-9ff9-45d7-bf9b-ca5e71a3b40a:c4a763956ede491c98b574600c86bac1
[I 10:35:20.330 LabApp] Adapting from protocol version 5.1 (kernel eabf855a-0412-47ae-8bae-ae76b127b6e9) to 5.3 (client).
[I 10:35:20.331 LabApp] Restoring connection for eabf855a-0412-47ae-8bae-ae76b127b6e9:db1679a8048d4d38838dd7f4574e6f2a
[I 10:35:20.405 LabApp] Adapting from protocol version 5.1 (kernel e4f39541-c636-4e93-9820-1a4ae1520340) to 5.3 (client).
[I 10:35:20.411 LabApp] Restoring connection for e4f39541-c636-4e93-9820-1a4ae1520340:98fb7f0da09145ed8c6fe2c7d020decf
[I 10:35:20.492 LabApp] Adapting from protocol version 5.1 (kernel 11777ca9-05bd-4ea4-bc65-bd1bf70a0360) to 5.3 (client).
[I 10:35:20.493 LabApp] Restoring connection for 11777ca9-05bd-4ea4-bc65-bd1bf70a0360:07552191011d4f5a8da9f495dae8b7a8
[I 10:35:20.565 LabApp] Adapting from protocol version 5.1 (kernel d849356d-faa3-448d-b20c-12997f49ba94) to 5.3 (client).
[I 10:35:20.566 LabApp] Restoring connection for d849356d-faa3-448d-b20c-12997f49ba94:dcf4d8f8f5d64133930dbf8089bec6a7
[I 10:35:34.229 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 10:35:34.784 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 10:35:35.120 LabApp] Adapting from protocol version 5.1 (kernel 778e73e2-db3f-47df-9c6f-d4384a6751b2) to 5.3 (client).
[I 10:35:35.134 LabApp] Restoring connection for 778e73e2-db3f-47df-9c6f-d4384a6751b2:25e1b94c36384b47817a4917c3fec724
[I 10:35:35.135 LabApp] Replaying 3675 buffered messages
[W 10:35:37.147 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 10:35:37.658 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.76ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA4-Copy1.ipynb
[I 10:35:38.834 LabApp] Kernel started: eb5078f2-6425-499a-9abd-25c5ca2d047d
[W 10:35:38.852 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 6.45ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA4-Copy1.ipynb
[I 10:35:41.905 LabApp] Adapting from protocol version 5.1 (kernel eb5078f2-6425-499a-9abd-25c5ca2d047d) to 5.3 (client).
[I 10:35:54.862 LabApp] Kernel interrupted: 778e73e2-db3f-47df-9c6f-d4384a6751b2
[I 10:36:28.974 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA6.ipynb
[I 10:36:35.071 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 10:37:34.456 LabApp] 302 GET /notebooks/avgn_paper/notebooks/6.0-neural-networks/ (::1) 1.21ms
[I 10:37:34.485 LabApp] 302 GET /notebooks/avgn_paper/notebooks/6.0-neural-networks (::1) 2.28ms
[W 10:37:35.111 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 3.54ms referer=http://localhost:8187/tree/avgn_paper/notebooks/6.0-neural-networks
[I 10:37:39.551 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA4-Copy1.ipynb
[W 10:37:41.589 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 5.31ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 10:37:42.559 LabApp] Kernel started: 793710b2-0367-468d-af3d-dcee2dc6e305
[W 10:37:42.574 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 7.05ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb
[I 10:37:45.194 LabApp] Adapting from protocol version 5.1 (kernel 793710b2-0367-468d-af3d-dcee2dc6e305) to 5.3 (client).
[I 10:37:45.548 LabApp] Copying avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA.ipynb to /avgn_paper/notebooks/6.0-neural-networks
[I 10:37:48.384 LabApp] Kernel started: 8a176c6a-8996-42d7-bccc-a9d6303bb7c0
[W 10:37:48.438 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.54ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA-Copy2.ipynb
[I 10:37:49.787 LabApp] Adapting from protocol version 5.1 (kernel 8a176c6a-8996-42d7-bccc-a9d6303bb7c0) to 5.3 (client).
[I 10:37:49.927 LabApp] Starting buffering for eabf855a-0412-47ae-8bae-ae76b127b6e9:db1679a8048d4d38838dd7f4574e6f2a
[I 10:37:52.865 LabApp] Kernel shutdown: eabf855a-0412-47ae-8bae-ae76b127b6e9
[I 10:37:57.286 LabApp] Starting buffering for 793710b2-0367-468d-af3d-dcee2dc6e305:896cecd97c364b578d9a6617b4b26fc3
[I 10:38:35.086 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 10:39:28.051 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 10:39:35.642 LabApp] Starting buffering for 8a176c6a-8996-42d7-bccc-a9d6303bb7c0:f6f50c1de9b147b18b2cce0931313a25
[I 10:39:36.188 LabApp] Kernel restarted: 8a176c6a-8996-42d7-bccc-a9d6303bb7c0
[I 10:39:38.644 LabApp] Adapting from protocol version 5.1 (kernel 8a176c6a-8996-42d7-bccc-a9d6303bb7c0) to 5.3 (client).
[I 10:39:38.645 LabApp] Restoring connection for 8a176c6a-8996-42d7-bccc-a9d6303bb7c0:f6f50c1de9b147b18b2cce0931313a25
[I 10:39:38.645 LabApp] Replaying 6 buffered messages
[I 10:39:48.341 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
2019-10-27 10:39:53.321625: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-27 10:39:53.948637: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-27 10:39:53.961662: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 10:39:53.965239: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 10:39:53.967947: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 10:39:53.977925: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 10:39:53.981424: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 10:39:53.984274: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 10:39:53.990488: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 10:39:53.993505: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 10:39:54.262683: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a2c9974470 executing computations on platform CUDA. Devices:
2019-10-27 10:39:54.262746: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-27 10:39:54.269227: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-27 10:39:54.271306: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a2c9a4aed0 executing computations on platform Host. Devices:
2019-10-27 10:39:54.271351: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-27 10:39:54.273234: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-27 10:39:54.273429: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 10:39:54.273526: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 10:39:54.273616: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 10:39:54.273706: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 10:39:54.273797: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 10:39:54.273887: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 10:39:54.273980: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 10:39:54.278048: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 10:39:54.278194: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 10:39:54.282427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-27 10:39:54.282497: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-27 10:39:54.282524: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-27 10:39:54.286181: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-27 10:40:02.567977: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-27 10:40:02.622879: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 10:40:02.867495: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 10:40:32.548068: W tensorflow/core/common_runtime/bfc_allocator.cc:314] Allocator (GPU_0_bfc) ran out of memory trying to allocate 264.06MiB (rounded to 276889600).  Current allocation summary follows.
2019-10-27 10:40:32.548219: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (256): 	Total Chunks: 192, Chunks in use: 191. 48.0KiB allocated for chunks. 47.8KiB in use in bin. 8.2KiB client-requested in use in bin.
2019-10-27 10:40:32.548260: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (512): 	Total Chunks: 30, Chunks in use: 30. 15.8KiB allocated for chunks. 15.8KiB in use in bin. 15.2KiB client-requested in use in bin.
2019-10-27 10:40:32.548289: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (1024): 	Total Chunks: 19, Chunks in use: 19. 21.8KiB allocated for chunks. 21.8KiB in use in bin. 19.8KiB client-requested in use in bin.
2019-10-27 10:40:32.548315: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (2048): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 10:40:32.548339: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (4096): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 10:40:32.548367: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (8192): 	Total Chunks: 6, Chunks in use: 6. 54.0KiB allocated for chunks. 54.0KiB in use in bin. 54.0KiB client-requested in use in bin.
2019-10-27 10:40:32.548397: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (16384): 	Total Chunks: 8, Chunks in use: 8. 175.8KiB allocated for chunks. 175.8KiB in use in bin. 156.0KiB client-requested in use in bin.
2019-10-27 10:40:32.548425: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (32768): 	Total Chunks: 7, Chunks in use: 7. 261.0KiB allocated for chunks. 261.0KiB in use in bin. 243.0KiB client-requested in use in bin.
2019-10-27 10:40:32.548452: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (65536): 	Total Chunks: 13, Chunks in use: 12. 1.12MiB allocated for chunks. 1.02MiB in use in bin. 972.0KiB client-requested in use in bin.
2019-10-27 10:40:32.548479: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (131072): 	Total Chunks: 11, Chunks in use: 10. 1.47MiB allocated for chunks. 1.34MiB in use in bin. 1.34MiB client-requested in use in bin.
2019-10-27 10:40:32.548505: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (262144): 	Total Chunks: 13, Chunks in use: 13. 4.05MiB allocated for chunks. 4.05MiB in use in bin. 3.91MiB client-requested in use in bin.
2019-10-27 10:40:32.548531: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (524288): 	Total Chunks: 12, Chunks in use: 12. 6.76MiB allocated for chunks. 6.76MiB in use in bin. 6.61MiB client-requested in use in bin.
2019-10-27 10:40:32.548581: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (1048576): 	Total Chunks: 13, Chunks in use: 13. 15.13MiB allocated for chunks. 15.13MiB in use in bin. 14.06MiB client-requested in use in bin.
2019-10-27 10:40:32.548612: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (2097152): 	Total Chunks: 13, Chunks in use: 13. 29.25MiB allocated for chunks. 29.25MiB in use in bin. 28.50MiB client-requested in use in bin.
2019-10-27 10:40:32.548640: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (4194304): 	Total Chunks: 5, Chunks in use: 5. 21.39MiB allocated for chunks. 21.39MiB in use in bin. 18.25MiB client-requested in use in bin.
2019-10-27 10:40:32.548669: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (8388608): 	Total Chunks: 11, Chunks in use: 10. 120.91MiB allocated for chunks. 109.74MiB in use in bin. 88.50MiB client-requested in use in bin.
2019-10-27 10:40:32.548697: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (16777216): 	Total Chunks: 14, Chunks in use: 13. 293.45MiB allocated for chunks. 262.63MiB in use in bin. 232.25MiB client-requested in use in bin.
2019-10-27 10:40:32.548725: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (33554432): 	Total Chunks: 19, Chunks in use: 19. 664.12MiB allocated for chunks. 664.12MiB in use in bin. 664.12MiB client-requested in use in bin.
2019-10-27 10:40:32.548751: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (67108864): 	Total Chunks: 23, Chunks in use: 22. 1.65GiB allocated for chunks. 1.56GiB in use in bin. 1.49GiB client-requested in use in bin.
2019-10-27 10:40:32.548777: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (134217728): 	Total Chunks: 17, Chunks in use: 17. 2.19GiB allocated for chunks. 2.19GiB in use in bin. 2.19GiB client-requested in use in bin.
2019-10-27 10:40:32.548802: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (268435456): 	Total Chunks: 20, Chunks in use: 20. 6.19GiB allocated for chunks. 6.19GiB in use in bin. 6.12GiB client-requested in use in bin.
2019-10-27 10:40:32.548828: I tensorflow/core/common_runtime/bfc_allocator.cc:780] Bin for 264.06MiB was 256.00MiB, Chunk State: 
2019-10-27 10:40:32.548849: I tensorflow/core/common_runtime/bfc_allocator.cc:793] Next region of size 11982716928
2019-10-27 10:40:32.548874: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec000000 next 1 of size 256
2019-10-27 10:40:32.548895: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec000100 next 2 of size 256
2019-10-27 10:40:32.548915: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec000200 next 3 of size 1280
2019-10-27 10:40:32.548934: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec000700 next 4 of size 256
2019-10-27 10:40:32.548955: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec000800 next 9 of size 512
2019-10-27 10:40:32.548980: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec000a00 next 5 of size 1792
2019-10-27 10:40:32.549001: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec001100 next 6 of size 1280
2019-10-27 10:40:32.549024: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec001600 next 16 of size 1024
2019-10-27 10:40:32.549044: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec001a00 next 17 of size 512
2019-10-27 10:40:32.549064: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec001c00 next 19 of size 256
2019-10-27 10:40:32.549083: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec001d00 next 22 of size 256
2019-10-27 10:40:32.549102: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec001e00 next 27 of size 256
2019-10-27 10:40:32.549122: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec001f00 next 28 of size 256
2019-10-27 10:40:32.549141: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec002000 next 32 of size 256
2019-10-27 10:40:32.549171: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec002100 next 20 of size 256
2019-10-27 10:40:32.549193: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec002200 next 21 of size 768
2019-10-27 10:40:32.549213: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec002500 next 36 of size 512
2019-10-27 10:40:32.549233: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec002700 next 37 of size 512
2019-10-27 10:40:32.549252: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec002900 next 41 of size 512
2019-10-27 10:40:32.549272: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec002b00 next 43 of size 512
2019-10-27 10:40:32.549292: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec002d00 next 44 of size 512
2019-10-27 10:40:32.549311: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec002f00 next 48 of size 512
2019-10-27 10:40:32.549331: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec003100 next 49 of size 256
2019-10-27 10:40:32.549351: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec003200 next 50 of size 256
2019-10-27 10:40:32.549371: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec003300 next 52 of size 256
2019-10-27 10:40:32.549390: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec003400 next 54 of size 256
2019-10-27 10:40:32.549410: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec003500 next 57 of size 256
2019-10-27 10:40:32.549429: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec003600 next 97 of size 1280
2019-10-27 10:40:32.549449: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec003b00 next 88 of size 256
2019-10-27 10:40:32.549469: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec003c00 next 100 of size 256
2019-10-27 10:40:32.549489: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec003d00 next 98 of size 512
2019-10-27 10:40:32.549508: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec003f00 next 87 of size 1024
2019-10-27 10:40:32.549528: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec004300 next 94 of size 1024
2019-10-27 10:40:32.549547: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec004700 next 102 of size 512
2019-10-27 10:40:32.549567: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec004900 next 106 of size 1024
2019-10-27 10:40:32.549587: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec004d00 next 107 of size 1024
2019-10-27 10:40:32.549607: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec005100 next 109 of size 512
2019-10-27 10:40:32.549626: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec005300 next 110 of size 256
2019-10-27 10:40:32.549645: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec005400 next 111 of size 256
2019-10-27 10:40:32.549665: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec005500 next 112 of size 1280
2019-10-27 10:40:32.549685: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec005a00 next 113 of size 256
2019-10-27 10:40:32.549705: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec005b00 next 114 of size 1280
2019-10-27 10:40:32.549725: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec006000 next 115 of size 256
2019-10-27 10:40:32.549744: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec006100 next 117 of size 256
2019-10-27 10:40:32.549764: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec006200 next 119 of size 512
2019-10-27 10:40:32.549783: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec006400 next 121 of size 1024
2019-10-27 10:40:32.549819: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec006800 next 23 of size 1280
2019-10-27 10:40:32.549844: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec006d00 next 24 of size 9216
2019-10-27 10:40:32.549865: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec009100 next 59 of size 256
2019-10-27 10:40:32.549884: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec009200 next 60 of size 256
2019-10-27 10:40:32.549904: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec009300 next 61 of size 256
2019-10-27 10:40:32.549924: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec009400 next 62 of size 256
2019-10-27 10:40:32.549944: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec009500 next 69 of size 1024
2019-10-27 10:40:32.549964: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec009900 next 71 of size 1024
2019-10-27 10:40:32.549983: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec009d00 next 73 of size 512
2019-10-27 10:40:32.550003: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec009f00 next 75 of size 256
2019-10-27 10:40:32.550023: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec00a000 next 84 of size 256
2019-10-27 10:40:32.550042: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec00a100 next 101 of size 256
2019-10-27 10:40:32.550061: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec00a200 next 92 of size 256
2019-10-27 10:40:32.550081: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec00a300 next 90 of size 256
2019-10-27 10:40:32.550101: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec00a400 next 96 of size 256
2019-10-27 10:40:32.550121: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec00a500 next 95 of size 256
2019-10-27 10:40:32.550141: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec00a600 next 86 of size 256
2019-10-27 10:40:32.550161: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec00a700 next 99 of size 256
2019-10-27 10:40:32.550180: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec00a800 next 89 of size 256
2019-10-27 10:40:32.550200: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec00a900 next 78 of size 256
2019-10-27 10:40:32.550219: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec00aa00 next 79 of size 1280
2019-10-27 10:40:32.550239: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec00af00 next 77 of size 256
2019-10-27 10:40:32.550258: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec00b000 next 80 of size 256
2019-10-27 10:40:32.550278: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec00b100 next 81 of size 256
2019-10-27 10:40:32.550298: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec00b200 next 82 of size 256
2019-10-27 10:40:32.550318: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec00b300 next 83 of size 256
2019-10-27 10:40:32.550337: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec00b400 next 58 of size 256
2019-10-27 10:40:32.550358: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec00b500 next 25 of size 9216
2019-10-27 10:40:32.550379: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec00d900 next 26 of size 18432
2019-10-27 10:40:32.550403: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec012100 next 55 of size 36864
2019-10-27 10:40:32.550425: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec01b100 next 104 of size 16384
2019-10-27 10:40:32.550445: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec01f100 next 124 of size 512
2019-10-27 10:40:32.550474: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec01f300 next 7 of size 25344
2019-10-27 10:40:32.550496: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec025600 next 8 of size 73728
2019-10-27 10:40:32.550516: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec037600 next 29 of size 36864
2019-10-27 10:40:32.550536: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec040600 next 56 of size 27648
2019-10-27 10:40:32.550560: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec047200 next 30 of size 46080
2019-10-27 10:40:32.550581: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec052600 next 31 of size 73728
2019-10-27 10:40:32.550604: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec064600 next 51 of size 147456
2019-10-27 10:40:32.550625: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec088600 next 76 of size 73728
2019-10-27 10:40:32.550645: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec09a600 next 91 of size 73728
2019-10-27 10:40:32.550667: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec0ac600 next 10 of size 110592
2019-10-27 10:40:32.550691: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec0c7600 next 11 of size 294912
2019-10-27 10:40:32.550711: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec10f600 next 74 of size 294912
2019-10-27 10:40:32.550731: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec157600 next 40 of size 294912
2019-10-27 10:40:32.550754: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec19f600 next 38 of size 589824
2019-10-27 10:40:32.550775: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec22f600 next 39 of size 589824
2019-10-27 10:40:32.550795: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec2bf600 next 13 of size 589824
2019-10-27 10:40:32.550818: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec34f600 next 14 of size 1179648
2019-10-27 10:40:32.550839: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec46f600 next 18 of size 1179648
2019-10-27 10:40:32.550859: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec58f600 next 34 of size 147456
2019-10-27 10:40:32.550878: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec5b3600 next 53 of size 110592
2019-10-27 10:40:32.550898: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec5ce600 next 116 of size 73728
2019-10-27 10:40:32.550918: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec5e0600 next 127 of size 1024
2019-10-27 10:40:32.550938: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec5e0a00 next 129 of size 1024
2019-10-27 10:40:32.550958: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec5e0e00 next 131 of size 512
2019-10-27 10:40:32.550977: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec5e1000 next 133 of size 256
2019-10-27 10:40:32.550998: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec5e1100 next 33 of size 107776
2019-10-27 10:40:32.551018: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec5fb600 next 35 of size 294912
2019-10-27 10:40:32.551038: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec643600 next 12 of size 442368
2019-10-27 10:40:32.551058: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec6af600 next 15 of size 2359296
2019-10-27 10:40:32.551078: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec8ef600 next 42 of size 589824
2019-10-27 10:40:32.551098: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec97f600 next 47 of size 589824
2019-10-27 10:40:32.551164: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50eca0f600 next 45 of size 1769472
2019-10-27 10:40:32.551188: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ecbbf600 next 46 of size 1179648
2019-10-27 10:40:32.551211: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50eccdf600 next 66 of size 4194304
2019-10-27 10:40:32.551232: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ed0df600 next 67 of size 2097152
2019-10-27 10:40:32.551252: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ed2df600 next 72 of size 1179648
2019-10-27 10:40:32.551271: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ed3ff600 next 64 of size 1179648
2019-10-27 10:40:32.551291: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ed51f600 next 68 of size 2359296
2019-10-27 10:40:32.551311: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ed75f600 next 70 of size 2359296
2019-10-27 10:40:32.551331: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ed99f600 next 103 of size 2097152
2019-10-27 10:40:32.551351: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50edb9f600 next 105 of size 2359296
2019-10-27 10:40:32.551374: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50edddf600 next 63 of size 3145728
2019-10-27 10:40:32.551395: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ee0df600 next 65 of size 16777216
2019-10-27 10:40:32.551415: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ef0df600 next 108 of size 1179648
2019-10-27 10:40:32.551434: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ef1ff600 next 118 of size 294912
2019-10-27 10:40:32.551455: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ef247600 next 120 of size 1179648
2019-10-27 10:40:32.551474: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ef367600 next 122 of size 2359296
2019-10-27 10:40:32.551494: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ef5a7600 next 123 of size 1179648
2019-10-27 10:40:32.551513: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ef6c7600 next 125 of size 2097152
2019-10-27 10:40:32.551532: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ef8c7600 next 126 of size 2359296
2019-10-27 10:40:32.551552: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50efb07600 next 128 of size 2359296
2019-10-27 10:40:32.551571: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50efd47600 next 130 of size 1179648
2019-10-27 10:40:32.551591: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50efe67600 next 132 of size 294912
2019-10-27 10:40:32.551610: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50efeaf600 next 134 of size 256
2019-10-27 10:40:32.551630: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50efeaf700 next 135 of size 1280
2019-10-27 10:40:32.551649: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50efeafc00 next 136 of size 256
2019-10-27 10:40:32.551669: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50efeafd00 next 137 of size 256
2019-10-27 10:40:32.551688: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50efeafe00 next 138 of size 256
2019-10-27 10:40:32.551707: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50efeaff00 next 139 of size 256
2019-10-27 10:40:32.551726: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50efeb0000 next 140 of size 256
2019-10-27 10:40:32.551746: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50efeb0100 next 141 of size 256
2019-10-27 10:40:32.551765: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50efeb0200 next 142 of size 768
2019-10-27 10:40:32.551784: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50efeb0500 next 143 of size 256
2019-10-27 10:40:32.551812: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50efeb0600 next 144 of size 9216
2019-10-27 10:40:32.551834: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50efeb2a00 next 145 of size 256
2019-10-27 10:40:32.551854: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50efeb2b00 next 146 of size 18432
2019-10-27 10:40:32.551873: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50efeb7300 next 147 of size 256
2019-10-27 10:40:32.551893: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50efeb7400 next 148 of size 36864
2019-10-27 10:40:32.551912: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50efec0400 next 149 of size 256
2019-10-27 10:40:32.551931: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50efec0500 next 150 of size 73728
2019-10-27 10:40:32.551950: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50efed2500 next 151 of size 256
2019-10-27 10:40:32.551969: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50efed2600 next 152 of size 147456
2019-10-27 10:40:32.551989: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50efef6600 next 153 of size 256
2019-10-27 10:40:32.552008: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50efef6700 next 154 of size 294912
2019-10-27 10:40:32.552027: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50eff3e700 next 155 of size 512
2019-10-27 10:40:32.552046: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50eff3e900 next 156 of size 589824
2019-10-27 10:40:32.552065: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50effce900 next 157 of size 512
2019-10-27 10:40:32.552085: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50effceb00 next 93 of size 1116928
2019-10-27 10:40:32.552105: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f00df600 next 85 of size 16777216
2019-10-27 10:40:32.552124: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f10df600 next 158 of size 512
2019-10-27 10:40:32.552144: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f10df800 next 159 of size 589824
2019-10-27 10:40:32.552163: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f116f800 next 160 of size 512
2019-10-27 10:40:32.552182: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f116fa00 next 161 of size 1179648
2019-10-27 10:40:32.552201: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f128fa00 next 162 of size 512
2019-10-27 10:40:32.552220: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f128fc00 next 163 of size 589824
2019-10-27 10:40:32.552239: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f131fc00 next 164 of size 512
2019-10-27 10:40:32.552259: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f131fe00 next 165 of size 442368
2019-10-27 10:40:32.552278: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f138be00 next 166 of size 256
2019-10-27 10:40:32.552297: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f138bf00 next 167 of size 147456
2019-10-27 10:40:32.552316: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f13aff00 next 168 of size 256
2019-10-27 10:40:32.552335: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f13b0000 next 169 of size 110592
2019-10-27 10:40:32.552355: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f13cb000 next 170 of size 256
2019-10-27 10:40:32.552374: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f13cb100 next 171 of size 36864
2019-10-27 10:40:32.552393: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f13d4100 next 172 of size 256
2019-10-27 10:40:32.552421: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f13d4200 next 173 of size 27648
2019-10-27 10:40:32.552442: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f13dae00 next 174 of size 256
2019-10-27 10:40:32.552461: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f13daf00 next 175 of size 9216
2019-10-27 10:40:32.552480: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f13dd300 next 176 of size 256
2019-10-27 10:40:32.552499: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f13dd400 next 177 of size 256
2019-10-27 10:40:32.552518: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f13dd500 next 178 of size 256
2019-10-27 10:40:32.552537: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f13dd600 next 179 of size 256
2019-10-27 10:40:32.552556: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f13dd700 next 180 of size 256
2019-10-27 10:40:32.552575: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f13dd800 next 181 of size 256
2019-10-27 10:40:32.552595: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f13dd900 next 182 of size 256
2019-10-27 10:40:32.552614: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f13dda00 next 183 of size 256
2019-10-27 10:40:32.552633: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f13ddb00 next 184 of size 256
2019-10-27 10:40:32.552652: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f13ddc00 next 185 of size 256
2019-10-27 10:40:32.552671: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f13ddd00 next 186 of size 256
2019-10-27 10:40:32.552690: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f13dde00 next 187 of size 256
2019-10-27 10:40:32.552710: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f13ddf00 next 188 of size 256
2019-10-27 10:40:32.552729: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f13de000 next 189 of size 256
2019-10-27 10:40:32.552752: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f13de100 next 190 of size 131072
2019-10-27 10:40:32.552773: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f13fe100 next 191 of size 131072
2019-10-27 10:40:32.552793: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f141e100 next 192 of size 256
2019-10-27 10:40:32.552812: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f141e200 next 193 of size 256
2019-10-27 10:40:32.552832: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f141e300 next 194 of size 256
2019-10-27 10:40:32.552852: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f141e400 next 195 of size 256
2019-10-27 10:40:32.552871: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f141e500 next 196 of size 256
2019-10-27 10:40:32.552890: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f141e600 next 197 of size 256
2019-10-27 10:40:32.552910: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f141e700 next 198 of size 256
2019-10-27 10:40:32.552929: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f141e800 next 199 of size 256
2019-10-27 10:40:32.552948: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f141e900 next 200 of size 256
2019-10-27 10:40:32.552968: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f141ea00 next 212 of size 256
2019-10-27 10:40:32.552988: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f141eb00 next 213 of size 262144
2019-10-27 10:40:32.553008: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f145eb00 next 214 of size 256
2019-10-27 10:40:32.553027: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f145ec00 next 215 of size 256
2019-10-27 10:40:32.553055: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f145ed00 next 218 of size 256
2019-10-27 10:40:32.553077: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f145ee00 next 219 of size 256
2019-10-27 10:40:32.553097: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f145ef00 next 220 of size 256
2019-10-27 10:40:32.553116: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f145f000 next 222 of size 256
2019-10-27 10:40:32.553135: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f145f100 next 223 of size 256
2019-10-27 10:40:32.553154: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f145f200 next 224 of size 9216
2019-10-27 10:40:32.553173: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f1461600 next 234 of size 256
2019-10-27 10:40:32.553193: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f1461700 next 235 of size 256
2019-10-27 10:40:32.553212: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f1461800 next 237 of size 256
2019-10-27 10:40:32.553231: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f1461900 next 238 of size 256
2019-10-27 10:40:32.553250: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f1461a00 next 239 of size 256
2019-10-27 10:40:32.553269: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f1461b00 next 240 of size 18432
2019-10-27 10:40:32.553289: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f1466300 next 242 of size 256
2019-10-27 10:40:32.553308: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f1466400 next 250 of size 256
2019-10-27 10:40:32.553327: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f1466500 next 251 of size 256
2019-10-27 10:40:32.553346: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f1466600 next 252 of size 256
2019-10-27 10:40:32.553366: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f1466700 next 253 of size 36864
2019-10-27 10:40:32.553385: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f146f700 next 255 of size 256
2019-10-27 10:40:32.553404: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f146f800 next 257 of size 256
2019-10-27 10:40:32.553423: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f146f900 next 258 of size 256
2019-10-27 10:40:32.553443: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f146fa00 next 259 of size 256
2019-10-27 10:40:32.553463: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f146fb00 next 260 of size 256
2019-10-27 10:40:32.553483: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f146fc00 next 270 of size 256
2019-10-27 10:40:32.553502: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f146fd00 next 273 of size 256
2019-10-27 10:40:32.553521: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f146fe00 next 274 of size 256
2019-10-27 10:40:32.553541: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f146ff00 next 275 of size 256
2019-10-27 10:40:32.553560: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f1470000 next 276 of size 256
2019-10-27 10:40:32.553579: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f1470100 next 277 of size 256
2019-10-27 10:40:32.553598: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f1470200 next 279 of size 131072
2019-10-27 10:40:32.553618: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f1490200 next 280 of size 256
2019-10-27 10:40:32.553637: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f1490300 next 281 of size 256
2019-10-27 10:40:32.553656: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f1490400 next 282 of size 256
2019-10-27 10:40:32.553684: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f1490500 next 283 of size 147456
2019-10-27 10:40:32.553705: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f14b4500 next 284 of size 256
2019-10-27 10:40:32.553725: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f14b4600 next 286 of size 256
2019-10-27 10:40:32.553744: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f14b4700 next 287 of size 256
2019-10-27 10:40:32.553763: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f14b4800 next 288 of size 256
2019-10-27 10:40:32.553782: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f14b4900 next 289 of size 256
2019-10-27 10:40:32.553801: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f14b4a00 next 290 of size 256
2019-10-27 10:40:32.553821: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f14b4b00 next 291 of size 256
2019-10-27 10:40:32.553839: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f14b4c00 next 292 of size 256
2019-10-27 10:40:32.553858: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f14b4d00 next 293 of size 256
2019-10-27 10:40:32.553877: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f14b4e00 next 294 of size 294912
2019-10-27 10:40:32.553896: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f14fce00 next 296 of size 256
2019-10-27 10:40:32.553916: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f14fcf00 next 298 of size 256
2019-10-27 10:40:32.553936: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f14fd000 next 299 of size 256
2019-10-27 10:40:32.553955: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f14fd100 next 300 of size 512
2019-10-27 10:40:32.553974: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f14fd300 next 302 of size 256
2019-10-27 10:40:32.553994: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f14fd400 next 306 of size 589824
2019-10-27 10:40:32.554013: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f158d400 next 308 of size 256
2019-10-27 10:40:32.554032: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f158d500 next 309 of size 256
2019-10-27 10:40:32.554051: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f158d600 next 310 of size 512
2019-10-27 10:40:32.554071: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f158d800 next 313 of size 256
2019-10-27 10:40:32.554090: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f158d900 next 316 of size 256
2019-10-27 10:40:32.554109: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f158da00 next 315 of size 589824
2019-10-27 10:40:32.554128: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f161da00 next 320 of size 256
2019-10-27 10:40:32.554147: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f161db00 next 318 of size 256
2019-10-27 10:40:32.554166: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f161dc00 next 321 of size 512
2019-10-27 10:40:32.554185: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f161de00 next 323 of size 256
2019-10-27 10:40:32.554205: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f161df00 next 326 of size 256
2019-10-27 10:40:32.554228: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f161e000 next 261 of size 596992
2019-10-27 10:40:32.554249: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f16afc00 next 262 of size 256
2019-10-27 10:40:32.554268: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f16afd00 next 264 of size 256
2019-10-27 10:40:32.554287: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f16afe00 next 265 of size 256
2019-10-27 10:40:32.554320: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f16aff00 next 266 of size 256
2019-10-27 10:40:32.554342: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f16b0000 next 267 of size 73728
2019-10-27 10:40:32.554362: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f16c2000 next 269 of size 2359296
2019-10-27 10:40:32.554382: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f1902000 next 272 of size 2359296
2019-10-27 10:40:32.554402: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f1b42000 next 243 of size 5653504
2019-10-27 10:40:32.554421: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f20a6400 next 244 of size 256
2019-10-27 10:40:32.554440: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f20a6500 next 245 of size 256
2019-10-27 10:40:32.554459: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f20a6600 next 246 of size 256
2019-10-27 10:40:32.554478: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f20a6700 next 248 of size 256
2019-10-27 10:40:32.554496: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f20a6800 next 249 of size 256
2019-10-27 10:40:32.554516: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f20a6900 next 226 of size 16624896
2019-10-27 10:40:32.554536: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f3081600 next 227 of size 256
2019-10-27 10:40:32.554556: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f3081700 next 228 of size 256
2019-10-27 10:40:32.554575: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f3081800 next 230 of size 256
2019-10-27 10:40:32.554594: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f3081900 next 231 of size 256
2019-10-27 10:40:32.554613: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f3081a00 next 232 of size 256
2019-10-27 10:40:32.554633: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f3081b00 next 201 of size 33214208
2019-10-27 10:40:32.554653: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f502ea00 next 207 of size 256
2019-10-27 10:40:32.554672: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f502eb00 next 208 of size 768
2019-10-27 10:40:32.554692: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f502ee00 next 297 of size 4194304
2019-10-27 10:40:32.554711: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f542ee00 next 328 of size 256
2019-10-27 10:40:32.554730: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f542ef00 next 331 of size 256
2019-10-27 10:40:32.554750: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f542f000 next 332 of size 512
2019-10-27 10:40:32.554770: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f542f200 next 254 of size 8649728
2019-10-27 10:40:32.554790: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f5c6ee00 next 236 of size 16646144
2019-10-27 10:40:32.554810: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f6c4ee00 next 217 of size 33488896
2019-10-27 10:40:32.554834: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f8c3ee00 next 443 of size 8388608
2019-10-27 10:40:32.554855: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f50f943ee00 next 432 of size 32309248
2019-10-27 10:40:32.554878: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50fb30ee00 next 434 of size 67108864
2019-10-27 10:40:32.554899: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ff30ee00 next 437 of size 67108864
2019-10-27 10:40:32.554919: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f510330ee00 next 202 of size 97614848
2019-10-27 10:40:32.554940: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5109026a00 next 203 of size 130056192
2019-10-27 10:40:32.554969: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5110c2ea00 next 204 of size 268435456
2019-10-27 10:40:32.554990: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5120c2ea00 next 205 of size 130056192
2019-10-27 10:40:32.555010: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5128836a00 next 206 of size 268435456
2019-10-27 10:40:32.555030: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5138836a00 next 209 of size 256
2019-10-27 10:40:32.555049: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5138836b00 next 210 of size 256
2019-10-27 10:40:32.555069: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5138836c00 next 211 of size 62980096
2019-10-27 10:40:32.555088: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f513c446c00 next 216 of size 268435456
2019-10-27 10:40:32.555122: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f514c446c00 next 221 of size 62980096
2019-10-27 10:40:32.555143: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5150056c00 next 225 of size 268435456
2019-10-27 10:40:32.555163: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5160056c00 next 229 of size 67108864
2019-10-27 10:40:32.555183: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5164056c00 next 233 of size 134217728
2019-10-27 10:40:32.555203: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f516c056c00 next 241 of size 134217728
2019-10-27 10:40:32.555222: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5174056c00 next 247 of size 134217728
2019-10-27 10:40:32.555241: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f517c056c00 next 256 of size 134217728
2019-10-27 10:40:32.555261: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5184056c00 next 263 of size 134217728
2019-10-27 10:40:32.555284: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f518c056c00 next 268 of size 33554432
2019-10-27 10:40:32.555305: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f518e056c00 next 271 of size 67108864
2019-10-27 10:40:32.555324: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5192056c00 next 278 of size 67108864
2019-10-27 10:40:32.555344: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5196056c00 next 285 of size 67108864
2019-10-27 10:40:32.555363: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f519a056c00 next 295 of size 67108864
2019-10-27 10:40:32.555383: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f519e056c00 next 301 of size 67108864
2019-10-27 10:40:32.555402: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a2056c00 next 303 of size 16777216
2019-10-27 10:40:32.555423: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a3056c00 next 304 of size 21233664
2019-10-27 10:40:32.555442: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4496c00 next 329 of size 256
2019-10-27 10:40:32.555461: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4496d00 next 339 of size 256
2019-10-27 10:40:32.555480: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4496e00 next 338 of size 512
2019-10-27 10:40:32.555499: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4497000 next 340 of size 256
2019-10-27 10:40:32.555519: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4497100 next 341 of size 589824
2019-10-27 10:40:32.555538: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4527100 next 352 of size 256
2019-10-27 10:40:32.555557: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4527200 next 353 of size 256
2019-10-27 10:40:32.555576: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4527300 next 358 of size 256
2019-10-27 10:40:32.555605: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4527400 next 359 of size 256
2019-10-27 10:40:32.555626: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4527500 next 361 of size 256
2019-10-27 10:40:32.555646: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4527600 next 363 of size 147456
2019-10-27 10:40:32.555665: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a454b600 next 365 of size 256
2019-10-27 10:40:32.555684: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a454b700 next 367 of size 256
2019-10-27 10:40:32.555703: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a454b800 next 369 of size 256
2019-10-27 10:40:32.555723: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a454b900 next 371 of size 110592
2019-10-27 10:40:32.555743: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4566900 next 372 of size 256
2019-10-27 10:40:32.555762: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4566a00 next 373 of size 256
2019-10-27 10:40:32.555782: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4566b00 next 375 of size 256
2019-10-27 10:40:32.555802: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4566c00 next 376 of size 36864
2019-10-27 10:40:32.555822: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a456fc00 next 377 of size 256
2019-10-27 10:40:32.555841: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a456fd00 next 380 of size 256
2019-10-27 10:40:32.555860: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a456fe00 next 381 of size 256
2019-10-27 10:40:32.555880: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a456ff00 next 383 of size 27648
2019-10-27 10:40:32.555899: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4576b00 next 385 of size 256
2019-10-27 10:40:32.555918: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4576c00 next 388 of size 256
2019-10-27 10:40:32.555938: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4576d00 next 389 of size 256
2019-10-27 10:40:32.555957: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4576e00 next 391 of size 9216
2019-10-27 10:40:32.555976: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4579200 next 392 of size 256
2019-10-27 10:40:32.555995: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4579300 next 394 of size 256
2019-10-27 10:40:32.556014: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4579400 next 397 of size 256
2019-10-27 10:40:32.556033: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4579500 next 398 of size 256
2019-10-27 10:40:32.556052: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4579600 next 401 of size 256
2019-10-27 10:40:32.556072: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4579700 next 396 of size 256
2019-10-27 10:40:32.556091: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4579800 next 403 of size 256
2019-10-27 10:40:32.556110: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4579900 next 433 of size 256
2019-10-27 10:40:32.556129: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f51a4579a00 next 431 of size 256
2019-10-27 10:40:32.556149: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4579b00 next 439 of size 256
2019-10-27 10:40:32.556168: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4579c00 next 441 of size 256
2019-10-27 10:40:32.556187: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f51a4579d00 next 425 of size 107008
2019-10-27 10:40:32.556207: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4593f00 next 423 of size 131072
2019-10-27 10:40:32.556236: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a45b3f00 next 305 of size 15609088
2019-10-27 10:40:32.556258: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a5496c00 next 312 of size 16777216
2019-10-27 10:40:32.556277: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a6496c00 next 334 of size 256
2019-10-27 10:40:32.556297: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a6496d00 next 335 of size 1179648
2019-10-27 10:40:32.556317: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a65b6d00 next 337 of size 256
2019-10-27 10:40:32.556337: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a65b6e00 next 307 of size 15597056
2019-10-27 10:40:32.556357: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a7496c00 next 311 of size 33554432
2019-10-27 10:40:32.556377: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a9496c00 next 314 of size 33554432
2019-10-27 10:40:32.556396: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51ab496c00 next 319 of size 33554432
2019-10-27 10:40:32.556416: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51ad496c00 next 317 of size 109314048
2019-10-27 10:40:32.556436: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51b3cd6c00 next 327 of size 33554432
2019-10-27 10:40:32.556456: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51b5cd6c00 next 342 of size 256
2019-10-27 10:40:32.556476: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51b5cd6d00 next 343 of size 8388608
2019-10-27 10:40:32.556495: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51b64d6d00 next 346 of size 256
2019-10-27 10:40:32.556514: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51b64d6e00 next 348 of size 256
2019-10-27 10:40:32.556534: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51b64d6f00 next 349 of size 512
2019-10-27 10:40:32.556553: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51b64d7100 next 350 of size 8388608
2019-10-27 10:40:32.556572: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51b6cd7100 next 351 of size 256
2019-10-27 10:40:32.556592: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51b6cd7200 next 355 of size 442368
2019-10-27 10:40:32.556611: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f51b6d43200 next 422 of size 131072
2019-10-27 10:40:32.556630: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51b6d63200 next 424 of size 4194304
2019-10-27 10:40:32.556650: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51b7163200 next 438 of size 294912
2019-10-27 10:40:32.556669: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f51b71ab200 next 322 of size 11713024
2019-10-27 10:40:32.556689: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51b7cd6c00 next 324 of size 33554432
2019-10-27 10:40:32.556708: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51b9cd6c00 next 325 of size 67108864
2019-10-27 10:40:32.556728: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51bdcd6c00 next 333 of size 134217728
2019-10-27 10:40:32.556747: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51c5cd6c00 next 362 of size 16777216
2019-10-27 10:40:32.556766: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51c6cd6c00 next 364 of size 16777216
2019-10-27 10:40:32.556786: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51c7cd6c00 next 366 of size 33554432
2019-10-27 10:40:32.556805: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51c9cd6c00 next 370 of size 33554432
2019-10-27 10:40:32.556824: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51cbcd6c00 next 330 of size 33554432
2019-10-27 10:40:32.556852: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51cdcd6c00 next 336 of size 134217728
2019-10-27 10:40:32.556874: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51d5cd6c00 next 344 of size 268435456
2019-10-27 10:40:32.556894: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51e5cd6c00 next 360 of size 67108864
2019-10-27 10:40:32.556914: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51e9cd6c00 next 345 of size 201326592
2019-10-27 10:40:32.556933: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51f5cd6c00 next 347 of size 268435456
2019-10-27 10:40:32.556953: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5205cd6c00 next 357 of size 536870912
2019-10-27 10:40:32.556974: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5225cd6c00 next 368 of size 268435456
2019-10-27 10:40:32.556993: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5235cd6c00 next 354 of size 268435456
2019-10-27 10:40:32.557013: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5245cd6c00 next 356 of size 536870912
2019-10-27 10:40:32.557032: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5265cd6c00 next 374 of size 268435456
2019-10-27 10:40:32.557052: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5275cd6c00 next 384 of size 67108864
2019-10-27 10:40:32.557071: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5279cd6c00 next 386 of size 67108864
2019-10-27 10:40:32.557090: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f527dcd6c00 next 378 of size 67108864
2019-10-27 10:40:32.557110: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5281cd6c00 next 379 of size 268435456
2019-10-27 10:40:32.557129: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5291cd6c00 next 382 of size 268435456
2019-10-27 10:40:32.557148: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f52a1cd6c00 next 395 of size 67108864
2019-10-27 10:40:32.557168: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f52a5cd6c00 next 387 of size 67108864
2019-10-27 10:40:32.557187: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f52a9cd6c00 next 390 of size 134217728
2019-10-27 10:40:32.557206: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f52b1cd6c00 next 393 of size 134217728
2019-10-27 10:40:32.557226: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f52b9cd6c00 next 399 of size 402653184
2019-10-27 10:40:32.557246: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f52d1cd6c00 next 400 of size 134217728
2019-10-27 10:40:32.557266: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f52d9cd6c00 next 402 of size 134217728
2019-10-27 10:40:32.557285: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f52e1cd6c00 next 412 of size 67108864
2019-10-27 10:40:32.557304: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f52e5cd6c00 next 410 of size 33554432
2019-10-27 10:40:32.557324: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f52e7cd6c00 next 404 of size 33554432
2019-10-27 10:40:32.557343: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f52e9cd6c00 next 405 of size 134217728
2019-10-27 10:40:32.557362: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f52f1cd6c00 next 406 of size 134217728
2019-10-27 10:40:32.557382: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f52f9cd6c00 next 407 of size 67108864
2019-10-27 10:40:32.557401: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f52fdcd6c00 next 408 of size 134217728
2019-10-27 10:40:32.557421: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5305cd6c00 next 409 of size 67108864
2019-10-27 10:40:32.557449: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5309cd6c00 next 417 of size 268435456
2019-10-27 10:40:32.557470: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5319cd6c00 next 419 of size 268435456
2019-10-27 10:40:32.557490: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5329cd6c00 next 436 of size 134217728
2019-10-27 10:40:32.557509: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5331cd6c00 next 440 of size 33554432
2019-10-27 10:40:32.557529: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5333cd6c00 next 444 of size 33554432
2019-10-27 10:40:32.557548: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5335cd6c00 next 445 of size 33554432
2019-10-27 10:40:32.557568: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f5337cd6c00 next 442 of size 100663296
2019-10-27 10:40:32.557587: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f533dcd6c00 next 435 of size 134217728
2019-10-27 10:40:32.557607: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5345cd6c00 next 411 of size 335544320
2019-10-27 10:40:32.557628: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5359cd6c00 next 413 of size 805306368
2019-10-27 10:40:32.557648: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5389cd6c00 next 414 of size 268435456
2019-10-27 10:40:32.557667: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5399cd6c00 next 415 of size 268435456
2019-10-27 10:40:32.557687: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f53a9cd6c00 next 416 of size 33554432
2019-10-27 10:40:32.557706: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f53abcd6c00 next 418 of size 33554432
2019-10-27 10:40:32.557726: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f53adcd6c00 next 420 of size 33554432
2019-10-27 10:40:32.557745: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f53afcd6c00 next 421 of size 16777216
2019-10-27 10:40:32.557765: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f53b0cd6c00 next 430 of size 8388608
2019-10-27 10:40:32.557785: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f53b14d6c00 next 427 of size 32309248
2019-10-27 10:40:32.557805: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f53b33a6c00 next 428 of size 4194304
2019-10-27 10:40:32.557824: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f53b37a6c00 next 429 of size 16777216
2019-10-27 10:40:32.557843: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f53b47a6c00 next 426 of size 8388608
2019-10-27 10:40:32.557864: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f53b4fa6c00 next 18446744073709551615 of size 20927488
2019-10-27 10:40:32.557882: I tensorflow/core/common_runtime/bfc_allocator.cc:809]      Summary of in-use Chunks by size: 
2019-10-27 10:40:32.557909: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 191 Chunks of size 256 totalling 47.8KiB
2019-10-27 10:40:32.557933: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 27 Chunks of size 512 totalling 13.5KiB
2019-10-27 10:40:32.557956: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 3 Chunks of size 768 totalling 2.2KiB
2019-10-27 10:40:32.557979: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 10 Chunks of size 1024 totalling 10.0KiB
2019-10-27 10:40:32.558002: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 8 Chunks of size 1280 totalling 10.0KiB
2019-10-27 10:40:32.558024: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 1792 totalling 1.8KiB
2019-10-27 10:40:32.558048: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 6 Chunks of size 9216 totalling 54.0KiB
2019-10-27 10:40:32.558070: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 16384 totalling 16.0KiB
2019-10-27 10:40:32.558093: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 3 Chunks of size 18432 totalling 54.0KiB
2019-10-27 10:40:32.558125: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 25344 totalling 24.8KiB
2019-10-27 10:40:32.558150: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 3 Chunks of size 27648 totalling 81.0KiB
2019-10-27 10:40:32.558173: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 6 Chunks of size 36864 totalling 216.0KiB
2019-10-27 10:40:32.558196: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 46080 totalling 45.0KiB
2019-10-27 10:40:32.558219: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 7 Chunks of size 73728 totalling 504.0KiB
2019-10-27 10:40:32.558243: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 107776 totalling 105.2KiB
2019-10-27 10:40:32.558266: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 4 Chunks of size 110592 totalling 432.0KiB
2019-10-27 10:40:32.558289: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 4 Chunks of size 131072 totalling 512.0KiB
2019-10-27 10:40:32.558312: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 6 Chunks of size 147456 totalling 864.0KiB
2019-10-27 10:40:32.558335: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 262144 totalling 256.0KiB
2019-10-27 10:40:32.558357: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 9 Chunks of size 294912 totalling 2.53MiB
2019-10-27 10:40:32.558379: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 3 Chunks of size 442368 totalling 1.27MiB
2019-10-27 10:40:32.558402: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 11 Chunks of size 589824 totalling 6.19MiB
2019-10-27 10:40:32.558426: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 596992 totalling 583.0KiB
2019-10-27 10:40:32.558449: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 1116928 totalling 1.06MiB
2019-10-27 10:40:32.558472: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 11 Chunks of size 1179648 totalling 12.38MiB
2019-10-27 10:40:32.558494: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 1769472 totalling 1.69MiB
2019-10-27 10:40:32.558516: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 3 Chunks of size 2097152 totalling 6.00MiB
2019-10-27 10:40:32.558539: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 9 Chunks of size 2359296 totalling 20.25MiB
2019-10-27 10:40:32.558562: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 3145728 totalling 3.00MiB
2019-10-27 10:40:32.558585: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 4 Chunks of size 4194304 totalling 16.00MiB
2019-10-27 10:40:32.558609: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 5653504 totalling 5.39MiB
2019-10-27 10:40:32.558632: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 5 Chunks of size 8388608 totalling 40.00MiB
2019-10-27 10:40:32.558654: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 8649728 totalling 8.25MiB
2019-10-27 10:40:32.558678: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 15597056 totalling 14.87MiB
2019-10-27 10:40:32.558702: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 15609088 totalling 14.89MiB
2019-10-27 10:40:32.558725: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 16624896 totalling 15.85MiB
2019-10-27 10:40:32.558748: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 16646144 totalling 15.88MiB
2019-10-27 10:40:32.558771: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 8 Chunks of size 16777216 totalling 128.00MiB
2019-10-27 10:40:32.558795: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 20927488 totalling 19.96MiB
2019-10-27 10:40:32.558818: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 21233664 totalling 20.25MiB
2019-10-27 10:40:32.558842: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 32309248 totalling 30.81MiB
2019-10-27 10:40:32.558874: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 33214208 totalling 31.67MiB
2019-10-27 10:40:32.558899: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 33488896 totalling 31.94MiB
2019-10-27 10:40:32.558922: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 17 Chunks of size 33554432 totalling 544.00MiB
2019-10-27 10:40:32.558946: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 62980096 totalling 120.12MiB
2019-10-27 10:40:32.558969: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 18 Chunks of size 67108864 totalling 1.12GiB
2019-10-27 10:40:32.558992: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 97614848 totalling 93.09MiB
2019-10-27 10:40:32.559015: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 109314048 totalling 104.25MiB
2019-10-27 10:40:32.559038: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 130056192 totalling 248.06MiB
2019-10-27 10:40:32.559061: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 16 Chunks of size 134217728 totalling 2.00GiB
2019-10-27 10:40:32.559084: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 201326592 totalling 192.00MiB
2019-10-27 10:40:32.559116: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 15 Chunks of size 268435456 totalling 3.75GiB
2019-10-27 10:40:32.559146: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 335544320 totalling 320.00MiB
2019-10-27 10:40:32.559169: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 402653184 totalling 384.00MiB
2019-10-27 10:40:32.559191: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 536870912 totalling 1.00GiB
2019-10-27 10:40:32.559215: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 805306368 totalling 768.00MiB
2019-10-27 10:40:32.559238: I tensorflow/core/common_runtime/bfc_allocator.cc:816] Sum Total of in-use chunks: 11.02GiB
2019-10-27 10:40:32.559258: I tensorflow/core/common_runtime/bfc_allocator.cc:818] total_region_allocated_bytes_: 11982716928 memory_limit_: 11982716928 available bytes: 0 curr_region_allocation_bytes_: 23965433856
2019-10-27 10:40:32.559291: I tensorflow/core/common_runtime/bfc_allocator.cc:824] Stats: 
Limit:                 11982716928
InUse:                 11837793024
MaxInUse:              11837793024
NumAllocs:                    2044
MaxAllocSize:           3680894976

2019-10-27 10:40:32.559369: W tensorflow/core/common_runtime/bfc_allocator.cc:319] ****************************************************************************************************
2019-10-27 10:40:32.559455: W tensorflow/core/framework/op_kernel.cc:1546] OP_REQUIRES failed at conv_grad_input_ops.cc:954 : Resource exhausted: OOM when allocating tensor with shape[256,64,65,65] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
2019-10-27 10:40:32.559479: W tensorflow/core/common_runtime/bfc_allocator.cc:314] Allocator (GPU_0_bfc) ran out of memory trying to allocate 128.00MiB (rounded to 134217728).  Current allocation summary follows.
2019-10-27 10:40:32.559571: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (256): 	Total Chunks: 192, Chunks in use: 191. 48.0KiB allocated for chunks. 47.8KiB in use in bin. 8.2KiB client-requested in use in bin.
2019-10-27 10:40:32.559608: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (512): 	Total Chunks: 30, Chunks in use: 30. 15.8KiB allocated for chunks. 15.8KiB in use in bin. 15.2KiB client-requested in use in bin.
2019-10-27 10:40:32.559638: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (1024): 	Total Chunks: 19, Chunks in use: 19. 21.8KiB allocated for chunks. 21.8KiB in use in bin. 19.8KiB client-requested in use in bin.
2019-10-27 10:40:32.559664: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (2048): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 10:40:32.559706: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (4096): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 10:40:32.559736: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (8192): 	Total Chunks: 6, Chunks in use: 6. 54.0KiB allocated for chunks. 54.0KiB in use in bin. 54.0KiB client-requested in use in bin.
2019-10-27 10:40:32.559766: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (16384): 	Total Chunks: 8, Chunks in use: 8. 175.8KiB allocated for chunks. 175.8KiB in use in bin. 156.0KiB client-requested in use in bin.
2019-10-27 10:40:32.559795: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (32768): 	Total Chunks: 7, Chunks in use: 7. 261.0KiB allocated for chunks. 261.0KiB in use in bin. 243.0KiB client-requested in use in bin.
2019-10-27 10:40:32.559823: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (65536): 	Total Chunks: 13, Chunks in use: 12. 1.12MiB allocated for chunks. 1.02MiB in use in bin. 972.0KiB client-requested in use in bin.
2019-10-27 10:40:32.559850: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (131072): 	Total Chunks: 11, Chunks in use: 10. 1.47MiB allocated for chunks. 1.34MiB in use in bin. 1.34MiB client-requested in use in bin.
2019-10-27 10:40:32.559876: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (262144): 	Total Chunks: 13, Chunks in use: 13. 4.05MiB allocated for chunks. 4.05MiB in use in bin. 3.91MiB client-requested in use in bin.
2019-10-27 10:40:32.559901: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (524288): 	Total Chunks: 12, Chunks in use: 12. 6.76MiB allocated for chunks. 6.76MiB in use in bin. 6.61MiB client-requested in use in bin.
2019-10-27 10:40:32.559930: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (1048576): 	Total Chunks: 13, Chunks in use: 13. 15.13MiB allocated for chunks. 15.13MiB in use in bin. 14.06MiB client-requested in use in bin.
2019-10-27 10:40:32.559958: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (2097152): 	Total Chunks: 13, Chunks in use: 13. 29.25MiB allocated for chunks. 29.25MiB in use in bin. 28.50MiB client-requested in use in bin.
2019-10-27 10:40:32.559986: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (4194304): 	Total Chunks: 5, Chunks in use: 5. 21.39MiB allocated for chunks. 21.39MiB in use in bin. 18.25MiB client-requested in use in bin.
2019-10-27 10:40:32.560015: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (8388608): 	Total Chunks: 11, Chunks in use: 10. 120.91MiB allocated for chunks. 109.74MiB in use in bin. 88.50MiB client-requested in use in bin.
2019-10-27 10:40:32.560044: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (16777216): 	Total Chunks: 14, Chunks in use: 13. 293.45MiB allocated for chunks. 262.63MiB in use in bin. 232.25MiB client-requested in use in bin.
2019-10-27 10:40:32.560072: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (33554432): 	Total Chunks: 19, Chunks in use: 19. 664.12MiB allocated for chunks. 664.12MiB in use in bin. 664.12MiB client-requested in use in bin.
2019-10-27 10:40:32.560098: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (67108864): 	Total Chunks: 23, Chunks in use: 22. 1.65GiB allocated for chunks. 1.56GiB in use in bin. 1.49GiB client-requested in use in bin.
2019-10-27 10:40:32.560124: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (134217728): 	Total Chunks: 17, Chunks in use: 17. 2.19GiB allocated for chunks. 2.19GiB in use in bin. 2.19GiB client-requested in use in bin.
2019-10-27 10:40:32.560150: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (268435456): 	Total Chunks: 20, Chunks in use: 20. 6.19GiB allocated for chunks. 6.19GiB in use in bin. 6.12GiB client-requested in use in bin.
2019-10-27 10:40:32.560176: I tensorflow/core/common_runtime/bfc_allocator.cc:780] Bin for 128.00MiB was 128.00MiB, Chunk State: 
2019-10-27 10:40:32.560196: I tensorflow/core/common_runtime/bfc_allocator.cc:793] Next region of size 11982716928
2019-10-27 10:40:32.560229: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec000000 next 1 of size 256
2019-10-27 10:40:32.560251: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec000100 next 2 of size 256
2019-10-27 10:40:32.560272: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec000200 next 3 of size 1280
2019-10-27 10:40:32.560292: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec000700 next 4 of size 256
2019-10-27 10:40:32.560313: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec000800 next 9 of size 512
2019-10-27 10:40:32.560333: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec000a00 next 5 of size 1792
2019-10-27 10:40:32.560353: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec001100 next 6 of size 1280
2019-10-27 10:40:32.560373: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec001600 next 16 of size 1024
2019-10-27 10:40:32.560393: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec001a00 next 17 of size 512
2019-10-27 10:40:32.560412: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec001c00 next 19 of size 256
2019-10-27 10:40:32.560432: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec001d00 next 22 of size 256
2019-10-27 10:40:32.560452: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec001e00 next 27 of size 256
2019-10-27 10:40:32.560471: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec001f00 next 28 of size 256
2019-10-27 10:40:32.560491: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec002000 next 32 of size 256
2019-10-27 10:40:32.560510: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec002100 next 20 of size 256
2019-10-27 10:40:32.560530: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec002200 next 21 of size 768
2019-10-27 10:40:32.560550: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec002500 next 36 of size 512
2019-10-27 10:40:32.560570: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec002700 next 37 of size 512
2019-10-27 10:40:32.560589: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec002900 next 41 of size 512
2019-10-27 10:40:32.560609: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec002b00 next 43 of size 512
2019-10-27 10:40:32.560628: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec002d00 next 44 of size 512
2019-10-27 10:40:32.560648: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec002f00 next 48 of size 512
2019-10-27 10:40:32.560668: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec003100 next 49 of size 256
2019-10-27 10:40:32.560688: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec003200 next 50 of size 256
2019-10-27 10:40:32.560707: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec003300 next 52 of size 256
2019-10-27 10:40:32.560727: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec003400 next 54 of size 256
2019-10-27 10:40:32.560747: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec003500 next 57 of size 256
2019-10-27 10:40:32.560766: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec003600 next 97 of size 1280
2019-10-27 10:40:32.560786: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec003b00 next 88 of size 256
2019-10-27 10:40:32.560805: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec003c00 next 100 of size 256
2019-10-27 10:40:32.560825: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec003d00 next 98 of size 512
2019-10-27 10:40:32.560845: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec003f00 next 87 of size 1024
2019-10-27 10:40:32.560873: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec004300 next 94 of size 1024
2019-10-27 10:40:32.560894: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec004700 next 102 of size 512
2019-10-27 10:40:32.560914: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec004900 next 106 of size 1024
2019-10-27 10:40:32.560934: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec004d00 next 107 of size 1024
2019-10-27 10:40:32.560953: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec005100 next 109 of size 512
2019-10-27 10:40:32.560973: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec005300 next 110 of size 256
2019-10-27 10:40:32.560992: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec005400 next 111 of size 256
2019-10-27 10:40:32.561012: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec005500 next 112 of size 1280
2019-10-27 10:40:32.561032: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec005a00 next 113 of size 256
2019-10-27 10:40:32.561052: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec005b00 next 114 of size 1280
2019-10-27 10:40:32.561071: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec006000 next 115 of size 256
2019-10-27 10:40:32.561091: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec006100 next 117 of size 256
2019-10-27 10:40:32.561110: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec006200 next 119 of size 512
2019-10-27 10:40:32.561130: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec006400 next 121 of size 1024
2019-10-27 10:40:32.561150: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec006800 next 23 of size 1280
2019-10-27 10:40:32.561171: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec006d00 next 24 of size 9216
2019-10-27 10:40:32.561191: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec009100 next 59 of size 256
2019-10-27 10:40:32.561210: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec009200 next 60 of size 256
2019-10-27 10:40:32.561230: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec009300 next 61 of size 256
2019-10-27 10:40:32.561249: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec009400 next 62 of size 256
2019-10-27 10:40:32.561269: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec009500 next 69 of size 1024
2019-10-27 10:40:32.561288: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec009900 next 71 of size 1024
2019-10-27 10:40:32.561308: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec009d00 next 73 of size 512
2019-10-27 10:40:32.561327: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec009f00 next 75 of size 256
2019-10-27 10:40:32.561347: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec00a000 next 84 of size 256
2019-10-27 10:40:32.561366: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec00a100 next 101 of size 256
2019-10-27 10:40:32.561385: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec00a200 next 92 of size 256
2019-10-27 10:40:32.561405: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec00a300 next 90 of size 256
2019-10-27 10:40:32.561424: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec00a400 next 96 of size 256
2019-10-27 10:40:32.561444: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec00a500 next 95 of size 256
2019-10-27 10:40:32.561463: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec00a600 next 86 of size 256
2019-10-27 10:40:32.561482: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec00a700 next 99 of size 256
2019-10-27 10:40:32.561510: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec00a800 next 89 of size 256
2019-10-27 10:40:32.561531: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec00a900 next 78 of size 256
2019-10-27 10:40:32.561550: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec00aa00 next 79 of size 1280
2019-10-27 10:40:32.561570: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec00af00 next 77 of size 256
2019-10-27 10:40:32.561589: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec00b000 next 80 of size 256
2019-10-27 10:40:32.561609: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec00b100 next 81 of size 256
2019-10-27 10:40:32.561628: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec00b200 next 82 of size 256
2019-10-27 10:40:32.561648: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec00b300 next 83 of size 256
2019-10-27 10:40:32.561668: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec00b400 next 58 of size 256
2019-10-27 10:40:32.561687: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec00b500 next 25 of size 9216
2019-10-27 10:40:32.561708: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec00d900 next 26 of size 18432
2019-10-27 10:40:32.561728: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec012100 next 55 of size 36864
2019-10-27 10:40:32.561749: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec01b100 next 104 of size 16384
2019-10-27 10:40:32.561769: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec01f100 next 124 of size 512
2019-10-27 10:40:32.561789: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec01f300 next 7 of size 25344
2019-10-27 10:40:32.561809: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec025600 next 8 of size 73728
2019-10-27 10:40:32.561829: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec037600 next 29 of size 36864
2019-10-27 10:40:32.561850: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec040600 next 56 of size 27648
2019-10-27 10:40:32.561870: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec047200 next 30 of size 46080
2019-10-27 10:40:32.561891: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec052600 next 31 of size 73728
2019-10-27 10:40:32.561911: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec064600 next 51 of size 147456
2019-10-27 10:40:32.561931: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec088600 next 76 of size 73728
2019-10-27 10:40:32.561950: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec09a600 next 91 of size 73728
2019-10-27 10:40:32.561971: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec0ac600 next 10 of size 110592
2019-10-27 10:40:32.561991: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec0c7600 next 11 of size 294912
2019-10-27 10:40:32.562011: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec10f600 next 74 of size 294912
2019-10-27 10:40:32.562031: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec157600 next 40 of size 294912
2019-10-27 10:40:32.562051: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec19f600 next 38 of size 589824
2019-10-27 10:40:32.562071: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec22f600 next 39 of size 589824
2019-10-27 10:40:32.562091: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec2bf600 next 13 of size 589824
2019-10-27 10:40:32.562111: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec34f600 next 14 of size 1179648
2019-10-27 10:40:32.562131: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec46f600 next 18 of size 1179648
2019-10-27 10:40:32.562159: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec58f600 next 34 of size 147456
2019-10-27 10:40:32.562180: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec5b3600 next 53 of size 110592
2019-10-27 10:40:32.562200: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec5ce600 next 116 of size 73728
2019-10-27 10:40:32.562220: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec5e0600 next 127 of size 1024
2019-10-27 10:40:32.562240: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec5e0a00 next 129 of size 1024
2019-10-27 10:40:32.562260: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec5e0e00 next 131 of size 512
2019-10-27 10:40:32.562280: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec5e1000 next 133 of size 256
2019-10-27 10:40:32.562300: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec5e1100 next 33 of size 107776
2019-10-27 10:40:32.562321: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec5fb600 next 35 of size 294912
2019-10-27 10:40:32.562342: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec643600 next 12 of size 442368
2019-10-27 10:40:32.562362: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec6af600 next 15 of size 2359296
2019-10-27 10:40:32.562382: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec8ef600 next 42 of size 589824
2019-10-27 10:40:32.562402: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ec97f600 next 47 of size 589824
2019-10-27 10:40:32.562422: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50eca0f600 next 45 of size 1769472
2019-10-27 10:40:32.562442: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ecbbf600 next 46 of size 1179648
2019-10-27 10:40:32.562463: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50eccdf600 next 66 of size 4194304
2019-10-27 10:40:32.562484: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ed0df600 next 67 of size 2097152
2019-10-27 10:40:32.562504: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ed2df600 next 72 of size 1179648
2019-10-27 10:40:32.562524: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ed3ff600 next 64 of size 1179648
2019-10-27 10:40:32.562544: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ed51f600 next 68 of size 2359296
2019-10-27 10:40:32.562563: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ed75f600 next 70 of size 2359296
2019-10-27 10:40:32.562583: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ed99f600 next 103 of size 2097152
2019-10-27 10:40:32.562603: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50edb9f600 next 105 of size 2359296
2019-10-27 10:40:32.562624: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50edddf600 next 63 of size 3145728
2019-10-27 10:40:32.562644: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ee0df600 next 65 of size 16777216
2019-10-27 10:40:32.562664: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ef0df600 next 108 of size 1179648
2019-10-27 10:40:32.562684: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ef1ff600 next 118 of size 294912
2019-10-27 10:40:32.562704: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ef247600 next 120 of size 1179648
2019-10-27 10:40:32.562724: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ef367600 next 122 of size 2359296
2019-10-27 10:40:32.562743: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ef5a7600 next 123 of size 1179648
2019-10-27 10:40:32.562763: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ef6c7600 next 125 of size 2097152
2019-10-27 10:40:32.562791: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ef8c7600 next 126 of size 2359296
2019-10-27 10:40:32.562813: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50efb07600 next 128 of size 2359296
2019-10-27 10:40:32.562832: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50efd47600 next 130 of size 1179648
2019-10-27 10:40:32.562852: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50efe67600 next 132 of size 294912
2019-10-27 10:40:32.562872: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50efeaf600 next 134 of size 256
2019-10-27 10:40:32.562892: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50efeaf700 next 135 of size 1280
2019-10-27 10:40:32.562911: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50efeafc00 next 136 of size 256
2019-10-27 10:40:32.562931: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50efeafd00 next 137 of size 256
2019-10-27 10:40:32.562951: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50efeafe00 next 138 of size 256
2019-10-27 10:40:32.562970: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50efeaff00 next 139 of size 256
2019-10-27 10:40:32.562989: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50efeb0000 next 140 of size 256
2019-10-27 10:40:32.563009: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50efeb0100 next 141 of size 256
2019-10-27 10:40:32.563029: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50efeb0200 next 142 of size 768
2019-10-27 10:40:32.563048: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50efeb0500 next 143 of size 256
2019-10-27 10:40:32.563068: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50efeb0600 next 144 of size 9216
2019-10-27 10:40:32.563087: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50efeb2a00 next 145 of size 256
2019-10-27 10:40:32.563133: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50efeb2b00 next 146 of size 18432
2019-10-27 10:40:32.563155: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50efeb7300 next 147 of size 256
2019-10-27 10:40:32.563178: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50efeb7400 next 148 of size 36864
2019-10-27 10:40:32.563197: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50efec0400 next 149 of size 256
2019-10-27 10:40:32.563217: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50efec0500 next 150 of size 73728
2019-10-27 10:40:32.563236: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50efed2500 next 151 of size 256
2019-10-27 10:40:32.563256: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50efed2600 next 152 of size 147456
2019-10-27 10:40:32.563276: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50efef6600 next 153 of size 256
2019-10-27 10:40:32.563296: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50efef6700 next 154 of size 294912
2019-10-27 10:40:32.563315: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50eff3e700 next 155 of size 512
2019-10-27 10:40:32.563334: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50eff3e900 next 156 of size 589824
2019-10-27 10:40:32.563354: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50effce900 next 157 of size 512
2019-10-27 10:40:32.563375: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50effceb00 next 93 of size 1116928
2019-10-27 10:40:32.563395: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f00df600 next 85 of size 16777216
2019-10-27 10:40:32.563414: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f10df600 next 158 of size 512
2019-10-27 10:40:32.563434: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f10df800 next 159 of size 589824
2019-10-27 10:40:32.563462: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f116f800 next 160 of size 512
2019-10-27 10:40:32.563483: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f116fa00 next 161 of size 1179648
2019-10-27 10:40:32.563503: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f128fa00 next 162 of size 512
2019-10-27 10:40:32.563523: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f128fc00 next 163 of size 589824
2019-10-27 10:40:32.563543: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f131fc00 next 164 of size 512
2019-10-27 10:40:32.563563: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f131fe00 next 165 of size 442368
2019-10-27 10:40:32.563583: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f138be00 next 166 of size 256
2019-10-27 10:40:32.563603: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f138bf00 next 167 of size 147456
2019-10-27 10:40:32.563622: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f13aff00 next 168 of size 256
2019-10-27 10:40:32.563642: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f13b0000 next 169 of size 110592
2019-10-27 10:40:32.563661: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f13cb000 next 170 of size 256
2019-10-27 10:40:32.563681: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f13cb100 next 171 of size 36864
2019-10-27 10:40:32.563701: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f13d4100 next 172 of size 256
2019-10-27 10:40:32.563721: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f13d4200 next 173 of size 27648
2019-10-27 10:40:32.563740: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f13dae00 next 174 of size 256
2019-10-27 10:40:32.563760: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f13daf00 next 175 of size 9216
2019-10-27 10:40:32.563780: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f13dd300 next 176 of size 256
2019-10-27 10:40:32.563799: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f13dd400 next 177 of size 256
2019-10-27 10:40:32.563818: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f13dd500 next 178 of size 256
2019-10-27 10:40:32.563838: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f13dd600 next 179 of size 256
2019-10-27 10:40:32.563857: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f13dd700 next 180 of size 256
2019-10-27 10:40:32.563877: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f13dd800 next 181 of size 256
2019-10-27 10:40:32.563897: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f13dd900 next 182 of size 256
2019-10-27 10:40:32.563917: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f13dda00 next 183 of size 256
2019-10-27 10:40:32.563936: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f13ddb00 next 184 of size 256
2019-10-27 10:40:32.563956: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f13ddc00 next 185 of size 256
2019-10-27 10:40:32.563975: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f13ddd00 next 186 of size 256
2019-10-27 10:40:32.563995: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f13dde00 next 187 of size 256
2019-10-27 10:40:32.564014: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f13ddf00 next 188 of size 256
2019-10-27 10:40:32.564034: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f13de000 next 189 of size 256
2019-10-27 10:40:32.564055: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f13de100 next 190 of size 131072
2019-10-27 10:40:32.564075: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f13fe100 next 191 of size 131072
2019-10-27 10:40:32.564103: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f141e100 next 192 of size 256
2019-10-27 10:40:32.564124: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f141e200 next 193 of size 256
2019-10-27 10:40:32.564143: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f141e300 next 194 of size 256
2019-10-27 10:40:32.564163: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f141e400 next 195 of size 256
2019-10-27 10:40:32.564183: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f141e500 next 196 of size 256
2019-10-27 10:40:32.564202: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f141e600 next 197 of size 256
2019-10-27 10:40:32.564222: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f141e700 next 198 of size 256
2019-10-27 10:40:32.564241: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f141e800 next 199 of size 256
2019-10-27 10:40:32.564261: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f141e900 next 200 of size 256
2019-10-27 10:40:32.564280: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f141ea00 next 212 of size 256
2019-10-27 10:40:32.564301: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f141eb00 next 213 of size 262144
2019-10-27 10:40:32.564320: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f145eb00 next 214 of size 256
2019-10-27 10:40:32.564340: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f145ec00 next 215 of size 256
2019-10-27 10:40:32.564359: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f145ed00 next 218 of size 256
2019-10-27 10:40:32.564378: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f145ee00 next 219 of size 256
2019-10-27 10:40:32.564398: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f145ef00 next 220 of size 256
2019-10-27 10:40:32.564417: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f145f000 next 222 of size 256
2019-10-27 10:40:32.564436: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f145f100 next 223 of size 256
2019-10-27 10:40:32.564456: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f145f200 next 224 of size 9216
2019-10-27 10:40:32.564475: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f1461600 next 234 of size 256
2019-10-27 10:40:32.564495: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f1461700 next 235 of size 256
2019-10-27 10:40:32.564515: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f1461800 next 237 of size 256
2019-10-27 10:40:32.564534: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f1461900 next 238 of size 256
2019-10-27 10:40:32.564553: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f1461a00 next 239 of size 256
2019-10-27 10:40:32.564573: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f1461b00 next 240 of size 18432
2019-10-27 10:40:32.564593: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f1466300 next 242 of size 256
2019-10-27 10:40:32.564612: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f1466400 next 250 of size 256
2019-10-27 10:40:32.564632: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f1466500 next 251 of size 256
2019-10-27 10:40:32.564651: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f1466600 next 252 of size 256
2019-10-27 10:40:32.564670: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f1466700 next 253 of size 36864
2019-10-27 10:40:32.564690: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f146f700 next 255 of size 256
2019-10-27 10:40:32.564709: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f146f800 next 257 of size 256
2019-10-27 10:40:32.564737: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f146f900 next 258 of size 256
2019-10-27 10:40:32.564758: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f146fa00 next 259 of size 256
2019-10-27 10:40:32.564778: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f146fb00 next 260 of size 256
2019-10-27 10:40:32.564797: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f146fc00 next 270 of size 256
2019-10-27 10:40:32.564817: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f146fd00 next 273 of size 256
2019-10-27 10:40:32.564837: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f146fe00 next 274 of size 256
2019-10-27 10:40:32.564857: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f146ff00 next 275 of size 256
2019-10-27 10:40:32.564876: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f1470000 next 276 of size 256
2019-10-27 10:40:32.564896: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f1470100 next 277 of size 256
2019-10-27 10:40:32.564916: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f1470200 next 279 of size 131072
2019-10-27 10:40:32.564935: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f1490200 next 280 of size 256
2019-10-27 10:40:32.564955: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f1490300 next 281 of size 256
2019-10-27 10:40:32.564974: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f1490400 next 282 of size 256
2019-10-27 10:40:32.564994: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f1490500 next 283 of size 147456
2019-10-27 10:40:32.565014: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f14b4500 next 284 of size 256
2019-10-27 10:40:32.565033: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f14b4600 next 286 of size 256
2019-10-27 10:40:32.565052: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f14b4700 next 287 of size 256
2019-10-27 10:40:32.565072: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f14b4800 next 288 of size 256
2019-10-27 10:40:32.565091: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f14b4900 next 289 of size 256
2019-10-27 10:40:32.565111: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f14b4a00 next 290 of size 256
2019-10-27 10:40:32.565130: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f14b4b00 next 291 of size 256
2019-10-27 10:40:32.565149: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f14b4c00 next 292 of size 256
2019-10-27 10:40:32.565169: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f14b4d00 next 293 of size 256
2019-10-27 10:40:32.565189: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f14b4e00 next 294 of size 294912
2019-10-27 10:40:32.565208: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f14fce00 next 296 of size 256
2019-10-27 10:40:32.565227: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f14fcf00 next 298 of size 256
2019-10-27 10:40:32.565247: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f14fd000 next 299 of size 256
2019-10-27 10:40:32.565267: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f14fd100 next 300 of size 512
2019-10-27 10:40:32.565286: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f14fd300 next 302 of size 256
2019-10-27 10:40:32.565306: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f14fd400 next 306 of size 589824
2019-10-27 10:40:32.565325: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f158d400 next 308 of size 256
2019-10-27 10:40:32.565345: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f158d500 next 309 of size 256
2019-10-27 10:40:32.565380: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f158d600 next 310 of size 512
2019-10-27 10:40:32.565402: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f158d800 next 313 of size 256
2019-10-27 10:40:32.565422: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f158d900 next 316 of size 256
2019-10-27 10:40:32.565442: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f158da00 next 315 of size 589824
2019-10-27 10:40:32.565462: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f161da00 next 320 of size 256
2019-10-27 10:40:32.565482: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f161db00 next 318 of size 256
2019-10-27 10:40:32.565502: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f161dc00 next 321 of size 512
2019-10-27 10:40:32.565522: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f161de00 next 323 of size 256
2019-10-27 10:40:32.565542: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f161df00 next 326 of size 256
2019-10-27 10:40:32.565563: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f161e000 next 261 of size 596992
2019-10-27 10:40:32.565583: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f16afc00 next 262 of size 256
2019-10-27 10:40:32.565603: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f16afd00 next 264 of size 256
2019-10-27 10:40:32.565623: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f16afe00 next 265 of size 256
2019-10-27 10:40:32.565642: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f16aff00 next 266 of size 256
2019-10-27 10:40:32.565662: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f16b0000 next 267 of size 73728
2019-10-27 10:40:32.565682: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f16c2000 next 269 of size 2359296
2019-10-27 10:40:32.565702: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f1902000 next 272 of size 2359296
2019-10-27 10:40:32.565723: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f1b42000 next 243 of size 5653504
2019-10-27 10:40:32.565742: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f20a6400 next 244 of size 256
2019-10-27 10:40:32.565762: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f20a6500 next 245 of size 256
2019-10-27 10:40:32.565782: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f20a6600 next 246 of size 256
2019-10-27 10:40:32.565801: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f20a6700 next 248 of size 256
2019-10-27 10:40:32.565821: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f20a6800 next 249 of size 256
2019-10-27 10:40:32.565842: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f20a6900 next 226 of size 16624896
2019-10-27 10:40:32.565862: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f3081600 next 227 of size 256
2019-10-27 10:40:32.565882: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f3081700 next 228 of size 256
2019-10-27 10:40:32.565901: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f3081800 next 230 of size 256
2019-10-27 10:40:32.565921: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f3081900 next 231 of size 256
2019-10-27 10:40:32.565941: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f3081a00 next 232 of size 256
2019-10-27 10:40:32.565962: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f3081b00 next 201 of size 33214208
2019-10-27 10:40:32.565983: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f502ea00 next 207 of size 256
2019-10-27 10:40:32.566011: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f502eb00 next 208 of size 768
2019-10-27 10:40:32.566032: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f502ee00 next 297 of size 4194304
2019-10-27 10:40:32.566052: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f542ee00 next 328 of size 256
2019-10-27 10:40:32.566072: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f542ef00 next 331 of size 256
2019-10-27 10:40:32.566092: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f542f000 next 332 of size 512
2019-10-27 10:40:32.566113: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f542f200 next 254 of size 8649728
2019-10-27 10:40:32.566134: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f5c6ee00 next 236 of size 16646144
2019-10-27 10:40:32.566155: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f6c4ee00 next 217 of size 33488896
2019-10-27 10:40:32.566176: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50f8c3ee00 next 443 of size 8388608
2019-10-27 10:40:32.566196: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f50f943ee00 next 432 of size 32309248
2019-10-27 10:40:32.566217: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50fb30ee00 next 434 of size 67108864
2019-10-27 10:40:32.566238: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f50ff30ee00 next 437 of size 67108864
2019-10-27 10:40:32.566259: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f510330ee00 next 202 of size 97614848
2019-10-27 10:40:32.566279: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5109026a00 next 203 of size 130056192
2019-10-27 10:40:32.566300: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5110c2ea00 next 204 of size 268435456
2019-10-27 10:40:32.566320: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5120c2ea00 next 205 of size 130056192
2019-10-27 10:40:32.566341: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5128836a00 next 206 of size 268435456
2019-10-27 10:40:32.566360: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5138836a00 next 209 of size 256
2019-10-27 10:40:32.566381: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5138836b00 next 210 of size 256
2019-10-27 10:40:32.566401: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5138836c00 next 211 of size 62980096
2019-10-27 10:40:32.566422: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f513c446c00 next 216 of size 268435456
2019-10-27 10:40:32.566442: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f514c446c00 next 221 of size 62980096
2019-10-27 10:40:32.566462: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5150056c00 next 225 of size 268435456
2019-10-27 10:40:32.566481: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5160056c00 next 229 of size 67108864
2019-10-27 10:40:32.566502: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5164056c00 next 233 of size 134217728
2019-10-27 10:40:32.566523: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f516c056c00 next 241 of size 134217728
2019-10-27 10:40:32.566543: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5174056c00 next 247 of size 134217728
2019-10-27 10:40:32.566563: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f517c056c00 next 256 of size 134217728
2019-10-27 10:40:32.566584: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5184056c00 next 263 of size 134217728
2019-10-27 10:40:32.566604: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f518c056c00 next 268 of size 33554432
2019-10-27 10:40:32.566625: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f518e056c00 next 271 of size 67108864
2019-10-27 10:40:32.566653: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5192056c00 next 278 of size 67108864
2019-10-27 10:40:32.566675: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5196056c00 next 285 of size 67108864
2019-10-27 10:40:32.566695: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f519a056c00 next 295 of size 67108864
2019-10-27 10:40:32.566715: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f519e056c00 next 301 of size 67108864
2019-10-27 10:40:32.566734: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a2056c00 next 303 of size 16777216
2019-10-27 10:40:32.566755: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a3056c00 next 304 of size 21233664
2019-10-27 10:40:32.566775: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4496c00 next 329 of size 256
2019-10-27 10:40:32.566794: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4496d00 next 339 of size 256
2019-10-27 10:40:32.566814: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4496e00 next 338 of size 512
2019-10-27 10:40:32.566833: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4497000 next 340 of size 256
2019-10-27 10:40:32.566853: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4497100 next 341 of size 589824
2019-10-27 10:40:32.566873: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4527100 next 352 of size 256
2019-10-27 10:40:32.566892: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4527200 next 353 of size 256
2019-10-27 10:40:32.566912: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4527300 next 358 of size 256
2019-10-27 10:40:32.566931: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4527400 next 359 of size 256
2019-10-27 10:40:32.566950: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4527500 next 361 of size 256
2019-10-27 10:40:32.566970: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4527600 next 363 of size 147456
2019-10-27 10:40:32.566989: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a454b600 next 365 of size 256
2019-10-27 10:40:32.567009: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a454b700 next 367 of size 256
2019-10-27 10:40:32.567028: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a454b800 next 369 of size 256
2019-10-27 10:40:32.567048: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a454b900 next 371 of size 110592
2019-10-27 10:40:32.567067: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4566900 next 372 of size 256
2019-10-27 10:40:32.567087: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4566a00 next 373 of size 256
2019-10-27 10:40:32.567117: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4566b00 next 375 of size 256
2019-10-27 10:40:32.567141: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4566c00 next 376 of size 36864
2019-10-27 10:40:32.567161: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a456fc00 next 377 of size 256
2019-10-27 10:40:32.567180: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a456fd00 next 380 of size 256
2019-10-27 10:40:32.567201: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a456fe00 next 381 of size 256
2019-10-27 10:40:32.567220: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a456ff00 next 383 of size 27648
2019-10-27 10:40:32.567240: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4576b00 next 385 of size 256
2019-10-27 10:40:32.567259: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4576c00 next 388 of size 256
2019-10-27 10:40:32.567279: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4576d00 next 389 of size 256
2019-10-27 10:40:32.567307: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4576e00 next 391 of size 9216
2019-10-27 10:40:32.567328: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4579200 next 392 of size 256
2019-10-27 10:40:32.567348: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4579300 next 394 of size 256
2019-10-27 10:40:32.567368: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4579400 next 397 of size 256
2019-10-27 10:40:32.567388: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4579500 next 398 of size 256
2019-10-27 10:40:32.567408: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4579600 next 401 of size 256
2019-10-27 10:40:32.567428: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4579700 next 396 of size 256
2019-10-27 10:40:32.567448: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4579800 next 403 of size 256
2019-10-27 10:40:32.567467: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4579900 next 433 of size 256
2019-10-27 10:40:32.567487: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f51a4579a00 next 431 of size 256
2019-10-27 10:40:32.567507: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4579b00 next 439 of size 256
2019-10-27 10:40:32.567527: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4579c00 next 441 of size 256
2019-10-27 10:40:32.567547: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f51a4579d00 next 425 of size 107008
2019-10-27 10:40:32.567567: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a4593f00 next 423 of size 131072
2019-10-27 10:40:32.567589: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a45b3f00 next 305 of size 15609088
2019-10-27 10:40:32.567609: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a5496c00 next 312 of size 16777216
2019-10-27 10:40:32.567629: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a6496c00 next 334 of size 256
2019-10-27 10:40:32.567649: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a6496d00 next 335 of size 1179648
2019-10-27 10:40:32.567669: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a65b6d00 next 337 of size 256
2019-10-27 10:40:32.567690: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a65b6e00 next 307 of size 15597056
2019-10-27 10:40:32.567710: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a7496c00 next 311 of size 33554432
2019-10-27 10:40:32.567730: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51a9496c00 next 314 of size 33554432
2019-10-27 10:40:32.567749: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51ab496c00 next 319 of size 33554432
2019-10-27 10:40:32.567771: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51ad496c00 next 317 of size 109314048
2019-10-27 10:40:32.567791: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51b3cd6c00 next 327 of size 33554432
2019-10-27 10:40:32.567810: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51b5cd6c00 next 342 of size 256
2019-10-27 10:40:32.567830: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51b5cd6d00 next 343 of size 8388608
2019-10-27 10:40:32.567850: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51b64d6d00 next 346 of size 256
2019-10-27 10:40:32.567870: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51b64d6e00 next 348 of size 256
2019-10-27 10:40:32.567889: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51b64d6f00 next 349 of size 512
2019-10-27 10:40:32.567909: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51b64d7100 next 350 of size 8388608
2019-10-27 10:40:32.567937: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51b6cd7100 next 351 of size 256
2019-10-27 10:40:32.567959: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51b6cd7200 next 355 of size 442368
2019-10-27 10:40:32.567979: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f51b6d43200 next 422 of size 131072
2019-10-27 10:40:32.567999: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51b6d63200 next 424 of size 4194304
2019-10-27 10:40:32.568019: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51b7163200 next 438 of size 294912
2019-10-27 10:40:32.568039: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f51b71ab200 next 322 of size 11713024
2019-10-27 10:40:32.568059: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51b7cd6c00 next 324 of size 33554432
2019-10-27 10:40:32.568079: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51b9cd6c00 next 325 of size 67108864
2019-10-27 10:40:32.568099: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51bdcd6c00 next 333 of size 134217728
2019-10-27 10:40:32.568119: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51c5cd6c00 next 362 of size 16777216
2019-10-27 10:40:32.568139: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51c6cd6c00 next 364 of size 16777216
2019-10-27 10:40:32.568159: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51c7cd6c00 next 366 of size 33554432
2019-10-27 10:40:32.568179: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51c9cd6c00 next 370 of size 33554432
2019-10-27 10:40:32.568199: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51cbcd6c00 next 330 of size 33554432
2019-10-27 10:40:32.568219: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51cdcd6c00 next 336 of size 134217728
2019-10-27 10:40:32.568239: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51d5cd6c00 next 344 of size 268435456
2019-10-27 10:40:32.568259: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51e5cd6c00 next 360 of size 67108864
2019-10-27 10:40:32.568281: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51e9cd6c00 next 345 of size 201326592
2019-10-27 10:40:32.568301: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f51f5cd6c00 next 347 of size 268435456
2019-10-27 10:40:32.568321: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5205cd6c00 next 357 of size 536870912
2019-10-27 10:40:32.568342: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5225cd6c00 next 368 of size 268435456
2019-10-27 10:40:32.568361: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5235cd6c00 next 354 of size 268435456
2019-10-27 10:40:32.568381: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5245cd6c00 next 356 of size 536870912
2019-10-27 10:40:32.568401: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5265cd6c00 next 374 of size 268435456
2019-10-27 10:40:32.568421: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5275cd6c00 next 384 of size 67108864
2019-10-27 10:40:32.568441: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5279cd6c00 next 386 of size 67108864
2019-10-27 10:40:32.568461: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f527dcd6c00 next 378 of size 67108864
2019-10-27 10:40:32.568481: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5281cd6c00 next 379 of size 268435456
2019-10-27 10:40:32.568501: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5291cd6c00 next 382 of size 268435456
2019-10-27 10:40:32.568521: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f52a1cd6c00 next 395 of size 67108864
2019-10-27 10:40:32.568541: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f52a5cd6c00 next 387 of size 67108864
2019-10-27 10:40:32.568569: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f52a9cd6c00 next 390 of size 134217728
2019-10-27 10:40:32.568591: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f52b1cd6c00 next 393 of size 134217728
2019-10-27 10:40:32.568612: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f52b9cd6c00 next 399 of size 402653184
2019-10-27 10:40:32.568632: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f52d1cd6c00 next 400 of size 134217728
2019-10-27 10:40:32.568652: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f52d9cd6c00 next 402 of size 134217728
2019-10-27 10:40:32.568672: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f52e1cd6c00 next 412 of size 67108864
2019-10-27 10:40:32.568692: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f52e5cd6c00 next 410 of size 33554432
2019-10-27 10:40:32.568712: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f52e7cd6c00 next 404 of size 33554432
2019-10-27 10:40:32.568732: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f52e9cd6c00 next 405 of size 134217728
2019-10-27 10:40:32.568753: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f52f1cd6c00 next 406 of size 134217728
2019-10-27 10:40:32.568773: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f52f9cd6c00 next 407 of size 67108864
2019-10-27 10:40:32.568793: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f52fdcd6c00 next 408 of size 134217728
2019-10-27 10:40:32.568813: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5305cd6c00 next 409 of size 67108864
2019-10-27 10:40:32.568833: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5309cd6c00 next 417 of size 268435456
2019-10-27 10:40:32.568853: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5319cd6c00 next 419 of size 268435456
2019-10-27 10:40:32.568873: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5329cd6c00 next 436 of size 134217728
2019-10-27 10:40:32.568893: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5331cd6c00 next 440 of size 33554432
2019-10-27 10:40:32.568913: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5333cd6c00 next 444 of size 33554432
2019-10-27 10:40:32.568933: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5335cd6c00 next 445 of size 33554432
2019-10-27 10:40:32.568953: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f5337cd6c00 next 442 of size 100663296
2019-10-27 10:40:32.568972: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f533dcd6c00 next 435 of size 134217728
2019-10-27 10:40:32.568993: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5345cd6c00 next 411 of size 335544320
2019-10-27 10:40:32.569014: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5359cd6c00 next 413 of size 805306368
2019-10-27 10:40:32.569035: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5389cd6c00 next 414 of size 268435456
2019-10-27 10:40:32.569055: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5399cd6c00 next 415 of size 268435456
2019-10-27 10:40:32.569075: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f53a9cd6c00 next 416 of size 33554432
2019-10-27 10:40:32.569095: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f53abcd6c00 next 418 of size 33554432
2019-10-27 10:40:32.569115: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f53adcd6c00 next 420 of size 33554432
2019-10-27 10:40:32.569135: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f53afcd6c00 next 421 of size 16777216
2019-10-27 10:40:32.569155: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f53b0cd6c00 next 430 of size 8388608
2019-10-27 10:40:32.569176: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f53b14d6c00 next 427 of size 32309248
2019-10-27 10:40:32.569204: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f53b33a6c00 next 428 of size 4194304
2019-10-27 10:40:32.569226: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f53b37a6c00 next 429 of size 16777216
2019-10-27 10:40:32.569246: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f53b47a6c00 next 426 of size 8388608
2019-10-27 10:40:32.569267: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f53b4fa6c00 next 18446744073709551615 of size 20927488
2019-10-27 10:40:32.569286: I tensorflow/core/common_runtime/bfc_allocator.cc:809]      Summary of in-use Chunks by size: 
2019-10-27 10:40:32.569312: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 191 Chunks of size 256 totalling 47.8KiB
2019-10-27 10:40:32.569336: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 27 Chunks of size 512 totalling 13.5KiB
2019-10-27 10:40:32.569360: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 3 Chunks of size 768 totalling 2.2KiB
2019-10-27 10:40:32.569383: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 10 Chunks of size 1024 totalling 10.0KiB
2019-10-27 10:40:32.569407: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 8 Chunks of size 1280 totalling 10.0KiB
2019-10-27 10:40:32.569430: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 1792 totalling 1.8KiB
2019-10-27 10:40:32.569454: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 6 Chunks of size 9216 totalling 54.0KiB
2019-10-27 10:40:32.569477: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 16384 totalling 16.0KiB
2019-10-27 10:40:32.569500: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 3 Chunks of size 18432 totalling 54.0KiB
2019-10-27 10:40:32.569523: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 25344 totalling 24.8KiB
2019-10-27 10:40:32.569547: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 3 Chunks of size 27648 totalling 81.0KiB
2019-10-27 10:40:32.569570: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 6 Chunks of size 36864 totalling 216.0KiB
2019-10-27 10:40:32.569594: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 46080 totalling 45.0KiB
2019-10-27 10:40:32.569617: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 7 Chunks of size 73728 totalling 504.0KiB
2019-10-27 10:40:32.569641: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 107776 totalling 105.2KiB
2019-10-27 10:40:32.569664: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 4 Chunks of size 110592 totalling 432.0KiB
2019-10-27 10:40:32.569688: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 4 Chunks of size 131072 totalling 512.0KiB
2019-10-27 10:40:32.569712: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 6 Chunks of size 147456 totalling 864.0KiB
2019-10-27 10:40:32.569735: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 262144 totalling 256.0KiB
2019-10-27 10:40:32.569758: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 9 Chunks of size 294912 totalling 2.53MiB
2019-10-27 10:40:32.569781: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 3 Chunks of size 442368 totalling 1.27MiB
2019-10-27 10:40:32.569804: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 11 Chunks of size 589824 totalling 6.19MiB
2019-10-27 10:40:32.569828: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 596992 totalling 583.0KiB
2019-10-27 10:40:32.569851: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 1116928 totalling 1.06MiB
2019-10-27 10:40:32.569874: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 11 Chunks of size 1179648 totalling 12.38MiB
2019-10-27 10:40:32.569897: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 1769472 totalling 1.69MiB
2019-10-27 10:40:32.569920: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 3 Chunks of size 2097152 totalling 6.00MiB
2019-10-27 10:40:32.569952: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 9 Chunks of size 2359296 totalling 20.25MiB
2019-10-27 10:40:32.569976: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 3145728 totalling 3.00MiB
2019-10-27 10:40:32.570000: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 4 Chunks of size 4194304 totalling 16.00MiB
2019-10-27 10:40:32.570023: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 5653504 totalling 5.39MiB
2019-10-27 10:40:32.570046: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 5 Chunks of size 8388608 totalling 40.00MiB
2019-10-27 10:40:32.570070: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 8649728 totalling 8.25MiB
2019-10-27 10:40:32.570093: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 15597056 totalling 14.87MiB
2019-10-27 10:40:32.570117: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 15609088 totalling 14.89MiB
2019-10-27 10:40:32.570141: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 16624896 totalling 15.85MiB
2019-10-27 10:40:32.570165: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 16646144 totalling 15.88MiB
2019-10-27 10:40:32.570188: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 8 Chunks of size 16777216 totalling 128.00MiB
2019-10-27 10:40:32.570213: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 20927488 totalling 19.96MiB
2019-10-27 10:40:32.570236: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 21233664 totalling 20.25MiB
2019-10-27 10:40:32.570260: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 32309248 totalling 30.81MiB
2019-10-27 10:40:32.570283: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 33214208 totalling 31.67MiB
2019-10-27 10:40:32.570307: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 33488896 totalling 31.94MiB
2019-10-27 10:40:32.570330: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 17 Chunks of size 33554432 totalling 544.00MiB
2019-10-27 10:40:32.570354: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 62980096 totalling 120.12MiB
2019-10-27 10:40:32.570378: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 18 Chunks of size 67108864 totalling 1.12GiB
2019-10-27 10:40:32.570401: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 97614848 totalling 93.09MiB
2019-10-27 10:40:32.570425: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 109314048 totalling 104.25MiB
2019-10-27 10:40:32.570449: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 130056192 totalling 248.06MiB
2019-10-27 10:40:32.570472: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 16 Chunks of size 134217728 totalling 2.00GiB
2019-10-27 10:40:32.570496: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 201326592 totalling 192.00MiB
2019-10-27 10:40:32.570519: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 15 Chunks of size 268435456 totalling 3.75GiB
2019-10-27 10:40:32.570543: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 335544320 totalling 320.00MiB
2019-10-27 10:40:32.570567: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 402653184 totalling 384.00MiB
2019-10-27 10:40:32.570590: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 536870912 totalling 1.00GiB
2019-10-27 10:40:32.570614: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 805306368 totalling 768.00MiB
2019-10-27 10:40:32.570637: I tensorflow/core/common_runtime/bfc_allocator.cc:816] Sum Total of in-use chunks: 11.02GiB
2019-10-27 10:40:32.570658: I tensorflow/core/common_runtime/bfc_allocator.cc:818] total_region_allocated_bytes_: 11982716928 memory_limit_: 11982716928 available bytes: 0 curr_region_allocation_bytes_: 23965433856
2019-10-27 10:40:32.570683: I tensorflow/core/common_runtime/bfc_allocator.cc:824] Stats: 
Limit:                 11982716928
InUse:                 11837793024
MaxInUse:              11837793024
NumAllocs:                    2044
MaxAllocSize:           3680894976

2019-10-27 10:40:32.570768: W tensorflow/core/common_runtime/bfc_allocator.cc:319] ****************************************************************************************************
2019-10-27 10:40:32.570828: W tensorflow/core/framework/op_kernel.cc:1546] OP_REQUIRES failed at image_resizer_state.h:140 : Resource exhausted: OOM when allocating tensor with shape[256,32,32,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
2019-10-27 10:40:32.570883: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Resource exhausted: OOM when allocating tensor with shape[256,64,65,65] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
	 [[{{node StatefulPartitionedCall/StatefulPartitionedCall/StatefulPartitionedCall/sequential_1_1/conv2d_transpose_3/conv2d_transpose}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

[I 10:40:35.650 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 10:41:50.317 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 10:42:35.983 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 10:44:36.007 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 10:46:09.044 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 10:46:11.847 LabApp] Starting buffering for 8a176c6a-8996-42d7-bccc-a9d6303bb7c0:f6f50c1de9b147b18b2cce0931313a25
[I 10:46:15.308 LabApp] Kernel restarted: 8a176c6a-8996-42d7-bccc-a9d6303bb7c0
[I 10:46:18.350 LabApp] Adapting from protocol version 5.1 (kernel 8a176c6a-8996-42d7-bccc-a9d6303bb7c0) to 5.3 (client).
[I 10:46:18.351 LabApp] Restoring connection for 8a176c6a-8996-42d7-bccc-a9d6303bb7c0:f6f50c1de9b147b18b2cce0931313a25
[I 10:46:18.351 LabApp] Replaying 8 buffered messages
2019-10-27 10:46:31.934953: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-27 10:46:32.540115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-27 10:46:32.544729: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 10:46:32.546948: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 10:46:32.548547: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 10:46:32.559119: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 10:46:32.561213: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 10:46:32.562911: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 10:46:32.566816: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 10:46:32.568815: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 10:46:32.799007: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555b4cca2b90 executing computations on platform CUDA. Devices:
2019-10-27 10:46:32.799147: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-27 10:46:32.805573: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-27 10:46:32.807264: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555b4cd79610 executing computations on platform Host. Devices:
2019-10-27 10:46:32.807307: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-27 10:46:32.808752: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-27 10:46:32.808880: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 10:46:32.808944: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 10:46:32.809005: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 10:46:32.809080: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 10:46:32.809139: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 10:46:32.809195: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 10:46:32.809253: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 10:46:32.812552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 10:46:32.812658: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 10:46:32.815394: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-27 10:46:32.815424: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-27 10:46:32.815439: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-27 10:46:32.818079: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
[I 10:46:35.071 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
2019-10-27 10:46:40.434570: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-27 10:46:40.495193: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 10:46:40.724291: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 10:47:00.553590: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.13GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-27 10:47:00.583700: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-27 10:47:00.681667: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.02GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-27 10:47:00.695415: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.12GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-27 10:47:00.738805: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.12GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-27 10:47:10.739443: W tensorflow/core/common_runtime/bfc_allocator.cc:314] Allocator (GPU_0_bfc) ran out of memory trying to allocate 384.00MiB (rounded to 402653184).  Current allocation summary follows.
2019-10-27 10:47:10.739531: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (256): 	Total Chunks: 193, Chunks in use: 192. 48.2KiB allocated for chunks. 48.0KiB in use in bin. 8.6KiB client-requested in use in bin.
2019-10-27 10:47:10.739551: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (512): 	Total Chunks: 30, Chunks in use: 30. 15.8KiB allocated for chunks. 15.8KiB in use in bin. 15.2KiB client-requested in use in bin.
2019-10-27 10:47:10.739565: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (1024): 	Total Chunks: 19, Chunks in use: 19. 21.8KiB allocated for chunks. 21.8KiB in use in bin. 19.8KiB client-requested in use in bin.
2019-10-27 10:47:10.739577: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (2048): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 10:47:10.739589: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (4096): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 10:47:10.739603: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (8192): 	Total Chunks: 8, Chunks in use: 8. 72.2KiB allocated for chunks. 72.2KiB in use in bin. 72.0KiB client-requested in use in bin.
2019-10-27 10:47:10.739617: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (16384): 	Total Chunks: 11, Chunks in use: 11. 256.8KiB allocated for chunks. 256.8KiB in use in bin. 237.0KiB client-requested in use in bin.
2019-10-27 10:47:10.739631: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (32768): 	Total Chunks: 7, Chunks in use: 7. 277.5KiB allocated for chunks. 277.5KiB in use in bin. 243.0KiB client-requested in use in bin.
2019-10-27 10:47:10.739644: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (65536): 	Total Chunks: 17, Chunks in use: 17. 1.33MiB allocated for chunks. 1.33MiB in use in bin. 1.26MiB client-requested in use in bin.
2019-10-27 10:47:10.739656: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (131072): 	Total Chunks: 6, Chunks in use: 6. 864.0KiB allocated for chunks. 864.0KiB in use in bin. 864.0KiB client-requested in use in bin.
2019-10-27 10:47:10.739669: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (262144): 	Total Chunks: 10, Chunks in use: 10. 3.09MiB allocated for chunks. 3.09MiB in use in bin. 2.95MiB client-requested in use in bin.
2019-10-27 10:47:10.739681: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (524288): 	Total Chunks: 14, Chunks in use: 14. 7.82MiB allocated for chunks. 7.82MiB in use in bin. 7.59MiB client-requested in use in bin.
2019-10-27 10:47:10.739694: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (1048576): 	Total Chunks: 14, Chunks in use: 14. 16.94MiB allocated for chunks. 16.94MiB in use in bin. 15.75MiB client-requested in use in bin.
2019-10-27 10:47:10.739708: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (2097152): 	Total Chunks: 16, Chunks in use: 15. 37.36MiB allocated for chunks. 34.30MiB in use in bin. 32.00MiB client-requested in use in bin.
2019-10-27 10:47:10.739732: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (4194304): 	Total Chunks: 17, Chunks in use: 15. 80.32MiB allocated for chunks. 72.32MiB in use in bin. 62.50MiB client-requested in use in bin.
2019-10-27 10:47:10.739748: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (8388608): 	Total Chunks: 17, Chunks in use: 15. 158.22MiB allocated for chunks. 142.22MiB in use in bin. 132.12MiB client-requested in use in bin.
2019-10-27 10:47:10.739761: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (16777216): 	Total Chunks: 30, Chunks in use: 26. 544.04MiB allocated for chunks. 464.04MiB in use in bin. 444.06MiB client-requested in use in bin.
2019-10-27 10:47:10.739773: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (33554432): 	Total Chunks: 33, Chunks in use: 33. 1.13GiB allocated for chunks. 1.13GiB in use in bin. 1.09GiB client-requested in use in bin.
2019-10-27 10:47:10.739785: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (67108864): 	Total Chunks: 29, Chunks in use: 27. 1.99GiB allocated for chunks. 1.87GiB in use in bin. 1.75GiB client-requested in use in bin.
2019-10-27 10:47:10.739797: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (134217728): 	Total Chunks: 27, Chunks in use: 21. 3.70GiB allocated for chunks. 2.89GiB in use in bin. 2.78GiB client-requested in use in bin.
2019-10-27 10:47:10.739809: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (268435456): 	Total Chunks: 11, Chunks in use: 10. 3.50GiB allocated for chunks. 3.25GiB in use in bin. 3.25GiB client-requested in use in bin.
2019-10-27 10:47:10.739821: I tensorflow/core/common_runtime/bfc_allocator.cc:780] Bin for 384.00MiB was 256.00MiB, Chunk State: 
2019-10-27 10:47:10.739842: I tensorflow/core/common_runtime/bfc_allocator.cc:786]   Size: 256.00MiB | Requested Size: 128.00MiB | in_use: 0 | bin_num: 20, prev:   Size: 384.00MiB | Requested Size: 384.00MiB | in_use: 1 | bin_num: -1, next:   Size: 384.00MiB | Requested Size: 384.00MiB | in_use: 1 | bin_num: -1
2019-10-27 10:47:10.739852: I tensorflow/core/common_runtime/bfc_allocator.cc:793] Next region of size 11982716928
2019-10-27 10:47:10.739864: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec000000 next 1 of size 256
2019-10-27 10:47:10.739873: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec000100 next 2 of size 256
2019-10-27 10:47:10.739883: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec000200 next 3 of size 1280
2019-10-27 10:47:10.739892: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec000700 next 4 of size 256
2019-10-27 10:47:10.739901: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec000800 next 9 of size 512
2019-10-27 10:47:10.739911: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec000a00 next 5 of size 1792
2019-10-27 10:47:10.739919: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec001100 next 6 of size 1280
2019-10-27 10:47:10.739928: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec001600 next 16 of size 1024
2019-10-27 10:47:10.739937: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec001a00 next 17 of size 512
2019-10-27 10:47:10.739946: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec001c00 next 19 of size 256
2019-10-27 10:47:10.739954: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec001d00 next 22 of size 256
2019-10-27 10:47:10.739963: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec001e00 next 27 of size 256
2019-10-27 10:47:10.739971: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec001f00 next 28 of size 256
2019-10-27 10:47:10.739980: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec002000 next 32 of size 256
2019-10-27 10:47:10.739989: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec002100 next 20 of size 256
2019-10-27 10:47:10.740003: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec002200 next 21 of size 768
2019-10-27 10:47:10.740013: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec002500 next 36 of size 512
2019-10-27 10:47:10.740021: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec002700 next 37 of size 512
2019-10-27 10:47:10.740030: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec002900 next 41 of size 512
2019-10-27 10:47:10.740039: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec002b00 next 43 of size 512
2019-10-27 10:47:10.740047: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec002d00 next 44 of size 512
2019-10-27 10:47:10.740056: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec002f00 next 48 of size 512
2019-10-27 10:47:10.740064: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec003100 next 49 of size 256
2019-10-27 10:47:10.740073: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec003200 next 50 of size 256
2019-10-27 10:47:10.740082: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec003300 next 52 of size 256
2019-10-27 10:47:10.740090: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec003400 next 54 of size 256
2019-10-27 10:47:10.740099: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec003500 next 57 of size 256
2019-10-27 10:47:10.740108: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec003600 next 92 of size 1280
2019-10-27 10:47:10.740116: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec003b00 next 105 of size 256
2019-10-27 10:47:10.740125: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec003c00 next 86 of size 256
2019-10-27 10:47:10.740133: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec003d00 next 101 of size 512
2019-10-27 10:47:10.740142: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec003f00 next 104 of size 1024
2019-10-27 10:47:10.740151: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec004300 next 94 of size 1024
2019-10-27 10:47:10.740159: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec004700 next 89 of size 512
2019-10-27 10:47:10.740168: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec004900 next 103 of size 1024
2019-10-27 10:47:10.740177: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec004d00 next 106 of size 1024
2019-10-27 10:47:10.740185: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec005100 next 91 of size 512
2019-10-27 10:47:10.740194: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec005300 next 108 of size 256
2019-10-27 10:47:10.740203: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec005400 next 107 of size 256
2019-10-27 10:47:10.740212: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec005500 next 111 of size 1280
2019-10-27 10:47:10.740220: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec005a00 next 112 of size 256
2019-10-27 10:47:10.740229: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec005b00 next 113 of size 1280
2019-10-27 10:47:10.740237: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec006000 next 114 of size 256
2019-10-27 10:47:10.740246: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec006100 next 116 of size 256
2019-10-27 10:47:10.740255: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec006200 next 118 of size 512
2019-10-27 10:47:10.740264: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec006400 next 120 of size 1024
2019-10-27 10:47:10.740272: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec006800 next 23 of size 1280
2019-10-27 10:47:10.740286: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec006d00 next 24 of size 9216
2019-10-27 10:47:10.740296: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec009100 next 59 of size 256
2019-10-27 10:47:10.740304: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec009200 next 60 of size 256
2019-10-27 10:47:10.740313: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec009300 next 61 of size 256
2019-10-27 10:47:10.740321: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec009400 next 62 of size 256
2019-10-27 10:47:10.740330: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec009500 next 68 of size 1024
2019-10-27 10:47:10.740339: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec009900 next 70 of size 1024
2019-10-27 10:47:10.740347: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec009d00 next 73 of size 512
2019-10-27 10:47:10.740356: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec009f00 next 75 of size 256
2019-10-27 10:47:10.740364: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec00a000 next 84 of size 256
2019-10-27 10:47:10.740373: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec00a100 next 100 of size 256
2019-10-27 10:47:10.740381: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec00a200 next 87 of size 256
2019-10-27 10:47:10.740390: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec00a300 next 85 of size 256
2019-10-27 10:47:10.740398: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec00a400 next 97 of size 256
2019-10-27 10:47:10.740407: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec00a500 next 110 of size 256
2019-10-27 10:47:10.740415: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec00a600 next 96 of size 256
2019-10-27 10:47:10.740424: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec00a700 next 90 of size 256
2019-10-27 10:47:10.740433: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec00a800 next 93 of size 256
2019-10-27 10:47:10.740441: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec00a900 next 78 of size 256
2019-10-27 10:47:10.740450: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec00aa00 next 79 of size 1280
2019-10-27 10:47:10.740458: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec00af00 next 77 of size 256
2019-10-27 10:47:10.740467: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec00b000 next 80 of size 256
2019-10-27 10:47:10.740475: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec00b100 next 81 of size 256
2019-10-27 10:47:10.740484: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec00b200 next 82 of size 256
2019-10-27 10:47:10.740492: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec00b300 next 83 of size 256
2019-10-27 10:47:10.740501: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec00b400 next 58 of size 256
2019-10-27 10:47:10.740510: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec00b500 next 25 of size 9216
2019-10-27 10:47:10.740519: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec00d900 next 26 of size 18432
2019-10-27 10:47:10.740528: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec012100 next 55 of size 36864
2019-10-27 10:47:10.740538: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec01b100 next 109 of size 16384
2019-10-27 10:47:10.740546: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec01f100 next 123 of size 512
2019-10-27 10:47:10.740556: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec01f300 next 7 of size 25344
2019-10-27 10:47:10.740569: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec025600 next 8 of size 73728
2019-10-27 10:47:10.740579: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec037600 next 29 of size 36864
2019-10-27 10:47:10.740588: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec040600 next 56 of size 27648
2019-10-27 10:47:10.740598: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec047200 next 30 of size 46080
2019-10-27 10:47:10.740606: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec052600 next 31 of size 73728
2019-10-27 10:47:10.740616: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec064600 next 51 of size 147456
2019-10-27 10:47:10.740624: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec088600 next 76 of size 73728
2019-10-27 10:47:10.740633: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec09a600 next 98 of size 73728
2019-10-27 10:47:10.740642: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec0ac600 next 10 of size 110592
2019-10-27 10:47:10.740651: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec0c7600 next 11 of size 294912
2019-10-27 10:47:10.740660: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec10f600 next 74 of size 294912
2019-10-27 10:47:10.740669: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec157600 next 40 of size 294912
2019-10-27 10:47:10.740678: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec19f600 next 38 of size 589824
2019-10-27 10:47:10.740687: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec22f600 next 39 of size 589824
2019-10-27 10:47:10.740696: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec2bf600 next 13 of size 589824
2019-10-27 10:47:10.740705: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec34f600 next 14 of size 1179648
2019-10-27 10:47:10.740714: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec46f600 next 18 of size 1179648
2019-10-27 10:47:10.740722: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec58f600 next 34 of size 147456
2019-10-27 10:47:10.740731: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec5b3600 next 53 of size 110592
2019-10-27 10:47:10.740739: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec5ce600 next 115 of size 73728
2019-10-27 10:47:10.740748: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec5e0600 next 126 of size 1024
2019-10-27 10:47:10.740757: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec5e0a00 next 128 of size 1024
2019-10-27 10:47:10.740765: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec5e0e00 next 130 of size 512
2019-10-27 10:47:10.740774: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec5e1000 next 132 of size 256
2019-10-27 10:47:10.740783: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec5e1100 next 33 of size 107776
2019-10-27 10:47:10.740792: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec5fb600 next 35 of size 294912
2019-10-27 10:47:10.740802: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec643600 next 12 of size 442368
2019-10-27 10:47:10.740811: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec6af600 next 15 of size 2359296
2019-10-27 10:47:10.740820: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec8ef600 next 42 of size 589824
2019-10-27 10:47:10.740829: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ec97f600 next 47 of size 589824
2019-10-27 10:47:10.740838: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08eca0f600 next 45 of size 1769472
2019-10-27 10:47:10.740847: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ecbbf600 next 46 of size 1179648
2019-10-27 10:47:10.740860: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08eccdf600 next 71 of size 1179648
2019-10-27 10:47:10.740869: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ecdff600 next 72 of size 1179648
2019-10-27 10:47:10.740878: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ecf1f600 next 66 of size 1835008
2019-10-27 10:47:10.740888: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ed0df600 next 67 of size 2097152
2019-10-27 10:47:10.740897: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ed2df600 next 63 of size 4194304
2019-10-27 10:47:10.740907: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ed6df600 next 65 of size 8388608
2019-10-27 10:47:10.740916: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ededf600 next 64 of size 2359296
2019-10-27 10:47:10.740924: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ee11f600 next 69 of size 2359296
2019-10-27 10:47:10.740933: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ee35f600 next 88 of size 2097152
2019-10-27 10:47:10.740941: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ee55f600 next 95 of size 2359296
2019-10-27 10:47:10.740951: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ee79f600 next 99 of size 3932160
2019-10-27 10:47:10.740960: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08eeb5f600 next 102 of size 8388608
2019-10-27 10:47:10.740969: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ef35f600 next 117 of size 294912
2019-10-27 10:47:10.740978: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ef3a7600 next 119 of size 1179648
2019-10-27 10:47:10.740986: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ef4c7600 next 121 of size 2359296
2019-10-27 10:47:10.740995: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ef707600 next 122 of size 1179648
2019-10-27 10:47:10.741004: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08ef827600 next 124 of size 2097152
2019-10-27 10:47:10.741013: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08efa27600 next 125 of size 2359296
2019-10-27 10:47:10.741021: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08efc67600 next 127 of size 2359296
2019-10-27 10:47:10.741030: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08efea7600 next 129 of size 1179648
2019-10-27 10:47:10.741038: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08effc7600 next 131 of size 294912
2019-10-27 10:47:10.741047: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f000f600 next 133 of size 256
2019-10-27 10:47:10.741056: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f000f700 next 134 of size 1280
2019-10-27 10:47:10.741064: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f000fc00 next 135 of size 256
2019-10-27 10:47:10.741073: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f000fd00 next 136 of size 256
2019-10-27 10:47:10.741081: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f000fe00 next 137 of size 256
2019-10-27 10:47:10.741090: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f000ff00 next 138 of size 256
2019-10-27 10:47:10.741099: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f0010000 next 139 of size 256
2019-10-27 10:47:10.741107: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f0010100 next 140 of size 256
2019-10-27 10:47:10.741116: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f0010200 next 141 of size 768
2019-10-27 10:47:10.741125: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f0010500 next 142 of size 256
2019-10-27 10:47:10.741141: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f0010600 next 143 of size 9216
2019-10-27 10:47:10.741151: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f0012a00 next 144 of size 256
2019-10-27 10:47:10.741160: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f0012b00 next 145 of size 18432
2019-10-27 10:47:10.741168: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f0017300 next 146 of size 256
2019-10-27 10:47:10.741177: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f0017400 next 147 of size 36864
2019-10-27 10:47:10.741186: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f0020400 next 148 of size 256
2019-10-27 10:47:10.741194: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f0020500 next 149 of size 73728
2019-10-27 10:47:10.741203: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f0032500 next 150 of size 256
2019-10-27 10:47:10.741212: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f0032600 next 151 of size 147456
2019-10-27 10:47:10.741220: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f0056600 next 152 of size 256
2019-10-27 10:47:10.741229: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f0056700 next 153 of size 294912
2019-10-27 10:47:10.741238: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f009e700 next 154 of size 512
2019-10-27 10:47:10.741246: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f009e900 next 155 of size 589824
2019-10-27 10:47:10.741255: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f012e900 next 156 of size 512
2019-10-27 10:47:10.741264: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f012eb00 next 157 of size 589824
2019-10-27 10:47:10.741272: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f01beb00 next 158 of size 512
2019-10-27 10:47:10.741281: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f01bed00 next 159 of size 589824
2019-10-27 10:47:10.741289: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f024ed00 next 160 of size 512
2019-10-27 10:47:10.741298: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f024ef00 next 161 of size 1179648
2019-10-27 10:47:10.741307: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f036ef00 next 162 of size 512
2019-10-27 10:47:10.741316: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f036f100 next 163 of size 589824
2019-10-27 10:47:10.741324: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f03ff100 next 164 of size 512
2019-10-27 10:47:10.741333: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f03ff300 next 165 of size 442368
2019-10-27 10:47:10.741341: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f046b300 next 166 of size 256
2019-10-27 10:47:10.741350: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f046b400 next 167 of size 147456
2019-10-27 10:47:10.741359: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f048f400 next 168 of size 256
2019-10-27 10:47:10.741367: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f048f500 next 169 of size 110592
2019-10-27 10:47:10.741376: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04aa500 next 170 of size 256
2019-10-27 10:47:10.741385: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04aa600 next 171 of size 36864
2019-10-27 10:47:10.741394: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04b3600 next 172 of size 256
2019-10-27 10:47:10.741402: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04b3700 next 173 of size 27648
2019-10-27 10:47:10.741411: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04ba300 next 174 of size 256
2019-10-27 10:47:10.741433: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04ba400 next 175 of size 9216
2019-10-27 10:47:10.741442: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04bc800 next 176 of size 256
2019-10-27 10:47:10.741451: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04bc900 next 177 of size 256
2019-10-27 10:47:10.741459: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04bca00 next 178 of size 256
2019-10-27 10:47:10.741468: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04bcb00 next 179 of size 256
2019-10-27 10:47:10.741476: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04bcc00 next 180 of size 256
2019-10-27 10:47:10.741485: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04bcd00 next 181 of size 256
2019-10-27 10:47:10.741494: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04bce00 next 182 of size 256
2019-10-27 10:47:10.741502: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04bcf00 next 183 of size 256
2019-10-27 10:47:10.741511: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04bd000 next 184 of size 256
2019-10-27 10:47:10.741519: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04bd100 next 185 of size 256
2019-10-27 10:47:10.741528: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04bd200 next 186 of size 256
2019-10-27 10:47:10.741537: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04bd300 next 187 of size 256
2019-10-27 10:47:10.741545: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04bd400 next 188 of size 256
2019-10-27 10:47:10.741554: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04bd500 next 189 of size 256
2019-10-27 10:47:10.741563: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04bd600 next 190 of size 65536
2019-10-27 10:47:10.741572: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04cd600 next 191 of size 65536
2019-10-27 10:47:10.741581: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04dd600 next 192 of size 256
2019-10-27 10:47:10.741589: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04dd700 next 193 of size 256
2019-10-27 10:47:10.741598: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04dd800 next 194 of size 256
2019-10-27 10:47:10.741606: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04dd900 next 195 of size 256
2019-10-27 10:47:10.741615: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04dda00 next 196 of size 256
2019-10-27 10:47:10.741623: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04ddb00 next 197 of size 256
2019-10-27 10:47:10.741632: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04ddc00 next 198 of size 256
2019-10-27 10:47:10.741641: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04ddd00 next 199 of size 256
2019-10-27 10:47:10.741649: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04dde00 next 200 of size 256
2019-10-27 10:47:10.741658: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04ddf00 next 201 of size 256
2019-10-27 10:47:10.741666: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04de000 next 208 of size 768
2019-10-27 10:47:10.741675: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04de300 next 209 of size 256
2019-10-27 10:47:10.741683: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04de400 next 217 of size 256
2019-10-27 10:47:10.741692: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04de500 next 218 of size 256
2019-10-27 10:47:10.741700: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04de600 next 225 of size 256
2019-10-27 10:47:10.741714: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04de700 next 226 of size 256
2019-10-27 10:47:10.741723: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04de800 next 227 of size 256
2019-10-27 10:47:10.741732: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04de900 next 236 of size 18432
2019-10-27 10:47:10.741740: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04e3100 next 237 of size 256
2019-10-27 10:47:10.741749: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04e3200 next 238 of size 256
2019-10-27 10:47:10.741758: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04e3300 next 241 of size 256
2019-10-27 10:47:10.741766: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04e3400 next 242 of size 256
2019-10-27 10:47:10.741775: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04e3500 next 233 of size 256
2019-10-27 10:47:10.741783: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04e3600 next 244 of size 256
2019-10-27 10:47:10.741792: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04e3700 next 253 of size 256
2019-10-27 10:47:10.741801: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04e3800 next 254 of size 256
2019-10-27 10:47:10.741809: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04e3900 next 257 of size 256
2019-10-27 10:47:10.741818: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04e3a00 next 258 of size 256
2019-10-27 10:47:10.741826: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04e3b00 next 259 of size 256
2019-10-27 10:47:10.741835: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04e3c00 next 262 of size 256
2019-10-27 10:47:10.741844: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04e3d00 next 263 of size 256
2019-10-27 10:47:10.741852: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04e3e00 next 273 of size 256
2019-10-27 10:47:10.741861: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04e3f00 next 274 of size 256
2019-10-27 10:47:10.741869: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04e4000 next 275 of size 256
2019-10-27 10:47:10.741878: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04e4100 next 282 of size 256
2019-10-27 10:47:10.741887: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04e4200 next 283 of size 256
2019-10-27 10:47:10.741895: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04e4300 next 284 of size 256
2019-10-27 10:47:10.741904: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04e4400 next 285 of size 256
2019-10-27 10:47:10.741912: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04e4500 next 286 of size 256
2019-10-27 10:47:10.741921: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04e4600 next 288 of size 256
2019-10-27 10:47:10.741929: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04e4700 next 289 of size 256
2019-10-27 10:47:10.741938: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04e4800 next 290 of size 256
2019-10-27 10:47:10.741946: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04e4900 next 292 of size 256
2019-10-27 10:47:10.741955: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04e4a00 next 293 of size 256
2019-10-27 10:47:10.741964: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04e4b00 next 279 of size 256
2019-10-27 10:47:10.741972: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04e4c00 next 280 of size 256
2019-10-27 10:47:10.741981: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f04e4d00 next 277 of size 147456
2019-10-27 10:47:10.741995: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f0508d00 next 278 of size 65536
2019-10-27 10:47:10.742004: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f0518d00 next 291 of size 65536
2019-10-27 10:47:10.742013: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f0528d00 next 299 of size 256
2019-10-27 10:47:10.742021: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f0528e00 next 300 of size 256
2019-10-27 10:47:10.742030: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f0528f00 next 301 of size 512
2019-10-27 10:47:10.742039: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f0529100 next 302 of size 256
2019-10-27 10:47:10.742047: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f0529200 next 309 of size 256
2019-10-27 10:47:10.742056: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f0529300 next 313 of size 256
2019-10-27 10:47:10.742064: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f0529400 next 308 of size 512
2019-10-27 10:47:10.742073: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f0529600 next 314 of size 256
2019-10-27 10:47:10.742082: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f0529700 next 312 of size 256
2019-10-27 10:47:10.742090: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f0529800 next 319 of size 256
2019-10-27 10:47:10.742099: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f0529900 next 324 of size 256
2019-10-27 10:47:10.742107: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f0529a00 next 325 of size 512
2019-10-27 10:47:10.742116: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f0529c00 next 328 of size 256
2019-10-27 10:47:10.742124: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f0529d00 next 322 of size 256
2019-10-27 10:47:10.742133: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f0529e00 next 331 of size 256
2019-10-27 10:47:10.742141: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f0529f00 next 333 of size 256
2019-10-27 10:47:10.742150: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f052a000 next 338 of size 512
2019-10-27 10:47:10.742159: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f052a200 next 339 of size 256
2019-10-27 10:47:10.742167: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f052a300 next 340 of size 256
2019-10-27 10:47:10.742176: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f052a400 next 344 of size 256
2019-10-27 10:47:10.742185: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f052a500 next 342 of size 256
2019-10-27 10:47:10.742194: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f052a600 next 348 of size 512
2019-10-27 10:47:10.742202: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f052a800 next 349 of size 256
2019-10-27 10:47:10.742211: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f052a900 next 353 of size 256
2019-10-27 10:47:10.742219: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f052aa00 next 357 of size 256
2019-10-27 10:47:10.742228: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f052ab00 next 358 of size 256
2019-10-27 10:47:10.742237: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f052ac00 next 355 of size 512
2019-10-27 10:47:10.742245: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f052ae00 next 360 of size 256
2019-10-27 10:47:10.742254: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f052af00 next 363 of size 256
2019-10-27 10:47:10.742262: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f052b000 next 364 of size 256
2019-10-27 10:47:10.742275: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f052b100 next 368 of size 256
2019-10-27 10:47:10.742284: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f052b200 next 366 of size 256
2019-10-27 10:47:10.742293: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f052b300 next 372 of size 256
2019-10-27 10:47:10.742302: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f052b400 next 369 of size 256
2019-10-27 10:47:10.742310: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f052b500 next 380 of size 256
2019-10-27 10:47:10.742319: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f052b600 next 383 of size 256
2019-10-27 10:47:10.742327: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f052b700 next 384 of size 256
2019-10-27 10:47:10.742336: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f052b800 next 387 of size 256
2019-10-27 10:47:10.742344: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f052b900 next 388 of size 256
2019-10-27 10:47:10.742353: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f052ba00 next 391 of size 256
2019-10-27 10:47:10.742363: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f052bb00 next 294 of size 53760
2019-10-27 10:47:10.742372: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f0538d00 next 296 of size 294912
2019-10-27 10:47:10.742380: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f0580d00 next 297 of size 256
2019-10-27 10:47:10.742389: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f0580e00 next 264 of size 536576
2019-10-27 10:47:10.742398: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f0603e00 next 266 of size 73728
2019-10-27 10:47:10.742407: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f0615e00 next 267 of size 256
2019-10-27 10:47:10.742415: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f0615f00 next 268 of size 256
2019-10-27 10:47:10.742424: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f0616000 next 270 of size 256
2019-10-27 10:47:10.742432: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f0616100 next 271 of size 256
2019-10-27 10:47:10.742441: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f0616200 next 272 of size 1179648
2019-10-27 10:47:10.742450: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f0736200 next 276 of size 1179648
2019-10-27 10:47:10.742459: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f0856200 next 245 of size 2807040
2019-10-27 10:47:10.742468: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f0b03700 next 247 of size 256
2019-10-27 10:47:10.742477: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f0b03800 next 248 of size 256
2019-10-27 10:47:10.742485: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f0b03900 next 249 of size 256
2019-10-27 10:47:10.742494: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f0b03a00 next 250 of size 36864
2019-10-27 10:47:10.742502: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f0b0ca00 next 251 of size 256
2019-10-27 10:47:10.742511: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f0b0cb00 next 252 of size 256
2019-10-27 10:47:10.742520: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f0b0cc00 next 228 of size 8264960
2019-10-27 10:47:10.742529: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f12ee900 next 230 of size 256
2019-10-27 10:47:10.742537: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f12eea00 next 231 of size 256
2019-10-27 10:47:10.742546: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f12eeb00 next 232 of size 256
2019-10-27 10:47:10.742559: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f12eec00 next 234 of size 256
2019-10-27 10:47:10.742568: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f12eed00 next 235 of size 256
2019-10-27 10:47:10.742577: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f12eee00 next 219 of size 16742400
2019-10-27 10:47:10.742587: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f22e6600 next 439 of size 33554432
2019-10-27 10:47:10.742596: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f42e6600 next 444 of size 16777216
2019-10-27 10:47:10.742605: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f52e6600 next 445 of size 8388608
2019-10-27 10:47:10.742614: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f5ae6600 next 446 of size 16777216
2019-10-27 10:47:10.742623: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f6ae6600 next 448 of size 16777216
2019-10-27 10:47:10.742631: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f7ae6600 next 449 of size 16777216
2019-10-27 10:47:10.742640: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f08f8ae6600 next 451 of size 16777216
2019-10-27 10:47:10.742649: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08f9ae6600 next 452 of size 16777216
2019-10-27 10:47:10.742658: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08faae6600 next 202 of size 25147648
2019-10-27 10:47:10.742667: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f08fc2e1f00 next 203 of size 65028096
2019-10-27 10:47:10.742677: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f09000e5f00 next 204 of size 134217728
2019-10-27 10:47:10.742686: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f09080e5f00 next 205 of size 65536
2019-10-27 10:47:10.742694: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f09080f5f00 next 206 of size 65028096
2019-10-27 10:47:10.742703: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f090bef9f00 next 207 of size 134217728
2019-10-27 10:47:10.742712: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0913ef9f00 next 210 of size 256
2019-10-27 10:47:10.742720: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0913efa000 next 211 of size 256
2019-10-27 10:47:10.742729: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0913efa100 next 212 of size 256
2019-10-27 10:47:10.742738: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0913efa200 next 213 of size 256
2019-10-27 10:47:10.742746: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0913efa300 next 214 of size 256
2019-10-27 10:47:10.742756: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0913efa400 next 215 of size 31490048
2019-10-27 10:47:10.742765: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0915d02400 next 216 of size 134217728
2019-10-27 10:47:10.742774: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f091dd02400 next 220 of size 9216
2019-10-27 10:47:10.742782: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f091dd04800 next 221 of size 256
2019-10-27 10:47:10.742791: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f091dd04900 next 222 of size 256
2019-10-27 10:47:10.742800: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f091dd04a00 next 223 of size 31490048
2019-10-27 10:47:10.742808: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f091fb0ca00 next 224 of size 134217728
2019-10-27 10:47:10.742817: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0927b0ca00 next 229 of size 33554432
2019-10-27 10:47:10.742826: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0929b0ca00 next 243 of size 14745600
2019-10-27 10:47:10.742840: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f092a91ca00 next 260 of size 6422528
2019-10-27 10:47:10.742850: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f092af3ca00 next 269 of size 16777216
2019-10-27 10:47:10.742859: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f092bf3ca00 next 239 of size 43909120
2019-10-27 10:47:10.742869: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f092e91ca00 next 240 of size 67108864
2019-10-27 10:47:10.742877: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f093291ca00 next 246 of size 67108864
2019-10-27 10:47:10.742886: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f093691ca00 next 295 of size 2097152
2019-10-27 10:47:10.742895: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0936b1ca00 next 303 of size 2097152
2019-10-27 10:47:10.742904: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0936d1ca00 next 255 of size 2228224
2019-10-27 10:47:10.742913: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0936f3ca00 next 256 of size 67108864
2019-10-27 10:47:10.742922: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f093af3ca00 next 261 of size 67108864
2019-10-27 10:47:10.742930: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f093ef3ca00 next 265 of size 67108864
2019-10-27 10:47:10.742939: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0942f3ca00 next 281 of size 33554432
2019-10-27 10:47:10.742948: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0944f3ca00 next 287 of size 33554432
2019-10-27 10:47:10.742957: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0946f3ca00 next 298 of size 33554432
2019-10-27 10:47:10.742965: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0948f3ca00 next 304 of size 33554432
2019-10-27 10:47:10.742974: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f094af3ca00 next 305 of size 8388608
2019-10-27 10:47:10.742982: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f094b73ca00 next 306 of size 589824
2019-10-27 10:47:10.742992: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f094b7cca00 next 307 of size 12386304
2019-10-27 10:47:10.743000: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f094c39ca00 next 330 of size 589824
2019-10-27 10:47:10.743010: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f094c42ca00 next 315 of size 7798784
2019-10-27 10:47:10.743020: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f094cb9ca00 next 311 of size 12976128
2019-10-27 10:47:10.743029: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f094d7fca00 next 317 of size 8388608
2019-10-27 10:47:10.743038: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f094dffca00 next 310 of size 16777216
2019-10-27 10:47:10.743047: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f094effca00 next 316 of size 16777216
2019-10-27 10:47:10.743056: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f094fffca00 next 318 of size 589824
2019-10-27 10:47:10.743064: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f095008ca00 next 320 of size 8388608
2019-10-27 10:47:10.743073: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f095088ca00 next 321 of size 16777216
2019-10-27 10:47:10.743082: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f095188ca00 next 334 of size 16777216
2019-10-27 10:47:10.743090: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f095288ca00 next 356 of size 589824
2019-10-27 10:47:10.744097: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f095291ca00 next 376 of size 147456
2019-10-27 10:47:10.744221: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0952940a00 next 385 of size 110592
2019-10-27 10:47:10.744267: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f095295ba00 next 394 of size 256
2019-10-27 10:47:10.744290: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f095295bb00 next 396 of size 256
2019-10-27 10:47:10.744309: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f095295bc00 next 398 of size 256
2019-10-27 10:47:10.744329: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f095295bd00 next 401 of size 27648
2019-10-27 10:47:10.744349: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0952962900 next 403 of size 256
2019-10-27 10:47:10.744368: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0952962a00 next 406 of size 256
2019-10-27 10:47:10.744387: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0952962b00 next 408 of size 256
2019-10-27 10:47:10.744406: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0952962c00 next 411 of size 9216
2019-10-27 10:47:10.744425: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0952965000 next 413 of size 256
2019-10-27 10:47:10.744444: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0952965100 next 415 of size 256
2019-10-27 10:47:10.744463: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0952965200 next 417 of size 256
2019-10-27 10:47:10.744482: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0952965300 next 420 of size 256
2019-10-27 10:47:10.744501: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0952965400 next 422 of size 256
2019-10-27 10:47:10.744520: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0952965500 next 425 of size 256
2019-10-27 10:47:10.744539: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0952965600 next 502 of size 256
2019-10-27 10:47:10.744559: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0952965700 next 504 of size 256
2019-10-27 10:47:10.744578: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f0952965800 next 518 of size 256
2019-10-27 10:47:10.744597: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0952965900 next 456 of size 256
2019-10-27 10:47:10.744616: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0952965a00 next 510 of size 256
2019-10-27 10:47:10.744638: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0952965b00 next 511 of size 9472
2019-10-27 10:47:10.744658: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0952968000 next 450 of size 256
2019-10-27 10:47:10.744677: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0952968100 next 470 of size 9216
2019-10-27 10:47:10.744696: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f095296a500 next 427 of size 27648
2019-10-27 10:47:10.744715: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0952971100 next 507 of size 27648
2019-10-27 10:47:10.744735: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0952977d00 next 505 of size 27648
2019-10-27 10:47:10.744754: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f095297e900 next 336 of size 3203328
2019-10-27 10:47:10.744775: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0952c8ca00 next 343 of size 1179648
2019-10-27 10:47:10.744795: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0952daca00 next 347 of size 4194304
2019-10-27 10:47:10.744815: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f09531aca00 next 329 of size 7208960
2019-10-27 10:47:10.744837: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f095388ca00 next 323 of size 48627712
2019-10-27 10:47:10.744857: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f09566eca00 next 326 of size 37879808
2019-10-27 10:47:10.744878: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0958b0ca00 next 327 of size 16777216
2019-10-27 10:47:10.744906: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0959b0ca00 next 332 of size 33554432
2019-10-27 10:47:10.744927: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f095bb0ca00 next 335 of size 33554432
2019-10-27 10:47:10.744946: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f095db0ca00 next 351 of size 4194304
2019-10-27 10:47:10.744979: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f095df0ca00 next 362 of size 4194304
2019-10-27 10:47:10.745000: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f095e30ca00 next 377 of size 8388608
2019-10-27 10:47:10.745020: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f095eb0ca00 next 379 of size 8388608
2019-10-27 10:47:10.745051: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f095f30ca00 next 382 of size 8388608
2019-10-27 10:47:10.745067: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f095fb0ca00 next 381 of size 16777216
2019-10-27 10:47:10.745083: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0960b0ca00 next 345 of size 16777216
2019-10-27 10:47:10.745100: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0961b0ca00 next 337 of size 104923136
2019-10-27 10:47:10.745117: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0967f1ca00 next 341 of size 71368704
2019-10-27 10:47:10.745132: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f096c32ca00 next 346 of size 67108864
2019-10-27 10:47:10.745148: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f097032ca00 next 350 of size 67108864
2019-10-27 10:47:10.745163: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f097432ca00 next 371 of size 33554432
2019-10-27 10:47:10.745179: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f097632ca00 next 390 of size 16777216
2019-10-27 10:47:10.745194: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f097732ca00 next 404 of size 33554432
2019-10-27 10:47:10.745211: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f097932ca00 next 359 of size 50331648
2019-10-27 10:47:10.745227: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f097c32ca00 next 352 of size 205553664
2019-10-27 10:47:10.745244: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0988734a00 next 354 of size 138444800
2019-10-27 10:47:10.745260: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0990b3ca00 next 361 of size 134217728
2019-10-27 10:47:10.745275: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0998b3ca00 next 365 of size 134217728
2019-10-27 10:47:10.745310: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f09a0b3ca00 next 386 of size 134217728
2019-10-27 10:47:10.745330: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f09a8b3ca00 next 373 of size 134217728
2019-10-27 10:47:10.745351: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f09b0b3ca00 next 374 of size 268435456
2019-10-27 10:47:10.745372: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f09c0b3ca00 next 367 of size 138428416
2019-10-27 10:47:10.745393: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f09c8f40a00 next 370 of size 272646144
2019-10-27 10:47:10.745412: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f09d9344a00 next 375 of size 268435456
2019-10-27 10:47:10.745431: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f09e9344a00 next 378 of size 268435456
2019-10-27 10:47:10.745450: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f09f9344a00 next 389 of size 134217728
2019-10-27 10:47:10.745469: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0a01344a00 next 392 of size 134217728
2019-10-27 10:47:10.745497: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0a09344a00 next 393 of size 134217728
2019-10-27 10:47:10.745520: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0a11344a00 next 395 of size 100663296
2019-10-27 10:47:10.745540: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0a17344a00 next 397 of size 134217728
2019-10-27 10:47:10.745559: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f0a1f344a00 next 399 of size 134217728
2019-10-27 10:47:10.745578: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0a27344a00 next 400 of size 134217728
2019-10-27 10:47:10.745597: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f0a2f344a00 next 402 of size 134217728
2019-10-27 10:47:10.745617: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0a37344a00 next 405 of size 134217728
2019-10-27 10:47:10.745636: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0a3f344a00 next 407 of size 33554432
2019-10-27 10:47:10.745656: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0a41344a00 next 409 of size 67108864
2019-10-27 10:47:10.745675: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0a45344a00 next 410 of size 33554432
2019-10-27 10:47:10.745694: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0a47344a00 next 412 of size 67108864
2019-10-27 10:47:10.745713: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0a4b344a00 next 414 of size 67108864
2019-10-27 10:47:10.745732: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0a4f344a00 next 416 of size 33554432
2019-10-27 10:47:10.745752: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0a51344a00 next 418 of size 67108864
2019-10-27 10:47:10.745771: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0a55344a00 next 419 of size 67108864
2019-10-27 10:47:10.745790: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0a59344a00 next 428 of size 67108864
2019-10-27 10:47:10.745809: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0a5d344a00 next 431 of size 33554432
2019-10-27 10:47:10.745829: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0a5f344a00 next 421 of size 33554432
2019-10-27 10:47:10.745848: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0a61344a00 next 423 of size 67108864
2019-10-27 10:47:10.745867: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0a65344a00 next 429 of size 67108864
2019-10-27 10:47:10.745887: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0a69344a00 next 430 of size 16777216
2019-10-27 10:47:10.745907: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0a6a344a00 next 424 of size 117440512
2019-10-27 10:47:10.745928: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0a71344a00 next 426 of size 201326592
2019-10-27 10:47:10.745947: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0a7d344a00 next 434 of size 33554432
2019-10-27 10:47:10.745966: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f0a7f344a00 next 508 of size 25165824
2019-10-27 10:47:10.745985: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0a80b44a00 next 432 of size 8388608
2019-10-27 10:47:10.746005: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0a81344a00 next 433 of size 67108864
2019-10-27 10:47:10.746024: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0a85344a00 next 440 of size 33554432
2019-10-27 10:47:10.746043: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0a87344a00 next 435 of size 33554432
2019-10-27 10:47:10.746062: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0a89344a00 next 436 of size 33554432
2019-10-27 10:47:10.746081: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0a8b344a00 next 437 of size 67108864
2019-10-27 10:47:10.746122: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0a8f344a00 next 438 of size 33554432
2019-10-27 10:47:10.746140: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0a91344a00 next 476 of size 16777216
2019-10-27 10:47:10.746155: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0a92344a00 next 473 of size 16777216
2019-10-27 10:47:10.746170: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0a93344a00 next 474 of size 33554432
2019-10-27 10:47:10.746186: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0a95344a00 next 475 of size 33554432
2019-10-27 10:47:10.746201: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0a97344a00 next 477 of size 16777216
2019-10-27 10:47:10.746216: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0a98344a00 next 443 of size 16777216
2019-10-27 10:47:10.746232: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f0a99344a00 next 447 of size 134217728
2019-10-27 10:47:10.746247: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0aa1344a00 next 466 of size 134217728
2019-10-27 10:47:10.746263: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f0aa9344a00 next 453 of size 134217728
2019-10-27 10:47:10.746278: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0ab1344a00 next 454 of size 16777216
2019-10-27 10:47:10.746294: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f0ab2344a00 next 457 of size 25165824
2019-10-27 10:47:10.746309: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0ab3b44a00 next 458 of size 16777216
2019-10-27 10:47:10.746325: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f0ab4b44a00 next 459 of size 4194304
2019-10-27 10:47:10.746340: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0ab4f44a00 next 460 of size 4194304
2019-10-27 10:47:10.746373: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0ab5344a00 next 461 of size 4194304
2019-10-27 10:47:10.746393: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0ab5744a00 next 462 of size 4194304
2019-10-27 10:47:10.746412: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f0ab5b44a00 next 463 of size 8388608
2019-10-27 10:47:10.746431: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0ab6344a00 next 464 of size 4194304
2019-10-27 10:47:10.746451: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f0ab6744a00 next 465 of size 4194304
2019-10-27 10:47:10.746470: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0ab6b44a00 next 467 of size 4194304
2019-10-27 10:47:10.746489: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0ab6f44a00 next 471 of size 4194304
2019-10-27 10:47:10.746509: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0ab7344a00 next 472 of size 4194304
2019-10-27 10:47:10.746530: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0ab7744a00 next 441 of size 29360128
2019-10-27 10:47:10.746551: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0ab9344a00 next 442 of size 402653184
2019-10-27 10:47:10.746570: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f0ad1344a00 next 455 of size 134217728
2019-10-27 10:47:10.746589: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0ad9344a00 next 478 of size 16777216
2019-10-27 10:47:10.746608: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0ada344a00 next 479 of size 33554432
2019-10-27 10:47:10.746627: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0adc344a00 next 483 of size 33554432
2019-10-27 10:47:10.746647: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f0ade344a00 next 512 of size 8388608
2019-10-27 10:47:10.746666: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0adeb44a00 next 506 of size 8388608
2019-10-27 10:47:10.746693: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f0adf344a00 next 484 of size 16777216
2019-10-27 10:47:10.746713: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0ae0344a00 next 485 of size 33554432
2019-10-27 10:47:10.746732: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0ae2344a00 next 480 of size 33554432
2019-10-27 10:47:10.746752: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0ae4344a00 next 481 of size 100663296
2019-10-27 10:47:10.746771: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0aea344a00 next 482 of size 100663296
2019-10-27 10:47:10.746790: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0af0344a00 next 486 of size 33554432
2019-10-27 10:47:10.746809: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0af2344a00 next 487 of size 67108864
2019-10-27 10:47:10.746828: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0af6344a00 next 491 of size 67108864
2019-10-27 10:47:10.746847: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f0afa344a00 next 492 of size 67108864
2019-10-27 10:47:10.746867: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0afe344a00 next 493 of size 67108864
2019-10-27 10:47:10.746886: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0b02344a00 next 488 of size 67108864
2019-10-27 10:47:10.746905: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0b06344a00 next 489 of size 201326592
2019-10-27 10:47:10.746924: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0b12344a00 next 490 of size 201326592
2019-10-27 10:47:10.746943: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0b1e344a00 next 494 of size 67108864
2019-10-27 10:47:10.746963: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0b22344a00 next 499 of size 402653184
2019-10-27 10:47:10.746982: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f0b3a344a00 next 496 of size 268435456
2019-10-27 10:47:10.747001: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0b4a344a00 next 497 of size 402653184
2019-10-27 10:47:10.747020: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0b62344a00 next 498 of size 402653184
2019-10-27 10:47:10.747040: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0b7a344a00 next 495 of size 402653184
2019-10-27 10:47:10.747059: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f0b92344a00 next 501 of size 402653184
2019-10-27 10:47:10.747078: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f0baa344a00 next 18446744073709551615 of size 201684480
2019-10-27 10:47:10.747096: I tensorflow/core/common_runtime/bfc_allocator.cc:809]      Summary of in-use Chunks by size: 
2019-10-27 10:47:10.747164: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 192 Chunks of size 256 totalling 48.0KiB
2019-10-27 10:47:10.747191: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 27 Chunks of size 512 totalling 13.5KiB
2019-10-27 10:47:10.747227: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 3 Chunks of size 768 totalling 2.2KiB
2019-10-27 10:47:10.747246: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 10 Chunks of size 1024 totalling 10.0KiB
2019-10-27 10:47:10.747264: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 8 Chunks of size 1280 totalling 10.0KiB
2019-10-27 10:47:10.747282: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 1792 totalling 1.8KiB
2019-10-27 10:47:10.747300: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 7 Chunks of size 9216 totalling 63.0KiB
2019-10-27 10:47:10.747318: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 9472 totalling 9.2KiB
2019-10-27 10:47:10.747336: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 16384 totalling 16.0KiB
2019-10-27 10:47:10.747362: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 3 Chunks of size 18432 totalling 54.0KiB
2019-10-27 10:47:10.747382: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 25344 totalling 24.8KiB
2019-10-27 10:47:10.747401: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 6 Chunks of size 27648 totalling 162.0KiB
2019-10-27 10:47:10.747420: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 5 Chunks of size 36864 totalling 180.0KiB
2019-10-27 10:47:10.747438: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 46080 totalling 45.0KiB
2019-10-27 10:47:10.747473: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 53760 totalling 52.5KiB
2019-10-27 10:47:10.747498: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 5 Chunks of size 65536 totalling 320.0KiB
2019-10-27 10:47:10.747521: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 7 Chunks of size 73728 totalling 504.0KiB
2019-10-27 10:47:10.747545: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 107776 totalling 105.2KiB
2019-10-27 10:47:10.747567: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 4 Chunks of size 110592 totalling 432.0KiB
2019-10-27 10:47:10.747590: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 6 Chunks of size 147456 totalling 864.0KiB
2019-10-27 10:47:10.747613: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 8 Chunks of size 294912 totalling 2.25MiB
2019-10-27 10:47:10.747636: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 442368 totalling 864.0KiB
2019-10-27 10:47:10.747659: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 536576 totalling 524.0KiB
2019-10-27 10:47:10.747682: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 13 Chunks of size 589824 totalling 7.31MiB
2019-10-27 10:47:10.747705: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 12 Chunks of size 1179648 totalling 13.50MiB
2019-10-27 10:47:10.747728: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 1769472 totalling 1.69MiB
2019-10-27 10:47:10.747750: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 1835008 totalling 1.75MiB
2019-10-27 10:47:10.747773: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 5 Chunks of size 2097152 totalling 10.00MiB
2019-10-27 10:47:10.747796: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 2228224 totalling 2.12MiB
2019-10-27 10:47:10.747819: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 7 Chunks of size 2359296 totalling 15.75MiB
2019-10-27 10:47:10.747841: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 2807040 totalling 2.68MiB
2019-10-27 10:47:10.747863: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 3932160 totalling 3.75MiB
2019-10-27 10:47:10.747886: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 11 Chunks of size 4194304 totalling 44.00MiB
2019-10-27 10:47:10.747909: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 6422528 totalling 6.12MiB
2019-10-27 10:47:10.747931: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 7208960 totalling 6.88MiB
2019-10-27 10:47:10.747954: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 7798784 totalling 7.44MiB
2019-10-27 10:47:10.747976: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 8264960 totalling 7.88MiB
2019-10-27 10:47:10.747999: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 11 Chunks of size 8388608 totalling 88.00MiB
2019-10-27 10:47:10.748022: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 12386304 totalling 11.81MiB
2019-10-27 10:47:10.748045: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 12976128 totalling 12.38MiB
2019-10-27 10:47:10.748069: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 14745600 totalling 14.06MiB
2019-10-27 10:47:10.748092: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 16742400 totalling 15.97MiB
2019-10-27 10:47:10.748123: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 22 Chunks of size 16777216 totalling 352.00MiB
2019-10-27 10:47:10.748148: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 25147648 totalling 23.98MiB
2019-10-27 10:47:10.748171: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 29360128 totalling 28.00MiB
2019-10-27 10:47:10.748194: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 31490048 totalling 60.06MiB
2019-10-27 10:47:10.748217: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 27 Chunks of size 33554432 totalling 864.00MiB
2019-10-27 10:47:10.748240: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 37879808 totalling 36.12MiB
2019-10-27 10:47:10.748263: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 43909120 totalling 41.88MiB
2019-10-27 10:47:10.748300: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 48627712 totalling 46.38MiB
2019-10-27 10:47:10.748321: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 50331648 totalling 48.00MiB
2019-10-27 10:47:10.748340: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 65028096 totalling 124.03MiB
2019-10-27 10:47:10.748358: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 21 Chunks of size 67108864 totalling 1.31GiB
2019-10-27 10:47:10.748376: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 71368704 totalling 68.06MiB
2019-10-27 10:47:10.748395: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 3 Chunks of size 100663296 totalling 288.00MiB
2019-10-27 10:47:10.748414: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 104923136 totalling 100.06MiB
2019-10-27 10:47:10.748433: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 117440512 totalling 112.00MiB
2019-10-27 10:47:10.748451: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 15 Chunks of size 134217728 totalling 1.88GiB
2019-10-27 10:47:10.748470: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 138428416 totalling 132.02MiB
2019-10-27 10:47:10.748488: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 138444800 totalling 132.03MiB
2019-10-27 10:47:10.748507: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 3 Chunks of size 201326592 totalling 576.00MiB
2019-10-27 10:47:10.748526: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 205553664 totalling 196.03MiB
2019-10-27 10:47:10.748544: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 3 Chunks of size 268435456 totalling 768.00MiB
2019-10-27 10:47:10.748584: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 272646144 totalling 260.02MiB
2019-10-27 10:47:10.748607: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 6 Chunks of size 402653184 totalling 2.25GiB
2019-10-27 10:47:10.748628: I tensorflow/core/common_runtime/bfc_allocator.cc:816] Sum Total of in-use chunks: 9.87GiB
2019-10-27 10:47:10.748649: I tensorflow/core/common_runtime/bfc_allocator.cc:818] total_region_allocated_bytes_: 11982716928 memory_limit_: 11982716928 available bytes: 0 curr_region_allocation_bytes_: 23965433856
2019-10-27 10:47:10.748678: I tensorflow/core/common_runtime/bfc_allocator.cc:824] Stats: 
Limit:                 11982716928
InUse:                 10595035136
MaxInUse:              11601612544
NumAllocs:                    2422
MaxAllocSize:           3653763072

2019-10-27 10:47:10.748765: W tensorflow/core/common_runtime/bfc_allocator.cc:319] ********************************************************************_**************_***************_
2019-10-27 10:47:10.748831: W tensorflow/core/framework/op_kernel.cc:1546] OP_REQUIRES failed at conv_grad_input_ops.cc:954 : Resource exhausted: OOM when allocating tensor with shape[128,48,128,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
2019-10-27 10:47:10.748959: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Resource exhausted: OOM when allocating tensor with shape[128,48,128,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
	 [[{{node StatefulPartitionedCall/PartitionedCall_1/gradients/StatefulPartitionedCall_grad/PartitionedCall/gradients/model_2/conv2d_21/Conv2D_grad/Conv2DBackpropInput}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

2019-10-27 10:47:10.912148: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.09GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
[I 10:47:48.752 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 10:48:35.108 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 10:48:45.692 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 10:48:47.645 LabApp] Starting buffering for 8a176c6a-8996-42d7-bccc-a9d6303bb7c0:f6f50c1de9b147b18b2cce0931313a25
[I 10:48:51.347 LabApp] Kernel restarted: 8a176c6a-8996-42d7-bccc-a9d6303bb7c0
[I 10:48:55.309 LabApp] Adapting from protocol version 5.1 (kernel 8a176c6a-8996-42d7-bccc-a9d6303bb7c0) to 5.3 (client).
[I 10:48:55.310 LabApp] Restoring connection for 8a176c6a-8996-42d7-bccc-a9d6303bb7c0:f6f50c1de9b147b18b2cce0931313a25
[I 10:48:55.310 LabApp] Replaying 8 buffered messages
2019-10-27 10:49:09.734740: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-27 10:49:10.345511: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-27 10:49:10.346546: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 10:49:10.348729: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 10:49:10.350367: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 10:49:10.351148: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 10:49:10.353319: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 10:49:10.355077: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 10:49:10.358988: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 10:49:10.363035: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 10:49:10.609248: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5604ed910880 executing computations on platform CUDA. Devices:
2019-10-27 10:49:10.609311: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-27 10:49:10.613028: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-27 10:49:10.615862: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5604ed9e7330 executing computations on platform Host. Devices:
2019-10-27 10:49:10.615930: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-27 10:49:10.617945: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-27 10:49:10.618123: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 10:49:10.618209: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 10:49:10.618289: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 10:49:10.618368: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 10:49:10.618448: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 10:49:10.618526: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 10:49:10.618605: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 10:49:10.623122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 10:49:10.623258: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 10:49:10.627466: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-27 10:49:10.627508: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-27 10:49:10.627530: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-27 10:49:10.631245: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-27 10:49:18.714647: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-27 10:49:18.773802: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 10:49:19.006349: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 10:49:49.056 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 10:50:35.105 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 10:50:42.145 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 10:50:43.576 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 10:50:44.319 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 10:50:45.567 LabApp] Starting buffering for 8a176c6a-8996-42d7-bccc-a9d6303bb7c0:f6f50c1de9b147b18b2cce0931313a25
[I 10:50:49.146 LabApp] Kernel restarted: 8a176c6a-8996-42d7-bccc-a9d6303bb7c0
[I 10:50:51.994 LabApp] Adapting from protocol version 5.1 (kernel 8a176c6a-8996-42d7-bccc-a9d6303bb7c0) to 5.3 (client).
[I 10:50:51.995 LabApp] Restoring connection for 8a176c6a-8996-42d7-bccc-a9d6303bb7c0:f6f50c1de9b147b18b2cce0931313a25
[I 10:50:51.995 LabApp] Replaying 6 buffered messages
2019-10-27 10:51:04.862025: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-27 10:51:05.443934: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-27 10:51:05.445087: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 10:51:05.447762: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 10:51:05.449660: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 10:51:05.450472: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 10:51:05.452527: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 10:51:05.454629: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 10:51:05.458843: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 10:51:05.460990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 10:51:05.703820: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556969dc4bd0 executing computations on platform CUDA. Devices:
2019-10-27 10:51:05.703882: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-27 10:51:05.707650: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-27 10:51:05.708916: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556969e9b660 executing computations on platform Host. Devices:
2019-10-27 10:51:05.708946: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-27 10:51:05.710873: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-27 10:51:05.711025: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 10:51:05.711133: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 10:51:05.711197: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 10:51:05.711241: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 10:51:05.711278: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 10:51:05.711315: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 10:51:05.711352: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 10:51:05.716102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 10:51:05.716238: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 10:51:05.720054: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-27 10:51:05.720089: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-27 10:51:05.720107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-27 10:51:05.723246: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-27 10:51:14.158845: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-27 10:51:14.218801: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 10:51:14.457432: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 10:51:48.790 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 10:52:35.145 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 10:53:18.196 LabApp] 302 GET /notebooks/avgn_paper/notebooks/6.0-neural-networks/ (::1) 1.68ms
[I 10:53:18.232 LabApp] 302 GET /notebooks/avgn_paper/notebooks/6.0-neural-networks (::1) 2.82ms
[I 10:53:18.314 LabApp] Starting buffering for eb5078f2-6425-499a-9abd-25c5ca2d047d:b4fa18b718514429970873972ad849f5
[W 10:53:18.682 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 2.07ms referer=http://localhost:8187/tree/avgn_paper/notebooks/6.0-neural-networks
[I 10:53:28.377 LabApp] Kernel started: f3c70116-fdff-4b12-a767-b8e95ef46f9e
[W 10:53:28.386 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.83ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA6.ipynb
[W 10:53:28.655 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 1.73ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA6.ipynb
[I 10:53:30.646 LabApp] Adapting from protocol version 5.1 (kernel f3c70116-fdff-4b12-a767-b8e95ef46f9e) to 5.3 (client).
[I 10:53:36.476 LabApp] KernelRestarter: restarting kernel (1/5), keep random ports
kernel 00cb76cf-9ff9-45d7-bf9b-ca5e71a3b40a restarted
[I 10:53:50.082 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 10:54:35.118 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 10:55:28.777 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-32-GAIA6.ipynb
[I 10:55:49.838 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 10:56:35.096 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 10:57:49.186 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 10:58:35.147 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 10:59:48.996 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 11:00:35.308 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 11:01:49.033 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 11:02:35.110 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 11:03:20.616 LabApp] Kernel interrupted: 8a176c6a-8996-42d7-bccc-a9d6303bb7c0
[I 11:03:49.103 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 11:04:35.104 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 11:05:43.876 LabApp] Starting buffering for f3c70116-fdff-4b12-a767-b8e95ef46f9e:3eec680ede064516838c5703bce1d370
[I 11:05:49.801 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 11:06:36.185 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 11:07:49.780 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 11:08:35.097 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 11:09:49.013 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 11:10:36.048 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 11:11:49.788 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 11:12:36.052 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 11:13:49.860 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 11:14:36.054 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 11:15:50.116 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 11:16:36.091 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 11:17:49.796 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 11:18:36.159 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 11:19:49.845 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 11:20:35.989 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 11:21:50.257 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 11:22:36.450 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 11:23:49.034 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 11:24:35.102 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 11:25:49.025 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 11:26:35.144 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 11:27:49.017 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 11:28:35.122 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 11:29:50.640 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 11:30:37.387 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 11:31:52.060 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 11:32:36.604 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 11:33:49.860 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 11:34:36.074 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 11:35:49.876 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 11:36:36.019 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 11:37:49.883 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 11:38:36.046 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 11:39:50.065 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 11:40:36.019 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 11:41:49.902 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 11:42:36.069 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 11:43:50.072 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 11:44:35.191 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 11:45:49.817 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 11:46:36.477 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 11:47:49.907 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 11:48:36.129 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 11:49:49.839 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 11:50:36.098 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 11:51:49.930 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 11:52:36.146 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 11:53:49.945 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 11:55:49.960 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 11:57:49.856 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 11:59:49.544 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 12:01:49.854 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 12:03:49.987 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 12:05:49.833 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 12:07:49.944 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 12:09:49.863 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 12:11:49.877 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 12:13:49.841 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 12:15:49.921 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 13:25:50.355 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 13:27:49.936 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 13:29:49.985 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 13:31:49.962 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 13:33:49.926 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 13:35:49.967 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 13:37:49.935 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 13:39:49.280 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 13:41:49.927 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 13:43:50.068 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 13:45:49.939 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 13:47:49.993 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 13:49:50.018 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 13:51:50.153 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 13:52:11.181 LabApp] 302 GET /notebooks/avgn_paper/notebooks/6.0-neural-networks/ (::1) 1.45ms
[I 13:52:11.228 LabApp] 302 GET /notebooks/avgn_paper/notebooks/6.0-neural-networks (::1) 2.79ms
[W 13:52:12.089 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 4.60ms referer=http://localhost:8187/tree/avgn_paper/notebooks/6.0-neural-networks
[W 13:52:36.059 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.81ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 13:52:36.866 LabApp] Adapting from protocol version 5.1 (kernel 68fe739f-0fae-442f-860e-d943da609e51) to 5.3 (client).
[W 13:52:36.874 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 2.96ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 13:53:17.394 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 13:53:25.486 LabApp] Copying avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb to /avgn_paper/notebooks/6.0-neural-networks
[I 13:53:28.484 LabApp] Kernel started: 0c39b35c-0a9a-4144-881f-3228ff8cbcbe
[W 13:53:28.541 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.78ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-AE-Copy1.ipynb
[I 13:53:30.344 LabApp] Adapting from protocol version 5.1 (kernel 0c39b35c-0a9a-4144-881f-3228ff8cbcbe) to 5.3 (client).
[I 13:53:49.263 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 13:53:53.568 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 13:53:59.412 LabApp] Starting buffering for 778e73e2-db3f-47df-9c6f-d4384a6751b2:25e1b94c36384b47817a4917c3fec724
[I 13:54:02.863 LabApp] Kernel shutdown: 778e73e2-db3f-47df-9c6f-d4384a6751b2
[I 13:54:08.114 LabApp] Starting buffering for 0c39b35c-0a9a-4144-881f-3228ff8cbcbe:167b2e84e96445ea80e32b375da364df
[I 13:54:08.573 LabApp] Kernel restarted: 0c39b35c-0a9a-4144-881f-3228ff8cbcbe
[I 13:54:09.871 LabApp] Adapting from protocol version 5.1 (kernel 0c39b35c-0a9a-4144-881f-3228ff8cbcbe) to 5.3 (client).
[I 13:54:09.872 LabApp] Restoring connection for 0c39b35c-0a9a-4144-881f-3228ff8cbcbe:167b2e84e96445ea80e32b375da364df
[I 13:54:09.872 LabApp] Replaying 6 buffered messages
2019-10-27 13:54:21.195305: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-27 13:54:24.374521: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-27 13:54:24.402770: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 13:54:24.405980: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 13:54:24.408176: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 13:54:24.435054: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 13:54:24.437597: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 13:54:24.439668: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 13:54:24.444331: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 13:54:24.451124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 13:54:24.682177: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5609476f7390 executing computations on platform CUDA. Devices:
2019-10-27 13:54:24.682251: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-27 13:54:24.688028: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-27 13:54:24.689918: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5609477cddf0 executing computations on platform Host. Devices:
2019-10-27 13:54:24.689977: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-27 13:54:24.691943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-27 13:54:24.692079: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 13:54:24.692187: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 13:54:24.692282: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 13:54:24.692358: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 13:54:24.692430: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 13:54:24.692517: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 13:54:24.692601: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 13:54:24.696432: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 13:54:24.696556: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 13:54:24.700469: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-27 13:54:24.700514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-27 13:54:24.700537: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-27 13:54:24.704245: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-27 13:54:27.077782: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 13:54:27.311068: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 13:55:36.302 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE-128D.ipynb
[I 13:55:50.153 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 13:57:50.024 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 13:59:50.031 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 14:01:49.975 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 14:03:49.949 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 14:05:50.014 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 14:07:49.966 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 14:09:49.983 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 14:11:50.387 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 14:13:50.002 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 14:15:50.010 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 14:17:29.130 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE-128D.ipynb
[I 14:17:49.165 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 14:19:29.300 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE-128D.ipynb
[I 14:19:49.394 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 14:21:29.200 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE-128D.ipynb
[I 14:21:49.187 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 14:23:29.400 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE-128D.ipynb
[I 14:23:49.180 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 14:25:29.409 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE-128D.ipynb
[I 14:25:49.327 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 14:27:29.703 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE-128D.ipynb
[I 14:27:49.349 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 14:29:29.452 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE-128D.ipynb
[I 14:29:49.280 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 14:31:29.436 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE-128D.ipynb
[I 14:31:49.484 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 14:33:29.904 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE-128D.ipynb
[I 14:33:49.317 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 14:35:30.031 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE-128D.ipynb
[I 14:35:50.156 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 14:37:30.304 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE-128D.ipynb
[I 14:37:49.978 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 14:39:30.284 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE-128D.ipynb
[I 14:39:50.092 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 14:41:30.258 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE-128D.ipynb
[I 14:41:50.043 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 14:43:30.388 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE-128D.ipynb
[I 14:43:50.123 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 14:45:30.327 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE-128D.ipynb
[I 14:45:50.278 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 14:47:30.286 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE-128D.ipynb
[I 14:47:50.057 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 14:49:30.271 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE-128D.ipynb
[I 14:49:49.945 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 14:51:30.313 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE-128D.ipynb
[I 14:51:50.011 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 14:53:30.344 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE-128D.ipynb
[I 14:53:50.067 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 14:55:30.304 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE-128D.ipynb
[I 14:55:50.321 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 14:57:30.118 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE-128D.ipynb
[I 14:57:50.007 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 14:59:30.279 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE-128D.ipynb
[I 14:59:50.640 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 15:01:30.341 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE-128D.ipynb
[I 15:01:50.130 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 15:03:30.843 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE-128D.ipynb
[I 15:03:50.546 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 15:05:30.306 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE-128D.ipynb
[I 15:05:49.963 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 15:07:30.285 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE-128D.ipynb
[I 15:07:50.044 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 15:09:30.284 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE-128D.ipynb
[I 15:09:49.969 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 15:11:29.956 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE-128D.ipynb
[I 15:11:50.021 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 15:12:26.734 LabApp] Kernel interrupted: 0c39b35c-0a9a-4144-881f-3228ff8cbcbe
[I 15:12:53.442 LabApp] Starting buffering for 68fe739f-0fae-442f-860e-d943da609e51:14754875e5104556bbca4c08408eb324
[I 15:13:00.937 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE-128D.ipynb
[I 15:13:01.367 LabApp] Copying avgn_paper/notebooks/6.0-neural-networks/Starling-AE-128D.ipynb to /avgn_paper/notebooks/6.0-neural-networks
[W 15:13:03.534 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.45ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-AE-128D-Copy1.ipynb
[I 15:13:04.248 LabApp] Kernel started: e09c13c7-9b11-4b6e-9a21-32105e9e0c49
[W 15:13:04.327 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 4.20ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-AE-128D-Copy1.ipynb
[I 15:13:07.256 LabApp] Adapting from protocol version 5.1 (kernel e09c13c7-9b11-4b6e-9a21-32105e9e0c49) to 5.3 (client).
2019-10-27 15:13:32.626570: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-27 15:13:35.192666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-27 15:13:35.212905: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 15:13:35.218001: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 15:13:35.220638: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 15:13:35.240913: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 15:13:35.243217: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 15:13:35.244987: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 15:13:35.248920: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 15:13:35.251096: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 15:13:35.420027: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55991a66ae60 executing computations on platform CUDA. Devices:
2019-10-27 15:13:35.420081: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K40c, Compute Capability 3.5
2019-10-27 15:13:35.423786: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-27 15:13:35.425367: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55991a7418f0 executing computations on platform Host. Devices:
2019-10-27 15:13:35.425407: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-27 15:13:35.426543: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-27 15:13:35.426628: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 15:13:35.426675: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 15:13:35.426717: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 15:13:35.426761: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 15:13:35.426804: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 15:13:35.426848: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 15:13:35.426892: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 15:13:35.429556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 15:13:35.429766: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 15:13:35.432110: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-27 15:13:35.432133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-27 15:13:35.432145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-27 15:13:35.434597: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10794 MB memory) -> physical GPU (device: 0, name: Tesla K40c, pci bus id: 0000:03:00.0, compute capability: 3.5)
[I 15:13:49.242 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
2019-10-27 15:14:07.461734: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 15:14:07.650680: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 15:14:33.939 LabApp] Starting buffering for 0c39b35c-0a9a-4144-881f-3228ff8cbcbe:167b2e84e96445ea80e32b375da364df
[I 15:14:36.687 LabApp] Kernel shutdown: 0c39b35c-0a9a-4144-881f-3228ff8cbcbe
[W 15:14:37.325 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 2.88ms referer=http://localhost:8187/tree/avgn_paper/notebooks/6.0-neural-networks
[W 15:14:44.793 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 5.68ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 15:14:45.276 LabApp] Adapting from protocol version 5.1 (kernel 73df9972-e766-4753-b8c4-396d4d1c07fb) to 5.3 (client).
[W 15:14:45.316 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 2.76ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 15:14:48.946 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb
[I 15:14:49.301 LabApp] Copying avgn_paper/notebooks/6.0-neural-networks/Starling-VAE.ipynb to /avgn_paper/notebooks/6.0-neural-networks
[W 15:14:50.860 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.48ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-Copy1.ipynb
[I 15:14:51.268 LabApp] Kernel started: 6dc0982f-041c-4052-9374-74126cdac817
[W 15:14:51.315 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 2.96ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-Copy1.ipynb
[I 15:14:53.084 LabApp] Adapting from protocol version 5.1 (kernel 6dc0982f-041c-4052-9374-74126cdac817) to 5.3 (client).
[I 15:15:05.734 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE-128D-Copy1.ipynb
[I 15:15:30.792 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE-128D.ipynb
[I 15:15:38.190 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 15:15:48.788 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 15:16:02.792 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 15:16:05.091 LabApp] Starting buffering for 6dc0982f-041c-4052-9374-74126cdac817:19aaab18bb964444859096dbcd1fdc84
[I 15:16:05.565 LabApp] Kernel restarted: 6dc0982f-041c-4052-9374-74126cdac817
[I 15:16:07.383 LabApp] Adapting from protocol version 5.1 (kernel 6dc0982f-041c-4052-9374-74126cdac817) to 5.3 (client).
[I 15:16:07.384 LabApp] Restoring connection for 6dc0982f-041c-4052-9374-74126cdac817:19aaab18bb964444859096dbcd1fdc84
[I 15:16:07.384 LabApp] Replaying 6 buffered messages
2019-10-27 15:16:18.116652: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-27 15:16:18.652553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-27 15:16:18.653902: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 15:16:18.656863: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 15:16:18.659290: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 15:16:18.660290: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 15:16:18.663061: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 15:16:18.665318: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 15:16:18.670390: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 15:16:18.673194: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 15:16:18.927780: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b4e2965bd0 executing computations on platform CUDA. Devices:
2019-10-27 15:16:18.927865: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-27 15:16:18.934257: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-27 15:16:18.936499: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b4e2a3c660 executing computations on platform Host. Devices:
2019-10-27 15:16:18.936550: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-27 15:16:18.938096: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-27 15:16:18.938210: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 15:16:18.938279: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 15:16:18.938364: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 15:16:18.938429: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 15:16:18.938492: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 15:16:18.938557: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 15:16:18.938621: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 15:16:18.941366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 15:16:18.941473: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 15:16:18.944785: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-27 15:16:18.944820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-27 15:16:18.944839: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-27 15:16:18.948136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-27 15:16:25.576442: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 15:16:25.764138: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 15:16:51.322 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 15:17:49.228 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 15:18:51.516 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 15:19:49.308 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 15:20:52.632 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 15:21:49.527 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 15:22:51.538 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 15:23:49.218 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 15:24:51.511 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 15:25:49.253 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 15:26:51.508 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 15:27:49.243 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 15:28:52.149 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 15:29:49.233 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 15:30:51.726 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 15:31:50.046 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 15:32:52.604 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 15:33:50.063 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 15:34:52.607 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 15:35:50.047 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 15:36:51.648 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 15:37:50.067 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 15:38:51.584 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 15:39:50.006 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 15:40:51.586 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 15:41:50.148 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 15:42:51.594 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 15:43:50.106 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 15:44:51.583 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 15:45:50.127 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 15:46:52.693 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 15:47:50.072 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 15:48:52.567 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 15:49:50.050 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 15:50:52.462 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 15:51:50.097 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 15:52:52.604 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 15:53:50.491 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 15:54:51.596 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 15:55:50.004 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 15:56:51.611 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 15:57:50.074 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 15:58:51.600 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 15:59:49.628 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 16:00:51.579 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 16:01:50.098 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 16:02:51.595 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 16:03:49.992 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 16:04:51.603 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 16:05:50.004 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 16:06:51.861 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 16:07:50.042 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 16:08:52.374 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 16:09:49.036 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 16:10:51.761 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 16:11:50.082 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 16:12:52.327 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 16:13:50.044 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 16:14:52.438 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 16:15:50.083 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 16:16:52.360 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 16:17:50.061 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 16:18:52.482 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 16:19:50.223 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 16:20:51.597 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 16:21:50.126 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 16:22:51.589 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 16:23:50.038 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 16:24:51.590 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 16:25:50.024 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 16:26:51.605 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 16:27:50.157 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 16:28:51.791 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 16:29:50.033 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 16:30:51.610 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 16:31:50.098 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 16:32:51.681 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 16:33:50.030 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 16:34:51.833 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 16:35:50.231 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 16:36:51.659 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 16:37:46.309 LabApp] Kernel interrupted: 6dc0982f-041c-4052-9374-74126cdac817
[I 16:37:49.414 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 16:37:56.123 LabApp] 302 GET /notebooks/avgn_paper/notebooks/6.0-neural-networks (::1) 3.50ms
[W 16:37:56.781 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 2.76ms referer=http://localhost:8187/tree/avgn_paper/notebooks/6.0-neural-networks
[I 16:38:07.611 LabApp] Kernel started: 554d832d-f579-4e1b-8f2a-a7de5a1f2453
[W 16:38:07.655 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 2.46ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[W 16:38:08.584 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 1.80ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 16:38:09.058 LabApp] Adapting from protocol version 5.1 (kernel 554d832d-f579-4e1b-8f2a-a7de5a1f2453) to 5.3 (client).
[I 16:38:15.520 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 16:38:15.959 LabApp] Copying avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb to /avgn_paper/notebooks/6.0-neural-networks
[W 16:38:17.607 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.56ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN-Copy1.ipynb
[I 16:38:18.312 LabApp] Kernel started: 3d086e4a-bb0d-43d4-87dd-f43fbf948635
[W 16:38:18.415 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 3.28ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN-Copy1.ipynb
[I 16:38:19.396 LabApp] Adapting from protocol version 5.1 (kernel 3d086e4a-bb0d-43d4-87dd-f43fbf948635) to 5.3 (client).
[I 16:38:20.737 LabApp] Starting buffering for 6dc0982f-041c-4052-9374-74126cdac817:19aaab18bb964444859096dbcd1fdc84
[I 16:38:23.295 LabApp] Kernel shutdown: 6dc0982f-041c-4052-9374-74126cdac817
[I 16:38:51.586 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 16:39:44.988 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAEGAN-Copy1.ipynb
[I 16:39:50.411 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 16:39:56.554 LabApp] Starting buffering for 3d086e4a-bb0d-43d4-87dd-f43fbf948635:f88c723b70434b179a741ff8aa7eaab4
[I 16:39:57.022 LabApp] Kernel restarted: 3d086e4a-bb0d-43d4-87dd-f43fbf948635
[I 16:39:58.717 LabApp] Adapting from protocol version 5.1 (kernel 3d086e4a-bb0d-43d4-87dd-f43fbf948635) to 5.3 (client).
[I 16:39:58.719 LabApp] Restoring connection for 3d086e4a-bb0d-43d4-87dd-f43fbf948635:f88c723b70434b179a741ff8aa7eaab4
[I 16:39:58.719 LabApp] Replaying 6 buffered messages
2019-10-27 16:40:11.753184: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-27 16:40:12.275289: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-27 16:40:12.276321: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 16:40:12.279676: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 16:40:12.282561: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 16:40:12.283650: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 16:40:12.287363: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 16:40:12.290228: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 16:40:12.297080: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 16:40:12.300275: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 16:40:12.578629: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e230929090 executing computations on platform CUDA. Devices:
2019-10-27 16:40:12.578726: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-27 16:40:12.585094: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-27 16:40:12.587353: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e2309ffb50 executing computations on platform Host. Devices:
2019-10-27 16:40:12.587422: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-27 16:40:12.589207: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-27 16:40:12.589344: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 16:40:12.589426: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 16:40:12.589503: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 16:40:12.589580: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 16:40:12.589680: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 16:40:12.589759: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 16:40:12.589837: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 16:40:12.592756: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 16:40:12.592870: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 16:40:12.596361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-27 16:40:12.596400: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-27 16:40:12.596420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-27 16:40:12.599949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
[I 16:40:18.761 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAEGAN-128.ipynb
2019-10-27 16:40:24.947534: W tensorflow/core/common_runtime/bfc_allocator.cc:314] Allocator (GPU_0_bfc) ran out of memory trying to allocate 7.88GiB (rounded to 8456241152).  Current allocation summary follows.
2019-10-27 16:40:24.947635: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (256): 	Total Chunks: 5, Chunks in use: 5. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 772B client-requested in use in bin.
2019-10-27 16:40:24.947679: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (512): 	Total Chunks: 2, Chunks in use: 2. 1.0KiB allocated for chunks. 1.0KiB in use in bin. 1.0KiB client-requested in use in bin.
2019-10-27 16:40:24.947707: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (1024): 	Total Chunks: 7, Chunks in use: 7. 8.8KiB allocated for chunks. 8.8KiB in use in bin. 7.3KiB client-requested in use in bin.
2019-10-27 16:40:24.947731: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (2048): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 16:40:24.947754: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (4096): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 16:40:24.947776: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (8192): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 16:40:24.947799: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (16384): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 16:40:24.947821: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (32768): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 16:40:24.947850: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (65536): 	Total Chunks: 3, Chunks in use: 2. 216.0KiB allocated for chunks. 144.0KiB in use in bin. 144.0KiB client-requested in use in bin.
2019-10-27 16:40:24.947877: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (131072): 	Total Chunks: 1, Chunks in use: 0. 138.2KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 16:40:24.947906: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (262144): 	Total Chunks: 4, Chunks in use: 2. 1.27MiB allocated for chunks. 576.0KiB in use in bin. 576.0KiB client-requested in use in bin.
2019-10-27 16:40:24.947929: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (524288): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 16:40:24.947972: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (1048576): 	Total Chunks: 4, Chunks in use: 2. 5.06MiB allocated for chunks. 2.25MiB in use in bin. 2.25MiB client-requested in use in bin.
2019-10-27 16:40:24.947999: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (2097152): 	Total Chunks: 2, Chunks in use: 2. 4.50MiB allocated for chunks. 4.50MiB in use in bin. 4.50MiB client-requested in use in bin.
2019-10-27 16:40:24.948022: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 16:40:24.948045: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (8388608): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 16:40:24.948068: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 16:40:24.948090: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (33554432): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 16:40:24.948115: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (67108864): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 16:40:24.948137: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 16:40:24.948164: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (268435456): 	Total Chunks: 2, Chunks in use: 1. 11.15GiB allocated for chunks. 7.88GiB in use in bin. 7.88GiB client-requested in use in bin.
2019-10-27 16:40:24.948188: I tensorflow/core/common_runtime/bfc_allocator.cc:780] Bin for 7.88GiB was 256.00MiB, Chunk State: 
2019-10-27 16:40:24.948222: I tensorflow/core/common_runtime/bfc_allocator.cc:786]   Size: 3.27GiB | Requested Size: 0B | in_use: 0 | bin_num: 20, prev:   Size: 7.88GiB | Requested Size: 7.88GiB | in_use: 1 | bin_num: -1
2019-10-27 16:40:24.948243: I tensorflow/core/common_runtime/bfc_allocator.cc:793] Next region of size 11981409280
2019-10-27 16:40:24.948267: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f64ec000000 next 1 of size 1280
2019-10-27 16:40:24.948288: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f64ec000500 next 2 of size 256
2019-10-27 16:40:24.948307: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f64ec000600 next 3 of size 256
2019-10-27 16:40:24.948326: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f64ec000700 next 6 of size 256
2019-10-27 16:40:24.948346: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f64ec000800 next 9 of size 512
2019-10-27 16:40:24.948366: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f64ec000a00 next 4 of size 1536
2019-10-27 16:40:24.948385: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f64ec001000 next 5 of size 1280
2019-10-27 16:40:24.948404: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f64ec001500 next 16 of size 1024
2019-10-27 16:40:24.948423: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f64ec001900 next 18 of size 1024
2019-10-27 16:40:24.948442: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f64ec001d00 next 19 of size 256
2019-10-27 16:40:24.948460: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f64ec001e00 next 24 of size 256
2019-10-27 16:40:24.948479: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f64ec001f00 next 27 of size 512
2019-10-27 16:40:24.948498: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f64ec002100 next 20 of size 1536
2019-10-27 16:40:24.948525: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f64ec002700 next 21 of size 1280
2019-10-27 16:40:24.948546: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f64ec002c00 next 7 of size 141568
2019-10-27 16:40:24.948566: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f64ec025500 next 8 of size 73728
2019-10-27 16:40:24.948584: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f64ec037500 next 22 of size 73728
2019-10-27 16:40:24.948604: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f64ec049500 next 23 of size 73728
2019-10-27 16:40:24.948623: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f64ec05b500 next 10 of size 442368
2019-10-27 16:40:24.948642: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f64ec0c7500 next 11 of size 294912
2019-10-27 16:40:24.948662: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f64ec10f500 next 25 of size 294912
2019-10-27 16:40:24.948681: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f64ec157500 next 26 of size 294912
2019-10-27 16:40:24.948700: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f64ec19f500 next 13 of size 1769472
2019-10-27 16:40:24.948720: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f64ec34f500 next 14 of size 1179648
2019-10-27 16:40:24.948739: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f64ec46f500 next 28 of size 1179648
2019-10-27 16:40:24.948758: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f64ec58f500 next 12 of size 1179648
2019-10-27 16:40:24.948778: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f64ec6af500 next 15 of size 2359296
2019-10-27 16:40:24.948797: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f64ec8ef500 next 17 of size 2359296
2019-10-27 16:40:24.948817: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f64ecb2f500 next 29 of size 8456241152
2019-10-27 16:40:24.948837: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f66e4baf500 next 18446744073709551615 of size 3513440000
2019-10-27 16:40:24.948855: I tensorflow/core/common_runtime/bfc_allocator.cc:809]      Summary of in-use Chunks by size: 
2019-10-27 16:40:24.948880: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 5 Chunks of size 256 totalling 1.2KiB
2019-10-27 16:40:24.948903: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 512 totalling 1.0KiB
2019-10-27 16:40:24.948925: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 1024 totalling 2.0KiB
2019-10-27 16:40:24.948947: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 3 Chunks of size 1280 totalling 3.8KiB
2019-10-27 16:40:24.948969: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 1536 totalling 3.0KiB
2019-10-27 16:40:24.948992: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 73728 totalling 144.0KiB
2019-10-27 16:40:24.949015: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 294912 totalling 576.0KiB
2019-10-27 16:40:24.949037: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 1179648 totalling 2.25MiB
2019-10-27 16:40:24.949059: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 2359296 totalling 4.50MiB
2019-10-27 16:40:24.949081: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 8456241152 totalling 7.88GiB
2019-10-27 16:40:24.949103: I tensorflow/core/common_runtime/bfc_allocator.cc:816] Sum Total of in-use chunks: 7.88GiB
2019-10-27 16:40:24.949123: I tensorflow/core/common_runtime/bfc_allocator.cc:818] total_region_allocated_bytes_: 11981409280 memory_limit_: 11981409485 available bytes: 205 curr_region_allocation_bytes_: 23962819072
2019-10-27 16:40:24.949151: I tensorflow/core/common_runtime/bfc_allocator.cc:824] Stats: 
Limit:                 11981409485
InUse:                  8464067584
MaxInUse:               8464067840
NumAllocs:                     104
MaxAllocSize:           8456241152

2019-10-27 16:40:24.949192: W tensorflow/core/common_runtime/bfc_allocator.cc:319] ***********************************************************************_____________________________
2019-10-27 16:40:24.949261: W tensorflow/core/framework/op_kernel.cc:1546] OP_REQUIRES failed at cwise_ops_common.cc:70 : Resource exhausted: OOM when allocating tensor with shape[4129024,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
[W 16:42:20.270 LabApp] WebSocket ping timeout after 119978 ms.
[W 16:42:20.412 LabApp] WebSocket ping timeout after 119979 ms.
[W 16:42:20.493 LabApp] WebSocket ping timeout after 119978 ms.
[W 16:42:20.566 LabApp] WebSocket ping timeout after 119978 ms.
[W 16:42:21.996 LabApp] WebSocket ping timeout after 119977 ms.
[W 16:42:22.032 LabApp] zmq message arrived on closed channel
[W 16:42:22.034 LabApp] zmq message arrived on closed channel
[W 16:42:22.434 LabApp] zmq message arrived on closed channel
[W 16:42:22.437 LabApp] zmq message arrived on closed channel
[W 16:42:22.837 LabApp] zmq message arrived on closed channel
[W 16:42:22.839 LabApp] zmq message arrived on closed channel
[W 16:42:23.241 LabApp] zmq message arrived on closed channel
[W 16:42:23.242 LabApp] zmq message arrived on closed channel
[W 16:42:23.645 LabApp] zmq message arrived on closed channel
[W 16:42:23.646 LabApp] zmq message arrived on closed channel
[W 16:42:24.050 LabApp] zmq message arrived on closed channel
[W 16:42:24.053 LabApp] zmq message arrived on closed channel
[W 16:42:24.455 LabApp] zmq message arrived on closed channel
[W 16:42:24.457 LabApp] zmq message arrived on closed channel
[W 16:42:24.859 LabApp] zmq message arrived on closed channel
[W 16:42:24.861 LabApp] zmq message arrived on closed channel
[W 16:42:25.260 LabApp] zmq message arrived on closed channel
[W 16:42:25.262 LabApp] zmq message arrived on closed channel
[I 16:42:25.273 LabApp] Starting buffering for 00cb76cf-9ff9-45d7-bf9b-ca5e71a3b40a:c4a763956ede491c98b574600c86bac1
[I 16:42:25.413 LabApp] Starting buffering for e4f39541-c636-4e93-9820-1a4ae1520340:98fb7f0da09145ed8c6fe2c7d020decf
[I 16:42:25.495 LabApp] Starting buffering for 11777ca9-05bd-4ea4-bc65-bd1bf70a0360:07552191011d4f5a8da9f495dae8b7a8
[I 16:42:25.569 LabApp] Starting buffering for d849356d-faa3-448d-b20c-12997f49ba94:dcf4d8f8f5d64133930dbf8089bec6a7
[W 16:42:25.659 LabApp] zmq message arrived on closed channel
[W 16:42:25.660 LabApp] zmq message arrived on closed channel
[W 16:42:26.061 LabApp] zmq message arrived on closed channel
[W 16:42:26.062 LabApp] zmq message arrived on closed channel
[W 16:42:26.467 LabApp] zmq message arrived on closed channel
[W 16:42:26.470 LabApp] zmq message arrived on closed channel
[W 16:42:26.869 LabApp] zmq message arrived on closed channel
[W 16:42:26.872 LabApp] zmq message arrived on closed channel
[I 16:42:26.997 LabApp] Starting buffering for 8a176c6a-8996-42d7-bccc-a9d6303bb7c0:f6f50c1de9b147b18b2cce0931313a25
[W 16:42:28.719 LabApp] WebSocket ping timeout after 119979 ms.
[I 16:42:33.721 LabApp] Starting buffering for 3d086e4a-bb0d-43d4-87dd-f43fbf948635:f88c723b70434b179a741ff8aa7eaab4
[W 16:42:37.258 LabApp] WebSocket ping timeout after 119787 ms.
[W 16:42:39.060 LabApp] WebSocket ping timeout after 119933 ms.
[I 16:42:42.260 LabApp] Starting buffering for e09c13c7-9b11-4b6e-9a21-32105e9e0c49:6a7bbef3cfe040798338339cd1a2ef92
[I 16:42:44.062 LabApp] Starting buffering for 554d832d-f579-4e1b-8f2a-a7de5a1f2453:e245557343e8484e8222f4681c7667f1
[W 16:42:45.278 LabApp] WebSocket ping timeout after 119980 ms.
[I 16:42:50.280 LabApp] Starting buffering for 73df9972-e766-4753-b8c4-396d4d1c07fb:4084dbd3498240c38f6f16ff0866286c
[I 22:22:55.148 LabApp] KernelRestarter: restarting kernel (1/5), keep random ports
[I 22:22:57.023 LabApp] KernelRestarter: restarting kernel (1/5), keep random ports
[I 22:23:18.717 LabApp] Adapting from protocol version 5.1 (kernel 3d086e4a-bb0d-43d4-87dd-f43fbf948635) to 5.3 (client).
[I 22:23:18.719 LabApp] Restoring connection for 3d086e4a-bb0d-43d4-87dd-f43fbf948635:f88c723b70434b179a741ff8aa7eaab4
[I 22:23:18.720 LabApp] Replaying 1 buffered messages
[I 22:23:21.711 LabApp] Starting buffering for 3d086e4a-bb0d-43d4-87dd-f43fbf948635:f88c723b70434b179a741ff8aa7eaab4
[I 22:23:22.203 LabApp] Kernel restarted: 3d086e4a-bb0d-43d4-87dd-f43fbf948635
[I 22:23:25.294 LabApp] Adapting from protocol version 5.1 (kernel 3d086e4a-bb0d-43d4-87dd-f43fbf948635) to 5.3 (client).
[I 22:23:25.296 LabApp] Restoring connection for 3d086e4a-bb0d-43d4-87dd-f43fbf948635:f88c723b70434b179a741ff8aa7eaab4
[I 22:23:25.296 LabApp] Replaying 6 buffered messages
[I 22:23:31.238 LabApp] 302 GET /notebooks/avgn_paper/notebooks/6.0-neural-networks/ (::1) 0.70ms
[I 22:23:31.267 LabApp] 302 GET /notebooks/avgn_paper/notebooks/6.0-neural-networks (::1) 1.56ms
[W 22:23:32.015 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 1.85ms referer=http://localhost:8187/tree/avgn_paper/notebooks/6.0-neural-networks
2019-10-27 22:23:37.847494: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-27 22:23:38.889365: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-27 22:23:38.890419: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 22:23:38.892520: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 22:23:38.894277: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 22:23:38.894957: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 22:23:38.896983: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 22:23:38.898692: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 22:23:38.902484: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 22:23:38.906846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 22:23:39.111356: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560059fb2c00 executing computations on platform CUDA. Devices:
2019-10-27 22:23:39.111468: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-27 22:23:39.117612: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-27 22:23:39.119957: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56005a089690 executing computations on platform Host. Devices:
2019-10-27 22:23:39.120009: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-27 22:23:39.120983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-27 22:23:39.121077: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 22:23:39.121121: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 22:23:39.121164: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 22:23:39.121207: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 22:23:39.121260: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 22:23:39.121304: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 22:23:39.121347: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 22:23:39.124409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 22:23:39.124486: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 22:23:39.126487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-27 22:23:39.126508: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-27 22:23:39.126519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-27 22:23:39.129087: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-27 22:23:51.572312: W tensorflow/core/common_runtime/bfc_allocator.cc:314] Allocator (GPU_0_bfc) ran out of memory trying to allocate 7.88GiB (rounded to 8456241152).  Current allocation summary follows.
2019-10-27 22:23:51.572461: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (256): 	Total Chunks: 5, Chunks in use: 5. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 772B client-requested in use in bin.
2019-10-27 22:23:51.572508: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (512): 	Total Chunks: 2, Chunks in use: 2. 1.0KiB allocated for chunks. 1.0KiB in use in bin. 1.0KiB client-requested in use in bin.
2019-10-27 22:23:51.572539: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (1024): 	Total Chunks: 7, Chunks in use: 7. 8.8KiB allocated for chunks. 8.8KiB in use in bin. 7.3KiB client-requested in use in bin.
2019-10-27 22:23:51.572563: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (2048): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:23:51.572587: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (4096): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:23:51.572610: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (8192): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:23:51.572633: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (16384): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:23:51.572656: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (32768): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:23:51.572687: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (65536): 	Total Chunks: 3, Chunks in use: 2. 216.0KiB allocated for chunks. 144.0KiB in use in bin. 144.0KiB client-requested in use in bin.
2019-10-27 22:23:51.572714: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (131072): 	Total Chunks: 1, Chunks in use: 0. 138.2KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:23:51.572742: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (262144): 	Total Chunks: 4, Chunks in use: 2. 1.27MiB allocated for chunks. 576.0KiB in use in bin. 576.0KiB client-requested in use in bin.
2019-10-27 22:23:51.572766: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (524288): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:23:51.572808: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (1048576): 	Total Chunks: 4, Chunks in use: 2. 5.06MiB allocated for chunks. 2.25MiB in use in bin. 2.25MiB client-requested in use in bin.
2019-10-27 22:23:51.572835: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (2097152): 	Total Chunks: 2, Chunks in use: 2. 4.50MiB allocated for chunks. 4.50MiB in use in bin. 4.50MiB client-requested in use in bin.
2019-10-27 22:23:51.572859: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:23:51.572882: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (8388608): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:23:51.572904: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:23:51.572927: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (33554432): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:23:51.572950: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (67108864): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:23:51.572972: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:23:51.572998: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (268435456): 	Total Chunks: 2, Chunks in use: 1. 11.15GiB allocated for chunks. 7.88GiB in use in bin. 7.88GiB client-requested in use in bin.
2019-10-27 22:23:51.573023: I tensorflow/core/common_runtime/bfc_allocator.cc:780] Bin for 7.88GiB was 256.00MiB, Chunk State: 
2019-10-27 22:23:51.573055: I tensorflow/core/common_runtime/bfc_allocator.cc:786]   Size: 3.27GiB | Requested Size: 0B | in_use: 0 | bin_num: 20, prev:   Size: 7.88GiB | Requested Size: 7.88GiB | in_use: 1 | bin_num: -1
2019-10-27 22:23:51.573078: I tensorflow/core/common_runtime/bfc_allocator.cc:793] Next region of size 11981409280
2019-10-27 22:23:51.573100: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8110000000 next 1 of size 1280
2019-10-27 22:23:51.573121: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8110000500 next 2 of size 256
2019-10-27 22:23:51.573140: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8110000600 next 3 of size 256
2019-10-27 22:23:51.573159: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8110000700 next 6 of size 256
2019-10-27 22:23:51.573179: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8110000800 next 9 of size 512
2019-10-27 22:23:51.573199: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8110000a00 next 4 of size 1536
2019-10-27 22:23:51.573218: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8110001000 next 5 of size 1280
2019-10-27 22:23:51.573238: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8110001500 next 16 of size 1024
2019-10-27 22:23:51.573257: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8110001900 next 18 of size 1024
2019-10-27 22:23:51.573276: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8110001d00 next 19 of size 256
2019-10-27 22:23:51.573295: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8110001e00 next 24 of size 256
2019-10-27 22:23:51.573314: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8110001f00 next 27 of size 512
2019-10-27 22:23:51.573333: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8110002100 next 20 of size 1536
2019-10-27 22:23:51.573361: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8110002700 next 21 of size 1280
2019-10-27 22:23:51.573382: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f8110002c00 next 7 of size 141568
2019-10-27 22:23:51.573403: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8110025500 next 8 of size 73728
2019-10-27 22:23:51.573421: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f8110037500 next 22 of size 73728
2019-10-27 22:23:51.573440: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8110049500 next 23 of size 73728
2019-10-27 22:23:51.573459: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f811005b500 next 10 of size 442368
2019-10-27 22:23:51.573479: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f81100c7500 next 11 of size 294912
2019-10-27 22:23:51.573498: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f811010f500 next 25 of size 294912
2019-10-27 22:23:51.573517: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8110157500 next 26 of size 294912
2019-10-27 22:23:51.573545: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f811019f500 next 13 of size 1769472
2019-10-27 22:23:51.573600: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f811034f500 next 14 of size 1179648
2019-10-27 22:23:51.573638: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f811046f500 next 28 of size 1179648
2019-10-27 22:23:51.573674: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f811058f500 next 12 of size 1179648
2019-10-27 22:23:51.573699: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f81106af500 next 15 of size 2359296
2019-10-27 22:23:51.573717: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f81108ef500 next 17 of size 2359296
2019-10-27 22:23:51.573735: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8110b2f500 next 29 of size 8456241152
2019-10-27 22:23:51.573754: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f8308baf500 next 18446744073709551615 of size 3513440000
2019-10-27 22:23:51.573771: I tensorflow/core/common_runtime/bfc_allocator.cc:809]      Summary of in-use Chunks by size: 
2019-10-27 22:23:51.573794: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 5 Chunks of size 256 totalling 1.2KiB
2019-10-27 22:23:51.573816: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 512 totalling 1.0KiB
2019-10-27 22:23:51.573836: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 1024 totalling 2.0KiB
2019-10-27 22:23:51.573856: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 3 Chunks of size 1280 totalling 3.8KiB
2019-10-27 22:23:51.573877: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 1536 totalling 3.0KiB
2019-10-27 22:23:51.573898: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 73728 totalling 144.0KiB
2019-10-27 22:23:51.573920: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 294912 totalling 576.0KiB
2019-10-27 22:23:51.573941: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 1179648 totalling 2.25MiB
2019-10-27 22:23:51.573961: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 2359296 totalling 4.50MiB
2019-10-27 22:23:51.573981: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 8456241152 totalling 7.88GiB
2019-10-27 22:23:51.574001: I tensorflow/core/common_runtime/bfc_allocator.cc:816] Sum Total of in-use chunks: 7.88GiB
2019-10-27 22:23:51.574020: I tensorflow/core/common_runtime/bfc_allocator.cc:818] total_region_allocated_bytes_: 11981409280 memory_limit_: 11981409485 available bytes: 205 curr_region_allocation_bytes_: 23962819072
2019-10-27 22:23:51.574044: I tensorflow/core/common_runtime/bfc_allocator.cc:824] Stats: 
Limit:                 11981409485
InUse:                  8464067584
MaxInUse:               8464067840
NumAllocs:                     104
MaxAllocSize:           8456241152

2019-10-27 22:23:51.574080: W tensorflow/core/common_runtime/bfc_allocator.cc:319] ***********************************************************************_____________________________
2019-10-27 22:23:51.574141: W tensorflow/core/framework/op_kernel.cc:1546] OP_REQUIRES failed at cwise_ops_common.cc:70 : Resource exhausted: OOM when allocating tensor with shape[4129024,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
[I 22:24:27.333 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAEGAN-128.ipynb
[I 22:24:34.929 LabApp] Starting buffering for 3d086e4a-bb0d-43d4-87dd-f43fbf948635:f88c723b70434b179a741ff8aa7eaab4
[I 22:24:37.289 LabApp] Kernel restarted: 3d086e4a-bb0d-43d4-87dd-f43fbf948635
[I 22:24:41.989 LabApp] Adapting from protocol version 5.1 (kernel 3d086e4a-bb0d-43d4-87dd-f43fbf948635) to 5.3 (client).
[I 22:24:41.991 LabApp] Restoring connection for 3d086e4a-bb0d-43d4-87dd-f43fbf948635:f88c723b70434b179a741ff8aa7eaab4
[I 22:24:41.991 LabApp] Replaying 6 buffered messages
2019-10-27 22:24:51.207864: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-27 22:24:52.277537: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-27 22:24:52.278715: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 22:24:52.281899: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 22:24:52.284261: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 22:24:52.285276: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 22:24:52.288340: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 22:24:52.290935: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 22:24:52.296367: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 22:24:52.298845: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 22:24:52.534295: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a4a884cec0 executing computations on platform CUDA. Devices:
2019-10-27 22:24:52.534380: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-27 22:24:52.539652: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-27 22:24:52.541479: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a4a8923950 executing computations on platform Host. Devices:
2019-10-27 22:24:52.541542: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-27 22:24:52.543063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-27 22:24:52.543221: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 22:24:52.543297: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 22:24:52.543366: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 22:24:52.543433: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 22:24:52.543517: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 22:24:52.543588: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 22:24:52.543655: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 22:24:52.546088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 22:24:52.546210: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 22:24:52.549240: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-27 22:24:52.549272: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-27 22:24:52.549288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-27 22:24:52.552147: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
[I 22:24:58.524 LabApp] Kernel started: 2a99eb03-fb60-4105-af1a-53d06da9dfd1
[W 22:24:58.576 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 2.86ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[W 22:24:59.340 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 5.00ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 22:24:59.630 LabApp] Adapting from protocol version 5.1 (kernel 2a99eb03-fb60-4105-af1a-53d06da9dfd1) to 5.3 (client).
2019-10-27 22:25:04.691205: W tensorflow/core/common_runtime/bfc_allocator.cc:314] Allocator (GPU_0_bfc) ran out of memory trying to allocate 7.88GiB (rounded to 8456241152).  Current allocation summary follows.
2019-10-27 22:25:04.691327: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (256): 	Total Chunks: 5, Chunks in use: 5. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 772B client-requested in use in bin.
2019-10-27 22:25:04.691373: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (512): 	Total Chunks: 2, Chunks in use: 2. 1.0KiB allocated for chunks. 1.0KiB in use in bin. 1.0KiB client-requested in use in bin.
2019-10-27 22:25:04.691427: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (1024): 	Total Chunks: 7, Chunks in use: 7. 8.8KiB allocated for chunks. 8.8KiB in use in bin. 7.3KiB client-requested in use in bin.
2019-10-27 22:25:04.691473: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (2048): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:25:04.691500: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (4096): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:25:04.691526: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (8192): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:25:04.691569: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (16384): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:25:04.691613: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (32768): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:25:04.691671: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (65536): 	Total Chunks: 3, Chunks in use: 2. 216.0KiB allocated for chunks. 144.0KiB in use in bin. 144.0KiB client-requested in use in bin.
2019-10-27 22:25:04.691726: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (131072): 	Total Chunks: 1, Chunks in use: 0. 138.2KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:25:04.691756: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (262144): 	Total Chunks: 4, Chunks in use: 2. 1.27MiB allocated for chunks. 576.0KiB in use in bin. 576.0KiB client-requested in use in bin.
2019-10-27 22:25:04.691778: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (524288): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:25:04.691802: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (1048576): 	Total Chunks: 4, Chunks in use: 2. 5.06MiB allocated for chunks. 2.25MiB in use in bin. 2.25MiB client-requested in use in bin.
2019-10-27 22:25:04.691826: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (2097152): 	Total Chunks: 2, Chunks in use: 2. 4.50MiB allocated for chunks. 4.50MiB in use in bin. 4.50MiB client-requested in use in bin.
2019-10-27 22:25:04.691848: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:25:04.691869: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (8388608): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:25:04.691891: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:25:04.691912: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (33554432): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:25:04.691933: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (67108864): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:25:04.691955: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:25:04.691979: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (268435456): 	Total Chunks: 2, Chunks in use: 1. 11.15GiB allocated for chunks. 7.88GiB in use in bin. 7.88GiB client-requested in use in bin.
2019-10-27 22:25:04.692003: I tensorflow/core/common_runtime/bfc_allocator.cc:780] Bin for 7.88GiB was 256.00MiB, Chunk State: 
2019-10-27 22:25:04.692037: I tensorflow/core/common_runtime/bfc_allocator.cc:786]   Size: 3.27GiB | Requested Size: 0B | in_use: 0 | bin_num: 20, prev:   Size: 7.88GiB | Requested Size: 7.88GiB | in_use: 1 | bin_num: -1
2019-10-27 22:25:04.692059: I tensorflow/core/common_runtime/bfc_allocator.cc:793] Next region of size 11981409280
2019-10-27 22:25:04.692082: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7faeb4000000 next 1 of size 1280
2019-10-27 22:25:04.692102: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7faeb4000500 next 2 of size 256
2019-10-27 22:25:04.692119: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7faeb4000600 next 3 of size 256
2019-10-27 22:25:04.692137: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7faeb4000700 next 6 of size 256
2019-10-27 22:25:04.692157: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7faeb4000800 next 9 of size 512
2019-10-27 22:25:04.692176: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7faeb4000a00 next 4 of size 1536
2019-10-27 22:25:04.692194: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7faeb4001000 next 5 of size 1280
2019-10-27 22:25:04.692213: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7faeb4001500 next 16 of size 1024
2019-10-27 22:25:04.692240: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7faeb4001900 next 18 of size 1024
2019-10-27 22:25:04.692260: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7faeb4001d00 next 19 of size 256
2019-10-27 22:25:04.692278: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7faeb4001e00 next 24 of size 256
2019-10-27 22:25:04.692295: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7faeb4001f00 next 27 of size 512
2019-10-27 22:25:04.692313: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7faeb4002100 next 20 of size 1536
2019-10-27 22:25:04.692332: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7faeb4002700 next 21 of size 1280
2019-10-27 22:25:04.692350: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7faeb4002c00 next 7 of size 141568
2019-10-27 22:25:04.692369: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7faeb4025500 next 8 of size 73728
2019-10-27 22:25:04.692387: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7faeb4037500 next 22 of size 73728
2019-10-27 22:25:04.692405: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7faeb4049500 next 23 of size 73728
2019-10-27 22:25:04.692423: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7faeb405b500 next 10 of size 442368
2019-10-27 22:25:04.692442: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7faeb40c7500 next 11 of size 294912
2019-10-27 22:25:04.692460: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7faeb410f500 next 25 of size 294912
2019-10-27 22:25:04.692479: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7faeb4157500 next 26 of size 294912
2019-10-27 22:25:04.692497: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7faeb419f500 next 13 of size 1769472
2019-10-27 22:25:04.692515: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7faeb434f500 next 14 of size 1179648
2019-10-27 22:25:04.692533: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7faeb446f500 next 28 of size 1179648
2019-10-27 22:25:04.692552: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7faeb458f500 next 12 of size 1179648
2019-10-27 22:25:04.692570: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7faeb46af500 next 15 of size 2359296
2019-10-27 22:25:04.692589: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7faeb48ef500 next 17 of size 2359296
2019-10-27 22:25:04.692607: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7faeb4b2f500 next 29 of size 8456241152
2019-10-27 22:25:04.692626: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7fb0acbaf500 next 18446744073709551615 of size 3513440000
2019-10-27 22:25:04.692643: I tensorflow/core/common_runtime/bfc_allocator.cc:809]      Summary of in-use Chunks by size: 
2019-10-27 22:25:04.692665: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 5 Chunks of size 256 totalling 1.2KiB
2019-10-27 22:25:04.692687: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 512 totalling 1.0KiB
2019-10-27 22:25:04.692707: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 1024 totalling 2.0KiB
2019-10-27 22:25:04.692726: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 3 Chunks of size 1280 totalling 3.8KiB
2019-10-27 22:25:04.692746: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 1536 totalling 3.0KiB
2019-10-27 22:25:04.692767: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 73728 totalling 144.0KiB
2019-10-27 22:25:04.692788: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 294912 totalling 576.0KiB
2019-10-27 22:25:04.692808: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 1179648 totalling 2.25MiB
2019-10-27 22:25:04.692828: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 2359296 totalling 4.50MiB
2019-10-27 22:25:04.692859: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 8456241152 totalling 7.88GiB
2019-10-27 22:25:04.692880: I tensorflow/core/common_runtime/bfc_allocator.cc:816] Sum Total of in-use chunks: 7.88GiB
2019-10-27 22:25:04.692899: I tensorflow/core/common_runtime/bfc_allocator.cc:818] total_region_allocated_bytes_: 11981409280 memory_limit_: 11981409485 available bytes: 205 curr_region_allocation_bytes_: 23962819072
2019-10-27 22:25:04.692925: I tensorflow/core/common_runtime/bfc_allocator.cc:824] Stats: 
Limit:                 11981409485
InUse:                  8464067584
MaxInUse:               8464067840
NumAllocs:                     104
MaxAllocSize:           8456241152

2019-10-27 22:25:04.692950: W tensorflow/core/common_runtime/bfc_allocator.cc:319] ***********************************************************************_____________________________
2019-10-27 22:25:04.693019: W tensorflow/core/framework/op_kernel.cc:1546] OP_REQUIRES failed at cwise_ops_common.cc:70 : Resource exhausted: OOM when allocating tensor with shape[4129024,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
[I 22:25:16.571 LabApp] 302 GET /notebooks/avgn_paper/notebooks/ (::1) 1.02ms
[I 22:25:16.604 LabApp] 302 GET /notebooks/avgn_paper/notebooks (::1) 2.29ms
[I 22:25:18.806 LabApp] 302 GET /notebooks/avgn_paper/data (::1) 2.09ms
[W 22:25:19.408 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 3.40ms referer=http://localhost:8187/tree/avgn_paper/data
[I 22:25:36.854 LabApp] Starting buffering for 2a99eb03-fb60-4105-af1a-53d06da9dfd1:06e3c6927d37468a898b0a1631111d1f
[W 22:25:57.866 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 5.12ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 22:25:58.726 LabApp] Adapting from protocol version 5.1 (kernel 8a176c6a-8996-42d7-bccc-a9d6303bb7c0) to 5.3 (client).
[I 22:25:58.728 LabApp] Discarding 134015 buffered messages for 8a176c6a-8996-42d7-bccc-a9d6303bb7c0:f6f50c1de9b147b18b2cce0931313a25
[W 22:25:58.904 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 5.19ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 22:26:22.542 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 22:26:27.427 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAEGAN-128.ipynb
[I 22:27:01.124 LabApp] Starting buffering for 8a176c6a-8996-42d7-bccc-a9d6303bb7c0:f75844756af942678bf072059575eb38
[I 22:27:01.617 LabApp] Kernel restarted: 8a176c6a-8996-42d7-bccc-a9d6303bb7c0
[I 22:27:03.544 LabApp] Adapting from protocol version 5.1 (kernel 8a176c6a-8996-42d7-bccc-a9d6303bb7c0) to 5.3 (client).
[I 22:27:03.546 LabApp] Restoring connection for 8a176c6a-8996-42d7-bccc-a9d6303bb7c0:f75844756af942678bf072059575eb38
[I 22:27:03.546 LabApp] Replaying 6 buffered messages
2019-10-27 22:27:17.011614: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-27 22:27:17.602731: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-27 22:27:17.604231: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 22:27:17.607757: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 22:27:17.610478: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 22:27:17.611686: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 22:27:17.615389: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 22:27:17.618412: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 22:27:17.625351: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 22:27:17.628688: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 22:27:17.914855: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55eeade34da0 executing computations on platform CUDA. Devices:
2019-10-27 22:27:17.914966: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-27 22:27:17.921973: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-27 22:27:17.924335: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55eeadf0b850 executing computations on platform Host. Devices:
2019-10-27 22:27:17.924391: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-27 22:27:17.926323: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-27 22:27:17.926517: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 22:27:17.926612: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 22:27:17.926704: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 22:27:17.926795: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 22:27:17.926884: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 22:27:17.926976: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 22:27:17.927067: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 22:27:17.930288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 22:27:17.930432: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 22:27:17.934587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-27 22:27:17.934633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-27 22:27:17.934658: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-27 22:27:17.938129: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
[I 22:27:19.017 LabApp] Starting buffering for 3d086e4a-bb0d-43d4-87dd-f43fbf948635:f88c723b70434b179a741ff8aa7eaab4
[I 22:27:21.629 LabApp] Kernel shutdown: 3d086e4a-bb0d-43d4-87dd-f43fbf948635
2019-10-27 22:27:25.521145: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-27 22:27:25.584997: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 22:27:25.947213: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[W 22:27:27.983 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb is not trusted
[W 22:27:28.202 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 1.82ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 22:27:28.918 LabApp] Adapting from protocol version 5.1 (kernel d9916fc0-f379-41c3-acdb-22feac30f803) to 5.3 (client).
[W 22:27:29.078 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 1.68ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 22:27:37.751 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 22:27:59.035 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[E 22:28:34.657 LabApp] Exception restarting kernel
    Traceback (most recent call last):
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/notebook/services/kernels/handlers.py", line 83, in post
        yield maybe_future(km.restart_kernel(kernel_id))
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/tornado/gen.py", line 735, in run
        value = future.result()
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/tornado/gen.py", line 209, in wrapper
        yielded = next(result)
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/notebook/services/kernels/kernelmanager.py", line 307, in restart_kernel
        self._check_kernel_id(kernel_id)
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/notebook/services/kernels/kernelmanager.py", line 387, in _check_kernel_id
        raise web.HTTPError(404, u'Kernel does not exist: %s' % kernel_id)
    tornado.web.HTTPError: HTTP 404: Not Found (Kernel does not exist: 6dc0982f-041c-4052-9374-74126cdac817)
[E 22:28:34.658 LabApp] {
      "Host": "localhost:8187",
      "Connection": "keep-alive",
      "Content-Length": "0",
      "Accept": "application/json, text/javascript, */*; q=0.01",
      "Origin": "http://localhost:8187",
      "X-Requested-With": "XMLHttpRequest",
      "X-Xsrftoken": "2|2b997e67|29d4ea20755e92079558d090866cac7e|1571165215",
      "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.120 Safari/537.36",
      "Sec-Fetch-Mode": "cors",
      "Sec-Fetch-Site": "same-origin",
      "Referer": "http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb",
      "Accept-Encoding": "gzip, deflate, br",
      "Accept-Language": "en-US,en;q=0.9,fr;q=0.8",
      "Cookie": "_ga=GA1.1.2135320950.1566148815; username-localhost-8195=\"2|1:0|10:1570831591|23:username-localhost-8195|44:Y2Q0M2Y0YjJhMDQxNDQwZThhOGNjZTdhNDFiNDNkNjI=|4fc2d73bc3298178be788038ba7812e8e7e1ca4ae1891ffcc42a6bd3445055ab\"; _xsrf=2|2b997e67|29d4ea20755e92079558d090866cac7e|1571165215; username-localhost-8187=\"2|1:0|10:1571972576|23:username-localhost-8187|44:MGIyNmM0MzhlMTcxNDQ2OGJlNTczNjAwZDNlZjQ1NGE=|909460f83df7fd5d2e23ab9cf52e046079d5caccf76ccde023e9d50b06ebbeb1\"; username-localhost-8186=\"2|1:0|10:1572148972|23:username-localhost-8186|44:MjAwMmFlOWIxYTRhNDc4ZmFiNDAzOTg3ODBmYzEyOTQ=|c0f3007a6fdd6628418763a8293ba019d9531ba148601913203f1e0121fd51ea\""
    }
[E 22:28:34.658 LabApp] 500 POST /api/kernels/6dc0982f-041c-4052-9374-74126cdac817/restart (::1) 2.41ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[W 22:28:34.685 LabApp] 404 DELETE /api/sessions/957a2766-dd52-4520-8a0e-c3ddc20d8c41 (::1): Session not found: session_id='957a2766-dd52-4520-8a0e-c3ddc20d8c41'
[W 22:28:34.685 LabApp] Session not found: session_id='957a2766-dd52-4520-8a0e-c3ddc20d8c41'
[W 22:28:34.685 LabApp] 404 DELETE /api/sessions/957a2766-dd52-4520-8a0e-c3ddc20d8c41 (::1) 1.50ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 22:28:34.793 LabApp] Kernel started: 611948cf-558c-4d3c-b741-a3cb59af520e
[I 22:28:36.956 LabApp] Adapting from protocol version 5.1 (kernel 611948cf-558c-4d3c-b741-a3cb59af520e) to 5.3 (client).
[I 22:29:31.076 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[W 22:29:31.077 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb is not trusted
[I 22:29:59.934 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 22:30:23.620 LabApp] Starting buffering for 611948cf-558c-4d3c-b741-a3cb59af520e:19aaab18bb964444859096dbcd1fdc84
[I 22:30:24.089 LabApp] Kernel restarted: 611948cf-558c-4d3c-b741-a3cb59af520e
[I 22:30:25.287 LabApp] Adapting from protocol version 5.1 (kernel 611948cf-558c-4d3c-b741-a3cb59af520e) to 5.3 (client).
[I 22:30:25.288 LabApp] Restoring connection for 611948cf-558c-4d3c-b741-a3cb59af520e:19aaab18bb964444859096dbcd1fdc84
[I 22:30:25.288 LabApp] Replaying 6 buffered messages
2019-10-27 22:30:35.876551: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-27 22:30:36.427403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-27 22:30:36.428468: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 22:30:36.430756: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 22:30:36.432311: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 22:30:36.433450: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 22:30:36.435619: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 22:30:36.437346: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 22:30:36.441190: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 22:30:36.443269: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 22:30:36.742663: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56378e98acc0 executing computations on platform CUDA. Devices:
2019-10-27 22:30:36.742767: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-27 22:30:36.749072: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-27 22:30:36.750885: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56378ea61720 executing computations on platform Host. Devices:
2019-10-27 22:30:36.750914: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-27 22:30:36.754540: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-27 22:30:36.754714: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 22:30:36.754789: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 22:30:36.754857: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 22:30:36.754926: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 22:30:36.755045: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 22:30:36.755164: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 22:30:36.755216: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 22:30:36.757849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 22:30:36.757951: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 22:30:36.761235: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-27 22:30:36.761271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-27 22:30:36.761290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-27 22:30:36.764467: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-27 22:30:44.466892: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 22:30:44.732491: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[W 22:30:48.622 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.69ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb
[I 22:30:49.341 LabApp] Adapting from protocol version 5.1 (kernel c4a93869-fff9-4616-b073-1014f8e4cd13) to 5.3 (client).
[W 22:30:49.410 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 1.73ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb
[I 22:30:51.606 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb
[I 22:30:51.961 LabApp] Copying avgn_paper/notebooks/6.0-neural-networks/Canary-GAN.ipynb to /avgn_paper/notebooks/6.0-neural-networks
[W 22:30:53.221 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 4.83ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-GAN-Copy1.ipynb
[I 22:30:53.801 LabApp] Kernel started: 436aec5b-f7fe-403a-8294-fb6685340c8c
[W 22:30:53.878 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 2.24ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-GAN-Copy1.ipynb
[I 22:30:54.040 LabApp] Starting buffering for c4a93869-fff9-4616-b073-1014f8e4cd13:ce67d8caee994e388bb054a3d6cbdc19
[I 22:30:54.840 LabApp] Adapting from protocol version 5.1 (kernel 436aec5b-f7fe-403a-8294-fb6685340c8c) to 5.3 (client).
[I 22:31:00.257 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 22:32:00.180 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 22:32:54.251 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 22:33:00.620 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 22:33:04.680 LabApp] Starting buffering for 436aec5b-f7fe-403a-8294-fb6685340c8c:cb553906fa9e47ed8ea06797fbb995f7
[I 22:33:05.139 LabApp] Kernel restarted: 436aec5b-f7fe-403a-8294-fb6685340c8c
[I 22:33:06.301 LabApp] Adapting from protocol version 5.1 (kernel 436aec5b-f7fe-403a-8294-fb6685340c8c) to 5.3 (client).
[I 22:33:06.301 LabApp] Restoring connection for 436aec5b-f7fe-403a-8294-fb6685340c8c:cb553906fa9e47ed8ea06797fbb995f7
[I 22:33:06.302 LabApp] Replaying 6 buffered messages
2019-10-27 22:33:14.259747: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-27 22:33:14.278854: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-27 22:33:14.279645: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 22:33:14.281615: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 22:33:14.283307: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 22:33:14.284128: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 22:33:14.286318: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 22:33:14.288172: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 22:33:14.292311: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 22:33:14.294008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 22:33:14.460740: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5650ff9a7bb0 executing computations on platform CUDA. Devices:
2019-10-27 22:33:14.460828: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K40c, Compute Capability 3.5
2019-10-27 22:33:14.464350: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-27 22:33:14.465406: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5650ffa7e630 executing computations on platform Host. Devices:
2019-10-27 22:33:14.465434: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-27 22:33:14.466668: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-27 22:33:14.466746: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 22:33:14.466781: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 22:33:14.466815: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 22:33:14.466849: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 22:33:14.466882: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 22:33:14.466916: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 22:33:14.466949: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 22:33:14.468438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 22:33:14.468494: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 22:33:14.470379: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-27 22:33:14.470405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-27 22:33:14.470415: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-27 22:33:14.471958: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 127 MB memory) -> physical GPU (device: 0, name: Tesla K40c, pci bus id: 0000:03:00.0, compute capability: 3.5)
2019-10-27 22:33:14.775885: W tensorflow/core/framework/op_kernel.cc:1546] OP_REQUIRES failed at example_parsing_ops.cc:240 : Invalid argument: Feature: phrase (data type: int64) is required but could not be found.
2019-10-27 22:33:14.775962: W tensorflow/core/framework/op_kernel.cc:1546] OP_REQUIRES failed at iterator_ops.cc:1055 : Invalid argument: Feature: phrase (data type: int64) is required but could not be found.
	 [[{{node ParseSingleExample/ParseSingleExample}}]]
[I 22:33:43.292 LabApp] Starting buffering for 436aec5b-f7fe-403a-8294-fb6685340c8c:cb553906fa9e47ed8ea06797fbb995f7
[I 22:33:44.543 LabApp] Kernel restarted: 436aec5b-f7fe-403a-8294-fb6685340c8c
[I 22:33:45.616 LabApp] Adapting from protocol version 5.1 (kernel 436aec5b-f7fe-403a-8294-fb6685340c8c) to 5.3 (client).
[I 22:33:45.617 LabApp] Restoring connection for 436aec5b-f7fe-403a-8294-fb6685340c8c:cb553906fa9e47ed8ea06797fbb995f7
[I 22:33:45.617 LabApp] Replaying 6 buffered messages
2019-10-27 22:33:51.975316: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-27 22:33:51.994928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-27 22:33:51.995508: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 22:33:51.997164: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 22:33:51.998323: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 22:33:51.998753: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 22:33:52.000338: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 22:33:52.001640: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 22:33:52.004973: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 22:33:52.006397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 22:33:52.180050: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5583b6683a90 executing computations on platform CUDA. Devices:
2019-10-27 22:33:52.180100: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K40c, Compute Capability 3.5
2019-10-27 22:33:52.183256: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-27 22:33:52.184336: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5583b675a520 executing computations on platform Host. Devices:
2019-10-27 22:33:52.184358: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-27 22:33:52.189408: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-27 22:33:52.189479: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 22:33:52.189515: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 22:33:52.189548: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 22:33:52.189582: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 22:33:52.189626: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 22:33:52.189661: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 22:33:52.189694: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 22:33:52.191025: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 22:33:52.191081: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 22:33:52.192814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-27 22:33:52.192832: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-27 22:33:52.192841: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-27 22:33:52.194412: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 127 MB memory) -> physical GPU (device: 0, name: Tesla K40c, pci bus id: 0000:03:00.0, compute capability: 3.5)
2019-10-27 22:33:52.474576: W tensorflow/core/framework/op_kernel.cc:1546] OP_REQUIRES failed at example_parsing_ops.cc:240 : Invalid argument: Feature: phrase (data type: int64) is required but could not be found.
2019-10-27 22:33:52.474722: W tensorflow/core/framework/op_kernel.cc:1546] OP_REQUIRES failed at iterator_ops.cc:1055 : Invalid argument: Feature: phrase (data type: int64) is required but could not be found.
	 [[{{node ParseSingleExample/ParseSingleExample}}]]
[I 22:34:00.064 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 22:34:53.805 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 22:35:00.589 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 22:36:00.023 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 22:36:56.587 LabApp] Kernel interrupted: 611948cf-558c-4d3c-b741-a3cb59af520e
[I 22:37:00.585 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
2019-10-27 22:37:25.684290: W tensorflow/core/framework/op_kernel.cc:1546] OP_REQUIRES failed at example_parsing_ops.cc:240 : Invalid argument: Feature: phrase (data type: int64) is required but could not be found.
2019-10-27 22:37:25.684421: W tensorflow/core/framework/op_kernel.cc:1546] OP_REQUIRES failed at iterator_ops.cc:1055 : Invalid argument: Feature: phrase (data type: int64) is required but could not be found.
	 [[{{node ParseSingleExample/ParseSingleExample}}]]
2019-10-27 22:37:33.612788: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 22:37:33.828325: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 22:37:34.579443: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 833.02MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-27 22:37:44.603091: W tensorflow/core/common_runtime/bfc_allocator.cc:314] Allocator (GPU_0_bfc) ran out of memory trying to allocate 16.50MiB (rounded to 17301504).  Current allocation summary follows.
2019-10-27 22:37:44.603192: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (256): 	Total Chunks: 1, Chunks in use: 0. 256B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:37:44.603208: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (512): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:37:44.603238: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (1024): 	Total Chunks: 3, Chunks in use: 3. 3.2KiB allocated for chunks. 3.2KiB in use in bin. 3.0KiB client-requested in use in bin.
2019-10-27 22:37:44.603250: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (2048): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:37:44.603260: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (4096): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:37:44.603269: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (8192): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:37:44.603280: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (16384): 	Total Chunks: 1, Chunks in use: 1. 16.0KiB allocated for chunks. 16.0KiB in use in bin. 16.0KiB client-requested in use in bin.
2019-10-27 22:37:44.603290: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (32768): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:37:44.603299: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (65536): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:37:44.603311: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (131072): 	Total Chunks: 2, Chunks in use: 1. 378.0KiB allocated for chunks. 132.0KiB in use in bin. 132.0KiB client-requested in use in bin.
2019-10-27 22:37:44.603320: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (262144): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:37:44.603330: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (524288): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:37:44.603339: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (1048576): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:37:44.603350: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (2097152): 	Total Chunks: 6, Chunks in use: 4. 16.11MiB allocated for chunks. 10.24MiB in use in bin. 8.75MiB client-requested in use in bin.
2019-10-27 22:37:44.603360: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (4194304): 	Total Chunks: 1, Chunks in use: 0. 4.12MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:37:44.603370: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (8388608): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:37:44.603380: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (16777216): 	Total Chunks: 2, Chunks in use: 2. 33.00MiB allocated for chunks. 33.00MiB in use in bin. 33.00MiB client-requested in use in bin.
2019-10-27 22:37:44.603390: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (33554432): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:37:44.603401: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (67108864): 	Total Chunks: 1, Chunks in use: 1. 73.56MiB allocated for chunks. 73.56MiB in use in bin. 66.00MiB client-requested in use in bin.
2019-10-27 22:37:44.603410: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:37:44.603419: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (268435456): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:37:44.603434: I tensorflow/core/common_runtime/bfc_allocator.cc:780] Bin for 16.50MiB was 16.00MiB, Chunk State: 
2019-10-27 22:37:44.603443: I tensorflow/core/common_runtime/bfc_allocator.cc:793] Next region of size 133365760
2019-10-27 22:37:44.603452: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x2304640000 next 6 of size 256
2019-10-27 22:37:44.603463: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x2304640100 next 10 of size 16384
2019-10-27 22:37:44.603471: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x2304644100 next 14 of size 1024
2019-10-27 22:37:44.603480: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x2304644500 next 16 of size 1024
2019-10-27 22:37:44.603488: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x2304644900 next 7 of size 251904
2019-10-27 22:37:44.603496: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x2304682100 next 8 of size 135168
2019-10-27 22:37:44.603505: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x23046a3100 next 1 of size 3919616
2019-10-27 22:37:44.603514: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x2304a60000 next 2 of size 1280
2019-10-27 22:37:44.603522: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x2304a60500 next 4 of size 2097152
2019-10-27 22:37:44.603531: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x2304c60500 next 9 of size 2097152
2019-10-27 22:37:44.603540: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x2304e60500 next 11 of size 2359296
2019-10-27 22:37:44.603548: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x23050a0500 next 12 of size 4325376
2019-10-27 22:37:44.603556: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x23054c0500 next 13 of size 2359296
2019-10-27 22:37:44.603564: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x2305700500 next 3 of size 4063232
2019-10-27 22:37:44.603572: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x2305ae0500 next 5 of size 17301504
2019-10-27 22:37:44.603581: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x2306b60500 next 15 of size 17301504
2019-10-27 22:37:44.603590: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x2307be0500 next 18446744073709551615 of size 77134592
2019-10-27 22:37:44.603598: I tensorflow/core/common_runtime/bfc_allocator.cc:809]      Summary of in-use Chunks by size: 
2019-10-27 22:37:44.603609: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 1024 totalling 2.0KiB
2019-10-27 22:37:44.603619: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 1280 totalling 1.2KiB
2019-10-27 22:37:44.603628: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 16384 totalling 16.0KiB
2019-10-27 22:37:44.603637: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 135168 totalling 132.0KiB
2019-10-27 22:37:44.603646: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 2097152 totalling 2.00MiB
2019-10-27 22:37:44.603655: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 2359296 totalling 4.50MiB
2019-10-27 22:37:44.603664: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 3919616 totalling 3.74MiB
2019-10-27 22:37:44.603673: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 17301504 totalling 33.00MiB
2019-10-27 22:37:44.603682: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 77134592 totalling 73.56MiB
2019-10-27 22:37:44.603692: I tensorflow/core/common_runtime/bfc_allocator.cc:816] Sum Total of in-use chunks: 116.95MiB
2019-10-27 22:37:44.603700: I tensorflow/core/common_runtime/bfc_allocator.cc:818] total_region_allocated_bytes_: 133365760 memory_limit_: 133365760 available bytes: 0 curr_region_allocation_bytes_: 266731520
2019-10-27 22:37:44.603714: I tensorflow/core/common_runtime/bfc_allocator.cc:824] Stats: 
Limit:                   133365760
InUse:                   122627840
MaxInUse:                122627840
NumAllocs:                      52
MaxAllocSize:             77134592

2019-10-27 22:37:44.603731: W tensorflow/core/common_runtime/bfc_allocator.cc:319] *********__***__*******************************************************************************xxxxx
2019-10-27 22:37:44.603768: W tensorflow/core/framework/op_kernel.cc:1546] OP_REQUIRES failed at conv_grad_input_ops.cc:932 : Resource exhausted: OOM when allocating tensor with shape[264,256,8,8] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
[I 22:37:59.530 LabApp] Starting buffering for 436aec5b-f7fe-403a-8294-fb6685340c8c:cb553906fa9e47ed8ea06797fbb995f7
[I 22:38:01.176 LabApp] Kernel restarted: 436aec5b-f7fe-403a-8294-fb6685340c8c
[I 22:38:01.193 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 22:38:02.214 LabApp] Adapting from protocol version 5.1 (kernel 436aec5b-f7fe-403a-8294-fb6685340c8c) to 5.3 (client).
[I 22:38:02.215 LabApp] Restoring connection for 436aec5b-f7fe-403a-8294-fb6685340c8c:cb553906fa9e47ed8ea06797fbb995f7
[I 22:38:02.215 LabApp] Replaying 6 buffered messages
2019-10-27 22:38:09.861358: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-27 22:38:09.877287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-27 22:38:09.877994: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 22:38:09.879674: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 22:38:09.881014: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 22:38:09.881635: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 22:38:09.883440: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 22:38:09.884993: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 22:38:09.888340: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 22:38:09.889757: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 22:38:10.063423: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55db061dba30 executing computations on platform CUDA. Devices:
2019-10-27 22:38:10.063474: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K40c, Compute Capability 3.5
2019-10-27 22:38:10.066478: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-27 22:38:10.067503: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55db062b24e0 executing computations on platform Host. Devices:
2019-10-27 22:38:10.067530: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-27 22:38:10.068452: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-27 22:38:10.068522: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 22:38:10.068558: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 22:38:10.068591: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 22:38:10.068635: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 22:38:10.068668: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 22:38:10.068701: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 22:38:10.068735: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 22:38:10.070243: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 22:38:10.070299: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 22:38:10.072207: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-27 22:38:10.072225: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-27 22:38:10.072234: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-27 22:38:10.074269: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 127 MB memory) -> physical GPU (device: 0, name: Tesla K40c, pci bus id: 0000:03:00.0, compute capability: 3.5)
2019-10-27 22:38:11.850578: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 22:38:12.029247: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 22:38:12.716051: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 544.02MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-27 22:38:12.753889: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 544.02MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-27 22:38:22.754144: W tensorflow/core/common_runtime/bfc_allocator.cc:314] Allocator (GPU_0_bfc) ran out of memory trying to allocate 32.00MiB (rounded to 33554432).  Current allocation summary follows.
2019-10-27 22:38:22.754248: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (256): 	Total Chunks: 1, Chunks in use: 0. 256B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:38:22.754274: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (512): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:38:22.754299: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (1024): 	Total Chunks: 3, Chunks in use: 3. 3.2KiB allocated for chunks. 3.2KiB in use in bin. 3.0KiB client-requested in use in bin.
2019-10-27 22:38:22.754320: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (2048): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:38:22.754340: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (4096): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:38:22.754359: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (8192): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:38:22.754383: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (16384): 	Total Chunks: 1, Chunks in use: 1. 16.0KiB allocated for chunks. 16.0KiB in use in bin. 16.0KiB client-requested in use in bin.
2019-10-27 22:38:22.754403: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (32768): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:38:22.754447: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (65536): 	Total Chunks: 2, Chunks in use: 1. 174.0KiB allocated for chunks. 64.0KiB in use in bin. 64.0KiB client-requested in use in bin.
2019-10-27 22:38:22.754469: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (131072): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:38:22.754489: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (262144): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:38:22.754508: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (524288): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:38:22.754528: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (1048576): 	Total Chunks: 1, Chunks in use: 0. 1.81MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:38:22.754551: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (2097152): 	Total Chunks: 5, Chunks in use: 4. 10.75MiB allocated for chunks. 8.75MiB in use in bin. 8.75MiB client-requested in use in bin.
2019-10-27 22:38:22.754573: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (4194304): 	Total Chunks: 1, Chunks in use: 0. 4.00MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:38:22.754595: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (8388608): 	Total Chunks: 3, Chunks in use: 3. 24.00MiB allocated for chunks. 24.00MiB in use in bin. 24.00MiB client-requested in use in bin.
2019-10-27 22:38:22.754615: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:38:22.754639: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (33554432): 	Total Chunks: 2, Chunks in use: 2. 86.44MiB allocated for chunks. 86.44MiB in use in bin. 68.12MiB client-requested in use in bin.
2019-10-27 22:38:22.754658: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (67108864): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:38:22.754677: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:38:22.754696: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (268435456): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:38:22.754717: I tensorflow/core/common_runtime/bfc_allocator.cc:780] Bin for 32.00MiB was 32.00MiB, Chunk State: 
2019-10-27 22:38:22.754733: I tensorflow/core/common_runtime/bfc_allocator.cc:793] Next region of size 133365760
2019-10-27 22:38:22.754752: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x2304640000 next 6 of size 256
2019-10-27 22:38:22.754770: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x2304640100 next 4 of size 16384
2019-10-27 22:38:22.754787: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x2304644100 next 12 of size 1024
2019-10-27 22:38:22.754803: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x2304644500 next 16 of size 1024
2019-10-27 22:38:22.754819: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x2304644900 next 7 of size 112640
2019-10-27 22:38:22.754836: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x2304660100 next 8 of size 65536
2019-10-27 22:38:22.754852: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x2304670100 next 1 of size 1900288
2019-10-27 22:38:22.754887: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x2304840000 next 2 of size 1280
2019-10-27 22:38:22.754905: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x2304840500 next 9 of size 4194304
2019-10-27 22:38:22.754922: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x2304c40500 next 10 of size 2097152
2019-10-27 22:38:22.754938: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x2304e40500 next 3 of size 2097152
2019-10-27 22:38:22.754955: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x2305040500 next 5 of size 8388608
2019-10-27 22:38:22.754972: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x2305840500 next 11 of size 2359296
2019-10-27 22:38:22.754988: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x2305a80500 next 13 of size 2359296
2019-10-27 22:38:22.755004: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x2305cc0500 next 14 of size 2359296
2019-10-27 22:38:22.755020: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x2305f00500 next 15 of size 8388608
2019-10-27 22:38:22.755036: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x2306700500 next 17 of size 33554432
2019-10-27 22:38:22.755052: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x2308700500 next 18 of size 8388608
2019-10-27 22:38:22.755069: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x2308f00500 next 18446744073709551615 of size 57080576
2019-10-27 22:38:22.755085: I tensorflow/core/common_runtime/bfc_allocator.cc:809]      Summary of in-use Chunks by size: 
2019-10-27 22:38:22.755127: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 1024 totalling 2.0KiB
2019-10-27 22:38:22.755166: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 1280 totalling 1.2KiB
2019-10-27 22:38:22.755185: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 16384 totalling 16.0KiB
2019-10-27 22:38:22.755204: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 65536 totalling 64.0KiB
2019-10-27 22:38:22.755221: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 2097152 totalling 2.00MiB
2019-10-27 22:38:22.755239: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 3 Chunks of size 2359296 totalling 6.75MiB
2019-10-27 22:38:22.755256: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 3 Chunks of size 8388608 totalling 24.00MiB
2019-10-27 22:38:22.755274: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 33554432 totalling 32.00MiB
2019-10-27 22:38:22.755293: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 57080576 totalling 54.44MiB
2019-10-27 22:38:22.755311: I tensorflow/core/common_runtime/bfc_allocator.cc:816] Sum Total of in-use chunks: 119.27MiB
2019-10-27 22:38:22.755327: I tensorflow/core/common_runtime/bfc_allocator.cc:818] total_region_allocated_bytes_: 133365760 memory_limit_: 133365760 available bytes: 0 curr_region_allocation_bytes_: 266731520
2019-10-27 22:38:22.755349: I tensorflow/core/common_runtime/bfc_allocator.cc:824] Stats: 
Limit:                   133365760
InUse:                   125061120
MaxInUse:                125061120
NumAllocs:                      54
MaxAllocSize:             57080576

2019-10-27 22:38:22.755369: W tensorflow/core/common_runtime/bfc_allocator.cc:319] **__**********************************************************************************xxxxxxxxxxxxxx
2019-10-27 22:38:22.755412: W tensorflow/core/framework/op_kernel.cc:1546] OP_REQUIRES failed at conv_grad_input_ops.cc:1057 : Resource exhausted: OOM when allocating tensor with shape[128,256,16,16] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
[I 22:38:53.892 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 22:39:00.639 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 22:40:00.216 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 22:41:00.653 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 22:42:00.085 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 22:43:00.654 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 22:43:02.010 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 22:43:04.609 LabApp] Starting buffering for 436aec5b-f7fe-403a-8294-fb6685340c8c:cb553906fa9e47ed8ea06797fbb995f7
[I 22:43:05.964 LabApp] Kernel restarted: 436aec5b-f7fe-403a-8294-fb6685340c8c
[I 22:43:07.051 LabApp] Adapting from protocol version 5.1 (kernel 436aec5b-f7fe-403a-8294-fb6685340c8c) to 5.3 (client).
[I 22:43:07.051 LabApp] Restoring connection for 436aec5b-f7fe-403a-8294-fb6685340c8c:cb553906fa9e47ed8ea06797fbb995f7
[I 22:43:07.052 LabApp] Replaying 6 buffered messages
2019-10-27 22:43:14.054328: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-27 22:43:14.070067: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-27 22:43:14.070791: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 22:43:14.072658: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 22:43:14.074029: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 22:43:14.074629: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 22:43:14.076396: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 22:43:14.077921: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 22:43:14.081245: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 22:43:14.082878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 22:43:14.256369: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e7d5161110 executing computations on platform CUDA. Devices:
2019-10-27 22:43:14.256418: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K40c, Compute Capability 3.5
2019-10-27 22:43:14.259712: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-27 22:43:14.260778: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e7d5237bc0 executing computations on platform Host. Devices:
2019-10-27 22:43:14.260805: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-27 22:43:14.261692: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-27 22:43:14.261776: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 22:43:14.261812: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 22:43:14.261845: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 22:43:14.261879: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 22:43:14.261912: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 22:43:14.261959: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 22:43:14.261994: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 22:43:14.263405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 22:43:14.263465: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 22:43:14.265405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-27 22:43:14.265424: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-27 22:43:14.265434: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-27 22:43:14.267060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 127 MB memory) -> physical GPU (device: 0, name: Tesla K40c, pci bus id: 0000:03:00.0, compute capability: 3.5)
2019-10-27 22:43:15.952941: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 22:43:16.155046: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 22:43:16.776647: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 340.02MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-27 22:43:16.790981: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 340.02MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-27 22:43:16.809324: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 238.05MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-27 22:43:16.837682: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 85.05MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2019-10-27 22:43:26.837904: W tensorflow/core/common_runtime/bfc_allocator.cc:314] Allocator (GPU_0_bfc) ran out of memory trying to allocate 32.00MiB (rounded to 33554432).  Current allocation summary follows.
2019-10-27 22:43:26.837966: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (256): 	Total Chunks: 2, Chunks in use: 1. 512B allocated for chunks. 256B in use in bin. 256B client-requested in use in bin.
2019-10-27 22:43:26.837982: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (512): 	Total Chunks: 1, Chunks in use: 1. 512B allocated for chunks. 512B in use in bin. 512B client-requested in use in bin.
2019-10-27 22:43:26.837996: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (1024): 	Total Chunks: 3, Chunks in use: 3. 3.2KiB allocated for chunks. 3.2KiB in use in bin. 3.0KiB client-requested in use in bin.
2019-10-27 22:43:26.838008: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (2048): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:43:26.838019: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (4096): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:43:26.838032: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (8192): 	Total Chunks: 1, Chunks in use: 0. 13.2KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:43:26.838057: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (16384): 	Total Chunks: 2, Chunks in use: 2. 32.0KiB allocated for chunks. 32.0KiB in use in bin. 32.0KiB client-requested in use in bin.
2019-10-27 22:43:26.838069: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (32768): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:43:26.838080: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (65536): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:43:26.838090: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (131072): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:43:26.838103: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (262144): 	Total Chunks: 3, Chunks in use: 2. 1.01MiB allocated for chunks. 576.0KiB in use in bin. 576.0KiB client-requested in use in bin.
2019-10-27 22:43:26.838114: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (524288): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:43:26.838125: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (1048576): 	Total Chunks: 2, Chunks in use: 1. 2.56MiB allocated for chunks. 1.12MiB in use in bin. 1.12MiB client-requested in use in bin.
2019-10-27 22:43:26.838138: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (2097152): 	Total Chunks: 6, Chunks in use: 4. 13.88MiB allocated for chunks. 8.50MiB in use in bin. 8.50MiB client-requested in use in bin.
2019-10-27 22:43:26.838148: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:43:26.838160: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (8388608): 	Total Chunks: 1, Chunks in use: 0. 8.00MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:43:26.838172: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (16777216): 	Total Chunks: 2, Chunks in use: 2. 32.00MiB allocated for chunks. 32.00MiB in use in bin. 32.00MiB client-requested in use in bin.
2019-10-27 22:43:26.838185: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (33554432): 	Total Chunks: 2, Chunks in use: 2. 69.69MiB allocated for chunks. 69.69MiB in use in bin. 65.01MiB client-requested in use in bin.
2019-10-27 22:43:26.838196: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (67108864): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:43:26.838207: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:43:26.838217: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (268435456): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-27 22:43:26.838228: I tensorflow/core/common_runtime/bfc_allocator.cc:780] Bin for 32.00MiB was 32.00MiB, Chunk State: 
2019-10-27 22:43:26.838238: I tensorflow/core/common_runtime/bfc_allocator.cc:793] Next region of size 133365760
2019-10-27 22:43:26.838248: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x2304640000 next 6 of size 256
2019-10-27 22:43:26.838259: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x2304640100 next 10 of size 16384
2019-10-27 22:43:26.838268: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x2304644100 next 12 of size 1024
2019-10-27 22:43:26.838277: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x2304644500 next 11 of size 1024
2019-10-27 22:43:26.838296: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x2304644900 next 18 of size 512
2019-10-27 22:43:26.838306: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x2304644b00 next 22 of size 256
2019-10-27 22:43:26.838315: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x2304644c00 next 7 of size 13568
2019-10-27 22:43:26.838323: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x2304648100 next 8 of size 16384
2019-10-27 22:43:26.838332: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x230464c100 next 1 of size 474880
2019-10-27 22:43:26.838342: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x23046c0000 next 2 of size 1280
2019-10-27 22:43:26.838351: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x23046c0500 next 20 of size 294912
2019-10-27 22:43:26.838360: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x2304708500 next 21 of size 294912
2019-10-27 22:43:26.838369: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x2304750500 next 3 of size 1507328
2019-10-27 22:43:26.838378: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x23048c0500 next 5 of size 2097152
2019-10-27 22:43:26.838387: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x2304ac0500 next 4 of size 2097152
2019-10-27 22:43:26.838396: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x2304cc0500 next 9 of size 2097152
2019-10-27 22:43:26.838405: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x2304ec0500 next 17 of size 1179648
2019-10-27 22:43:26.838414: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x2304fe0500 next 13 of size 3538944
2019-10-27 22:43:26.838423: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x2305340500 next 14 of size 2359296
2019-10-27 22:43:26.838432: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x2305580500 next 15 of size 2359296
2019-10-27 22:43:26.838441: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x23057c0500 next 16 of size 8388608
2019-10-27 22:43:26.838450: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x2305fc0500 next 19 of size 16777216
2019-10-27 22:43:26.838459: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x2306fc0500 next 23 of size 33554432
2019-10-27 22:43:26.838468: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x2308fc0500 next 24 of size 16777216
2019-10-27 22:43:26.838477: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x2309fc0500 next 18446744073709551615 of size 39516928
2019-10-27 22:43:26.838486: I tensorflow/core/common_runtime/bfc_allocator.cc:809]      Summary of in-use Chunks by size: 
2019-10-27 22:43:26.838497: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 256 totalling 256B
2019-10-27 22:43:26.838507: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 512 totalling 512B
2019-10-27 22:43:26.838517: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 1024 totalling 2.0KiB
2019-10-27 22:43:26.838528: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 1280 totalling 1.2KiB
2019-10-27 22:43:26.838538: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 16384 totalling 32.0KiB
2019-10-27 22:43:26.838549: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 294912 totalling 576.0KiB
2019-10-27 22:43:26.838559: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 1179648 totalling 1.12MiB
2019-10-27 22:43:26.838570: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 2097152 totalling 4.00MiB
2019-10-27 22:43:26.838580: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 2359296 totalling 4.50MiB
2019-10-27 22:43:26.838591: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 16777216 totalling 32.00MiB
2019-10-27 22:43:26.838606: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 33554432 totalling 32.00MiB
2019-10-27 22:43:26.838617: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 39516928 totalling 37.69MiB
2019-10-27 22:43:26.838628: I tensorflow/core/common_runtime/bfc_allocator.cc:816] Sum Total of in-use chunks: 111.91MiB
2019-10-27 22:43:26.838637: I tensorflow/core/common_runtime/bfc_allocator.cc:818] total_region_allocated_bytes_: 133365760 memory_limit_: 133365760 available bytes: 0 curr_region_allocation_bytes_: 266731520
2019-10-27 22:43:26.838651: I tensorflow/core/common_runtime/bfc_allocator.cc:824] Stats: 
Limit:                   133365760
InUse:                   117345024
MaxInUse:                117345024
NumAllocs:                      88
MaxAllocSize:             39516928

2019-10-27 22:43:26.838663: W tensorflow/core/common_runtime/bfc_allocator.cc:319] ****_***__****______*****************************************************************************xxx
2019-10-27 22:43:26.838695: W tensorflow/core/framework/op_kernel.cc:1546] OP_REQUIRES failed at conv_grad_input_ops.cc:1057 : Resource exhausted: OOM when allocating tensor with shape[32,64,64,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
[I 22:43:44.965 LabApp] KernelRestarter: restarting kernel (1/5), keep random ports
kernel 436aec5b-f7fe-403a-8294-fb6685340c8c restarted
[I 22:43:52.245 LabApp] KernelRestarter: restarting kernel (1/5), keep random ports
[I 22:44:01.336 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 22:44:35.583 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 22:44:38.457 LabApp] Starting buffering for 436aec5b-f7fe-403a-8294-fb6685340c8c:cb553906fa9e47ed8ea06797fbb995f7
[I 22:44:38.913 LabApp] Kernel restarted: 436aec5b-f7fe-403a-8294-fb6685340c8c
[I 22:44:39.967 LabApp] Adapting from protocol version 5.1 (kernel 436aec5b-f7fe-403a-8294-fb6685340c8c) to 5.3 (client).
[I 22:44:39.968 LabApp] Restoring connection for 436aec5b-f7fe-403a-8294-fb6685340c8c:cb553906fa9e47ed8ea06797fbb995f7
[I 22:44:39.968 LabApp] Replaying 6 buffered messages
2019-10-27 22:44:47.402404: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-27 22:44:49.808700: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-27 22:44:49.809582: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 22:44:49.811489: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 22:44:49.812904: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 22:44:49.813525: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 22:44:49.815323: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 22:44:49.816837: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 22:44:49.820191: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 22:44:49.821888: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 22:44:49.980287: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555e5d4e6a30 executing computations on platform CUDA. Devices:
2019-10-27 22:44:49.980334: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K40c, Compute Capability 3.5
2019-10-27 22:44:49.983258: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-27 22:44:49.984313: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555e5d5bd4e0 executing computations on platform Host. Devices:
2019-10-27 22:44:49.984341: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-27 22:44:49.985422: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-27 22:44:49.985498: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 22:44:49.985543: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 22:44:49.985579: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-27 22:44:49.985620: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-27 22:44:49.985655: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-27 22:44:49.985696: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-27 22:44:49.985732: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-27 22:44:49.987804: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-27 22:44:49.987927: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-27 22:44:49.991582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-27 22:44:49.991601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-27 22:44:49.991611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-27 22:44:49.995215: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10794 MB memory) -> physical GPU (device: 0, name: Tesla K40c, pci bus id: 0000:03:00.0, compute capability: 3.5)
2019-10-27 22:44:51.920312: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-27 22:44:52.093800: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 22:44:53.874 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 22:45:01.054 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 22:46:00.100 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 22:46:53.910 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 22:47:00.663 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 22:48:00.280 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 22:49:00.676 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 22:49:59.934 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 22:51:00.674 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 22:52:00.033 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 22:52:14.288 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 22:52:38.081 LabApp] Kernel interrupted: 436aec5b-f7fe-403a-8294-fb6685340c8c
[I 22:52:54.299 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 22:53:00.667 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 22:54:00.271 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 22:54:54.708 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 22:55:00.734 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 22:56:00.218 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 22:56:54.552 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 22:57:00.708 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 22:58:00.089 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 22:58:54.510 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 22:59:00.742 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:00:00.025 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 23:00:54.527 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 23:01:00.801 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:02:00.050 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 23:02:54.690 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 23:03:00.873 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:04:00.205 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 23:04:54.659 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 23:05:00.819 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:06:00.043 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 23:06:55.061 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 23:07:00.816 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:08:00.120 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 23:08:54.899 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 23:09:00.749 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:10:00.272 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 23:10:54.862 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 23:11:01.027 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:12:00.385 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 23:12:54.718 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 23:13:00.755 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:14:00.128 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 23:14:54.642 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 23:15:00.956 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:15:59.995 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 23:16:54.458 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 23:17:00.745 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:18:00.120 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 23:18:54.815 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 23:19:00.785 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:20:00.309 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 23:20:55.055 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 23:21:00.753 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:22:00.074 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 23:22:54.945 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 23:23:00.831 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:24:00.209 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 23:24:54.841 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 23:25:01.160 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:26:00.092 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 23:26:54.674 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 23:27:00.764 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:28:00.087 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 23:28:39.977 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 23:29:00.686 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:29:31.313 LabApp] Kernel interrupted: 436aec5b-f7fe-403a-8294-fb6685340c8c
[I 23:30:00.261 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 23:30:55.039 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 23:31:00.819 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:32:00.067 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 23:32:54.660 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 23:33:00.735 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:34:00.177 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 23:34:54.844 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 23:35:01.143 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:36:00.126 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 23:36:54.743 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 23:37:00.771 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:38:00.472 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 23:38:54.741 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 23:39:00.948 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:40:00.196 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 23:40:54.925 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 23:41:00.864 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:41:59.886 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 23:42:54.734 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 23:43:00.811 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:44:00.254 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 23:44:54.934 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 23:45:00.823 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:46:00.237 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 23:46:54.872 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 23:47:00.795 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:48:00.274 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 23:48:54.747 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 23:49:00.811 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:50:00.345 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 23:50:55.103 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 23:51:00.881 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:52:00.110 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 23:52:54.764 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 23:53:00.789 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:54:00.217 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 23:54:54.730 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 23:55:00.797 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:56:00.210 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 23:56:54.832 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 23:57:00.834 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:58:00.262 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 23:58:54.974 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 23:59:00.873 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:00:00.407 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 00:00:54.372 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 00:01:00.751 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:01:59.598 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 00:02:54.686 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 00:03:00.893 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:04:00.140 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 00:04:54.742 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 00:05:00.863 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:06:00.239 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 00:06:54.901 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 00:07:00.790 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:08:00.144 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 00:08:54.746 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 00:09:00.787 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:10:00.180 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 00:10:54.755 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 00:11:00.777 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:12:00.174 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 00:12:54.796 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 00:13:00.801 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:14:00.407 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 00:14:54.947 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 00:15:00.784 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:16:00.127 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 00:16:54.740 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 00:17:00.869 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:18:00.207 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 00:18:57.806 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 00:19:03.843 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:20:00.121 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 00:20:54.975 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 00:21:00.889 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:22:00.250 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 00:22:54.879 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 00:23:00.785 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:24:00.157 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 00:24:54.844 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 00:25:01.076 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:26:00.332 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 00:26:54.742 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 00:27:00.790 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:28:00.161 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 00:28:54.733 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 00:29:00.804 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:30:02.161 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 00:30:54.913 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 00:31:00.825 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:32:00.201 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 00:32:54.890 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 00:33:00.784 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:34:00.143 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 00:34:54.840 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 00:35:00.876 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:36:00.229 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 00:36:54.805 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 00:37:01.179 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:38:00.162 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 00:38:54.782 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 00:39:00.834 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:39:59.638 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 00:40:54.703 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 00:41:00.814 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:42:00.243 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 00:42:54.772 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 00:43:00.959 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:44:00.308 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 00:44:54.953 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 00:45:00.797 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:46:00.226 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 00:46:54.801 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 00:47:00.826 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:48:00.282 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 00:48:54.919 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 00:49:00.906 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:50:00.153 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 00:50:54.701 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 00:51:01.248 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:52:00.139 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 00:52:54.920 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 00:53:00.828 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:54:00.222 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 00:54:54.866 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 00:55:01.056 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:56:00.301 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 00:56:54.978 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 00:57:00.808 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:58:00.194 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 00:58:54.839 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 00:59:00.817 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 01:00:07.733 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 01:00:55.155 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 01:01:00.856 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 01:02:00.192 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 01:02:54.771 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 01:03:00.802 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 01:04:00.298 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 01:04:54.890 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 01:05:00.928 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 01:06:00.198 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 01:06:54.949 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 01:07:00.947 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 01:08:00.226 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 01:09:03.081 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 01:09:04.690 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 01:10:00.271 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 01:10:54.908 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 01:11:00.837 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 01:12:00.216 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 01:12:54.829 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 01:13:00.838 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 01:14:00.244 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 01:14:54.811 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 01:15:00.815 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 01:16:00.235 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 01:16:54.915 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 01:17:00.949 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 01:18:00.215 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 01:18:54.966 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 01:19:00.922 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 01:20:00.303 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 01:20:55.017 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 01:21:01.081 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 01:22:00.177 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 01:22:54.783 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 01:23:00.843 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 01:24:00.177 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 01:24:54.747 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 01:25:00.846 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 01:26:00.212 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 01:26:54.982 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 01:27:00.821 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 01:28:00.214 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 01:28:54.999 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 01:29:00.937 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 01:30:00.260 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 01:30:54.871 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 01:31:00.902 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 01:32:00.168 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 01:32:54.748 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 01:33:00.908 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 01:34:00.595 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 01:34:54.850 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 01:35:00.844 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 01:36:00.291 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 01:36:54.742 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 01:37:00.846 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 01:37:59.962 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 01:38:55.029 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 01:39:00.860 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 01:40:00.171 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 01:40:54.914 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 01:41:00.942 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 01:42:00.190 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 01:42:54.841 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 01:43:00.866 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 01:44:00.171 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 01:44:54.970 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 01:45:00.934 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 01:46:00.186 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 01:46:54.870 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 01:47:00.865 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 01:48:00.210 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 01:48:54.761 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 01:49:00.911 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 01:50:00.216 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 01:50:54.786 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 01:51:01.024 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 01:52:00.215 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 01:52:54.950 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 01:53:00.846 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 01:53:59.921 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 01:54:54.951 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 01:55:00.963 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 01:56:00.261 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 01:56:54.825 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 01:57:00.936 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 01:58:00.275 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 01:58:54.817 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 01:59:01.238 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 02:00:00.243 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 02:00:54.956 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 02:01:00.877 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 02:02:00.206 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 02:02:55.328 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[W 02:03:25.288 LabApp] WebSocket ping timeout after 119979 ms.
[W 02:03:25.449 LabApp] zmq message arrived on closed channel
[W 02:03:25.449 LabApp] zmq message arrived on closed channel
[W 02:03:25.819 LabApp] zmq message arrived on closed channel
[W 02:03:25.820 LabApp] zmq message arrived on closed channel
[W 02:03:26.189 LabApp] zmq message arrived on closed channel
[W 02:03:26.190 LabApp] zmq message arrived on closed channel
[W 02:03:26.559 LabApp] zmq message arrived on closed channel
[W 02:03:26.560 LabApp] zmq message arrived on closed channel
[W 02:03:26.943 LabApp] zmq message arrived on closed channel
[W 02:03:26.944 LabApp] zmq message arrived on closed channel
[W 02:03:27.337 LabApp] zmq message arrived on closed channel
[W 02:03:27.338 LabApp] zmq message arrived on closed channel
[W 02:03:27.729 LabApp] zmq message arrived on closed channel
[W 02:03:27.729 LabApp] zmq message arrived on closed channel
[W 02:03:28.116 LabApp] zmq message arrived on closed channel
[W 02:03:28.117 LabApp] zmq message arrived on closed channel
[W 02:03:28.486 LabApp] zmq message arrived on closed channel
[W 02:03:28.487 LabApp] zmq message arrived on closed channel
[W 02:03:28.859 LabApp] zmq message arrived on closed channel
[W 02:03:28.859 LabApp] zmq message arrived on closed channel
[W 02:03:29.233 LabApp] zmq message arrived on closed channel
[W 02:03:29.234 LabApp] zmq message arrived on closed channel
[W 02:03:29.609 LabApp] zmq message arrived on closed channel
[W 02:03:29.610 LabApp] zmq message arrived on closed channel
[W 02:03:29.990 LabApp] zmq message arrived on closed channel
[W 02:03:29.991 LabApp] zmq message arrived on closed channel
[I 02:03:30.291 LabApp] Starting buffering for 611948cf-558c-4d3c-b741-a3cb59af520e:19aaab18bb964444859096dbcd1fdc84
[I 02:04:00.194 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 02:04:54.771 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 02:06:00.238 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 02:06:55.014 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 02:08:00.205 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 02:08:54.804 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 02:10:00.199 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 02:10:54.828 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 02:12:00.215 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 02:12:54.943 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 02:14:00.389 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 02:14:54.858 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 02:16:00.239 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 02:16:54.902 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 02:18:00.260 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 02:18:54.863 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 02:20:00.270 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 02:20:55.058 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 02:22:00.268 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 02:22:55.036 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 02:24:00.317 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 02:24:54.795 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 02:26:00.321 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 02:26:55.040 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 02:28:00.239 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 02:28:54.837 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 02:30:00.227 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 02:30:55.027 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 02:32:00.337 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 02:32:54.952 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 02:34:00.205 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 02:34:55.022 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 02:36:00.010 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 02:36:54.838 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 02:38:00.699 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 02:38:55.006 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 02:40:00.342 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 02:40:55.044 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 02:42:00.240 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 02:42:54.829 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 02:44:00.261 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 02:44:54.853 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 02:46:00.255 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 02:46:54.929 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 02:48:00.277 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 02:48:55.052 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 02:50:00.307 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 02:50:54.990 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 02:52:00.310 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 02:52:54.830 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 02:54:00.212 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 02:54:54.815 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 02:56:00.234 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 02:56:55.085 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 02:58:00.241 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 02:58:54.946 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 03:00:00.289 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 03:00:54.840 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 03:02:00.319 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 03:02:55.050 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 03:04:00.212 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 03:04:54.801 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 03:06:00.359 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 03:06:55.428 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 03:08:00.209 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 03:08:54.826 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 03:10:00.299 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 03:10:54.983 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 03:12:00.237 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 03:12:55.070 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 03:14:00.268 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 03:14:54.957 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 03:16:00.209 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 03:16:55.048 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 03:18:00.289 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 03:18:55.058 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 03:20:00.249 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 03:20:54.869 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 03:22:00.479 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 03:22:54.857 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 03:24:00.279 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 03:24:54.859 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 03:26:00.334 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 03:26:55.008 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 03:28:00.211 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 03:28:55.105 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 03:30:00.351 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 03:30:55.021 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 03:32:00.745 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 03:32:54.912 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 03:34:00.383 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 03:34:54.950 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 03:36:00.215 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 03:36:55.570 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 03:38:00.220 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 03:38:54.957 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 03:40:00.227 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 03:40:54.892 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 03:42:00.387 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 03:42:54.912 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 03:44:00.079 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 03:44:54.923 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 03:46:00.241 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 03:46:54.832 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 03:48:00.295 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 03:48:54.885 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 03:50:00.309 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 03:50:54.876 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 03:52:00.297 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 03:52:55.049 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 03:54:00.247 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 03:54:55.062 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 03:56:00.302 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 03:56:54.849 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 03:58:00.290 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 03:58:55.001 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 04:00:00.151 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 04:00:54.931 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 04:02:00.271 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 04:02:54.973 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 04:04:00.397 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 04:04:55.065 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 04:06:00.265 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 04:06:54.991 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 04:08:00.446 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 04:08:54.938 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 04:10:00.390 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 04:10:54.971 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 04:12:00.290 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 04:12:55.092 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 04:14:00.310 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 04:14:54.855 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 04:16:00.277 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 04:16:54.937 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 04:18:00.340 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 04:18:54.866 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 04:20:00.275 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 04:20:54.939 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 04:22:00.299 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 04:22:54.916 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 04:24:00.303 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 04:24:55.028 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 04:26:00.234 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 04:26:54.999 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 04:28:00.296 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 04:28:54.918 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 04:30:00.260 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 04:30:54.902 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 04:32:00.323 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 04:32:54.910 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 04:34:00.279 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 04:34:55.163 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 04:36:00.299 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 04:36:55.027 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 04:38:00.394 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 04:38:54.999 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 04:40:00.303 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 04:40:54.977 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 04:42:00.272 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 04:42:55.094 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 04:44:00.384 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 04:44:54.889 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 04:46:00.310 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 04:46:55.020 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 04:48:00.493 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 04:48:54.860 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 04:50:00.508 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 04:50:55.002 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 04:52:00.363 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 04:52:54.913 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 04:54:00.352 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 04:54:54.872 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 04:56:00.317 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 04:56:54.891 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 04:58:00.282 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 04:58:55.095 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 05:00:00.364 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 05:00:54.897 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 05:02:00.301 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 05:02:55.101 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 05:04:00.355 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 05:04:54.953 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 05:06:00.296 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 05:06:55.112 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 05:08:00.435 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 05:08:54.909 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 05:10:00.330 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 05:10:55.087 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 05:12:00.315 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 05:12:54.967 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 05:14:00.049 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 05:14:54.982 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 05:16:00.389 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 05:16:54.901 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 05:18:00.319 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 05:18:55.086 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 05:20:00.564 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 05:20:55.078 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 05:22:00.296 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 05:22:54.898 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 05:24:00.332 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 05:24:55.085 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 05:26:00.276 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 05:26:54.960 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 05:28:00.406 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 05:28:55.102 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 05:30:00.521 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 05:30:54.918 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 05:32:00.428 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 05:32:55.128 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 05:34:00.342 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 05:34:54.912 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 05:36:00.333 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 05:36:55.081 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 05:38:00.373 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 05:38:54.927 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 05:40:00.337 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 05:40:54.926 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 05:42:00.374 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 05:42:54.981 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 05:44:00.387 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 05:44:55.016 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 05:46:00.418 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 05:46:55.096 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 05:48:00.343 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 05:48:55.014 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 05:50:00.319 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 05:50:55.008 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 05:52:00.461 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 05:52:55.168 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 05:54:00.343 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 05:54:54.939 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 05:56:00.134 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 05:56:55.207 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 05:58:00.411 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 05:58:54.964 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 06:00:00.542 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 06:00:54.971 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 06:02:00.415 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 06:02:54.937 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 06:04:00.388 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 06:04:55.000 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 06:06:00.334 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 06:06:55.011 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 06:08:00.324 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 06:08:55.203 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 06:10:00.415 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 06:10:54.956 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 06:12:00.365 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 06:12:55.031 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 06:14:00.358 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 06:14:55.000 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 06:16:00.350 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 06:16:54.903 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 06:18:00.334 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 06:18:55.021 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 06:20:00.320 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 06:20:55.108 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 06:22:00.363 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 06:22:54.974 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 06:24:00.343 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 06:24:55.163 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 06:26:00.354 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 06:26:55.011 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 06:28:00.388 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 06:28:54.971 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 06:30:00.380 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 06:30:55.149 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 06:32:00.342 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 06:32:54.979 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 06:34:00.549 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 06:34:55.088 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 06:36:00.373 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 06:36:55.068 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 06:38:00.357 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 06:38:55.016 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 06:40:00.441 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 06:40:55.007 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 06:42:00.371 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 06:42:54.984 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 06:44:00.508 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 06:44:55.191 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 06:46:00.428 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 06:46:55.025 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 06:48:00.345 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 06:48:55.207 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 06:50:00.348 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 06:50:54.988 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 06:52:00.481 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 06:52:55.035 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 06:54:00.154 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 06:54:55.125 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 06:56:00.357 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 06:56:54.943 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 06:58:00.376 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 06:58:54.980 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 07:00:00.402 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 07:00:54.984 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 07:02:00.412 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 07:02:54.980 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 07:04:00.344 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 07:04:55.033 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 07:06:00.351 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 07:06:55.102 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 07:08:00.497 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 07:08:54.996 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 07:10:00.349 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 07:10:54.925 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 07:12:00.393 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 07:12:55.170 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 07:14:00.383 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 07:14:54.980 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 07:16:00.396 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 07:16:55.196 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 07:18:00.425 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 07:18:54.948 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 07:20:00.283 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 07:20:55.190 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 07:22:00.450 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 07:22:55.024 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 07:24:00.425 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 07:24:54.937 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 07:26:00.370 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 07:26:55.099 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 07:28:00.460 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 07:28:55.148 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 07:30:00.382 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 07:30:55.107 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 07:32:00.403 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 07:32:55.241 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 07:34:00.382 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 07:34:55.001 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 07:36:00.376 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 07:36:54.967 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 07:38:00.437 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 07:38:55.080 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 07:40:00.389 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 07:40:55.151 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 07:42:00.415 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 07:42:55.109 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 07:44:00.522 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 07:44:55.155 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 07:46:00.394 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 07:46:55.294 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 07:48:00.438 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 07:48:55.105 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 07:50:00.456 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 07:50:54.998 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 07:52:00.412 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 07:52:55.416 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 07:54:00.407 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 07:54:55.056 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 07:56:00.465 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 07:56:55.197 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 07:58:00.435 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 07:58:55.109 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 08:00:00.465 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 08:00:55.288 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 08:02:00.606 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 08:02:55.202 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 08:04:00.403 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 08:04:55.073 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 08:06:00.412 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 08:06:55.202 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 08:08:00.445 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 08:08:55.046 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 08:10:00.435 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 08:10:55.122 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 08:12:00.465 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 08:12:55.059 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 08:14:00.415 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 08:14:55.103 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 08:16:00.421 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 08:16:55.005 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 08:18:01.138 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 08:18:55.004 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 08:20:00.476 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 08:20:55.135 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 08:22:00.414 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 08:22:55.129 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 08:24:00.493 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 08:24:54.997 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 08:26:00.558 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 08:26:55.506 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 08:28:02.589 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 08:28:55.273 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 08:30:00.401 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 08:30:55.412 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 08:32:00.804 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 08:32:55.164 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 08:34:01.240 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 08:34:55.007 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 08:36:00.505 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 08:36:55.092 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 08:38:00.455 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 08:38:55.726 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 08:40:00.406 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 08:40:55.010 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 08:42:00.397 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 08:42:55.244 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 08:44:00.402 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 08:44:55.049 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 08:46:00.535 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 08:46:55.132 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 08:48:00.434 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 08:48:55.128 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 08:50:00.496 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 08:50:55.258 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 08:52:00.512 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 08:52:55.107 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 08:54:00.691 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 08:54:55.091 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 08:56:00.436 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 08:56:55.126 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 08:58:00.446 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 08:58:55.039 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 09:00:00.504 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 09:00:55.046 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 09:02:00.488 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 09:02:55.079 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 09:04:00.447 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 09:04:55.207 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 09:06:00.449 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 09:06:55.149 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 09:08:00.409 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 09:08:55.024 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 09:10:00.479 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 09:10:55.078 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 09:12:00.536 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 09:12:55.145 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 09:14:00.439 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 09:14:55.246 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 09:16:00.460 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 09:16:55.019 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 09:18:00.437 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 09:18:55.125 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 09:20:00.462 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 09:20:55.273 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 09:22:00.497 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 09:22:55.191 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 09:23:38.319 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 09:23:38.534 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 09:23:38.798 LabApp] Adapting from protocol version 5.1 (kernel 611948cf-558c-4d3c-b741-a3cb59af520e) to 5.3 (client).
[I 09:23:38.804 LabApp] Restoring connection for 611948cf-558c-4d3c-b741-a3cb59af520e:19aaab18bb964444859096dbcd1fdc84
[I 09:23:38.804 LabApp] Replaying 54910 buffered messages
[W 09:23:40.633 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 09:23:42.173 LabApp] iopub messages resumed
[W 09:23:44.118 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 09:23:45.536 LabApp] iopub messages resumed
[W 09:23:48.121 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 09:23:49.542 LabApp] iopub messages resumed
[W 09:23:51.604 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 09:23:52.958 LabApp] iopub messages resumed
[W 09:23:54.886 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 09:23:56.323 LabApp] iopub messages resumed
[W 09:23:58.287 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 09:23:59.704 LabApp] iopub messages resumed
[W 09:24:02.296 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 09:24:03.124 LabApp] iopub messages resumed
[W 09:24:05.014 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 09:24:06.429 LabApp] iopub messages resumed
[W 09:24:08.275 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[I 09:24:09.532 LabApp] Kernel interrupted: 8a176c6a-8996-42d7-bccc-a9d6303bb7c0
[I 09:24:09.532 LabApp] Kernel interrupted: 436aec5b-f7fe-403a-8294-fb6685340c8c
[I 09:24:09.533 LabApp] Kernel interrupted: 611948cf-558c-4d3c-b741-a3cb59af520e
[I 09:24:09.538 LabApp] Kernel interrupted: 611948cf-558c-4d3c-b741-a3cb59af520e
[I 09:24:10.558 LabApp] Starting buffering for 611948cf-558c-4d3c-b741-a3cb59af520e:19aaab18bb964444859096dbcd1fdc84
[I 09:24:10.899 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 09:24:11.354 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 09:24:55.432 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 09:29:33.218 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 09:32:54.683 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[W 09:34:07.624 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 2.66ms referer=http://localhost:8187/tree/avgn_paper/notebooks/6.0-neural-networks
[W 09:34:17.853 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb is not trusted
[I 09:34:18.568 LabApp] Adapting from protocol version 5.1 (kernel d9916fc0-f379-41c3-acdb-22feac30f803) to 5.3 (client).
[W 09:34:18.611 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.03ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 09:34:21.742 LabApp] Adapting from protocol version 5.1 (kernel 611948cf-558c-4d3c-b741-a3cb59af520e) to 5.3 (client).
[I 09:34:21.744 LabApp] Discarding 6 buffered messages for 611948cf-558c-4d3c-b741-a3cb59af520e:19aaab18bb964444859096dbcd1fdc84
[W 09:34:21.750 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.61ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 09:36:19.605 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[W 09:36:19.607 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb is not trusted
[I 09:36:22.230 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 09:36:22.646 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 09:36:23.170 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 09:36:25.685 LabApp] Starting buffering for 611948cf-558c-4d3c-b741-a3cb59af520e:e819fb585e874a088a33c9cb23095150
[I 09:36:29.238 LabApp] Kernel restarted: 611948cf-558c-4d3c-b741-a3cb59af520e
[I 09:36:31.734 LabApp] Adapting from protocol version 5.1 (kernel 611948cf-558c-4d3c-b741-a3cb59af520e) to 5.3 (client).
[I 09:36:31.736 LabApp] Restoring connection for 611948cf-558c-4d3c-b741-a3cb59af520e:e819fb585e874a088a33c9cb23095150
[I 09:36:31.736 LabApp] Replaying 6 buffered messages
2019-10-28 09:36:44.977650: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-28 09:36:47.638702: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-28 09:36:47.653801: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-28 09:36:47.656036: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-28 09:36:47.657773: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-28 09:36:47.664965: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-28 09:36:47.667367: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-28 09:36:47.669302: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-28 09:36:47.673697: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-28 09:36:47.675821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-28 09:36:47.918378: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562db91e20e0 executing computations on platform CUDA. Devices:
2019-10-28 09:36:47.918466: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-28 09:36:47.924866: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-28 09:36:47.926741: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562db92b8b80 executing computations on platform Host. Devices:
2019-10-28 09:36:47.926837: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-28 09:36:47.928721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-28 09:36:47.928862: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-28 09:36:47.928949: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-28 09:36:47.929032: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-28 09:36:47.929113: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-28 09:36:47.929193: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-28 09:36:47.929276: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-28 09:36:47.929358: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-28 09:36:47.932514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-28 09:36:47.932642: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-28 09:36:47.936819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-28 09:36:47.936866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-28 09:36:47.936890: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-28 09:36:47.940573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-28 09:36:55.841377: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-28 09:36:56.052006: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 09:38:22.054 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 09:40:12.692 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 09:40:22.010 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 09:42:22.020 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 09:44:21.758 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 09:46:22.073 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 09:48:22.046 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 09:50:22.987 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 09:52:22.996 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 09:54:22.958 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 09:56:24.337 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 09:58:22.987 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 10:00:26.218 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 10:02:26.938 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 10:04:22.161 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 10:04:25.511 LabApp] 302 GET /notebooks/avgn_paper/notebooks/ (::1) 0.60ms
[I 10:04:25.546 LabApp] 302 GET /notebooks/avgn_paper/notebooks (::1) 1.19ms
[W 10:04:26.264 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 2.70ms referer=http://localhost:8187/tree/avgn_paper/notebooks
[I 10:05:20.943 LabApp] Starting buffering for 8a176c6a-8996-42d7-bccc-a9d6303bb7c0:f75844756af942678bf072059575eb38
[I 10:05:24.786 LabApp] Kernel shutdown: 8a176c6a-8996-42d7-bccc-a9d6303bb7c0
[W 10:05:56.028 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 1.52ms referer=http://localhost:8187/tree/avgn_paper/notebooks/4.0-clusters-vs-labels-metrics
[W 10:06:04.061 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 1.53ms referer=http://localhost:8187/tree/avgn_paper/notebooks/3.0-compare-clusters-vs-labels
[W 10:06:11.998 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 2.66ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/4.0-clusters-vs-labels-metrics/cassins-cluster-label-performance.ipynb
[I 10:06:13.198 LabApp] Kernel started: c8084708-8d0c-459b-8093-c8b72b3248ec
[W 10:06:14.838 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 1.52ms referer=http://localhost:8187/tree/avgn_paper/notebooks/5.0-visualize-transitions
[I 10:06:14.918 LabApp] Adapting from protocol version 5.1 (kernel c8084708-8d0c-459b-8093-c8b72b3248ec) to 5.3 (client).
[I 10:06:22.059 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[W 10:06:25.295 LabApp] Notebook avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-832-5.ipynb is not trusted
[W 10:06:26.995 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 1.97ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-832-5.ipynb
[I 10:06:31.758 LabApp] Kernel started: c7bfe510-943d-4b56-ac5a-407722096692
[I 10:06:33.206 LabApp] Adapting from protocol version 5.1 (kernel c7bfe510-943d-4b56-ac5a-407722096692) to 5.3 (client).
[I 10:08:20.618 LabApp] Saving file at /avgn_paper/notebooks/4.0-clusters-vs-labels-metrics/cassins-cluster-label-performance.ipynb
[I 10:08:22.168 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 10:08:49.986 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-832-5.ipynb
[W 10:08:49.991 LabApp] Notebook avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-project-umap-832-5.ipynb is not trusted
[I 10:10:21.850 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 10:12:23.021 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 10:13:31.139 LabApp] Starting buffering for c7bfe510-943d-4b56-ac5a-407722096692:486e4319db814dfe84772efd762cac2e
[I 10:13:31.757 LabApp] Starting buffering for c8084708-8d0c-459b-8093-c8b72b3248ec:b4d2d21ed037429e8f4853913a5cf06d
[I 10:14:22.079 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 10:14:54.681 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 10:16:23.274 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 10:16:55.208 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 10:18:22.070 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 10:18:54.677 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 10:20:22.092 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 10:20:54.682 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 10:22:22.099 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 10:22:54.928 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 10:24:22.200 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 10:24:54.702 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 10:25:55.215 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 10:26:22.150 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 10:28:22.084 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 10:28:54.796 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 10:30:22.115 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 10:32:25.021 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 10:34:22.098 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 10:36:22.097 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 10:38:23.053 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 10:40:23.002 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 10:42:23.064 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 10:44:22.113 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 10:46:23.297 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 10:48:25.581 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 10:50:23.048 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 10:52:23.022 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 10:54:23.029 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 10:56:23.075 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 10:58:23.067 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 11:00:23.115 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 11:02:23.128 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 11:04:24.708 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 11:06:23.036 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 11:08:23.030 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 11:10:23.049 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 11:12:23.088 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 11:14:23.101 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 11:16:23.084 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 11:18:23.043 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 11:20:21.901 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 11:22:23.116 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 11:24:23.152 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[W 11:25:26.046 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 1.64ms referer=http://localhost:8187/tree/avgn_paper/data/models
[I 11:25:30.142 LabApp] 302 GET /notebooks/avgn_paper/notebooks/6.0-neural-networks/ (::1) 0.59ms
[I 11:25:30.169 LabApp] 302 GET /notebooks/avgn_paper/notebooks/6.0-neural-networks (::1) 1.06ms
[W 11:25:30.949 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 1.76ms referer=http://localhost:8187/tree/avgn_paper/notebooks/6.0-neural-networks
[W 11:25:35.950 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb is not trusted
[W 11:25:37.092 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 1.58ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 11:25:37.110 LabApp] Adapting from protocol version 5.1 (kernel d9916fc0-f379-41c3-acdb-22feac30f803) to 5.3 (client).
[I 11:25:50.849 LabApp] Kernel interrupted: 611948cf-558c-4d3c-b741-a3cb59af520e
[I 11:26:22.162 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 11:27:38.060 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[W 11:27:38.061 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb is not trusted
[I 11:28:23.056 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 11:30:22.137 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 11:32:23.048 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 11:34:23.132 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 11:36:23.074 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 11:38:23.116 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 11:40:02.184 LabApp] Kernel interrupted: d9916fc0-f379-41c3-acdb-22feac30f803
[I 11:40:05.591 LabApp] Kernel interrupted: 611948cf-558c-4d3c-b741-a3cb59af520e
[I 11:40:21.889 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 11:42:23.085 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 11:44:23.097 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[W 11:47:58.920 LabApp] WebSocket ping timeout after 119975 ms.
[W 11:48:01.736 LabApp] WebSocket ping timeout after 119980 ms.
[W 11:48:01.894 LabApp] zmq message arrived on closed channel
[W 11:48:01.894 LabApp] zmq message arrived on closed channel
[W 11:48:02.267 LabApp] zmq message arrived on closed channel
[W 11:48:02.268 LabApp] zmq message arrived on closed channel
[W 11:48:02.638 LabApp] zmq message arrived on closed channel
[W 11:48:02.639 LabApp] zmq message arrived on closed channel
[W 11:48:03.011 LabApp] zmq message arrived on closed channel
[W 11:48:03.012 LabApp] zmq message arrived on closed channel
[W 11:48:03.390 LabApp] zmq message arrived on closed channel
[W 11:48:03.391 LabApp] zmq message arrived on closed channel
[W 11:48:03.773 LabApp] zmq message arrived on closed channel
[W 11:48:03.774 LabApp] zmq message arrived on closed channel
[W 11:48:04.136 LabApp] zmq message arrived on closed channel
[W 11:48:04.137 LabApp] zmq message arrived on closed channel
[W 11:48:04.504 LabApp] zmq message arrived on closed channel
[W 11:48:04.505 LabApp] zmq message arrived on closed channel
[W 11:48:04.873 LabApp] zmq message arrived on closed channel
[W 11:48:04.873 LabApp] zmq message arrived on closed channel
[W 11:48:05.248 LabApp] zmq message arrived on closed channel
[W 11:48:05.248 LabApp] zmq message arrived on closed channel
[W 11:48:05.624 LabApp] zmq message arrived on closed channel
[W 11:48:05.625 LabApp] zmq message arrived on closed channel
[W 11:48:05.998 LabApp] zmq message arrived on closed channel
[W 11:48:05.999 LabApp] zmq message arrived on closed channel
[W 11:48:06.368 LabApp] zmq message arrived on closed channel
[W 11:48:06.368 LabApp] zmq message arrived on closed channel
[W 11:48:06.735 LabApp] zmq message arrived on closed channel
[W 11:48:06.736 LabApp] zmq message arrived on closed channel
[I 11:48:06.737 LabApp] Starting buffering for 611948cf-558c-4d3c-b741-a3cb59af520e:e819fb585e874a088a33c9cb23095150
[W 11:48:07.113 LabApp] WebSocket ping timeout after 119981 ms.
[W 11:48:09.968 LabApp] WebSocket ping timeout after 119874 ms.
[I 11:48:12.115 LabApp] Starting buffering for d9916fc0-f379-41c3-acdb-22feac30f803:fdaeb9710d974f3c8a1e917d28865d0f
[I 11:48:14.970 LabApp] Starting buffering for 436aec5b-f7fe-403a-8294-fb6685340c8c:cb553906fa9e47ed8ea06797fbb995f7
[I 19:06:02.243 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 20:03:10.493 LabApp] Adapting from protocol version 5.1 (kernel d9916fc0-f379-41c3-acdb-22feac30f803) to 5.3 (client).
[I 20:03:10.494 LabApp] Restoring connection for d9916fc0-f379-41c3-acdb-22feac30f803:fdaeb9710d974f3c8a1e917d28865d0f
[I 20:03:14.716 LabApp] Adapting from protocol version 5.1 (kernel 611948cf-558c-4d3c-b741-a3cb59af520e) to 5.3 (client).
[I 20:03:14.718 LabApp] Restoring connection for 611948cf-558c-4d3c-b741-a3cb59af520e:e819fb585e874a088a33c9cb23095150
[I 20:03:14.718 LabApp] Replaying 83546 buffered messages
[W 20:03:16.769 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 20:03:18.167 LabApp] iopub messages resumed
[W 20:03:19.985 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 20:03:21.532 LabApp] iopub messages resumed
[W 20:03:23.348 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 20:03:24.896 LabApp] iopub messages resumed
[W 20:03:27.140 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 20:03:28.266 LabApp] iopub messages resumed
[W 20:03:29.876 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 20:03:31.423 LabApp] iopub messages resumed
[W 20:03:33.241 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 20:03:34.792 LabApp] iopub messages resumed
[W 20:03:36.605 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 20:03:38.152 LabApp] iopub messages resumed
[W 20:03:39.970 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 20:03:41.520 LabApp] iopub messages resumed
[W 20:03:43.338 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 20:03:44.882 LabApp] iopub messages resumed
[W 20:03:47.094 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 20:03:48.247 LabApp] iopub messages resumed
[W 20:03:48.980 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 20:03:49.380 LabApp] iopub messages resumed
[W 20:03:50.465 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 20:03:51.621 LabApp] iopub messages resumed
[W 20:03:52.353 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 20:03:52.751 LabApp] iopub messages resumed
[W 20:03:53.845 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[W 20:03:54.980 LabApp] iopub messages resumed
[W 20:03:55.713 LabApp] IOPub message rate exceeded.
    The notebook server will temporarily stop sending output
    to the client in order to avoid crashing it.
    To change this limit, set the config variable
    `--NotebookApp.iopub_msg_rate_limit`.
    
    Current values:
    NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
    NotebookApp.rate_limit_window=3.0 (secs)
    
[I 20:04:01.584 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[W 20:05:06.612 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 2.93ms referer=http://localhost:8187/tree/avgn_paper/data/models
[I 20:05:07.766 LabApp] Starting buffering for d9916fc0-f379-41c3-acdb-22feac30f803:fdaeb9710d974f3c8a1e917d28865d0f
[I 20:06:01.548 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[W 20:06:13.296 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.64ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/sober-bf-PCA-projections.ipynb
[I 20:06:15.686 LabApp] Kernel started: d5d75290-153c-4cd3-8cee-7e0f11e4a4ff
[W 20:06:16.851 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.08ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-umap-make-windows.ipynb
[I 20:06:17.899 LabApp] Adapting from protocol version 5.1 (kernel d5d75290-153c-4cd3-8cee-7e0f11e4a4ff) to 5.3 (client).
[I 20:06:17.974 LabApp] Kernel started: 8caa3d8a-d4ea-4e91-aeec-f07423784a9b
[W 20:06:18.051 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 1.98ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-umap-make-windows.ipynb
[I 20:06:18.923 LabApp] Adapting from protocol version 5.1 (kernel 8caa3d8a-d4ea-4e91-aeec-f07423784a9b) to 5.3 (client).
[I 20:08:21.247 LabApp] Saving file at /avgn_paper/notebooks/5.0-visualize-transitions/castellucci-mouse-umap-make-windows.ipynb
[I 20:27:34.208 LabApp] Starting buffering for 611948cf-558c-4d3c-b741-a3cb59af520e:e819fb585e874a088a33c9cb23095150
[I 20:27:34.286 LabApp] Adapting from protocol version 5.1 (kernel 611948cf-558c-4d3c-b741-a3cb59af520e) to 5.3 (client).
[I 20:27:34.287 LabApp] Restoring connection for 611948cf-558c-4d3c-b741-a3cb59af520e:e819fb585e874a088a33c9cb23095150
[I 20:27:36.989 LabApp] Starting buffering for 611948cf-558c-4d3c-b741-a3cb59af520e:e819fb585e874a088a33c9cb23095150
[I 20:27:41.966 LabApp] Kernel shutdown: 611948cf-558c-4d3c-b741-a3cb59af520e
[I 20:27:41.971 LabApp] Starting buffering for 8caa3d8a-d4ea-4e91-aeec-f07423784a9b:b4460adfd9aa45d381b836d54910bd50
[I 20:27:53.615 LabApp] Adapting from protocol version 5.1 (kernel 436aec5b-f7fe-403a-8294-fb6685340c8c) to 5.3 (client).
[I 20:27:53.616 LabApp] Restoring connection for 436aec5b-f7fe-403a-8294-fb6685340c8c:cb553906fa9e47ed8ea06797fbb995f7
[I 20:27:57.219 LabApp] 302 GET /notebooks/avgn_paper/notebooks/6.0-neural-networks/ (::1) 1.04ms
[I 20:27:57.245 LabApp] 302 GET /notebooks/avgn_paper/notebooks/6.0-neural-networks (::1) 2.02ms
[W 20:27:58.044 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 3.39ms referer=http://localhost:8187/tree/avgn_paper/notebooks/6.0-neural-networks
[W 20:28:06.559 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb is not trusted
[I 20:28:07.303 LabApp] Adapting from protocol version 5.1 (kernel d9916fc0-f379-41c3-acdb-22feac30f803) to 5.3 (client).
[W 20:28:07.326 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.06ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 20:28:25.706 LabApp] Starting buffering for d9916fc0-f379-41c3-acdb-22feac30f803:4b35666f9dc84c56ad6d6b937f1d0fbe
[I 20:28:26.282 LabApp] Kernel restarted: d9916fc0-f379-41c3-acdb-22feac30f803
[I 20:28:28.257 LabApp] Adapting from protocol version 5.1 (kernel d9916fc0-f379-41c3-acdb-22feac30f803) to 5.3 (client).
[I 20:28:28.258 LabApp] Restoring connection for d9916fc0-f379-41c3-acdb-22feac30f803:4b35666f9dc84c56ad6d6b937f1d0fbe
[I 20:28:28.258 LabApp] Replaying 6 buffered messages
2019-10-28 20:28:39.706029: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-28 20:28:42.285510: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-28 20:28:42.306569: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-28 20:28:42.308568: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-28 20:28:42.310112: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-28 20:28:42.330142: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-28 20:28:42.332235: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-28 20:28:42.333942: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-28 20:28:42.337746: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-28 20:28:42.339576: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-28 20:28:42.572456: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5559f28c7120 executing computations on platform CUDA. Devices:
2019-10-28 20:28:42.572546: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-28 20:28:42.578171: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-28 20:28:42.579967: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5559f299dbd0 executing computations on platform Host. Devices:
2019-10-28 20:28:42.580022: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-28 20:28:42.583655: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-28 20:28:42.583815: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-28 20:28:42.583856: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-28 20:28:42.583893: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-28 20:28:42.583929: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-28 20:28:42.583966: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-28 20:28:42.584003: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-28 20:28:42.584041: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-28 20:28:42.585525: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-28 20:28:42.585594: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-28 20:28:42.587469: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-28 20:28:42.587490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-28 20:28:42.587500: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-28 20:28:42.589297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-28 20:28:48.052648: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-28 20:28:48.236943: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 20:30:07.325 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 20:32:08.174 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 20:34:08.157 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 20:36:08.364 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 20:38:08.430 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 20:40:08.192 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 20:42:08.165 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 20:44:08.163 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 20:46:08.336 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 20:48:08.178 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 20:50:08.184 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 20:52:08.182 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 20:54:08.178 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 20:56:08.208 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 20:58:08.242 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 21:00:08.200 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 21:02:07.349 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 21:04:08.197 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 21:06:08.190 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 21:08:08.201 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 21:10:08.175 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 21:12:08.239 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 21:14:08.205 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 21:16:08.228 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 21:18:08.213 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 21:20:08.278 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 21:22:08.210 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 21:24:08.247 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 21:26:08.241 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 21:28:08.219 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 21:30:08.263 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 21:32:08.256 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 21:34:08.242 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 21:36:08.261 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 21:38:08.234 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 21:40:08.248 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 21:42:08.242 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 21:44:08.253 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 21:46:08.235 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 21:48:08.230 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 21:50:08.271 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 21:52:08.246 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 21:54:08.266 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 21:56:08.305 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 21:58:08.270 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 22:00:08.297 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 22:02:08.244 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 22:04:08.294 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 22:06:08.273 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 22:08:08.258 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 22:10:08.258 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 22:12:08.275 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 22:14:08.265 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 22:16:08.271 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 22:18:08.250 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 22:20:08.322 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 22:22:08.300 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 22:24:08.276 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 22:26:08.267 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 22:28:08.284 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 22:30:08.292 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 22:32:08.262 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 22:34:08.266 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 22:36:08.288 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 22:38:08.313 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 22:40:08.274 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 22:42:08.279 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 22:44:08.311 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 22:46:08.401 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 22:48:08.328 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 22:50:08.302 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 22:52:08.289 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 22:54:08.296 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 22:56:08.286 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 22:58:08.279 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 23:00:08.305 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 23:02:08.341 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 23:04:08.321 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 23:06:08.303 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 23:08:08.346 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 23:10:08.327 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 23:12:08.297 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 23:14:08.342 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 23:16:08.306 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 23:18:08.307 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 23:20:08.341 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 23:22:08.315 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 23:24:08.322 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 23:26:08.340 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 23:28:08.320 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 23:30:08.350 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 23:32:08.333 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 23:34:08.328 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 23:36:08.338 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 23:38:08.332 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 23:40:08.367 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 23:42:08.353 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 23:44:08.330 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 23:46:08.350 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 23:48:08.347 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 23:50:08.340 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 23:52:08.335 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 23:54:08.347 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 23:56:08.343 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 23:58:07.560 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 00:00:08.399 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 00:02:08.375 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 00:04:08.354 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 00:06:08.369 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 00:08:08.369 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 00:10:08.353 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 00:12:08.355 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 00:14:08.374 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 00:16:08.369 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 00:18:08.367 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 00:20:08.371 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 00:22:08.368 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 00:24:08.374 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 00:26:07.735 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 00:28:08.378 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 00:30:08.378 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 00:32:08.364 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 00:34:07.403 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 00:36:08.480 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 00:38:08.373 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 00:40:08.394 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 00:42:08.400 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 00:44:08.414 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 00:46:08.414 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 00:48:08.395 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 00:50:08.401 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 00:52:08.411 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 00:54:08.400 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 00:56:08.391 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 00:58:09.872 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[W 08:51:53.617 LabApp] WebSocket ping timeout after 119977 ms.
[W 08:51:58.258 LabApp] WebSocket ping timeout after 119939 ms.
[I 08:51:58.619 LabApp] Starting buffering for 436aec5b-f7fe-403a-8294-fb6685340c8c:cb553906fa9e47ed8ea06797fbb995f7
[I 08:52:03.260 LabApp] Starting buffering for d9916fc0-f379-41c3-acdb-22feac30f803:4b35666f9dc84c56ad6d6b937f1d0fbe
[I 20:40:26.542 LabApp] 302 GET / (::1) 1.85ms
[I 20:40:29.168 LabApp] Build is up to date
[W 20:40:29.366 LabApp] 404 GET /api/contents/tsainbur/Projects/github_repos/GAIA-simple/gaia_2d/notebooks/GAIA_blobs.ipynb?content=0&1572493229328 (::1): No such file or directory: tsainbur/Projects/github_repos/GAIA-simple/gaia_2d/notebooks/GAIA_blobs.ipynb
[W 20:40:29.366 LabApp] No such file or directory: tsainbur/Projects/github_repos/GAIA-simple/gaia_2d/notebooks/GAIA_blobs.ipynb
[W 20:40:29.367 LabApp] 404 GET /api/contents/tsainbur/Projects/github_repos/GAIA-simple/gaia_2d/notebooks/GAIA_blobs.ipynb?content=0&1572493229328 (::1) 2.91ms referer=http://localhost:8187/lab?
[W 20:40:29.367 LabApp] 404 GET /api/contents/tsainbur/Projects/github_repos/GAIA-simple/gaia_2d/gaia?1572493229327 (::1): No such file or directory: tsainbur/Projects/github_repos/GAIA-simple/gaia_2d/gaia
[W 20:40:29.368 LabApp] No such file or directory: tsainbur/Projects/github_repos/GAIA-simple/gaia_2d/gaia
[W 20:40:29.368 LabApp] 404 GET /api/contents/tsainbur/Projects/github_repos/GAIA-simple/gaia_2d/gaia?1572493229327 (::1) 3.33ms referer=http://localhost:8187/lab?
[W 20:40:29.370 LabApp] 404 GET /api/contents/tsainbur/Projects/github_repos/GAIA-simple/gaia_2d/gaia/gaia.py?content=0&1572493229328 (::1): No such file or directory: tsainbur/Projects/github_repos/GAIA-simple/gaia_2d/gaia/gaia.py
[W 20:40:29.370 LabApp] No such file or directory: tsainbur/Projects/github_repos/GAIA-simple/gaia_2d/gaia/gaia.py
[W 20:40:29.371 LabApp] 404 GET /api/contents/tsainbur/Projects/github_repos/GAIA-simple/gaia_2d/gaia/gaia.py?content=0&1572493229328 (::1) 1.90ms referer=http://localhost:8187/lab?
[W 20:40:31.233 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 3.85ms referer=http://localhost:8187/tree
[W 20:40:42.191 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 4.31ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 20:40:42.290 LabApp] Adapting from protocol version 5.1 (kernel 554d832d-f579-4e1b-8f2a-a7de5a1f2453) to 5.3 (client).
[W 20:40:42.759 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.56ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 20:40:42.765 LabApp] Adapting from protocol version 5.1 (kernel d9916fc0-f379-41c3-acdb-22feac30f803) to 5.3 (client).
[W 20:40:42.844 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 2.38ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 20:41:06.806 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[W 20:41:49.085 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 11.71ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 20:41:49.092 LabApp] Adapting from protocol version 5.1 (kernel 00cb76cf-9ff9-45d7-bf9b-ca5e71a3b40a) to 5.3 (client).
[I 20:42:45.894 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 20:42:46.310 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 20:43:51.049 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 20:44:17.954 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 20:44:44.109 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 20:45:17.248 LabApp] Starting buffering for d9916fc0-f379-41c3-acdb-22feac30f803:e519463eb0f848e3b40dcfb67512f5ba
[I 20:45:19.981 LabApp] Kernel shutdown: d9916fc0-f379-41c3-acdb-22feac30f803
[I 20:46:28.040 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[E 20:46:29.270 LabApp] Exception restarting kernel
    Traceback (most recent call last):
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/notebook/services/kernels/handlers.py", line 83, in post
        yield maybe_future(km.restart_kernel(kernel_id))
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/tornado/gen.py", line 735, in run
        value = future.result()
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/tornado/gen.py", line 209, in wrapper
        yielded = next(result)
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/notebook/services/kernels/kernelmanager.py", line 307, in restart_kernel
        self._check_kernel_id(kernel_id)
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/notebook/services/kernels/kernelmanager.py", line 387, in _check_kernel_id
        raise web.HTTPError(404, u'Kernel does not exist: %s' % kernel_id)
    tornado.web.HTTPError: HTTP 404: Not Found (Kernel does not exist: d9916fc0-f379-41c3-acdb-22feac30f803)
[E 20:46:29.272 LabApp] {
      "Host": "localhost:8187",
      "Connection": "keep-alive",
      "Content-Length": "0",
      "Accept": "application/json, text/javascript, */*; q=0.01",
      "Origin": "http://localhost:8187",
      "X-Requested-With": "XMLHttpRequest",
      "X-Xsrftoken": "2|2b997e67|29d4ea20755e92079558d090866cac7e|1571165215",
      "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.70 Safari/537.36",
      "Sec-Fetch-Site": "same-origin",
      "Sec-Fetch-Mode": "cors",
      "Referer": "http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb",
      "Accept-Encoding": "gzip, deflate, br",
      "Accept-Language": "en-US,en;q=0.9,fr;q=0.8",
      "Cookie": "_ga=GA1.1.2135320950.1566148815; username-localhost-8195=\"2|1:0|10:1570831591|23:username-localhost-8195|44:Y2Q0M2Y0YjJhMDQxNDQwZThhOGNjZTdhNDFiNDNkNjI=|4fc2d73bc3298178be788038ba7812e8e7e1ca4ae1891ffcc42a6bd3445055ab\"; _xsrf=2|2b997e67|29d4ea20755e92079558d090866cac7e|1571165215; username-localhost-8186=\"2|1:0|10:1572148972|23:username-localhost-8186|44:MjAwMmFlOWIxYTRhNDc4ZmFiNDAzOTg3ODBmYzEyOTQ=|c0f3007a6fdd6628418763a8293ba019d9531ba148601913203f1e0121fd51ea\"; username-localhost-8187=\"2|1:0|10:1572493229|23:username-localhost-8187|44:ZGY4ZGEyMzQ2ZTRlNDUzOGExMTczY2U0OTA0MmFkOTU=|3275349390afc9e6baa1f6f9ee83e54d4eb18ebc1a9c62739a25d81664456c6b\""
    }
[E 20:46:29.272 LabApp] 500 POST /api/kernels/d9916fc0-f379-41c3-acdb-22feac30f803/restart (::1) 2.80ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[W 20:46:29.301 LabApp] 404 DELETE /api/sessions/2c1265e3-1c19-44b7-9110-1fca83ffd01b (::1): Session not found: session_id='2c1265e3-1c19-44b7-9110-1fca83ffd01b'
[W 20:46:29.301 LabApp] Session not found: session_id='2c1265e3-1c19-44b7-9110-1fca83ffd01b'
[W 20:46:29.302 LabApp] 404 DELETE /api/sessions/2c1265e3-1c19-44b7-9110-1fca83ffd01b (::1) 2.68ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 20:46:29.513 LabApp] Kernel started: 63ea2550-e76e-4850-9bc1-580632af6ecc
[I 20:46:32.397 LabApp] Adapting from protocol version 5.1 (kernel 63ea2550-e76e-4850-9bc1-580632af6ecc) to 5.3 (client).
[I 20:46:44.060 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
2019-10-30 20:46:46.274101: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-30 20:46:48.959269: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-30 20:46:48.970048: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 20:46:48.971917: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 20:46:48.973394: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 20:46:48.982458: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 20:46:48.984362: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 20:46:48.985992: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 20:46:48.989452: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 20:46:48.991164: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 20:46:49.240722: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fa55f3f6a0 executing computations on platform CUDA. Devices:
2019-10-30 20:46:49.240799: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-30 20:46:49.246262: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-30 20:46:49.248193: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fa56016110 executing computations on platform Host. Devices:
2019-10-30 20:46:49.248226: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-30 20:46:49.249309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-30 20:46:49.249433: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 20:46:49.249479: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 20:46:49.249537: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 20:46:49.249581: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 20:46:49.249623: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 20:46:49.249666: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 20:46:49.249708: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 20:46:49.251368: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 20:46:49.251443: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 20:46:49.254180: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-30 20:46:49.254201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-30 20:46:49.254213: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-30 20:46:49.256207: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-30 20:46:55.003791: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 20:46:55.267835: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 20:46:58.079 LabApp] Kernel interrupted: 63ea2550-e76e-4850-9bc1-580632af6ecc
[I 20:48:44.311 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 20:49:02.217 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 20:50:49.335 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 20:52:43.931 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 20:52:45.457 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 20:54:44.363 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 20:55:51.878 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 20:56:43.880 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 20:57:51.998 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 20:58:44.121 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 20:58:56.023 LabApp] Starting buffering for 63ea2550-e76e-4850-9bc1-580632af6ecc:e519463eb0f848e3b40dcfb67512f5ba
[I 20:58:59.036 LabApp] Kernel shutdown: 63ea2550-e76e-4850-9bc1-580632af6ecc
2019-10-30 21:01:02.623149: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-30 21:01:05.205044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
2019-10-30 21:01:05.216246: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 21:01:05.218255: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 21:01:05.223428: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 21:01:05.231361: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 21:01:05.234569: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 21:01:05.236463: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 21:01:05.240357: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 21:01:05.242169: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 21:01:05.410095: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ade96b43e0 executing computations on platform CUDA. Devices:
2019-10-30 21:01:05.410165: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K40c, Compute Capability 3.5
2019-10-30 21:01:05.414544: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-30 21:01:05.416389: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ade978ae40 executing computations on platform Host. Devices:
2019-10-30 21:01:05.416422: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-30 21:01:05.418116: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
2019-10-30 21:01:05.418290: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 21:01:05.418375: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 21:01:05.418453: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 21:01:05.418530: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 21:01:05.418609: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 21:01:05.418687: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 21:01:05.418765: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 21:01:05.421794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 21:01:05.421927: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 21:01:05.424958: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-30 21:01:05.424984: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-30 21:01:05.424998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-30 21:01:05.427418: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10794 MB memory) -> physical GPU (device: 0, name: Tesla K40c, pci bus id: 0000:02:00.0, compute capability: 3.5)
2019-10-30 21:01:08.171273: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 21:01:08.362589: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 21:01:18.853 LabApp] Kernel interrupted: 00cb76cf-9ff9-45d7-bf9b-ca5e71a3b40a
[I 21:01:50.686 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 21:03:51.924 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-MDSAE.ipynb
[I 21:05:02.920 LabApp] 302 GET /notebooks/avgn_paper/notebooks/6.0-neural-networks/ (::1) 1.27ms
[I 21:05:02.945 LabApp] 302 GET /notebooks/avgn_paper/notebooks/6.0-neural-networks (::1) 2.40ms
[W 21:05:04.682 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 3.40ms referer=http://localhost:8187/tree/avgn_paper/notebooks/6.0-neural-networks
2019-10-30 21:05:23.552756: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-30 21:05:23.990283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-30 21:05:23.998313: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 21:05:24.001229: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 21:05:24.003472: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 21:05:24.016519: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 21:05:24.019470: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 21:05:24.021886: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 21:05:24.027610: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 21:05:24.029522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 21:05:24.216899: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562a70c5f170 executing computations on platform CUDA. Devices:
2019-10-30 21:05:24.216995: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K40c, Compute Capability 3.5
2019-10-30 21:05:24.222944: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-30 21:05:24.224789: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562a70d35c20 executing computations on platform Host. Devices:
2019-10-30 21:05:24.224850: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-30 21:05:24.226418: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-30 21:05:24.226561: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 21:05:24.226635: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 21:05:24.226704: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 21:05:24.226774: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 21:05:24.226843: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 21:05:24.226913: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 21:05:24.226983: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 21:05:24.229086: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 21:05:24.229204: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 21:05:24.232494: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-30 21:05:24.232554: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-30 21:05:24.232577: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-30 21:05:24.234914: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 126 MB memory) -> physical GPU (device: 0, name: Tesla K40c, pci bus id: 0000:03:00.0, compute capability: 3.5)
[I 21:05:38.877 LabApp] Starting buffering for 00cb76cf-9ff9-45d7-bf9b-ca5e71a3b40a:170a0f237def46bf86e7856a48328f6c
[I 21:05:41.736 LabApp] Kernel shutdown: 00cb76cf-9ff9-45d7-bf9b-ca5e71a3b40a
[W 21:05:42.381 LabApp] 404 DELETE /api/sessions/3a502ef3-2ab7-442f-8fbd-5caf5a6be7ca (::1): Session not found: session_id='3a502ef3-2ab7-442f-8fbd-5caf5a6be7ca'
[W 21:05:42.381 LabApp] Session not found: session_id='3a502ef3-2ab7-442f-8fbd-5caf5a6be7ca'
[W 21:05:42.382 LabApp] 404 DELETE /api/sessions/3a502ef3-2ab7-442f-8fbd-5caf5a6be7ca (::1) 2.48ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-VAE.ipynb
[I 21:05:55.251 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 21:05:56.480 LabApp] Starting buffering for 554d832d-f579-4e1b-8f2a-a7de5a1f2453:6a3916b34ec24c91bea72ffc9bd09451
[I 21:05:57.662 LabApp] Kernel restarted: 554d832d-f579-4e1b-8f2a-a7de5a1f2453
[I 21:05:59.849 LabApp] Adapting from protocol version 5.1 (kernel 554d832d-f579-4e1b-8f2a-a7de5a1f2453) to 5.3 (client).
[I 21:05:59.850 LabApp] Restoring connection for 554d832d-f579-4e1b-8f2a-a7de5a1f2453:6a3916b34ec24c91bea72ffc9bd09451
[I 21:05:59.850 LabApp] Replaying 6 buffered messages
2019-10-30 21:06:07.909105: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-30 21:06:10.547385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-30 21:06:10.572744: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 21:06:10.574685: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 21:06:10.576054: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 21:06:10.591435: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 21:06:10.593290: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 21:06:10.594865: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 21:06:10.598728: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 21:06:10.605741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 21:06:10.862750: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560a9a5c89e0 executing computations on platform CUDA. Devices:
2019-10-30 21:06:10.862820: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-30 21:06:10.869594: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-30 21:06:10.872194: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560a9a69f4a0 executing computations on platform Host. Devices:
2019-10-30 21:06:10.872237: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-30 21:06:10.873448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-30 21:06:10.873574: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 21:06:10.873627: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 21:06:10.873676: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 21:06:10.873724: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 21:06:10.873772: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 21:06:10.873821: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 21:06:10.873871: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 21:06:10.875996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 21:06:10.876080: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 21:06:10.878651: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-30 21:06:10.878677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-30 21:06:10.878692: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-30 21:06:10.881150: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-30 21:06:13.951032: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 21:06:14.889650: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
[I 21:06:18.610 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[W 21:07:23.133 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 2.25ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[W 21:07:23.986 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 1.81ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 21:07:23.991 LabApp] Adapting from protocol version 5.1 (kernel 68fe739f-0fae-442f-860e-d943da609e51) to 5.3 (client).
[I 21:08:55.896 LabApp] Adapting from protocol version 5.1 (kernel 436aec5b-f7fe-403a-8294-fb6685340c8c) to 5.3 (client).
[W 21:08:55.930 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 1.77ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 21:09:26.497 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 21:10:43.658 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 21:10:56.300 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 21:12:43.766 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 21:12:56.283 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 21:14:56.354 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 21:16:43.495 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 21:16:56.400 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 21:18:43.549 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 21:18:57.089 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 21:20:57.036 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 21:22:43.546 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 21:22:56.835 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 21:23:10.837 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 21:24:43.623 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 21:24:50.026 LabApp] Kernel interrupted: 436aec5b-f7fe-403a-8294-fb6685340c8c
[I 21:24:57.141 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 21:26:44.766 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 21:26:57.661 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 21:30:44.337 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 21:30:48.378 LabApp] Starting buffering for 436aec5b-f7fe-403a-8294-fb6685340c8c:36def891d90c4b138b049f6480a9ee4f
[I 21:30:51.927 LabApp] Kernel shutdown: 436aec5b-f7fe-403a-8294-fb6685340c8c
[I 21:30:57.486 LabApp] 302 GET /notebooks/avgn_paper/notebooks/6.0-neural-networks/ (::1) 1.01ms
[I 21:30:57.516 LabApp] 302 GET /notebooks/avgn_paper/notebooks/6.0-neural-networks (::1) 2.35ms
[W 21:30:58.238 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 1.80ms referer=http://localhost:8187/tree/avgn_paper/notebooks/6.0-neural-networks
[I 21:31:16.062 LabApp] Kernel started: e0392896-a444-48dd-95a2-a1fbf2fad18c
[W 21:31:16.114 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 2.60ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 21:31:18.640 LabApp] Adapting from protocol version 5.1 (kernel e0392896-a444-48dd-95a2-a1fbf2fad18c) to 5.3 (client).
2019-10-30 21:31:59.208235: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-30 21:32:03.599291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-30 21:32:03.606670: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 21:32:03.608437: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 21:32:03.609833: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 21:32:03.620183: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 21:32:03.622029: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 21:32:03.623655: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 21:32:03.627044: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 21:32:03.628673: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 21:32:03.777151: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5596e4f271b0 executing computations on platform CUDA. Devices:
2019-10-30 21:32:03.777217: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K40c, Compute Capability 3.5
2019-10-30 21:32:03.780958: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-30 21:32:03.781944: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5596e4ffdc60 executing computations on platform Host. Devices:
2019-10-30 21:32:03.781981: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-30 21:32:03.782850: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-30 21:32:03.782921: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 21:32:03.782956: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 21:32:03.782989: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 21:32:03.783021: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 21:32:03.783054: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 21:32:03.783086: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 21:32:03.783132: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 21:32:03.785668: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 21:32:03.785785: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 21:32:03.787953: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-30 21:32:03.787976: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-30 21:32:03.787988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-30 21:32:03.790166: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10794 MB memory) -> physical GPU (device: 0, name: Tesla K40c, pci bus id: 0000:03:00.0, compute capability: 3.5)
2019-10-30 21:32:10.314886: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-30 21:32:10.367954: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 21:32:10.537800: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 21:32:44.811 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 21:33:17.435 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 21:33:36.310 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 21:34:57.621 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 21:35:18.600 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 21:36:44.973 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 21:37:18.132 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 21:38:44.493 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 21:39:17.844 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 21:41:18.684 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
2019-10-30 21:42:21.699911: W tensorflow/core/framework/op_kernel.cc:1546] OP_REQUIRES failed at strided_slice_op.cc:108 : Invalid argument: slice index 109 of dimension 0 out of bounds.
2019-10-30 21:42:27.977825: W tensorflow/core/framework/op_kernel.cc:1546] OP_REQUIRES failed at strided_slice_op.cc:108 : Invalid argument: slice index 80 of dimension 0 out of bounds.
2019-10-30 21:42:34.290135: W tensorflow/core/framework/op_kernel.cc:1546] OP_REQUIRES failed at strided_slice_op.cc:108 : Invalid argument: slice index 200 of dimension 0 out of bounds.
[I 21:42:44.768 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 21:43:18.302 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 21:44:39.099 LabApp] Starting buffering for e0392896-a444-48dd-95a2-a1fbf2fad18c:072a087c2cf54eafaf42fa2f0e0080ff
[I 21:44:41.915 LabApp] Kernel shutdown: e0392896-a444-48dd-95a2-a1fbf2fad18c
[I 21:44:44.197 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 21:45:18.599 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 21:45:50.663 LabApp] Kernel interrupted: 554d832d-f579-4e1b-8f2a-a7de5a1f2453
2019-10-30 21:46:19.811572: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-30 21:46:24.232767: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-30 21:46:24.244134: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 21:46:24.246368: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 21:46:24.247938: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 21:46:24.260219: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 21:46:24.262261: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 21:46:24.263983: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 21:46:24.267786: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 21:46:24.269705: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 21:46:24.444357: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fa6a0b77e0 executing computations on platform CUDA. Devices:
2019-10-30 21:46:24.444408: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K40c, Compute Capability 3.5
2019-10-30 21:46:24.448360: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-30 21:46:24.449480: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fa6a18e290 executing computations on platform Host. Devices:
2019-10-30 21:46:24.449509: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-30 21:46:24.450490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-30 21:46:24.450577: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 21:46:24.450621: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 21:46:24.450662: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 21:46:24.450716: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 21:46:24.450758: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 21:46:24.450799: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 21:46:24.450841: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 21:46:24.452733: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 21:46:24.452800: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 21:46:24.455479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-30 21:46:24.455525: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-30 21:46:24.455548: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-30 21:46:24.458071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10794 MB memory) -> physical GPU (device: 0, name: Tesla K40c, pci bus id: 0000:03:00.0, compute capability: 3.5)
2019-10-30 21:46:26.573965: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 21:46:26.760945: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 21:46:35.438 LabApp] Kernel interrupted: 68fe739f-0fae-442f-860e-d943da609e51
[I 21:46:44.474 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 21:47:14.908 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 21:48:20.701 LabApp] Starting buffering for 68fe739f-0fae-442f-860e-d943da609e51:1a1eb9501a6642578cbe93e5cfcadaac
[I 21:48:23.400 LabApp] Kernel restarted: 68fe739f-0fae-442f-860e-d943da609e51
[I 21:48:25.243 LabApp] Adapting from protocol version 5.1 (kernel 68fe739f-0fae-442f-860e-d943da609e51) to 5.3 (client).
[I 21:48:25.244 LabApp] Restoring connection for 68fe739f-0fae-442f-860e-d943da609e51:1a1eb9501a6642578cbe93e5cfcadaac
[I 21:48:25.244 LabApp] Replaying 6 buffered messages
2019-10-30 21:48:36.207652: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-30 21:48:40.617736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-30 21:48:40.618662: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 21:48:40.620734: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 21:48:40.622144: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 21:48:40.622819: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 21:48:40.624682: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 21:48:40.626187: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 21:48:40.629607: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 21:48:40.631270: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 21:48:40.789730: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5557b74016d0 executing computations on platform CUDA. Devices:
2019-10-30 21:48:40.789791: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K40c, Compute Capability 3.5
2019-10-30 21:48:40.793119: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-30 21:48:40.794723: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5557b74d8140 executing computations on platform Host. Devices:
2019-10-30 21:48:40.794756: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-30 21:48:40.796297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-30 21:48:40.796448: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 21:48:40.796490: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 21:48:40.796527: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 21:48:40.796565: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 21:48:40.796602: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 21:48:40.796660: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 21:48:40.796743: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 21:48:40.799611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 21:48:40.799739: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 21:48:40.802002: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-30 21:48:40.802033: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-30 21:48:40.802044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-30 21:48:40.804068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10794 MB memory) -> physical GPU (device: 0, name: Tesla K40c, pci bus id: 0000:03:00.0, compute capability: 3.5)
2019-10-30 21:48:42.900635: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 21:48:43.090797: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 21:49:31.549 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 21:50:44.245 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 21:51:24.892 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 21:52:44.624 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 21:54:44.231 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 21:55:24.637 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 21:58:44.209 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[W 21:59:22.976 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb is not trusted
[W 21:59:23.831 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 2.68ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[I 21:59:23.845 LabApp] Adapting from protocol version 5.1 (kernel 1c23d551-7d11-4d02-ac6c-999284268760) to 5.3 (client).
[I 21:59:24.702 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[W 21:59:25.120 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 1.79ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
2019-10-30 21:59:55.187749: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-30 21:59:58.136355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
2019-10-30 21:59:58.156480: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 21:59:58.158408: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 21:59:58.159929: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 21:59:58.183185: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 21:59:58.185219: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 21:59:58.186909: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 21:59:58.190645: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 21:59:58.192400: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 21:59:58.341708: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f4449f9f80 executing computations on platform CUDA. Devices:
2019-10-30 21:59:58.341832: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K40c, Compute Capability 3.5
2019-10-30 21:59:58.347486: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-30 21:59:58.349290: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f444ad0a90 executing computations on platform Host. Devices:
2019-10-30 21:59:58.349323: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-30 21:59:58.350344: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:02:00.0
2019-10-30 21:59:58.350433: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 21:59:58.350476: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 21:59:58.350518: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 21:59:58.350558: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 21:59:58.350599: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 21:59:58.350640: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 21:59:58.350682: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 21:59:58.352324: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 21:59:58.352389: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 21:59:58.354461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-30 21:59:58.354494: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-30 21:59:58.354506: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-30 21:59:58.356563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10794 MB memory) -> physical GPU (device: 0, name: Tesla K40c, pci bus id: 0000:02:00.0, compute capability: 3.5)
2019-10-30 22:00:00.422698: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 22:00:00.609866: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 22:00:44.191 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 22:01:15.748 LabApp] Kernel started: 05dbaa32-f34d-4797-9f83-6084409786a0
[W 22:01:15.839 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 2.09ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[W 22:01:16.019 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 2.22ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 22:01:18.274 LabApp] Adapting from protocol version 5.1 (kernel 05dbaa32-f34d-4797-9f83-6084409786a0) to 5.3 (client).
[W 22:01:22.016 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 1.67ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-VAEGAN-128.ipynb
[I 22:01:22.614 LabApp] Kernel started: aec916f2-f60a-47e4-a889-1610dc8bc414
[W 22:01:22.765 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 1.92ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-VAEGAN-128.ipynb
[I 22:01:24.116 LabApp] Adapting from protocol version 5.1 (kernel aec916f2-f60a-47e4-a889-1610dc8bc414) to 5.3 (client).
[I 22:01:25.835 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[W 22:01:25.836 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb is not trusted
2019-10-30 22:01:46.279760: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-30 22:01:46.701684: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-30 22:01:46.705902: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:01:46.708226: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 22:01:46.710044: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 22:01:46.717264: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 22:01:46.719800: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 22:01:46.721978: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 22:01:46.727119: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 22:01:46.729783: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 22:01:46.941789: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5624cebda5e0 executing computations on platform CUDA. Devices:
2019-10-30 22:01:46.941837: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-30 22:01:46.945224: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-30 22:01:46.946595: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5624cecb10c0 executing computations on platform Host. Devices:
2019-10-30 22:01:46.946629: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-30 22:01:46.947652: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-30 22:01:46.947729: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:01:46.947768: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 22:01:46.947805: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 22:01:46.947842: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 22:01:46.947879: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 22:01:46.947916: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 22:01:46.947953: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 22:01:46.949720: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 22:01:46.949778: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:01:46.951817: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-30 22:01:46.951838: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-30 22:01:46.951849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-30 22:01:46.953950: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-30 22:02:04.366085: W tensorflow/core/common_runtime/bfc_allocator.cc:314] Allocator (GPU_0_bfc) ran out of memory trying to allocate 7.88GiB (rounded to 8456241152).  Current allocation summary follows.
2019-10-30 22:02:04.366190: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (256): 	Total Chunks: 5, Chunks in use: 5. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 772B client-requested in use in bin.
2019-10-30 22:02:04.366208: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (512): 	Total Chunks: 2, Chunks in use: 2. 1.0KiB allocated for chunks. 1.0KiB in use in bin. 1.0KiB client-requested in use in bin.
2019-10-30 22:02:04.366222: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (1024): 	Total Chunks: 7, Chunks in use: 7. 8.8KiB allocated for chunks. 8.8KiB in use in bin. 7.3KiB client-requested in use in bin.
2019-10-30 22:02:04.366234: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (2048): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-30 22:02:04.366245: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (4096): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-30 22:02:04.366256: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (8192): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-30 22:02:04.366267: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (16384): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-30 22:02:04.366296: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (32768): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-30 22:02:04.366311: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (65536): 	Total Chunks: 3, Chunks in use: 2. 216.0KiB allocated for chunks. 144.0KiB in use in bin. 144.0KiB client-requested in use in bin.
2019-10-30 22:02:04.366324: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (131072): 	Total Chunks: 1, Chunks in use: 0. 138.2KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-30 22:02:04.366336: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (262144): 	Total Chunks: 4, Chunks in use: 2. 1.27MiB allocated for chunks. 576.0KiB in use in bin. 576.0KiB client-requested in use in bin.
2019-10-30 22:02:04.366347: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (524288): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-30 22:02:04.366359: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (1048576): 	Total Chunks: 4, Chunks in use: 2. 5.06MiB allocated for chunks. 2.25MiB in use in bin. 2.25MiB client-requested in use in bin.
2019-10-30 22:02:04.366370: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (2097152): 	Total Chunks: 2, Chunks in use: 2. 4.50MiB allocated for chunks. 4.50MiB in use in bin. 4.50MiB client-requested in use in bin.
2019-10-30 22:02:04.366381: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-30 22:02:04.366391: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (8388608): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-30 22:02:04.366402: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-30 22:02:04.366413: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (33554432): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-30 22:02:04.366423: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (67108864): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-30 22:02:04.366434: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-30 22:02:04.366446: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (268435456): 	Total Chunks: 2, Chunks in use: 1. 11.15GiB allocated for chunks. 7.88GiB in use in bin. 7.88GiB client-requested in use in bin.
2019-10-30 22:02:04.366457: I tensorflow/core/common_runtime/bfc_allocator.cc:780] Bin for 7.88GiB was 256.00MiB, Chunk State: 
2019-10-30 22:02:04.366474: I tensorflow/core/common_runtime/bfc_allocator.cc:786]   Size: 3.27GiB | Requested Size: 0B | in_use: 0 | bin_num: 20, prev:   Size: 7.88GiB | Requested Size: 7.88GiB | in_use: 1 | bin_num: -1
2019-10-30 22:02:04.366485: I tensorflow/core/common_runtime/bfc_allocator.cc:793] Next region of size 11982716928
2019-10-30 22:02:04.366497: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7fc708000000 next 1 of size 1280
2019-10-30 22:02:04.366506: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7fc708000500 next 2 of size 256
2019-10-30 22:02:04.366515: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7fc708000600 next 3 of size 256
2019-10-30 22:02:04.366524: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7fc708000700 next 6 of size 256
2019-10-30 22:02:04.366539: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7fc708000800 next 9 of size 512
2019-10-30 22:02:04.366549: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7fc708000a00 next 4 of size 1536
2019-10-30 22:02:04.366559: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7fc708001000 next 5 of size 1280
2019-10-30 22:02:04.366568: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7fc708001500 next 16 of size 1024
2019-10-30 22:02:04.366577: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7fc708001900 next 18 of size 1024
2019-10-30 22:02:04.366586: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7fc708001d00 next 19 of size 256
2019-10-30 22:02:04.366595: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7fc708001e00 next 24 of size 256
2019-10-30 22:02:04.366604: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7fc708001f00 next 27 of size 512
2019-10-30 22:02:04.366613: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7fc708002100 next 20 of size 1536
2019-10-30 22:02:04.366622: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7fc708002700 next 21 of size 1280
2019-10-30 22:02:04.366631: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7fc708002c00 next 7 of size 141568
2019-10-30 22:02:04.366641: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7fc708025500 next 8 of size 73728
2019-10-30 22:02:04.366649: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7fc708037500 next 22 of size 73728
2019-10-30 22:02:04.366658: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7fc708049500 next 23 of size 73728
2019-10-30 22:02:04.366667: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7fc70805b500 next 10 of size 442368
2019-10-30 22:02:04.366677: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7fc7080c7500 next 11 of size 294912
2019-10-30 22:02:04.366686: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7fc70810f500 next 25 of size 294912
2019-10-30 22:02:04.366695: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7fc708157500 next 26 of size 294912
2019-10-30 22:02:04.366704: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7fc70819f500 next 13 of size 1769472
2019-10-30 22:02:04.366713: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7fc70834f500 next 14 of size 1179648
2019-10-30 22:02:04.366722: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7fc70846f500 next 28 of size 1179648
2019-10-30 22:02:04.366730: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7fc70858f500 next 12 of size 1179648
2019-10-30 22:02:04.366740: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7fc7086af500 next 15 of size 2359296
2019-10-30 22:02:04.366749: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7fc7088ef500 next 17 of size 2359296
2019-10-30 22:02:04.366758: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7fc708b2f500 next 29 of size 8456241152
2019-10-30 22:02:04.366767: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7fc900baf500 next 18446744073709551615 of size 3514747648
2019-10-30 22:02:04.366775: I tensorflow/core/common_runtime/bfc_allocator.cc:809]      Summary of in-use Chunks by size: 
2019-10-30 22:02:04.366788: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 5 Chunks of size 256 totalling 1.2KiB
2019-10-30 22:02:04.366799: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 512 totalling 1.0KiB
2019-10-30 22:02:04.366809: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 1024 totalling 2.0KiB
2019-10-30 22:02:04.366820: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 3 Chunks of size 1280 totalling 3.8KiB
2019-10-30 22:02:04.366834: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 1536 totalling 3.0KiB
2019-10-30 22:02:04.366846: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 73728 totalling 144.0KiB
2019-10-30 22:02:04.366856: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 294912 totalling 576.0KiB
2019-10-30 22:02:04.366866: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 1179648 totalling 2.25MiB
2019-10-30 22:02:04.366877: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 2359296 totalling 4.50MiB
2019-10-30 22:02:04.366887: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 8456241152 totalling 7.88GiB
2019-10-30 22:02:04.366896: I tensorflow/core/common_runtime/bfc_allocator.cc:816] Sum Total of in-use chunks: 7.88GiB
2019-10-30 22:02:04.366906: I tensorflow/core/common_runtime/bfc_allocator.cc:818] total_region_allocated_bytes_: 11982716928 memory_limit_: 11982716928 available bytes: 0 curr_region_allocation_bytes_: 23965433856
2019-10-30 22:02:04.366920: I tensorflow/core/common_runtime/bfc_allocator.cc:824] Stats: 
Limit:                 11982716928
InUse:                  8464067584
MaxInUse:               8464067840
NumAllocs:                     104
MaxAllocSize:           8456241152

2019-10-30 22:02:04.366933: W tensorflow/core/common_runtime/bfc_allocator.cc:319] ***********************************************************************_____________________________
2019-10-30 22:02:04.366980: W tensorflow/core/framework/op_kernel.cc:1546] OP_REQUIRES failed at cwise_ops_common.cc:70 : Resource exhausted: OOM when allocating tensor with shape[4129024,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
[I 22:02:17.873 LabApp] Starting buffering for aec916f2-f60a-47e4-a889-1610dc8bc414:d80ad922eb5e4352a0089cb214619d8c
[I 22:02:19.887 LabApp] Kernel shutdown: aec916f2-f60a-47e4-a889-1610dc8bc414
2019-10-30 22:02:30.399696: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
[I 22:02:30.772 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
2019-10-30 22:02:30.959372: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-30 22:02:30.959937: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:02:30.961853: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 22:02:30.963709: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 22:02:30.964306: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 22:02:30.966843: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 22:02:30.968940: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 22:02:30.974411: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 22:02:30.976466: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 22:02:31.170000: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563a5e2ddbb0 executing computations on platform CUDA. Devices:
2019-10-30 22:02:31.170060: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-30 22:02:31.173846: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-30 22:02:31.174958: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563a5e3b4630 executing computations on platform Host. Devices:
2019-10-30 22:02:31.174997: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-30 22:02:31.175920: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-30 22:02:31.176001: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:02:31.176041: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 22:02:31.176077: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 22:02:31.176115: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 22:02:31.176153: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 22:02:31.176190: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 22:02:31.176227: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 22:02:31.177502: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 22:02:31.177564: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:02:31.179420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-30 22:02:31.179440: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-30 22:02:31.179451: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-30 22:02:31.181012: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 204 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-30 22:02:35.539978: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 204.75M (214695936 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2019-10-30 22:02:35.683793: F ./tensorflow/core/kernels/random_op_gpu.h:227] Non-OK-status: GpuLaunchKernel(FillPhiloxRandomKernelLaunch<Distribution>, num_blocks, block_size, 0, d.stream(), gen, data, size, dist) status: Internal: out of memory
[I 22:02:36.746 LabApp] KernelRestarter: restarting kernel (1/5), keep random ports
kernel 05dbaa32-f34d-4797-9f83-6084409786a0 restarted
[I 22:02:42.386 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
2019-10-30 22:02:54.589612: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-30 22:02:55.128376: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-30 22:02:55.129234: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:02:55.131224: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 22:02:55.132780: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 22:02:55.133441: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 22:02:55.135440: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 22:02:55.137137: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 22:02:55.140895: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 22:02:55.145407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 22:02:55.367052: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55aa83064330 executing computations on platform CUDA. Devices:
2019-10-30 22:02:55.367135: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-30 22:02:55.371004: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-30 22:02:55.372160: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55aa8313adc0 executing computations on platform Host. Devices:
2019-10-30 22:02:55.372189: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-30 22:02:55.373310: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-30 22:02:55.373398: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:02:55.373439: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 22:02:55.373476: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 22:02:55.373513: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 22:02:55.373550: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 22:02:55.373587: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 22:02:55.373625: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 22:02:55.375518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 22:02:55.375583: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:02:55.377630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-30 22:02:55.377651: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-30 22:02:55.377662: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-30 22:02:55.380253: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-30 22:03:14.386461: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 22:03:14.597126: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 22:03:15.937 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 22:03:23.557 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAEGAN-128.ipynb
[I 22:03:25.886 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[W 22:03:25.887 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb is not trusted
[I 22:04:44.177 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 22:05:16.095 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 22:05:26.396 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 22:05:26.687 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[W 22:05:26.688 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb is not trusted
[I 22:06:44.233 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 22:07:15.831 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 22:07:25.973 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[W 22:07:25.974 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb is not trusted
[I 22:09:05.748 LabApp] Kernel interrupted: 05dbaa32-f34d-4797-9f83-6084409786a0
[I 22:09:08.338 LabApp] Starting buffering for 05dbaa32-f34d-4797-9f83-6084409786a0:a840cb30374b46a980d892039fa6e8f7
[I 22:09:13.993 LabApp] Kernel restarted: 05dbaa32-f34d-4797-9f83-6084409786a0
[I 22:09:15.665 LabApp] Adapting from protocol version 5.1 (kernel 05dbaa32-f34d-4797-9f83-6084409786a0) to 5.3 (client).
[I 22:09:15.666 LabApp] Restoring connection for 05dbaa32-f34d-4797-9f83-6084409786a0:a840cb30374b46a980d892039fa6e8f7
[I 22:09:15.666 LabApp] Replaying 11 buffered messages
[I 22:09:16.181 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
2019-10-30 22:09:25.768625: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-30 22:09:26.274319: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-30 22:09:26.275228: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:09:26.277244: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 22:09:26.278729: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 22:09:26.279499: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 22:09:26.281462: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 22:09:26.283128: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 22:09:26.286839: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 22:09:26.289337: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 22:09:26.493876: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fa9425a850 executing computations on platform CUDA. Devices:
2019-10-30 22:09:26.493943: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-30 22:09:26.497626: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-30 22:09:26.498751: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fa94331300 executing computations on platform Host. Devices:
2019-10-30 22:09:26.498779: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-30 22:09:26.499799: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-30 22:09:26.499899: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:09:26.499939: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 22:09:26.499977: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 22:09:26.500029: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 22:09:26.500067: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 22:09:26.500104: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 22:09:26.500142: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 22:09:26.501893: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 22:09:26.501958: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:09:26.504021: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-30 22:09:26.504043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-30 22:09:26.504054: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-30 22:09:26.506157: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
[I 22:09:26.583 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 22:09:26.952 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[W 22:09:26.953 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb is not trusted
2019-10-30 22:09:33.792900: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 22:09:34.010714: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 22:10:43.076 LabApp] Starting buffering for 05dbaa32-f34d-4797-9f83-6084409786a0:a840cb30374b46a980d892039fa6e8f7
[I 22:10:45.640 LabApp] Kernel restarted: 05dbaa32-f34d-4797-9f83-6084409786a0
[I 22:10:45.661 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 22:10:47.402 LabApp] Adapting from protocol version 5.1 (kernel 05dbaa32-f34d-4797-9f83-6084409786a0) to 5.3 (client).
[I 22:10:47.403 LabApp] Restoring connection for 05dbaa32-f34d-4797-9f83-6084409786a0:a840cb30374b46a980d892039fa6e8f7
[I 22:10:47.403 LabApp] Replaying 6 buffered messages
2019-10-30 22:10:57.765491: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-30 22:10:58.283128: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-30 22:10:58.284100: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:10:58.286247: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 22:10:58.287890: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 22:10:58.288718: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 22:10:58.290744: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 22:10:58.292424: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 22:10:58.296202: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 22:10:58.298277: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 22:10:58.508818: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55be65694850 executing computations on platform CUDA. Devices:
2019-10-30 22:10:58.508884: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-30 22:10:58.512502: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-30 22:10:58.513490: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55be6576b300 executing computations on platform Host. Devices:
2019-10-30 22:10:58.513519: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-30 22:10:58.514758: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-30 22:10:58.514853: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:10:58.514901: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 22:10:58.514947: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 22:10:58.514994: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 22:10:58.515035: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 22:10:58.515083: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 22:10:58.515145: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 22:10:58.517091: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 22:10:58.517164: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:10:58.519419: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-30 22:10:58.519447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-30 22:10:58.519463: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-30 22:10:58.524773: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
[I 22:11:15.800 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 22:11:26.056 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[W 22:11:26.057 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb is not trusted
2019-10-30 22:11:26.991852: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 22:11:27.225677: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 22:11:48.646 LabApp] Kernel interrupted: 05dbaa32-f34d-4797-9f83-6084409786a0
[I 22:12:13.769 LabApp] Starting buffering for 05dbaa32-f34d-4797-9f83-6084409786a0:a840cb30374b46a980d892039fa6e8f7
[I 22:12:15.862 LabApp] Kernel restarted: 05dbaa32-f34d-4797-9f83-6084409786a0
[I 22:12:17.523 LabApp] Adapting from protocol version 5.1 (kernel 05dbaa32-f34d-4797-9f83-6084409786a0) to 5.3 (client).
[I 22:12:17.524 LabApp] Restoring connection for 05dbaa32-f34d-4797-9f83-6084409786a0:a840cb30374b46a980d892039fa6e8f7
[I 22:12:17.524 LabApp] Replaying 6 buffered messages
2019-10-30 22:12:30.732692: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-30 22:12:31.263044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-30 22:12:31.263899: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:12:31.265906: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 22:12:31.267420: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 22:12:31.268234: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 22:12:31.270207: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 22:12:31.271885: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 22:12:31.275591: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 22:12:31.277526: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 22:12:31.486955: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e5d5b03000 executing computations on platform CUDA. Devices:
2019-10-30 22:12:31.487021: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-30 22:12:31.490795: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-30 22:12:31.492065: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e5d5bd9aa0 executing computations on platform Host. Devices:
2019-10-30 22:12:31.492118: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-30 22:12:31.493119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-30 22:12:31.493202: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:12:31.493241: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 22:12:31.493278: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 22:12:31.493315: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 22:12:31.493351: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 22:12:31.493388: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 22:12:31.493425: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 22:12:31.495199: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 22:12:31.495266: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:12:31.497846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-30 22:12:31.497867: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-30 22:12:31.497878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-30 22:12:31.503815: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-30 22:12:33.646700: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 22:12:34.600911: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
[I 22:12:44.185 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 22:13:16.163 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 22:13:25.869 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[W 22:13:25.870 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb is not trusted
[I 22:14:44.242 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 22:15:16.170 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 22:15:26.614 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 22:15:26.907 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[W 22:15:26.908 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb is not trusted
[I 22:17:16.355 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 22:17:25.820 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[W 22:17:25.821 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb is not trusted
[I 22:18:44.222 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 22:18:52.471 LabApp] Kernel interrupted: 05dbaa32-f34d-4797-9f83-6084409786a0
[I 22:19:15.936 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 22:19:26.166 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 22:19:26.694 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[W 22:19:26.695 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb is not trusted
[I 22:19:39.758 LabApp] Starting buffering for 05dbaa32-f34d-4797-9f83-6084409786a0:a840cb30374b46a980d892039fa6e8f7
[I 22:19:42.068 LabApp] Kernel restarted: 05dbaa32-f34d-4797-9f83-6084409786a0
[I 22:19:43.922 LabApp] Adapting from protocol version 5.1 (kernel 05dbaa32-f34d-4797-9f83-6084409786a0) to 5.3 (client).
[I 22:19:43.923 LabApp] Restoring connection for 05dbaa32-f34d-4797-9f83-6084409786a0:a840cb30374b46a980d892039fa6e8f7
[I 22:19:43.923 LabApp] Replaying 6 buffered messages
2019-10-30 22:19:54.095346: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-30 22:19:54.611997: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-30 22:19:54.612908: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:19:54.614928: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 22:19:54.616450: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 22:19:54.617141: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 22:19:54.619143: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 22:19:54.620844: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 22:19:54.624601: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 22:19:54.628110: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 22:19:54.836428: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b0f7485660 executing computations on platform CUDA. Devices:
2019-10-30 22:19:54.836480: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-30 22:19:54.839739: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-30 22:19:54.840845: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b0f755c100 executing computations on platform Host. Devices:
2019-10-30 22:19:54.840872: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-30 22:19:54.841976: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-30 22:19:54.842064: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:19:54.842109: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 22:19:54.842157: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 22:19:54.842207: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 22:19:54.842248: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 22:19:54.842296: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 22:19:54.842340: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 22:19:54.844391: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 22:19:54.844462: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:19:54.846766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-30 22:19:54.846787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-30 22:19:54.846798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-30 22:19:54.849130: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-30 22:19:57.168461: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 22:19:58.087515: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
[I 22:20:00.635 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 22:20:05.664 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 22:20:17.109 LabApp] Kernel interrupted: 05dbaa32-f34d-4797-9f83-6084409786a0
[I 22:20:19.633 LabApp] Starting buffering for 05dbaa32-f34d-4797-9f83-6084409786a0:a840cb30374b46a980d892039fa6e8f7
[I 22:20:21.491 LabApp] Kernel restarted: 05dbaa32-f34d-4797-9f83-6084409786a0
[I 22:20:22.551 LabApp] Adapting from protocol version 5.1 (kernel 05dbaa32-f34d-4797-9f83-6084409786a0) to 5.3 (client).
[I 22:20:22.552 LabApp] Restoring connection for 05dbaa32-f34d-4797-9f83-6084409786a0:a840cb30374b46a980d892039fa6e8f7
[I 22:20:22.552 LabApp] Replaying 6 buffered messages
2019-10-30 22:20:28.959089: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-30 22:20:29.480306: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-30 22:20:29.480799: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:20:29.482536: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 22:20:29.483873: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 22:20:29.484330: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 22:20:29.486087: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 22:20:29.487553: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 22:20:29.491292: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 22:20:29.493223: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 22:20:29.692439: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e691874050 executing computations on platform CUDA. Devices:
2019-10-30 22:20:29.692499: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-30 22:20:29.695633: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-30 22:20:29.696822: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e69194ab10 executing computations on platform Host. Devices:
2019-10-30 22:20:29.696857: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-30 22:20:29.699435: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-30 22:20:29.699557: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:20:29.699598: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 22:20:29.699647: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 22:20:29.699685: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 22:20:29.699722: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 22:20:29.699759: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 22:20:29.699797: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 22:20:29.701422: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 22:20:29.701497: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:20:29.703336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-30 22:20:29.703357: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-30 22:20:29.703367: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-30 22:20:29.705245: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-30 22:20:31.796777: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 22:20:32.667334: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
[I 22:20:44.208 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 22:21:15.827 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 22:21:25.830 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[W 22:21:25.832 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb is not trusted
[I 22:23:15.954 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 22:23:25.870 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[W 22:23:25.871 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb is not trusted
[I 22:24:26.501 LabApp] Kernel interrupted: 05dbaa32-f34d-4797-9f83-6084409786a0
[I 22:24:34.264 LabApp] Starting buffering for 05dbaa32-f34d-4797-9f83-6084409786a0:a840cb30374b46a980d892039fa6e8f7
[I 22:24:36.479 LabApp] Kernel restarted: 05dbaa32-f34d-4797-9f83-6084409786a0
[I 22:24:38.321 LabApp] Adapting from protocol version 5.1 (kernel 05dbaa32-f34d-4797-9f83-6084409786a0) to 5.3 (client).
[I 22:24:38.322 LabApp] Restoring connection for 05dbaa32-f34d-4797-9f83-6084409786a0:a840cb30374b46a980d892039fa6e8f7
[I 22:24:38.322 LabApp] Replaying 6 buffered messages
[I 22:24:44.195 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
2019-10-30 22:24:48.412501: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-30 22:24:48.929043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-30 22:24:48.939266: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:24:48.941357: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 22:24:48.942908: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 22:24:48.951680: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 22:24:48.954155: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 22:24:48.956240: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 22:24:48.960870: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 22:24:48.963240: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 22:24:49.176374: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fc8bd3a2f0 executing computations on platform CUDA. Devices:
2019-10-30 22:24:49.176429: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-30 22:24:49.179977: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-30 22:24:49.181126: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fc8be10d80 executing computations on platform Host. Devices:
2019-10-30 22:24:49.181152: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-30 22:24:49.182201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-30 22:24:49.182294: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:24:49.182346: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 22:24:49.182384: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 22:24:49.182420: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 22:24:49.182456: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 22:24:49.182492: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 22:24:49.182529: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 22:24:49.184322: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 22:24:49.184387: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:24:49.189649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-30 22:24:49.189713: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-30 22:24:49.189726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-30 22:24:49.192003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-30 22:24:51.302850: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 22:24:52.250876: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
[I 22:25:16.322 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 22:25:21.061 LabApp] Kernel interrupted: 554d832d-f579-4e1b-8f2a-a7de5a1f2453
[I 22:25:26.211 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 22:25:26.691 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[W 22:25:26.692 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb is not trusted
[I 22:25:40.103 LabApp] Starting buffering for 554d832d-f579-4e1b-8f2a-a7de5a1f2453:6a3916b34ec24c91bea72ffc9bd09451
[I 22:25:42.582 LabApp] Kernel restarted: 554d832d-f579-4e1b-8f2a-a7de5a1f2453
[I 22:25:44.618 LabApp] Adapting from protocol version 5.1 (kernel 554d832d-f579-4e1b-8f2a-a7de5a1f2453) to 5.3 (client).
[I 22:25:44.619 LabApp] Restoring connection for 554d832d-f579-4e1b-8f2a-a7de5a1f2453:6a3916b34ec24c91bea72ffc9bd09451
[I 22:25:44.619 LabApp] Replaying 7 buffered messages
2019-10-30 22:25:53.790191: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-30 22:25:54.301681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-30 22:25:54.302713: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:25:54.304777: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 22:25:54.306200: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 22:25:54.306816: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 22:25:54.308676: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 22:25:54.310263: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 22:25:54.313827: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 22:25:54.315781: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 22:25:54.517764: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5564a1728e40 executing computations on platform CUDA. Devices:
2019-10-30 22:25:54.517824: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-30 22:25:54.522457: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-30 22:25:54.523745: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5564a17ff8d0 executing computations on platform Host. Devices:
2019-10-30 22:25:54.523775: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-30 22:25:54.524900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-30 22:25:54.525007: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:25:54.525059: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 22:25:54.525107: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 22:25:54.525154: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 22:25:54.525202: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 22:25:54.525250: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 22:25:54.525299: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 22:25:54.527838: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 22:25:54.527919: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:25:54.531288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-30 22:25:54.531309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-30 22:25:54.531320: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-30 22:25:54.533652: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-30 22:25:57.339486: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 22:25:58.281995: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
[I 22:26:24.350 LabApp] Kernel interrupted: 05dbaa32-f34d-4797-9f83-6084409786a0
[I 22:26:42.053 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 22:27:10.083 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 22:27:23.587 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 22:27:25.839 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[W 22:27:25.840 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb is not trusted
[I 22:27:27.856 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 22:27:31.500 LabApp] Starting buffering for 05dbaa32-f34d-4797-9f83-6084409786a0:a840cb30374b46a980d892039fa6e8f7
[I 22:27:34.318 LabApp] Kernel restarted: 05dbaa32-f34d-4797-9f83-6084409786a0
[I 22:27:36.971 LabApp] Adapting from protocol version 5.1 (kernel 05dbaa32-f34d-4797-9f83-6084409786a0) to 5.3 (client).
[I 22:27:36.974 LabApp] Restoring connection for 05dbaa32-f34d-4797-9f83-6084409786a0:a840cb30374b46a980d892039fa6e8f7
[I 22:27:36.974 LabApp] Replaying 6 buffered messages
2019-10-30 22:27:48.330088: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-30 22:27:48.817468: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-30 22:27:48.837993: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:27:48.839833: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 22:27:48.841225: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 22:27:48.842125: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 22:27:48.844066: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 22:27:48.845601: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 22:27:48.849055: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 22:27:48.863624: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 22:27:49.051030: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5654fb7b7e20 executing computations on platform CUDA. Devices:
2019-10-30 22:27:49.051081: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-30 22:27:49.055305: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-30 22:27:49.056510: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5654fb88e8b0 executing computations on platform Host. Devices:
2019-10-30 22:27:49.056542: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-30 22:27:49.057655: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-30 22:27:49.057749: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:27:49.057790: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 22:27:49.057828: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 22:27:49.057866: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 22:27:49.057904: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 22:27:49.057942: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 22:27:49.057981: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 22:27:49.061060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 22:27:49.061211: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:27:49.065372: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-30 22:27:49.065393: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-30 22:27:49.065405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-30 22:27:49.067503: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-30 22:27:51.076396: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 22:27:52.019349: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
[I 22:28:43.462 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 22:28:44.432 LabApp] Kernel interrupted: 05dbaa32-f34d-4797-9f83-6084409786a0
[I 22:28:46.665 LabApp] Starting buffering for 05dbaa32-f34d-4797-9f83-6084409786a0:a840cb30374b46a980d892039fa6e8f7
[I 22:28:48.755 LabApp] Kernel restarted: 05dbaa32-f34d-4797-9f83-6084409786a0
[I 22:28:50.465 LabApp] Adapting from protocol version 5.1 (kernel 05dbaa32-f34d-4797-9f83-6084409786a0) to 5.3 (client).
[I 22:28:50.466 LabApp] Restoring connection for 05dbaa32-f34d-4797-9f83-6084409786a0:a840cb30374b46a980d892039fa6e8f7
[I 22:28:50.466 LabApp] Replaying 6 buffered messages
2019-10-30 22:28:59.408015: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-30 22:28:59.916860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-30 22:28:59.917609: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:28:59.919615: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 22:28:59.921178: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 22:28:59.921929: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 22:28:59.923910: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 22:28:59.925592: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 22:28:59.929344: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 22:28:59.931265: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 22:29:00.138254: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562d8da61540 executing computations on platform CUDA. Devices:
2019-10-30 22:29:00.138309: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-30 22:29:00.141937: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-30 22:29:00.143423: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562d8db37fd0 executing computations on platform Host. Devices:
2019-10-30 22:29:00.143454: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-30 22:29:00.144469: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-30 22:29:00.144580: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:29:00.144625: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 22:29:00.144666: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 22:29:00.144707: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 22:29:00.144748: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 22:29:00.144789: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 22:29:00.144830: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 22:29:00.147630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 22:29:00.147751: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:29:00.149880: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-30 22:29:00.149901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-30 22:29:00.149913: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-30 22:29:00.152054: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-30 22:29:02.406076: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 22:29:03.274749: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
[I 22:29:15.906 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 22:29:26.577 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 22:29:26.830 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[W 22:29:26.831 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb is not trusted
[I 22:29:45.569 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 22:29:46.879 LabApp] Kernel interrupted: 05dbaa32-f34d-4797-9f83-6084409786a0
[I 22:29:48.144 LabApp] Starting buffering for 05dbaa32-f34d-4797-9f83-6084409786a0:a840cb30374b46a980d892039fa6e8f7
[I 22:29:48.168 LabApp] Adapting from protocol version 5.1 (kernel 05dbaa32-f34d-4797-9f83-6084409786a0) to 5.3 (client).
[I 22:29:48.169 LabApp] Restoring connection for 05dbaa32-f34d-4797-9f83-6084409786a0:a840cb30374b46a980d892039fa6e8f7
[I 22:29:49.891 LabApp] Starting buffering for 05dbaa32-f34d-4797-9f83-6084409786a0:a840cb30374b46a980d892039fa6e8f7
[I 22:29:49.944 LabApp] Adapting from protocol version 5.1 (kernel 05dbaa32-f34d-4797-9f83-6084409786a0) to 5.3 (client).
[I 22:29:49.945 LabApp] Restoring connection for 05dbaa32-f34d-4797-9f83-6084409786a0:a840cb30374b46a980d892039fa6e8f7
[I 22:29:52.128 LabApp] Starting buffering for 05dbaa32-f34d-4797-9f83-6084409786a0:a840cb30374b46a980d892039fa6e8f7
[I 22:29:54.185 LabApp] Kernel restarted: 05dbaa32-f34d-4797-9f83-6084409786a0
[I 22:29:55.289 LabApp] Adapting from protocol version 5.1 (kernel 05dbaa32-f34d-4797-9f83-6084409786a0) to 5.3 (client).
[I 22:29:55.289 LabApp] Restoring connection for 05dbaa32-f34d-4797-9f83-6084409786a0:a840cb30374b46a980d892039fa6e8f7
[I 22:29:55.290 LabApp] Replaying 6 buffered messages
2019-10-30 22:30:02.435805: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-30 22:30:02.949307: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-30 22:30:02.950013: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:30:02.951986: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 22:30:02.953457: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 22:30:02.954083: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 22:30:02.956046: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 22:30:02.957696: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 22:30:02.961447: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 22:30:02.966139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 22:30:03.174173: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560749e74880 executing computations on platform CUDA. Devices:
2019-10-30 22:30:03.174233: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-30 22:30:03.177501: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-30 22:30:03.178593: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560749f4b330 executing computations on platform Host. Devices:
2019-10-30 22:30:03.178622: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-30 22:30:03.179739: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-30 22:30:03.179817: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:30:03.179856: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 22:30:03.179893: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 22:30:03.179929: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 22:30:03.179966: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 22:30:03.180005: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 22:30:03.180042: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 22:30:03.182325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 22:30:03.182452: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:30:03.184622: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-30 22:30:03.184645: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-30 22:30:03.184656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-30 22:30:03.186753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-30 22:30:05.374725: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 22:30:06.321879: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
[I 22:30:42.144 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 22:30:59.069 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 22:30:59.300 LabApp] Kernel interrupted: 05dbaa32-f34d-4797-9f83-6084409786a0
[I 22:31:02.117 LabApp] Starting buffering for 05dbaa32-f34d-4797-9f83-6084409786a0:a840cb30374b46a980d892039fa6e8f7
[I 22:31:04.299 LabApp] Kernel restarted: 05dbaa32-f34d-4797-9f83-6084409786a0
[I 22:31:05.724 LabApp] Adapting from protocol version 5.1 (kernel 05dbaa32-f34d-4797-9f83-6084409786a0) to 5.3 (client).
[I 22:31:05.724 LabApp] Restoring connection for 05dbaa32-f34d-4797-9f83-6084409786a0:a840cb30374b46a980d892039fa6e8f7
[I 22:31:05.725 LabApp] Replaying 6 buffered messages
2019-10-30 22:31:13.464712: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-30 22:31:14.003986: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-30 22:31:14.004967: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:31:14.007063: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 22:31:14.008646: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 22:31:14.009443: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 22:31:14.011470: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 22:31:14.013138: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 22:31:14.016849: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 22:31:14.018761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 22:31:14.231076: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d878a2fd90 executing computations on platform CUDA. Devices:
2019-10-30 22:31:14.231158: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-30 22:31:14.235013: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-30 22:31:14.236382: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d878b06830 executing computations on platform Host. Devices:
2019-10-30 22:31:14.236412: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-30 22:31:14.237530: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-30 22:31:14.237610: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:31:14.237651: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 22:31:14.237689: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 22:31:14.237726: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 22:31:14.237776: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 22:31:14.237814: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 22:31:14.237852: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 22:31:14.239639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 22:31:14.239705: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:31:14.241771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-30 22:31:14.241791: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-30 22:31:14.241802: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-30 22:31:14.244089: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
[I 22:31:15.800 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
2019-10-30 22:31:16.425081: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 22:31:17.400115: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
[I 22:31:25.967 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[W 22:31:25.968 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb is not trusted
[I 22:31:46.673 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 22:31:47.132 LabApp] Kernel interrupted: 05dbaa32-f34d-4797-9f83-6084409786a0
[I 22:31:49.428 LabApp] Starting buffering for 05dbaa32-f34d-4797-9f83-6084409786a0:a840cb30374b46a980d892039fa6e8f7
[I 22:31:55.010 LabApp] Kernel restarted: 05dbaa32-f34d-4797-9f83-6084409786a0
[I 22:31:56.084 LabApp] Adapting from protocol version 5.1 (kernel 05dbaa32-f34d-4797-9f83-6084409786a0) to 5.3 (client).
[I 22:31:56.086 LabApp] Restoring connection for 05dbaa32-f34d-4797-9f83-6084409786a0:a840cb30374b46a980d892039fa6e8f7
[I 22:31:56.086 LabApp] Replaying 71 buffered messages
2019-10-30 22:32:03.367254: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-30 22:32:03.869773: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-30 22:32:03.870418: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:32:03.872215: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 22:32:03.873500: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 22:32:03.873944: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 22:32:03.875759: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 22:32:03.877205: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 22:32:03.880908: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 22:32:03.882942: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 22:32:04.189521: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559af5449190 executing computations on platform CUDA. Devices:
2019-10-30 22:32:04.189581: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-30 22:32:04.193027: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-30 22:32:04.194331: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559af551fc40 executing computations on platform Host. Devices:
2019-10-30 22:32:04.194356: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-30 22:32:04.195495: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-30 22:32:04.195572: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:32:04.195612: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 22:32:04.195649: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 22:32:04.195686: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 22:32:04.195723: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 22:32:04.195760: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 22:32:04.195798: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 22:32:04.197605: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 22:32:04.197667: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:32:04.199700: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-30 22:32:04.199721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-30 22:32:04.199732: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-30 22:32:04.202500: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-30 22:32:06.279326: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 22:32:07.262808: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
[I 22:32:42.173 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 22:33:16.055 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 22:33:25.835 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[W 22:33:25.836 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb is not trusted
[I 22:34:42.185 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 22:35:16.064 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 22:35:26.060 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 22:35:26.733 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[W 22:35:26.733 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb is not trusted
[I 22:35:50.462 LabApp] Kernel interrupted: 05dbaa32-f34d-4797-9f83-6084409786a0
[I 22:35:59.835 LabApp] Starting buffering for 05dbaa32-f34d-4797-9f83-6084409786a0:a840cb30374b46a980d892039fa6e8f7
[I 22:36:02.259 LabApp] Kernel restarted: 05dbaa32-f34d-4797-9f83-6084409786a0
[I 22:36:04.220 LabApp] Adapting from protocol version 5.1 (kernel 05dbaa32-f34d-4797-9f83-6084409786a0) to 5.3 (client).
[I 22:36:04.221 LabApp] Restoring connection for 05dbaa32-f34d-4797-9f83-6084409786a0:a840cb30374b46a980d892039fa6e8f7
[I 22:36:04.221 LabApp] Replaying 6 buffered messages
2019-10-30 22:36:14.517291: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-30 22:36:15.062265: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-30 22:36:15.063324: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:36:15.065241: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 22:36:15.066753: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 22:36:15.067735: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 22:36:15.069676: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 22:36:15.071333: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 22:36:15.075017: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 22:36:15.077819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 22:36:15.286358: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559a78a17320 executing computations on platform CUDA. Devices:
2019-10-30 22:36:15.286414: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-30 22:36:15.289712: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-30 22:36:15.291076: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559a78aeddb0 executing computations on platform Host. Devices:
2019-10-30 22:36:15.291121: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-30 22:36:15.292485: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-30 22:36:15.292587: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:36:15.292645: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 22:36:15.292696: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 22:36:15.292751: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 22:36:15.292801: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 22:36:15.292856: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 22:36:15.292906: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 22:36:15.295083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 22:36:15.295161: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:36:15.297667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-30 22:36:15.297697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-30 22:36:15.297711: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-30 22:36:15.300377: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-30 22:36:17.639626: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 22:36:18.672286: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
[I 22:36:41.032 LabApp] Kernel interrupted: 05dbaa32-f34d-4797-9f83-6084409786a0
[I 22:36:42.667 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 22:36:49.884 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 22:36:50.426 LabApp] Kernel interrupted: 05dbaa32-f34d-4797-9f83-6084409786a0
[I 22:36:52.672 LabApp] Starting buffering for 05dbaa32-f34d-4797-9f83-6084409786a0:a840cb30374b46a980d892039fa6e8f7
[I 22:36:54.633 LabApp] Kernel restarted: 05dbaa32-f34d-4797-9f83-6084409786a0
[I 22:36:56.291 LabApp] Adapting from protocol version 5.1 (kernel 05dbaa32-f34d-4797-9f83-6084409786a0) to 5.3 (client).
[I 22:36:56.292 LabApp] Restoring connection for 05dbaa32-f34d-4797-9f83-6084409786a0:a840cb30374b46a980d892039fa6e8f7
[I 22:36:56.292 LabApp] Replaying 6 buffered messages
2019-10-30 22:37:04.892693: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-30 22:37:05.446141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-30 22:37:05.446874: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:37:05.449189: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 22:37:05.450694: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 22:37:05.451303: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 22:37:05.453341: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 22:37:05.455030: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 22:37:05.459216: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 22:37:05.461110: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 22:37:05.673996: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b20a8ae090 executing computations on platform CUDA. Devices:
2019-10-30 22:37:05.674051: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-30 22:37:05.677464: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-30 22:37:05.678470: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b20a984b50 executing computations on platform Host. Devices:
2019-10-30 22:37:05.678498: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-30 22:37:05.679589: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-30 22:37:05.679690: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:37:05.679735: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 22:37:05.679776: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 22:37:05.679817: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 22:37:05.679857: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 22:37:05.679898: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 22:37:05.679938: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 22:37:05.684763: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 22:37:05.684907: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:37:05.686996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-30 22:37:05.687018: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-30 22:37:05.687030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-30 22:37:05.689136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-30 22:37:07.944158: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 22:37:08.871777: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
[I 22:37:15.797 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 22:37:25.852 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[W 22:37:25.853 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb is not trusted
[I 22:37:55.739 LabApp] Kernel interrupted: 05dbaa32-f34d-4797-9f83-6084409786a0
[I 22:38:42.667 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 22:39:15.960 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 22:39:26.720 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[W 22:39:26.721 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb is not trusted
[I 22:39:26.897 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 22:40:42.407 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 22:41:16.041 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 22:41:25.854 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[W 22:41:25.855 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb is not trusted
[I 22:42:12.513 LabApp] Starting buffering for 05dbaa32-f34d-4797-9f83-6084409786a0:a840cb30374b46a980d892039fa6e8f7
[I 22:42:15.001 LabApp] Kernel restarted: 05dbaa32-f34d-4797-9f83-6084409786a0
[I 22:42:17.854 LabApp] Adapting from protocol version 5.1 (kernel 05dbaa32-f34d-4797-9f83-6084409786a0) to 5.3 (client).
[I 22:42:17.854 LabApp] Restoring connection for 05dbaa32-f34d-4797-9f83-6084409786a0:a840cb30374b46a980d892039fa6e8f7
[I 22:42:17.855 LabApp] Replaying 6 buffered messages
2019-10-30 22:42:30.246467: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-30 22:42:30.788842: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-30 22:42:30.789723: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:42:30.791871: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 22:42:30.793377: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 22:42:30.794077: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 22:42:30.796055: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 22:42:30.797772: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 22:42:30.801486: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 22:42:30.803479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 22:42:30.993070: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55baf9eaa410 executing computations on platform CUDA. Devices:
2019-10-30 22:42:30.993126: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-30 22:42:30.997698: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-30 22:42:30.999021: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55baf9f80e70 executing computations on platform Host. Devices:
2019-10-30 22:42:30.999051: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-30 22:42:31.000096: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-30 22:42:31.000177: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:42:31.000218: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 22:42:31.000256: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 22:42:31.000294: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 22:42:31.000332: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 22:42:31.000369: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 22:42:31.000408: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 22:42:31.002226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 22:42:31.002290: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:42:31.013976: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-30 22:42:31.014006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-30 22:42:31.014018: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-30 22:42:31.016226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-30 22:42:33.302402: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 22:42:34.346608: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
[I 22:43:16.224 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 22:43:25.828 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[W 22:43:25.829 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb is not trusted
[I 22:44:42.663 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 22:45:16.193 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 22:45:26.216 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 22:45:26.749 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[W 22:45:26.750 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb is not trusted
[I 22:45:56.363 LabApp] Kernel interrupted: 05dbaa32-f34d-4797-9f83-6084409786a0
[I 22:46:31.627 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 22:46:33.647 LabApp] Starting buffering for 05dbaa32-f34d-4797-9f83-6084409786a0:a840cb30374b46a980d892039fa6e8f7
[I 22:46:35.923 LabApp] Kernel restarted: 05dbaa32-f34d-4797-9f83-6084409786a0
[I 22:46:37.889 LabApp] Adapting from protocol version 5.1 (kernel 05dbaa32-f34d-4797-9f83-6084409786a0) to 5.3 (client).
[I 22:46:37.890 LabApp] Restoring connection for 05dbaa32-f34d-4797-9f83-6084409786a0:a840cb30374b46a980d892039fa6e8f7
[I 22:46:37.890 LabApp] Replaying 6 buffered messages
[I 22:46:42.182 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
2019-10-30 22:46:47.479096: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-30 22:46:48.007210: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-30 22:46:48.008128: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:46:48.010151: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 22:46:48.011688: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 22:46:48.012365: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 22:46:48.014327: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 22:46:48.015986: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 22:46:48.019711: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 22:46:48.025013: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 22:46:48.232320: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56535f1e08e0 executing computations on platform CUDA. Devices:
2019-10-30 22:46:48.232379: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-30 22:46:48.235813: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-30 22:46:48.236807: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56535f2b7390 executing computations on platform Host. Devices:
2019-10-30 22:46:48.236839: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-30 22:46:48.237962: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-30 22:46:48.238049: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:46:48.238093: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 22:46:48.238134: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 22:46:48.238175: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 22:46:48.238216: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 22:46:48.238256: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 22:46:48.238297: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 22:46:48.240732: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 22:46:48.240860: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 22:46:48.242969: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-30 22:46:48.242990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-30 22:46:48.243002: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-30 22:46:48.245191: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-30 22:46:50.461716: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 22:46:51.462142: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
[I 22:47:16.073 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 22:47:25.853 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[W 22:47:25.854 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb is not trusted
[I 22:49:13.751 LabApp] Kernel interrupted: 554d832d-f579-4e1b-8f2a-a7de5a1f2453
[I 22:49:16.058 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 22:49:26.387 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 22:49:26.727 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[W 22:49:26.728 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb is not trusted
[W 22:49:34.816 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb is not trusted
[W 22:49:34.883 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.30ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[I 22:49:35.629 LabApp] Adapting from protocol version 5.1 (kernel 1c23d551-7d11-4d02-ac6c-999284268760) to 5.3 (client).
[W 22:49:35.772 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 1.68ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[I 22:50:42.589 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 22:51:16.009 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 22:51:24.948 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[W 22:51:24.949 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb is not trusted
[I 22:52:43.847 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[I 22:53:15.984 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 22:53:24.948 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[W 22:53:24.949 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb is not trusted
[I 22:54:44.293 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-VAEGAN.ipynb
[W 22:54:50.665 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 1.74ms referer=http://localhost:8187/tree/avgn_paper/figures/networks/starling128
[I 22:55:16.016 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 22:55:26.316 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 22:55:26.700 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[W 22:55:26.701 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb is not trusted
[I 22:56:16.524 LabApp] Kernel interrupted: 1c23d551-7d11-4d02-ac6c-999284268760
[I 22:57:16.593 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 22:57:25.406 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[W 22:57:25.407 LabApp] Notebook avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb is not trusted
[I 22:59:15.997 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 22:59:25.045 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[I 22:59:25.916 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 23:01:16.095 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:01:25.005 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-AE.ipynb
[I 23:02:37.861 LabApp] Kernel interrupted: 05dbaa32-f34d-4797-9f83-6084409786a0
[I 23:02:39.762 LabApp] Starting buffering for 05dbaa32-f34d-4797-9f83-6084409786a0:a840cb30374b46a980d892039fa6e8f7
[I 23:02:45.500 LabApp] Kernel restarted: 05dbaa32-f34d-4797-9f83-6084409786a0
[I 23:02:47.707 LabApp] Adapting from protocol version 5.1 (kernel 05dbaa32-f34d-4797-9f83-6084409786a0) to 5.3 (client).
[I 23:02:47.708 LabApp] Restoring connection for 05dbaa32-f34d-4797-9f83-6084409786a0:a840cb30374b46a980d892039fa6e8f7
[I 23:02:47.708 LabApp] Replaying 62 buffered messages
2019-10-30 23:02:59.917954: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-30 23:03:00.496670: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-30 23:03:00.497682: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 23:03:00.499803: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 23:03:00.501410: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 23:03:00.502153: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 23:03:00.504273: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 23:03:00.506000: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 23:03:00.509848: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 23:03:00.511949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 23:03:00.758265: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562bd47f2f60 executing computations on platform CUDA. Devices:
2019-10-30 23:03:00.758330: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-30 23:03:00.764428: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-30 23:03:00.766883: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562bd48c99e0 executing computations on platform Host. Devices:
2019-10-30 23:03:00.766952: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-30 23:03:00.768088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-30 23:03:00.768176: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 23:03:00.768217: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 23:03:00.768255: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 23:03:00.768294: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 23:03:00.768334: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 23:03:00.768373: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 23:03:00.768413: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 23:03:00.770957: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 23:03:00.771028: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 23:03:00.773366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-30 23:03:00.773391: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-30 23:03:00.773404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-30 23:03:00.775827: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-30 23:03:03.093955: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 23:03:04.060324: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
[I 23:03:15.856 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:04:57.632 LabApp] Kernel interrupted: 05dbaa32-f34d-4797-9f83-6084409786a0
[I 23:05:16.101 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:05:24.809 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 23:05:26.973 LabApp] Starting buffering for 05dbaa32-f34d-4797-9f83-6084409786a0:a840cb30374b46a980d892039fa6e8f7
[I 23:05:29.524 LabApp] Kernel restarted: 05dbaa32-f34d-4797-9f83-6084409786a0
[I 23:05:32.017 LabApp] Adapting from protocol version 5.1 (kernel 05dbaa32-f34d-4797-9f83-6084409786a0) to 5.3 (client).
[I 23:05:32.018 LabApp] Restoring connection for 05dbaa32-f34d-4797-9f83-6084409786a0:a840cb30374b46a980d892039fa6e8f7
[I 23:05:32.018 LabApp] Replaying 6 buffered messages
2019-10-30 23:05:42.878234: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-30 23:05:43.405423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-30 23:05:43.416721: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 23:05:43.418736: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 23:05:43.420253: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 23:05:43.435541: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 23:05:43.437562: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 23:05:43.439297: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 23:05:43.443081: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 23:05:43.445116: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 23:05:43.672452: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c9cc6ed8e0 executing computations on platform CUDA. Devices:
2019-10-30 23:05:43.672518: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-30 23:05:43.676163: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-30 23:05:43.677232: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c9cc7c4390 executing computations on platform Host. Devices:
2019-10-30 23:05:43.677263: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-30 23:05:43.678283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-30 23:05:43.678388: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 23:05:43.678433: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-30 23:05:43.678474: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-30 23:05:43.678515: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-30 23:05:43.678556: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-30 23:05:43.678597: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-30 23:05:43.678638: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 23:05:43.680491: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-30 23:05:43.680562: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-30 23:05:43.684372: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-30 23:05:43.684418: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-30 23:05:43.684442: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-30 23:05:43.688958: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-30 23:05:45.720944: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-30 23:05:46.679510: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
[I 23:07:16.087 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:09:16.087 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:11:04.880 LabApp] Kernel interrupted: 05dbaa32-f34d-4797-9f83-6084409786a0
[I 23:11:16.110 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:11:24.817 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 23:13:16.093 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:15:16.124 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:15:24.808 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 23:17:16.123 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:19:16.130 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:21:16.130 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:21:24.829 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 23:23:16.142 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:25:16.236 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:25:25.632 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 23:27:16.174 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:29:16.142 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:31:16.158 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:31:25.629 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 23:33:16.155 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:35:16.178 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:35:25.649 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 23:37:16.165 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:37:25.626 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 23:39:16.177 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:41:16.176 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:41:26.079 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 23:43:16.196 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:45:16.167 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:47:16.192 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:47:25.704 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 23:49:16.210 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:51:16.182 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:51:25.653 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 23:53:16.183 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:55:16.206 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:57:16.204 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 23:57:25.658 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 23:59:16.178 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:01:16.179 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:01:25.684 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 00:03:16.202 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:05:16.189 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:07:16.188 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:07:25.657 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 00:09:16.212 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:11:16.224 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:13:16.236 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:13:25.689 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 00:15:16.212 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:17:16.282 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:17:25.677 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 00:19:16.206 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:21:16.227 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:23:16.205 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:23:25.677 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 00:25:16.244 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:27:16.208 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:27:25.660 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 00:29:16.231 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:31:16.185 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:33:16.221 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:33:25.685 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 00:35:16.225 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:37:16.241 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:37:25.665 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 00:39:16.249 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:39:25.669 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 00:41:16.260 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:43:16.232 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:43:25.677 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 00:45:16.222 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:47:16.246 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:49:16.248 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:49:25.692 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 00:51:16.265 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:53:16.253 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:53:25.702 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 00:55:16.268 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:57:16.248 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:59:17.010 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 00:59:25.747 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 01:03:25.768 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 01:09:25.714 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 01:15:25.708 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 01:19:25.707 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 01:25:25.777 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 01:31:25.718 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 01:35:25.731 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 01:41:25.749 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 01:45:25.707 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 01:51:25.720 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 01:57:25.730 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 02:01:25.762 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 02:07:25.794 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 02:11:25.824 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 02:17:25.759 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 02:23:25.759 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 02:27:25.737 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 02:33:25.864 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 02:37:25.782 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 02:39:25.736 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 02:43:25.798 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 02:49:25.775 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 02:53:25.800 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 02:59:26.077 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 03:05:25.781 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 03:09:26.000 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 03:15:25.830 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 03:19:25.941 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 03:25:25.839 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 03:31:25.790 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 03:35:25.780 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 03:41:25.841 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 03:45:25.815 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 03:47:25.829 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 03:51:25.805 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 03:57:25.838 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 04:01:25.785 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 04:07:25.828 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 04:13:25.821 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 04:17:25.837 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 04:23:25.972 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 04:27:25.824 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 04:33:25.818 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 04:39:25.854 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 04:43:25.809 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 04:49:25.864 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 04:53:25.841 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 04:59:25.854 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 05:05:25.912 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 05:09:25.821 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 05:15:25.857 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 05:19:25.869 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 05:21:25.842 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 05:25:25.864 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 05:31:25.903 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 05:35:25.856 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 05:41:25.873 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 05:45:25.857 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 05:47:25.895 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 05:51:25.841 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 05:57:25.890 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 06:01:25.916 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 06:07:25.893 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 06:13:25.886 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 06:17:25.870 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 06:23:25.896 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 06:27:25.879 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 06:33:25.900 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 06:39:25.953 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 06:43:25.876 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 06:49:25.925 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 06:53:25.886 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 06:59:25.929 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 07:05:25.967 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 07:09:25.889 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 07:15:25.939 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 07:19:25.911 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 07:21:25.936 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 07:25:25.930 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 07:31:25.962 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 07:35:25.917 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 07:41:25.999 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 07:47:25.944 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 07:51:25.908 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 07:57:25.950 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 08:01:25.896 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 08:07:25.941 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 08:13:25.956 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 08:17:25.946 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 08:23:25.964 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 08:27:25.958 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 08:29:25.952 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 08:33:25.941 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 08:39:26.000 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 08:43:25.990 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 08:49:26.035 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 08:55:25.975 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 08:59:25.952 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 09:05:25.972 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 09:09:26.001 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 09:11:26.027 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 09:15:25.983 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 09:21:25.996 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 09:25:26.031 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 09:31:26.038 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 09:37:25.996 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 09:41:25.970 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 09:47:25.990 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 09:51:26.155 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 09:55:16.810 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 09:56:04.121 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb
[I 09:56:06.903 LabApp] Copying avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128.ipynb to /avgn_paper/notebooks/6.0-neural-networks
[W 09:56:08.664 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 5.37ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 09:56:09.459 LabApp] Kernel started: 2915ac90-c4d5-4155-9446-f46e34869d66
[W 09:56:09.468 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 4.85ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 09:56:10.974 LabApp] Kernel interrupted: 68fe739f-0fae-442f-860e-d943da609e51
[I 09:56:11.612 LabApp] Adapting from protocol version 5.1 (kernel 2915ac90-c4d5-4155-9446-f46e34869d66) to 5.3 (client).
[I 09:57:25.644 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[W 09:57:27.578 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 2.89ms referer=http://localhost:8187/tree/avgn_paper/notebooks/6.0-neural-networks
[I 09:57:35.460 LabApp] Adapting from protocol version 5.1 (kernel 2a99eb03-fb60-4105-af1a-53d06da9dfd1) to 5.3 (client).
[W 09:57:35.471 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 2.88ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-64-GAIA6.ipynb
[I 09:58:04.902 LabApp] Starting buffering for 2a99eb03-fb60-4105-af1a-53d06da9dfd1:a17520e8b65848f4829b7e9bf5ebf156
[W 09:58:05.018 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.69ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 09:58:05.946 LabApp] Kernel started: 0a1edf0a-98cf-42c4-aecc-b7d13bb175a8
[W 09:58:06.113 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 4.09ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 09:58:07.925 LabApp] Adapting from protocol version 5.1 (kernel 0a1edf0a-98cf-42c4-aecc-b7d13bb175a8) to 5.3 (client).
[I 09:59:25.647 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 10:00:07.476 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 10:01:25.773 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 10:03:25.799 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 10:05:25.870 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 10:07:26.146 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 10:08:16.705 LabApp] Starting buffering for 05dbaa32-f34d-4797-9f83-6084409786a0:a840cb30374b46a980d892039fa6e8f7
[I 10:08:19.882 LabApp] Kernel shutdown: 05dbaa32-f34d-4797-9f83-6084409786a0
[I 10:08:23.993 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 10:08:24.780 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 10:08:26.696 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 10:08:30.528 LabApp] Starting buffering for 2915ac90-c4d5-4155-9446-f46e34869d66:f10a4eccc7224b648ba9b2dd8ad6d9a4
[I 10:08:31.279 LabApp] Kernel restarted: 2915ac90-c4d5-4155-9446-f46e34869d66
[I 10:08:34.705 LabApp] Adapting from protocol version 5.1 (kernel 2915ac90-c4d5-4155-9446-f46e34869d66) to 5.3 (client).
[I 10:08:34.706 LabApp] Restoring connection for 2915ac90-c4d5-4155-9446-f46e34869d66:f10a4eccc7224b648ba9b2dd8ad6d9a4
[I 10:08:34.706 LabApp] Replaying 6 buffered messages
2019-10-31 10:08:49.559888: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-31 10:08:50.137845: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-31 10:08:50.147530: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 10:08:50.151174: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-31 10:08:50.153856: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-31 10:08:50.155228: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-31 10:08:50.158769: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-31 10:08:50.161489: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-31 10:08:50.168101: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-31 10:08:50.171281: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-31 10:08:50.421186: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e2dd2ca0f0 executing computations on platform CUDA. Devices:
2019-10-31 10:08:50.421255: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-31 10:08:50.427380: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-31 10:08:50.429571: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e2dd3a0ba0 executing computations on platform Host. Devices:
2019-10-31 10:08:50.429624: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-31 10:08:50.431214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-31 10:08:50.431337: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 10:08:50.431386: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-31 10:08:50.431433: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-31 10:08:50.431481: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-31 10:08:50.431528: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-31 10:08:50.431573: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-31 10:08:50.431620: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-31 10:08:50.433753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-31 10:08:50.433831: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 10:08:50.436371: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-31 10:08:50.436399: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-31 10:08:50.436412: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-31 10:08:50.438999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-31 10:08:53.093700: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-31 10:08:54.037414: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
[I 10:09:26.109 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 10:10:10.435 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 10:11:25.917 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 10:12:10.428 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 10:13:25.924 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 10:14:10.426 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 10:15:25.967 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 10:16:10.448 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 10:17:25.957 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 10:18:10.450 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 10:19:25.962 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 10:20:09.661 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 10:22:09.847 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 10:23:15.276 LabApp] Kernel interrupted: 2915ac90-c4d5-4155-9446-f46e34869d66
[I 10:23:43.043 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 10:24:46.214 LabApp] Kernel interrupted: 2915ac90-c4d5-4155-9446-f46e34869d66
[I 10:24:48.666 LabApp] Starting buffering for 2915ac90-c4d5-4155-9446-f46e34869d66:f10a4eccc7224b648ba9b2dd8ad6d9a4
[I 10:24:51.648 LabApp] Kernel restarted: 2915ac90-c4d5-4155-9446-f46e34869d66
[I 10:24:55.408 LabApp] Adapting from protocol version 5.1 (kernel 2915ac90-c4d5-4155-9446-f46e34869d66) to 5.3 (client).
[I 10:24:55.409 LabApp] Restoring connection for 2915ac90-c4d5-4155-9446-f46e34869d66:f10a4eccc7224b648ba9b2dd8ad6d9a4
[I 10:24:55.410 LabApp] Replaying 6 buffered messages
2019-10-31 10:25:11.488656: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-31 10:25:12.073160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-31 10:25:12.074702: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 10:25:12.078348: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-31 10:25:12.081186: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-31 10:25:12.082362: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-31 10:25:12.086082: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-31 10:25:12.089047: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-31 10:25:12.096072: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-31 10:25:12.099486: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-31 10:25:12.393828: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5617a23a2440 executing computations on platform CUDA. Devices:
2019-10-31 10:25:12.393904: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-31 10:25:12.400209: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-31 10:25:12.403721: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5617a2478f00 executing computations on platform Host. Devices:
2019-10-31 10:25:12.403793: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-31 10:25:12.405702: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-31 10:25:12.405873: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 10:25:12.405956: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-31 10:25:12.406036: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-31 10:25:12.406113: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-31 10:25:12.406192: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-31 10:25:12.406271: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-31 10:25:12.406349: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-31 10:25:12.413287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-31 10:25:12.413458: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 10:25:12.417846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-31 10:25:12.417891: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-31 10:25:12.417915: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-31 10:25:12.421966: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-31 10:25:14.950266: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-31 10:25:15.920821: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
[I 10:26:09.665 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 10:28:09.765 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 10:30:09.658 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 10:32:09.654 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 10:34:09.728 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 10:34:36.322 LabApp] Kernel interrupted: 2915ac90-c4d5-4155-9446-f46e34869d66
[I 10:34:38.091 LabApp] Starting buffering for 2915ac90-c4d5-4155-9446-f46e34869d66:f10a4eccc7224b648ba9b2dd8ad6d9a4
[I 10:34:43.899 LabApp] Kernel restarted: 2915ac90-c4d5-4155-9446-f46e34869d66
[I 10:34:46.660 LabApp] Adapting from protocol version 5.1 (kernel 2915ac90-c4d5-4155-9446-f46e34869d66) to 5.3 (client).
[I 10:34:46.662 LabApp] Restoring connection for 2915ac90-c4d5-4155-9446-f46e34869d66:f10a4eccc7224b648ba9b2dd8ad6d9a4
[I 10:34:46.662 LabApp] Replaying 73 buffered messages
2019-10-31 10:35:01.700824: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-31 10:35:02.283453: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-31 10:35:02.284523: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 10:35:02.287665: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-31 10:35:02.290139: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-31 10:35:02.291157: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-31 10:35:02.294215: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-31 10:35:02.296858: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-31 10:35:02.302909: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-31 10:35:02.305581: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-31 10:35:02.587285: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563874c947f0 executing computations on platform CUDA. Devices:
2019-10-31 10:35:02.587366: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-31 10:35:02.591969: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-31 10:35:02.594006: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563874d6b2b0 executing computations on platform Host. Devices:
2019-10-31 10:35:02.594059: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-31 10:35:02.596047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-31 10:35:02.596208: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 10:35:02.596293: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-31 10:35:02.596372: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-31 10:35:02.596454: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-31 10:35:02.596534: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-31 10:35:02.596613: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-31 10:35:02.596692: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-31 10:35:02.599980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-31 10:35:02.600113: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 10:35:02.604195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-31 10:35:02.604240: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-31 10:35:02.604264: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-31 10:35:02.609544: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-31 10:35:06.465456: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-31 10:35:07.605207: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
[I 10:36:09.773 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 10:38:09.454 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 10:40:09.720 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 10:40:43.773 LabApp] Kernel interrupted: 2915ac90-c4d5-4155-9446-f46e34869d66
[I 10:41:32.034 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 10:42:59.815 LabApp] Kernel interrupted: 2915ac90-c4d5-4155-9446-f46e34869d66
[I 10:43:04.684 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 10:44:09.476 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 10:46:09.728 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 10:47:25.977 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb
[I 10:48:09.741 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 10:49:33.865 LabApp] Starting buffering for 68fe739f-0fae-442f-860e-d943da609e51:1a1eb9501a6642578cbe93e5cfcadaac
[I 10:49:37.541 LabApp] Kernel shutdown: 68fe739f-0fae-442f-860e-d943da609e51
[I 10:50:09.734 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
2019-10-31 10:50:54.610906: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-31 10:50:57.182782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-31 10:50:57.202748: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 10:50:57.206057: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-31 10:50:57.208580: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-31 10:50:57.210016: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-31 10:50:57.213368: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-31 10:50:57.216246: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-31 10:50:57.222382: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-31 10:50:57.225334: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-31 10:50:57.422011: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555f425d8ee0 executing computations on platform CUDA. Devices:
2019-10-31 10:50:57.422075: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K40c, Compute Capability 3.5
2019-10-31 10:50:57.426007: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-31 10:50:57.427942: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555f426af970 executing computations on platform Host. Devices:
2019-10-31 10:50:57.428008: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-31 10:50:57.429666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-31 10:50:57.429796: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 10:50:57.429859: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-31 10:50:57.429918: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-31 10:50:57.429977: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-31 10:50:57.430054: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-31 10:50:57.430114: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-31 10:50:57.430174: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-31 10:50:57.433167: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-31 10:50:57.433269: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 10:50:57.436598: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-31 10:50:57.436632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-31 10:50:57.436650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-31 10:50:57.439797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10794 MB memory) -> physical GPU (device: 0, name: Tesla K40c, pci bus id: 0000:03:00.0, compute capability: 3.5)
2019-10-31 10:51:05.889578: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-10-31 10:51:05.946013: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-31 10:51:06.121086: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 10:52:07.798 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 10:52:10.519 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 10:54:07.912 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 10:54:10.527 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 10:54:49.567 LabApp] Starting buffering for 0a1edf0a-98cf-42c4-aecc-b7d13bb175a8:8ba4d716ba164d7c8e814f25b6cba531
[I 10:54:52.688 LabApp] Kernel shutdown: 0a1edf0a-98cf-42c4-aecc-b7d13bb175a8
[I 10:56:09.769 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 10:56:42.720 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 10:56:44.525 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[W 10:56:50.386 LabApp] 404 POST /api/kernels/436aec5b-f7fe-403a-8294-fb6685340c8c/interrupt (::1): Kernel does not exist: 436aec5b-f7fe-403a-8294-fb6685340c8c
[W 10:56:50.387 LabApp] Kernel does not exist: 436aec5b-f7fe-403a-8294-fb6685340c8c
[W 10:56:50.388 LabApp] 404 POST /api/kernels/436aec5b-f7fe-403a-8294-fb6685340c8c/interrupt (::1) 3.32ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 10:56:51.847 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 10:57:14.183 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 10:57:15.012 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 10:57:18.461 LabApp] Kernel started: 79f8f375-2c2a-4ecd-8a08-f1f50bfd962d
[W 10:57:18.474 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 5.03ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[W 10:57:19.384 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 3.15ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 10:57:21.894 LabApp] Adapting from protocol version 5.1 (kernel 79f8f375-2c2a-4ecd-8a08-f1f50bfd962d) to 5.3 (client).
2019-10-31 10:57:42.714129: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-31 10:57:44.763907: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-31 10:57:44.774807: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 10:57:44.778538: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-31 10:57:44.780570: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-31 10:57:44.781858: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-31 10:57:44.784639: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-31 10:57:44.786923: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-31 10:57:44.792042: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-31 10:57:44.794497: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-31 10:57:44.971571: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5645e2f068a0 executing computations on platform CUDA. Devices:
2019-10-31 10:57:44.971627: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K40c, Compute Capability 3.5
2019-10-31 10:57:44.974789: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-31 10:57:44.976165: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5645e2fdd300 executing computations on platform Host. Devices:
2019-10-31 10:57:44.976210: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-31 10:57:44.977422: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745
pciBusID: 0000:03:00.0
2019-10-31 10:57:44.977504: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 10:57:44.977549: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-31 10:57:44.977590: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-31 10:57:44.977632: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-31 10:57:44.977673: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-31 10:57:44.977715: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-31 10:57:44.977756: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-31 10:57:44.981241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-31 10:57:44.981373: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 10:57:44.983592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-31 10:57:44.983632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-31 10:57:44.983645: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-31 10:57:44.985989: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10794 MB memory) -> physical GPU (device: 0, name: Tesla K40c, pci bus id: 0000:03:00.0, compute capability: 3.5)
2019-10-31 10:57:47.330584: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-31 10:57:47.501737: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 10:58:10.534 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 10:59:19.720 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 11:00:09.913 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 11:01:19.404 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 11:02:10.546 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 11:03:19.380 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 11:04:10.560 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 11:05:19.373 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 11:06:10.597 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 11:06:22.103 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 11:07:19.552 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 11:08:05.796 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 11:08:06.090 LabApp] Kernel interrupted: 79f8f375-2c2a-4ecd-8a08-f1f50bfd962d
[I 11:08:10.570 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 11:09:19.545 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 11:10:09.784 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 11:11:19.838 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 11:12:09.773 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 11:12:29.711 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 11:12:37.032 LabApp] Kernel interrupted: 79f8f375-2c2a-4ecd-8a08-f1f50bfd962d
[I 11:13:19.750 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 11:13:24.209 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 11:14:10.569 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 11:15:20.075 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 11:16:10.581 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 11:17:20.098 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 11:18:10.553 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 11:19:20.040 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 11:20:10.440 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 11:21:20.215 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 11:22:10.559 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 11:23:20.519 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 11:24:10.595 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 11:25:21.210 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 11:26:10.589 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 11:27:21.089 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 11:27:51.904 LabApp] Kernel interrupted: 79f8f375-2c2a-4ecd-8a08-f1f50bfd962d
[I 11:28:09.776 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 11:29:19.372 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 11:30:10.566 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 11:32:09.769 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 11:34:09.850 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 11:35:20.222 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 11:36:10.567 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 11:38:09.836 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 11:40:09.813 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 11:42:09.825 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 11:44:10.600 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 11:46:10.722 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 11:48:10.707 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 11:50:09.843 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 11:51:21.078 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 11:52:10.605 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 11:53:20.257 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 11:54:10.615 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 11:55:20.317 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 11:55:33.073 LabApp] Starting buffering for 554d832d-f579-4e1b-8f2a-a7de5a1f2453:6a3916b34ec24c91bea72ffc9bd09451
[I 11:56:09.850 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 11:57:20.184 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 11:58:09.794 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE-128-Copy1.ipynb
[I 11:59:14.455 LabApp] Kernel interrupted: 2915ac90-c4d5-4155-9446-f46e34869d66
[I 11:59:20.181 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 12:00:09.856 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE2-128.ipynb
[I 12:01:21.161 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 12:02:10.241 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE2-128.ipynb
[I 12:03:21.134 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 12:04:10.604 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE2-128.ipynb
[I 12:04:16.706 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE2-128.ipynb
[I 12:04:17.018 LabApp] Kernel interrupted: 2915ac90-c4d5-4155-9446-f46e34869d66
[I 12:05:22.080 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 12:06:11.364 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE2-128.ipynb
[I 12:07:21.331 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 12:08:11.369 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE2-128.ipynb
[I 12:08:58.814 LabApp] Kernel interrupted: 79f8f375-2c2a-4ecd-8a08-f1f50bfd962d
[I 12:09:20.203 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 12:10:11.397 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE2-128.ipynb
[I 12:11:20.258 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 12:12:11.675 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE2-128.ipynb
[I 12:13:20.194 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 12:14:11.434 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE2-128.ipynb
[I 12:15:21.312 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 12:16:11.365 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE2-128.ipynb
[I 12:16:51.571 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 12:18:11.383 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE2-128.ipynb
[I 12:19:21.101 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 12:20:11.301 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE2-128.ipynb
[I 12:21:21.014 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 12:22:11.294 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE2-128.ipynb
[I 12:23:21.169 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 12:24:11.287 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE2-128.ipynb
[I 12:25:21.023 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 12:26:09.965 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAEGAN-128.ipynb
[I 12:26:11.419 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE2-128.ipynb
[I 12:26:21.699 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAEGAN-128.ipynb
[I 12:26:22.918 LabApp] Copying avgn_paper/notebooks/6.0-neural-networks/Starling-VAEGAN-128.ipynb to /avgn_paper/notebooks/6.0-neural-networks
[W 12:26:24.626 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 18.88ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-VAEGAN-128-Copy1.ipynb
[I 12:26:25.497 LabApp] Kernel started: 98e3f4b4-ec88-46fd-a714-d558f562ab4c
[W 12:26:25.584 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 1.92ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-VAEGAN-128-Copy1.ipynb
[W 12:26:27.896 LabApp] 404 DELETE /api/sessions/d0a54bec-6d9b-448a-b094-cccc1c2a6ec9 (::1): Session not found: session_id='d0a54bec-6d9b-448a-b094-cccc1c2a6ec9'
[W 12:26:27.896 LabApp] Session not found: session_id='d0a54bec-6d9b-448a-b094-cccc1c2a6ec9'
[W 12:26:27.896 LabApp] 404 DELETE /api/sessions/d0a54bec-6d9b-448a-b094-cccc1c2a6ec9 (::1) 1.57ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-VAEGAN-128.ipynb
[I 12:26:30.404 LabApp] Adapting from protocol version 5.1 (kernel 98e3f4b4-ec88-46fd-a714-d558f562ab4c) to 5.3 (client).
[I 12:26:40.972 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAEGAN-128-Copy1.ipynb
[E 12:26:48.227 LabApp] Uncaught exception PATCH /api/contents/avgn_paper/notebooks/6.0-neural-networks/Starling-VAEGAN-128-Copy1.ipynb (::1)
    HTTPServerRequest(protocol='http', host='localhost:8187', method='PATCH', uri='/api/contents/avgn_paper/notebooks/6.0-neural-networks/Starling-VAEGAN-128-Copy1.ipynb', version='HTTP/1.1', remote_ip='::1')
    Traceback (most recent call last):
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/tornado/web.py", line 1699, in _execute
        result = await result
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/tornado/gen.py", line 209, in wrapper
        yielded = next(result)
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/notebook/services/contents/handlers.py", line 125, in patch
        model = yield maybe_future(cm.update(model, path))
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/notebook/services/contents/manager.py", line 296, in update
        self.rename(path, new_path)
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/notebook/services/contents/manager.py", line 284, in rename
        self.rename_file(old_path, new_path)
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/site-packages/notebook/services/contents/filemanager.py", line 569, in rename_file
        if os.path.exists(new_os_path) and not samefile(old_os_path, new_os_path):
      File "/home/AD/tsainbur/anaconda3/envs/py19/lib/python3.6/genericpath.py", line 96, in samefile
        s1 = os.stat(f1)
    FileNotFoundError: [Errno 2] No such file or directory: '/home/AD/tsainbur/github_repos/avgn_paper/notebooks/6.0-neural-networks/Starling-VAEGAN-128-Copy1.ipynb'
[W 12:26:48.285 LabApp] Unhandled error
[E 12:26:48.285 LabApp] {
      "Host": "localhost:8187",
      "Connection": "keep-alive",
      "Content-Length": "78",
      "Accept": "application/json, text/javascript, */*; q=0.01",
      "Origin": "http://localhost:8187",
      "X-Requested-With": "XMLHttpRequest",
      "X-Xsrftoken": "2|2b997e67|29d4ea20755e92079558d090866cac7e|1571165215",
      "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.70 Safari/537.36",
      "Content-Type": "application/json",
      "Sec-Fetch-Site": "same-origin",
      "Sec-Fetch-Mode": "cors",
      "Referer": "http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-VAEGAN-128-Copy1.ipynb",
      "Accept-Encoding": "gzip, deflate, br",
      "Accept-Language": "en-US,en;q=0.9,fr;q=0.8",
      "Cookie": "_ga=GA1.1.2135320950.1566148815; username-localhost-8195=\"2|1:0|10:1570831591|23:username-localhost-8195|44:Y2Q0M2Y0YjJhMDQxNDQwZThhOGNjZTdhNDFiNDNkNjI=|4fc2d73bc3298178be788038ba7812e8e7e1ca4ae1891ffcc42a6bd3445055ab\"; _xsrf=2|2b997e67|29d4ea20755e92079558d090866cac7e|1571165215; username-localhost-8186=\"2|1:0|10:1572148972|23:username-localhost-8186|44:MjAwMmFlOWIxYTRhNDc4ZmFiNDAzOTg3ODBmYzEyOTQ=|c0f3007a6fdd6628418763a8293ba019d9531ba148601913203f1e0121fd51ea\"; username-localhost-8187=\"2|1:0|10:1572493229|23:username-localhost-8187|44:ZGY4ZGEyMzQ2ZTRlNDUzOGExMTczY2U0OTA0MmFkOTU=|3275349390afc9e6baa1f6f9ee83e54d4eb18ebc1a9c62739a25d81664456c6b\""
    }
[E 12:26:48.285 LabApp] 500 PATCH /api/contents/avgn_paper/notebooks/6.0-neural-networks/Starling-VAEGAN-128-Copy1.ipynb (::1) 59.10ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-VAEGAN-128-Copy1.ipynb
[I 12:27:00.360 LabApp] Starting buffering for 1c23d551-7d11-4d02-ac6c-999284268760:4f2392bf065a40468f2b362814098eeb
[I 12:27:11.676 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE2-128.ipynb
[I 12:27:12.591 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE2-128.ipynb
[I 12:27:16.596 LabApp] Kernel interrupted: 2915ac90-c4d5-4155-9446-f46e34869d66
[I 12:27:21.033 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 12:27:31.016 LabApp] Starting buffering for 2915ac90-c4d5-4155-9446-f46e34869d66:f10a4eccc7224b648ba9b2dd8ad6d9a4
[I 12:27:34.069 LabApp] Kernel shutdown: 2915ac90-c4d5-4155-9446-f46e34869d66
[I 12:27:37.865 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 12:27:40.053 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAIA6.ipynb
[I 12:27:59.149 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAEGAN2-128.ipynb
[I 12:28:11.843 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAE2-128.ipynb
2019-10-31 12:28:15.575176: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-31 12:28:16.098971: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-31 12:28:16.130472: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 12:28:16.528834: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-31 12:28:16.628760: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-31 12:28:17.155757: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-31 12:28:17.665063: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-31 12:28:17.742798: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-31 12:28:17.796366: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-31 12:28:17.799447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-31 12:28:18.027383: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563eb9481650 executing computations on platform CUDA. Devices:
2019-10-31 12:28:18.027452: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-31 12:28:18.031043: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-31 12:28:18.032562: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563eb9558110 executing computations on platform Host. Devices:
2019-10-31 12:28:18.032588: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-31 12:28:18.033591: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-31 12:28:18.033678: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 12:28:18.033724: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-31 12:28:18.033767: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-31 12:28:18.033810: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-31 12:28:18.033853: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-31 12:28:18.033896: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-31 12:28:18.033940: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-31 12:28:18.035266: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-31 12:28:18.035335: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 12:28:18.037264: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-31 12:28:18.037296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-31 12:28:18.037309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-31 12:28:18.038788: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 204 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-31 12:28:19.078096: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 204.75M (214695936 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2019-10-31 12:28:19.160657: F ./tensorflow/core/kernels/random_op_gpu.h:227] Non-OK-status: GpuLaunchKernel(FillPhiloxRandomKernelLaunch<Distribution>, num_blocks, block_size, 0, d.stream(), gen, data, size, dist) status: Internal: out of memory
[I 12:28:22.495 LabApp] KernelRestarter: restarting kernel (1/5), keep random ports
kernel 98e3f4b4-ec88-46fd-a714-d558f562ab4c restarted
[I 12:28:25.207 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAEGAN2-128.ipynb
[I 12:28:33.388 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAEGAN2-128.ipynb
[I 12:28:35.293 LabApp] Starting buffering for 98e3f4b4-ec88-46fd-a714-d558f562ab4c:dfc469f7956f4cf58329f2df4c457d97
[I 12:28:35.755 LabApp] Kernel restarted: 98e3f4b4-ec88-46fd-a714-d558f562ab4c
[I 12:28:37.265 LabApp] Adapting from protocol version 5.1 (kernel 98e3f4b4-ec88-46fd-a714-d558f562ab4c) to 5.3 (client).
[I 12:28:37.267 LabApp] Restoring connection for 98e3f4b4-ec88-46fd-a714-d558f562ab4c:dfc469f7956f4cf58329f2df4c457d97
[I 12:28:37.267 LabApp] Replaying 6 buffered messages
2019-10-31 12:28:46.677493: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-31 12:28:47.191054: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-31 12:28:47.191934: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 12:28:47.195216: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-31 12:28:47.197542: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-31 12:28:47.198352: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-31 12:28:47.201602: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-31 12:28:47.204270: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-31 12:28:47.210843: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-31 12:28:47.214042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-31 12:28:47.452816: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556df1af2530 executing computations on platform CUDA. Devices:
2019-10-31 12:28:47.452880: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-31 12:28:47.457086: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-31 12:28:47.458533: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556df1bc8fc0 executing computations on platform Host. Devices:
2019-10-31 12:28:47.458572: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-31 12:28:47.460023: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-31 12:28:47.460133: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 12:28:47.460189: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-31 12:28:47.460240: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-31 12:28:47.460291: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-31 12:28:47.460341: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-31 12:28:47.460392: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-31 12:28:47.460445: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-31 12:28:47.463372: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-31 12:28:47.463459: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 12:28:47.466183: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-31 12:28:47.466211: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-31 12:28:47.466226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-31 12:28:47.468672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-31 12:28:59.487310: W tensorflow/core/common_runtime/bfc_allocator.cc:314] Allocator (GPU_0_bfc) ran out of memory trying to allocate 7.88GiB (rounded to 8456241152).  Current allocation summary follows.
2019-10-31 12:28:59.487422: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (256): 	Total Chunks: 5, Chunks in use: 5. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 772B client-requested in use in bin.
2019-10-31 12:28:59.487456: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (512): 	Total Chunks: 2, Chunks in use: 2. 1.0KiB allocated for chunks. 1.0KiB in use in bin. 1.0KiB client-requested in use in bin.
2019-10-31 12:28:59.487483: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (1024): 	Total Chunks: 7, Chunks in use: 7. 8.8KiB allocated for chunks. 8.8KiB in use in bin. 7.3KiB client-requested in use in bin.
2019-10-31 12:28:59.487507: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (2048): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:28:59.487529: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (4096): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:28:59.487551: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (8192): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:28:59.487573: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (16384): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:28:59.487594: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (32768): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:28:59.487622: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (65536): 	Total Chunks: 3, Chunks in use: 2. 216.0KiB allocated for chunks. 144.0KiB in use in bin. 144.0KiB client-requested in use in bin.
2019-10-31 12:28:59.487667: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (131072): 	Total Chunks: 1, Chunks in use: 0. 138.2KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:28:59.487694: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (262144): 	Total Chunks: 4, Chunks in use: 2. 1.27MiB allocated for chunks. 576.0KiB in use in bin. 576.0KiB client-requested in use in bin.
2019-10-31 12:28:59.487717: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (524288): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:28:59.487740: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (1048576): 	Total Chunks: 4, Chunks in use: 2. 5.06MiB allocated for chunks. 2.25MiB in use in bin. 2.25MiB client-requested in use in bin.
2019-10-31 12:28:59.487763: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (2097152): 	Total Chunks: 2, Chunks in use: 2. 4.50MiB allocated for chunks. 4.50MiB in use in bin. 4.50MiB client-requested in use in bin.
2019-10-31 12:28:59.487785: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:28:59.487806: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (8388608): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:28:59.487827: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:28:59.487848: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (33554432): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:28:59.487870: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (67108864): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:28:59.487891: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:28:59.487916: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (268435456): 	Total Chunks: 2, Chunks in use: 1. 11.15GiB allocated for chunks. 7.88GiB in use in bin. 7.88GiB client-requested in use in bin.
2019-10-31 12:28:59.487938: I tensorflow/core/common_runtime/bfc_allocator.cc:780] Bin for 7.88GiB was 256.00MiB, Chunk State: 
2019-10-31 12:28:59.487971: I tensorflow/core/common_runtime/bfc_allocator.cc:786]   Size: 3.27GiB | Requested Size: 0B | in_use: 0 | bin_num: 20, prev:   Size: 7.88GiB | Requested Size: 7.88GiB | in_use: 1 | bin_num: -1
2019-10-31 12:28:59.487992: I tensorflow/core/common_runtime/bfc_allocator.cc:793] Next region of size 11982716928
2019-10-31 12:28:59.488014: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5d54000000 next 1 of size 1280
2019-10-31 12:28:59.488033: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5d54000500 next 2 of size 256
2019-10-31 12:28:59.488052: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5d54000600 next 3 of size 256
2019-10-31 12:28:59.488069: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5d54000700 next 6 of size 256
2019-10-31 12:28:59.488090: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5d54000800 next 9 of size 512
2019-10-31 12:28:59.488108: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5d54000a00 next 4 of size 1536
2019-10-31 12:28:59.488126: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5d54001000 next 5 of size 1280
2019-10-31 12:28:59.488144: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5d54001500 next 16 of size 1024
2019-10-31 12:28:59.488171: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5d54001900 next 18 of size 1024
2019-10-31 12:28:59.488190: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5d54001d00 next 19 of size 256
2019-10-31 12:28:59.488207: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5d54001e00 next 24 of size 256
2019-10-31 12:28:59.488225: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5d54001f00 next 27 of size 512
2019-10-31 12:28:59.488243: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5d54002100 next 20 of size 1536
2019-10-31 12:28:59.488260: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5d54002700 next 21 of size 1280
2019-10-31 12:28:59.488277: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f5d54002c00 next 7 of size 141568
2019-10-31 12:28:59.488296: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5d54025500 next 8 of size 73728
2019-10-31 12:28:59.488314: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f5d54037500 next 22 of size 73728
2019-10-31 12:28:59.488332: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5d54049500 next 23 of size 73728
2019-10-31 12:28:59.488350: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f5d5405b500 next 10 of size 442368
2019-10-31 12:28:59.488369: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5d540c7500 next 11 of size 294912
2019-10-31 12:28:59.488387: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f5d5410f500 next 25 of size 294912
2019-10-31 12:28:59.488405: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5d54157500 next 26 of size 294912
2019-10-31 12:28:59.488423: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f5d5419f500 next 13 of size 1769472
2019-10-31 12:28:59.488442: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5d5434f500 next 14 of size 1179648
2019-10-31 12:28:59.488460: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f5d5446f500 next 28 of size 1179648
2019-10-31 12:28:59.488478: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5d5458f500 next 12 of size 1179648
2019-10-31 12:28:59.488497: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5d546af500 next 15 of size 2359296
2019-10-31 12:28:59.488515: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5d548ef500 next 17 of size 2359296
2019-10-31 12:28:59.488533: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f5d54b2f500 next 29 of size 8456241152
2019-10-31 12:28:59.488552: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f5f4cbaf500 next 18446744073709551615 of size 3514747648
2019-10-31 12:28:59.488569: I tensorflow/core/common_runtime/bfc_allocator.cc:809]      Summary of in-use Chunks by size: 
2019-10-31 12:28:59.488591: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 5 Chunks of size 256 totalling 1.2KiB
2019-10-31 12:28:59.488612: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 512 totalling 1.0KiB
2019-10-31 12:28:59.488633: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 1024 totalling 2.0KiB
2019-10-31 12:28:59.488653: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 3 Chunks of size 1280 totalling 3.8KiB
2019-10-31 12:28:59.488673: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 1536 totalling 3.0KiB
2019-10-31 12:28:59.488695: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 73728 totalling 144.0KiB
2019-10-31 12:28:59.488716: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 294912 totalling 576.0KiB
2019-10-31 12:28:59.488737: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 1179648 totalling 2.25MiB
2019-10-31 12:28:59.488757: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 2359296 totalling 4.50MiB
2019-10-31 12:28:59.488786: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 8456241152 totalling 7.88GiB
2019-10-31 12:28:59.488807: I tensorflow/core/common_runtime/bfc_allocator.cc:816] Sum Total of in-use chunks: 7.88GiB
2019-10-31 12:28:59.488826: I tensorflow/core/common_runtime/bfc_allocator.cc:818] total_region_allocated_bytes_: 11982716928 memory_limit_: 11982716928 available bytes: 0 curr_region_allocation_bytes_: 23965433856
2019-10-31 12:28:59.488851: I tensorflow/core/common_runtime/bfc_allocator.cc:824] Stats: 
Limit:                 11982716928
InUse:                  8464067584
MaxInUse:               8464067840
NumAllocs:                     104
MaxAllocSize:           8456241152

2019-10-31 12:28:59.488876: W tensorflow/core/common_runtime/bfc_allocator.cc:319] ***********************************************************************_____________________________
2019-10-31 12:28:59.488942: W tensorflow/core/framework/op_kernel.cc:1546] OP_REQUIRES failed at cwise_ops_common.cc:70 : Resource exhausted: OOM when allocating tensor with shape[4129024,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
[I 12:29:10.761 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAEGAN2-128.ipynb
[I 12:29:12.032 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAEGAN2-128.ipynb
[I 12:29:20.165 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 12:29:22.118 LabApp] Starting buffering for 98e3f4b4-ec88-46fd-a714-d558f562ab4c:dfc469f7956f4cf58329f2df4c457d97
[I 12:29:24.322 LabApp] Kernel restarted: 98e3f4b4-ec88-46fd-a714-d558f562ab4c
[I 12:29:27.744 LabApp] Adapting from protocol version 5.1 (kernel 98e3f4b4-ec88-46fd-a714-d558f562ab4c) to 5.3 (client).
[I 12:29:27.746 LabApp] Restoring connection for 98e3f4b4-ec88-46fd-a714-d558f562ab4c:dfc469f7956f4cf58329f2df4c457d97
[I 12:29:27.746 LabApp] Replaying 6 buffered messages
2019-10-31 12:29:39.741565: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-31 12:29:40.264859: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-31 12:29:40.266102: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 12:29:40.269721: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-31 12:29:40.272591: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-31 12:29:40.273793: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-31 12:29:40.277635: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-31 12:29:40.280695: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-31 12:29:40.287766: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-31 12:29:40.291065: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-31 12:29:40.535036: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556033f38cc0 executing computations on platform CUDA. Devices:
2019-10-31 12:29:40.535162: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-31 12:29:40.541070: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-31 12:29:40.543796: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55603400f720 executing computations on platform Host. Devices:
2019-10-31 12:29:40.543880: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-31 12:29:40.545922: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-31 12:29:40.546063: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 12:29:40.546147: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-31 12:29:40.546226: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-31 12:29:40.546304: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-31 12:29:40.546381: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-31 12:29:40.546460: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-31 12:29:40.546540: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-31 12:29:40.550182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-31 12:29:40.550306: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 12:29:40.554473: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-31 12:29:40.554517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-31 12:29:40.554540: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-31 12:29:40.558556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-31 12:29:52.926649: W tensorflow/core/common_runtime/bfc_allocator.cc:314] Allocator (GPU_0_bfc) ran out of memory trying to allocate 7.88GiB (rounded to 8456241152).  Current allocation summary follows.
2019-10-31 12:29:52.926728: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (256): 	Total Chunks: 5, Chunks in use: 5. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 772B client-requested in use in bin.
2019-10-31 12:29:52.926746: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (512): 	Total Chunks: 2, Chunks in use: 2. 1.0KiB allocated for chunks. 1.0KiB in use in bin. 1.0KiB client-requested in use in bin.
2019-10-31 12:29:52.926760: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (1024): 	Total Chunks: 7, Chunks in use: 7. 8.8KiB allocated for chunks. 8.8KiB in use in bin. 7.3KiB client-requested in use in bin.
2019-10-31 12:29:52.926772: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (2048): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:29:52.926784: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (4096): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:29:52.926795: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (8192): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:29:52.926806: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (16384): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:29:52.926817: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (32768): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:29:52.926844: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (65536): 	Total Chunks: 3, Chunks in use: 2. 216.0KiB allocated for chunks. 144.0KiB in use in bin. 144.0KiB client-requested in use in bin.
2019-10-31 12:29:52.926858: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (131072): 	Total Chunks: 1, Chunks in use: 0. 138.2KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:29:52.926871: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (262144): 	Total Chunks: 4, Chunks in use: 2. 1.27MiB allocated for chunks. 576.0KiB in use in bin. 576.0KiB client-requested in use in bin.
2019-10-31 12:29:52.926883: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (524288): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:29:52.926895: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (1048576): 	Total Chunks: 4, Chunks in use: 2. 5.06MiB allocated for chunks. 2.25MiB in use in bin. 2.25MiB client-requested in use in bin.
2019-10-31 12:29:52.926907: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (2097152): 	Total Chunks: 2, Chunks in use: 2. 4.50MiB allocated for chunks. 4.50MiB in use in bin. 4.50MiB client-requested in use in bin.
2019-10-31 12:29:52.926918: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:29:52.926929: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (8388608): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:29:52.926939: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:29:52.926950: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (33554432): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:29:52.926961: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (67108864): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:29:52.926972: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:29:52.926984: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (268435456): 	Total Chunks: 2, Chunks in use: 1. 11.15GiB allocated for chunks. 7.88GiB in use in bin. 7.88GiB client-requested in use in bin.
2019-10-31 12:29:52.926996: I tensorflow/core/common_runtime/bfc_allocator.cc:780] Bin for 7.88GiB was 256.00MiB, Chunk State: 
2019-10-31 12:29:52.927013: I tensorflow/core/common_runtime/bfc_allocator.cc:786]   Size: 3.27GiB | Requested Size: 0B | in_use: 0 | bin_num: 20, prev:   Size: 7.88GiB | Requested Size: 7.88GiB | in_use: 1 | bin_num: -1
2019-10-31 12:29:52.927024: I tensorflow/core/common_runtime/bfc_allocator.cc:793] Next region of size 11982716928
2019-10-31 12:29:52.927036: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7fc100000000 next 1 of size 1280
2019-10-31 12:29:52.927046: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7fc100000500 next 2 of size 256
2019-10-31 12:29:52.927055: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7fc100000600 next 3 of size 256
2019-10-31 12:29:52.927063: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7fc100000700 next 6 of size 256
2019-10-31 12:29:52.927073: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7fc100000800 next 9 of size 512
2019-10-31 12:29:52.927083: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7fc100000a00 next 4 of size 1536
2019-10-31 12:29:52.927097: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7fc100001000 next 5 of size 1280
2019-10-31 12:29:52.927119: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7fc100001500 next 16 of size 1024
2019-10-31 12:29:52.927148: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7fc100001900 next 18 of size 1024
2019-10-31 12:29:52.927169: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7fc100001d00 next 19 of size 256
2019-10-31 12:29:52.927189: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7fc100001e00 next 24 of size 256
2019-10-31 12:29:52.927209: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7fc100001f00 next 27 of size 512
2019-10-31 12:29:52.927228: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7fc100002100 next 20 of size 1536
2019-10-31 12:29:52.927248: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7fc100002700 next 21 of size 1280
2019-10-31 12:29:52.927268: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7fc100002c00 next 7 of size 141568
2019-10-31 12:29:52.927289: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7fc100025500 next 8 of size 73728
2019-10-31 12:29:52.927309: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7fc100037500 next 22 of size 73728
2019-10-31 12:29:52.927329: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7fc100049500 next 23 of size 73728
2019-10-31 12:29:52.927348: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7fc10005b500 next 10 of size 442368
2019-10-31 12:29:52.927369: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7fc1000c7500 next 11 of size 294912
2019-10-31 12:29:52.927389: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7fc10010f500 next 25 of size 294912
2019-10-31 12:29:52.927408: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7fc100157500 next 26 of size 294912
2019-10-31 12:29:52.927428: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7fc10019f500 next 13 of size 1769472
2019-10-31 12:29:52.927448: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7fc10034f500 next 14 of size 1179648
2019-10-31 12:29:52.927468: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7fc10046f500 next 28 of size 1179648
2019-10-31 12:29:52.927487: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7fc10058f500 next 12 of size 1179648
2019-10-31 12:29:52.927508: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7fc1006af500 next 15 of size 2359296
2019-10-31 12:29:52.927527: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7fc1008ef500 next 17 of size 2359296
2019-10-31 12:29:52.927547: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7fc100b2f500 next 29 of size 8456241152
2019-10-31 12:29:52.927567: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7fc2f8baf500 next 18446744073709551615 of size 3514747648
2019-10-31 12:29:52.927586: I tensorflow/core/common_runtime/bfc_allocator.cc:809]      Summary of in-use Chunks by size: 
2019-10-31 12:29:52.927611: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 5 Chunks of size 256 totalling 1.2KiB
2019-10-31 12:29:52.927635: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 512 totalling 1.0KiB
2019-10-31 12:29:52.927658: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 1024 totalling 2.0KiB
2019-10-31 12:29:52.927681: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 3 Chunks of size 1280 totalling 3.8KiB
2019-10-31 12:29:52.927703: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 1536 totalling 3.0KiB
2019-10-31 12:29:52.927726: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 73728 totalling 144.0KiB
2019-10-31 12:29:52.927750: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 294912 totalling 576.0KiB
2019-10-31 12:29:52.927785: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 1179648 totalling 2.25MiB
2019-10-31 12:29:52.927810: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 2359296 totalling 4.50MiB
2019-10-31 12:29:52.927833: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 8456241152 totalling 7.88GiB
2019-10-31 12:29:52.927855: I tensorflow/core/common_runtime/bfc_allocator.cc:816] Sum Total of in-use chunks: 7.88GiB
2019-10-31 12:29:52.927875: I tensorflow/core/common_runtime/bfc_allocator.cc:818] total_region_allocated_bytes_: 11982716928 memory_limit_: 11982716928 available bytes: 0 curr_region_allocation_bytes_: 23965433856
2019-10-31 12:29:52.927903: I tensorflow/core/common_runtime/bfc_allocator.cc:824] Stats: 
Limit:                 11982716928
InUse:                  8464067584
MaxInUse:               8464067840
NumAllocs:                     104
MaxAllocSize:           8456241152

2019-10-31 12:29:52.927930: W tensorflow/core/common_runtime/bfc_allocator.cc:319] ***********************************************************************_____________________________
2019-10-31 12:29:52.927999: W tensorflow/core/framework/op_kernel.cc:1546] OP_REQUIRES failed at cwise_ops_common.cc:70 : Resource exhausted: OOM when allocating tensor with shape[4129024,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
[I 12:30:25.287 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAEGAN2-128.ipynb
[I 12:31:20.159 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 12:33:20.200 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 12:35:20.152 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 12:36:37.559 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAEGAN2-128.ipynb
[I 12:36:46.818 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAEGAN2-128.ipynb
[I 12:36:58.901 LabApp] Starting buffering for 98e3f4b4-ec88-46fd-a714-d558f562ab4c:dfc469f7956f4cf58329f2df4c457d97
[I 12:37:01.291 LabApp] Kernel restarted: 98e3f4b4-ec88-46fd-a714-d558f562ab4c
[I 12:37:04.521 LabApp] Adapting from protocol version 5.1 (kernel 98e3f4b4-ec88-46fd-a714-d558f562ab4c) to 5.3 (client).
[I 12:37:04.522 LabApp] Restoring connection for 98e3f4b4-ec88-46fd-a714-d558f562ab4c:dfc469f7956f4cf58329f2df4c457d97
[I 12:37:04.522 LabApp] Replaying 6 buffered messages
2019-10-31 12:37:17.293408: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-31 12:37:17.806096: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-31 12:37:17.807377: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 12:37:17.809658: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-31 12:37:17.811468: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-31 12:37:17.812664: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-31 12:37:17.814929: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-31 12:37:17.817073: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-31 12:37:17.821232: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-31 12:37:17.823041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-31 12:37:18.060875: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5605b0c70240 executing computations on platform CUDA. Devices:
2019-10-31 12:37:18.060960: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-31 12:37:18.066837: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-31 12:37:18.068271: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5605b0d46cd0 executing computations on platform Host. Devices:
2019-10-31 12:37:18.068301: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-31 12:37:18.069329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-31 12:37:18.069417: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 12:37:18.069461: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-31 12:37:18.069502: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-31 12:37:18.069542: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-31 12:37:18.069583: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-31 12:37:18.069623: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-31 12:37:18.069665: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-31 12:37:18.072202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-31 12:37:18.072404: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 12:37:18.074225: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-31 12:37:18.074244: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-31 12:37:18.074255: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-31 12:37:18.076341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
[I 12:37:21.003 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
2019-10-31 12:37:30.197605: W tensorflow/core/common_runtime/bfc_allocator.cc:314] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.94GiB (rounded to 4228120576).  Current allocation summary follows.
2019-10-31 12:37:30.197732: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (256): 	Total Chunks: 5, Chunks in use: 5. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 772B client-requested in use in bin.
2019-10-31 12:37:30.197778: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (512): 	Total Chunks: 3, Chunks in use: 3. 1.5KiB allocated for chunks. 1.5KiB in use in bin. 1.5KiB client-requested in use in bin.
2019-10-31 12:37:30.197806: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (1024): 	Total Chunks: 7, Chunks in use: 6. 8.2KiB allocated for chunks. 7.2KiB in use in bin. 6.3KiB client-requested in use in bin.
2019-10-31 12:37:30.197831: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (2048): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:37:30.197854: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (4096): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:37:30.197896: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (8192): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:37:30.197921: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (16384): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:37:30.197944: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (32768): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:37:30.197975: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (65536): 	Total Chunks: 3, Chunks in use: 2. 216.0KiB allocated for chunks. 144.0KiB in use in bin. 144.0KiB client-requested in use in bin.
2019-10-31 12:37:30.198002: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (131072): 	Total Chunks: 1, Chunks in use: 0. 138.2KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:37:30.198029: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (262144): 	Total Chunks: 4, Chunks in use: 2. 1.27MiB allocated for chunks. 576.0KiB in use in bin. 576.0KiB client-requested in use in bin.
2019-10-31 12:37:30.198055: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (524288): 	Total Chunks: 1, Chunks in use: 1. 576.0KiB allocated for chunks. 576.0KiB in use in bin. 576.0KiB client-requested in use in bin.
2019-10-31 12:37:30.198080: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (1048576): 	Total Chunks: 2, Chunks in use: 1. 2.25MiB allocated for chunks. 1.12MiB in use in bin. 1.12MiB client-requested in use in bin.
2019-10-31 12:37:30.198105: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (2097152): 	Total Chunks: 3, Chunks in use: 2. 6.75MiB allocated for chunks. 4.50MiB in use in bin. 4.50MiB client-requested in use in bin.
2019-10-31 12:37:30.198127: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:37:30.198150: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (8388608): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:37:30.198173: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:37:30.198195: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (33554432): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:37:30.198218: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (67108864): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:37:30.198240: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:37:30.198266: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (268435456): 	Total Chunks: 3, Chunks in use: 2. 11.15GiB allocated for chunks. 7.88GiB in use in bin. 7.88GiB client-requested in use in bin.
2019-10-31 12:37:30.198291: I tensorflow/core/common_runtime/bfc_allocator.cc:780] Bin for 3.94GiB was 256.00MiB, Chunk State: 
2019-10-31 12:37:30.198327: I tensorflow/core/common_runtime/bfc_allocator.cc:786]   Size: 3.27GiB | Requested Size: 0B | in_use: 0 | bin_num: 20, prev:   Size: 3.94GiB | Requested Size: 3.94GiB | in_use: 1 | bin_num: -1
2019-10-31 12:37:30.198348: I tensorflow/core/common_runtime/bfc_allocator.cc:793] Next region of size 11982716928
2019-10-31 12:37:30.198372: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f55a4000000 next 1 of size 1280
2019-10-31 12:37:30.198401: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f55a4000500 next 2 of size 256
2019-10-31 12:37:30.198421: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f55a4000600 next 3 of size 256
2019-10-31 12:37:30.198440: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f55a4000700 next 6 of size 256
2019-10-31 12:37:30.198461: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f55a4000800 next 9 of size 512
2019-10-31 12:37:30.198481: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f55a4000a00 next 4 of size 1536
2019-10-31 12:37:30.198500: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f55a4001000 next 5 of size 1280
2019-10-31 12:37:30.198519: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f55a4001500 next 16 of size 1024
2019-10-31 12:37:30.198538: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f55a4001900 next 18 of size 1024
2019-10-31 12:37:30.198557: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f55a4001d00 next 19 of size 256
2019-10-31 12:37:30.198575: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f55a4001e00 next 24 of size 256
2019-10-31 12:37:30.198594: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f55a4001f00 next 27 of size 512
2019-10-31 12:37:30.198613: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f55a4002100 next 28 of size 512
2019-10-31 12:37:30.198631: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f55a4002300 next 20 of size 1024
2019-10-31 12:37:30.198650: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f55a4002700 next 21 of size 1280
2019-10-31 12:37:30.198669: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f55a4002c00 next 7 of size 141568
2019-10-31 12:37:30.198689: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f55a4025500 next 8 of size 73728
2019-10-31 12:37:30.198708: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f55a4037500 next 22 of size 73728
2019-10-31 12:37:30.198727: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f55a4049500 next 23 of size 73728
2019-10-31 12:37:30.198745: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f55a405b500 next 10 of size 442368
2019-10-31 12:37:30.198764: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f55a40c7500 next 11 of size 294912
2019-10-31 12:37:30.198783: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f55a410f500 next 25 of size 294912
2019-10-31 12:37:30.198802: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f55a4157500 next 26 of size 294912
2019-10-31 12:37:30.198821: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f55a419f500 next 29 of size 1179648
2019-10-31 12:37:30.198840: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f55a42bf500 next 13 of size 589824
2019-10-31 12:37:30.198859: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f55a434f500 next 14 of size 1179648
2019-10-31 12:37:30.198878: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f55a446f500 next 12 of size 2359296
2019-10-31 12:37:30.198897: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f55a46af500 next 15 of size 2359296
2019-10-31 12:37:30.198916: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f55a48ef500 next 17 of size 2359296
2019-10-31 12:37:30.198935: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f55a4b2f500 next 30 of size 4228120576
2019-10-31 12:37:30.198954: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f56a0b6f500 next 31 of size 4228120576
2019-10-31 12:37:30.198974: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f579cbaf500 next 18446744073709551615 of size 3514747648
2019-10-31 12:37:30.199004: I tensorflow/core/common_runtime/bfc_allocator.cc:809]      Summary of in-use Chunks by size: 
2019-10-31 12:37:30.199030: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 5 Chunks of size 256 totalling 1.2KiB
2019-10-31 12:37:30.199055: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 3 Chunks of size 512 totalling 1.5KiB
2019-10-31 12:37:30.199077: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 1024 totalling 2.0KiB
2019-10-31 12:37:30.199124: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 3 Chunks of size 1280 totalling 3.8KiB
2019-10-31 12:37:30.199154: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 1536 totalling 1.5KiB
2019-10-31 12:37:30.199178: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 73728 totalling 144.0KiB
2019-10-31 12:37:30.199201: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 294912 totalling 576.0KiB
2019-10-31 12:37:30.199224: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 589824 totalling 576.0KiB
2019-10-31 12:37:30.199246: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 1179648 totalling 1.12MiB
2019-10-31 12:37:30.199268: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 2359296 totalling 4.50MiB
2019-10-31 12:37:30.199289: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 4228120576 totalling 7.88GiB
2019-10-31 12:37:30.199310: I tensorflow/core/common_runtime/bfc_allocator.cc:816] Sum Total of in-use chunks: 7.88GiB
2019-10-31 12:37:30.199330: I tensorflow/core/common_runtime/bfc_allocator.cc:818] total_region_allocated_bytes_: 11982716928 memory_limit_: 11982716928 available bytes: 0 curr_region_allocation_bytes_: 23965433856
2019-10-31 12:37:30.199358: I tensorflow/core/common_runtime/bfc_allocator.cc:824] Stats: 
Limit:                 11982716928
InUse:                  8463476736
MaxInUse:               8463476736
NumAllocs:                     106
MaxAllocSize:           4228120576

2019-10-31 12:37:30.199384: W tensorflow/core/common_runtime/bfc_allocator.cc:319] ***********************************************************************_____________________________
2019-10-31 12:37:30.199451: W tensorflow/core/framework/op_kernel.cc:1546] OP_REQUIRES failed at cwise_ops_common.cc:70 : Resource exhausted: OOM when allocating tensor with shape[2064512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
[I 12:38:25.789 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAEGAN2-128.ipynb
[I 12:38:28.094 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAEGAN2-128.ipynb
[I 12:39:07.635 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAEGAN2-128.ipynb
[I 12:39:10.449 LabApp] Starting buffering for 98e3f4b4-ec88-46fd-a714-d558f562ab4c:dfc469f7956f4cf58329f2df4c457d97
[I 12:39:12.779 LabApp] Kernel restarted: 98e3f4b4-ec88-46fd-a714-d558f562ab4c
[I 12:39:15.937 LabApp] Adapting from protocol version 5.1 (kernel 98e3f4b4-ec88-46fd-a714-d558f562ab4c) to 5.3 (client).
[I 12:39:15.939 LabApp] Restoring connection for 98e3f4b4-ec88-46fd-a714-d558f562ab4c:dfc469f7956f4cf58329f2df4c457d97
[I 12:39:15.939 LabApp] Replaying 6 buffered messages
[I 12:39:21.058 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
2019-10-31 12:39:28.878475: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-31 12:39:29.491991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-31 12:39:29.493251: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 12:39:29.495318: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-31 12:39:29.496832: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-31 12:39:29.497737: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-31 12:39:29.499734: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-31 12:39:29.501427: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-31 12:39:29.505230: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-31 12:39:29.507333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-31 12:39:29.723278: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c6662c77b0 executing computations on platform CUDA. Devices:
2019-10-31 12:39:29.723334: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-31 12:39:29.727140: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-31 12:39:29.728505: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c66639e260 executing computations on platform Host. Devices:
2019-10-31 12:39:29.728533: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-31 12:39:29.730286: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-31 12:39:29.730359: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 12:39:29.730399: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-31 12:39:29.730435: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-31 12:39:29.730530: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-31 12:39:29.730609: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-31 12:39:29.730688: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-31 12:39:29.730768: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-31 12:39:29.732927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-31 12:39:29.732995: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 12:39:29.735256: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-31 12:39:29.735277: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-31 12:39:29.735288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-31 12:39:29.737591: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
[I 12:39:31.079 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAEGAN2-128.ipynb
2019-10-31 12:39:42.684368: W tensorflow/core/common_runtime/bfc_allocator.cc:314] Allocator (GPU_0_bfc) ran out of memory trying to allocate 63.75GiB (rounded to 68451303424).  Current allocation summary follows.
2019-10-31 12:39:42.684472: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (256): 	Total Chunks: 5, Chunks in use: 4. 1.2KiB allocated for chunks. 1.0KiB in use in bin. 768B client-requested in use in bin.
2019-10-31 12:39:42.684516: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (512): 	Total Chunks: 5, Chunks in use: 5. 2.5KiB allocated for chunks. 2.5KiB in use in bin. 2.5KiB client-requested in use in bin.
2019-10-31 12:39:42.684542: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (1024): 	Total Chunks: 6, Chunks in use: 6. 7.2KiB allocated for chunks. 7.2KiB in use in bin. 6.3KiB client-requested in use in bin.
2019-10-31 12:39:42.684563: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (2048): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:39:42.684584: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (4096): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:39:42.684604: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (8192): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:39:42.684624: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (16384): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:39:42.684644: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (32768): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:39:42.684670: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (65536): 	Total Chunks: 3, Chunks in use: 2. 216.0KiB allocated for chunks. 144.0KiB in use in bin. 144.0KiB client-requested in use in bin.
2019-10-31 12:39:42.684694: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (131072): 	Total Chunks: 1, Chunks in use: 0. 138.2KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:39:42.684718: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (262144): 	Total Chunks: 4, Chunks in use: 2. 1.27MiB allocated for chunks. 576.0KiB in use in bin. 576.0KiB client-requested in use in bin.
2019-10-31 12:39:42.684741: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (524288): 	Total Chunks: 3, Chunks in use: 3. 1.69MiB allocated for chunks. 1.69MiB in use in bin. 1.69MiB client-requested in use in bin.
2019-10-31 12:39:42.684764: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (1048576): 	Total Chunks: 3, Chunks in use: 1. 3.38MiB allocated for chunks. 1.12MiB in use in bin. 1.12MiB client-requested in use in bin.
2019-10-31 12:39:42.684786: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (2097152): 	Total Chunks: 2, Chunks in use: 2. 4.50MiB allocated for chunks. 4.50MiB in use in bin. 4.50MiB client-requested in use in bin.
2019-10-31 12:39:42.684807: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:39:42.684827: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (8388608): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:39:42.684848: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:39:42.684868: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (33554432): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:39:42.684888: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (67108864): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:39:42.684909: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:39:42.684940: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (268435456): 	Total Chunks: 1, Chunks in use: 0. 11.15GiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:39:42.684964: I tensorflow/core/common_runtime/bfc_allocator.cc:780] Bin for 63.75GiB was 256.00MiB, Chunk State: 
2019-10-31 12:39:42.684996: I tensorflow/core/common_runtime/bfc_allocator.cc:786]   Size: 11.15GiB | Requested Size: 0B | in_use: 0 | bin_num: 20, prev:   Size: 2.25MiB | Requested Size: 2.25MiB | in_use: 1 | bin_num: -1
2019-10-31 12:39:42.685015: I tensorflow/core/common_runtime/bfc_allocator.cc:793] Next region of size 11982716928
2019-10-31 12:39:42.685037: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848000000 next 1 of size 1280
2019-10-31 12:39:42.685056: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f2848000500 next 2 of size 256
2019-10-31 12:39:42.685074: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848000600 next 3 of size 256
2019-10-31 12:39:42.685091: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848000700 next 6 of size 256
2019-10-31 12:39:42.685110: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848000800 next 9 of size 512
2019-10-31 12:39:42.685128: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848000a00 next 4 of size 1536
2019-10-31 12:39:42.685145: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848001000 next 5 of size 1280
2019-10-31 12:39:42.685163: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848001500 next 16 of size 1024
2019-10-31 12:39:42.685180: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848001900 next 18 of size 1024
2019-10-31 12:39:42.685198: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848001d00 next 19 of size 256
2019-10-31 12:39:42.685215: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848001e00 next 24 of size 256
2019-10-31 12:39:42.685233: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848001f00 next 27 of size 512
2019-10-31 12:39:42.685250: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848002100 next 28 of size 512
2019-10-31 12:39:42.685267: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848002300 next 30 of size 512
2019-10-31 12:39:42.685285: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848002500 next 20 of size 512
2019-10-31 12:39:42.685302: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848002700 next 21 of size 1280
2019-10-31 12:39:42.685320: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f2848002c00 next 7 of size 141568
2019-10-31 12:39:42.685338: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848025500 next 8 of size 73728
2019-10-31 12:39:42.685355: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f2848037500 next 22 of size 73728
2019-10-31 12:39:42.685373: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848049500 next 23 of size 73728
2019-10-31 12:39:42.685390: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f284805b500 next 10 of size 442368
2019-10-31 12:39:42.685408: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f28480c7500 next 11 of size 294912
2019-10-31 12:39:42.685425: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f284810f500 next 25 of size 294912
2019-10-31 12:39:42.685443: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848157500 next 26 of size 294912
2019-10-31 12:39:42.685461: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f284819f500 next 29 of size 1179648
2019-10-31 12:39:42.685479: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f28482bf500 next 13 of size 589824
2019-10-31 12:39:42.685505: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f284834f500 next 14 of size 1179648
2019-10-31 12:39:42.685524: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f284846f500 next 31 of size 589824
2019-10-31 12:39:42.685542: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f28484ff500 next 33 of size 589824
2019-10-31 12:39:42.685559: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f284858f500 next 12 of size 1179648
2019-10-31 12:39:42.685577: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f28486af500 next 15 of size 2359296
2019-10-31 12:39:42.685595: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f28488ef500 next 17 of size 2359296
2019-10-31 12:39:42.685613: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f2848b2f500 next 18446744073709551615 of size 11970988800
2019-10-31 12:39:42.685629: I tensorflow/core/common_runtime/bfc_allocator.cc:809]      Summary of in-use Chunks by size: 
2019-10-31 12:39:42.685651: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 4 Chunks of size 256 totalling 1.0KiB
2019-10-31 12:39:42.685672: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 5 Chunks of size 512 totalling 2.5KiB
2019-10-31 12:39:42.685691: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 1024 totalling 2.0KiB
2019-10-31 12:39:42.685711: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 3 Chunks of size 1280 totalling 3.8KiB
2019-10-31 12:39:42.685730: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 1536 totalling 1.5KiB
2019-10-31 12:39:42.685752: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 73728 totalling 144.0KiB
2019-10-31 12:39:42.685773: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 294912 totalling 576.0KiB
2019-10-31 12:39:42.685793: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 3 Chunks of size 589824 totalling 1.69MiB
2019-10-31 12:39:42.685812: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 1179648 totalling 1.12MiB
2019-10-31 12:39:42.685832: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 2359296 totalling 4.50MiB
2019-10-31 12:39:42.685851: I tensorflow/core/common_runtime/bfc_allocator.cc:816] Sum Total of in-use chunks: 8.03MiB
2019-10-31 12:39:42.685870: I tensorflow/core/common_runtime/bfc_allocator.cc:818] total_region_allocated_bytes_: 11982716928 memory_limit_: 11982716928 available bytes: 0 curr_region_allocation_bytes_: 23965433856
2019-10-31 12:39:42.685894: I tensorflow/core/common_runtime/bfc_allocator.cc:824] Stats: 
Limit:                 11982716928
InUse:                     8416000
MaxInUse:                 10991872
NumAllocs:                     121
MaxAllocSize:              2359296

2019-10-31 12:39:42.685918: W tensorflow/core/common_runtime/bfc_allocator.cc:319] *___________________________________________________________________________________________________
2019-10-31 12:39:42.685981: W tensorflow/core/framework/op_kernel.cc:1546] OP_REQUIRES failed at random_op.cc:76 : Resource exhausted: OOM when allocating tensor with shape[33423488,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
[I 12:40:14.254 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAEGAN2-128.ipynb
[I 12:40:45.495 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAEGAN2-128.ipynb
[I 12:41:20.170 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 12:41:25.985 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAEGAN2-128.ipynb
[I 12:41:29.683 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAEGAN2-128.ipynb
2019-10-31 12:41:44.965376: W tensorflow/core/common_runtime/bfc_allocator.cc:314] Allocator (GPU_0_bfc) ran out of memory trying to allocate 15.94GiB (rounded to 17112825856).  Current allocation summary follows.
2019-10-31 12:41:44.965475: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (256): 	Total Chunks: 14, Chunks in use: 13. 3.5KiB allocated for chunks. 3.2KiB in use in bin. 2.2KiB client-requested in use in bin.
2019-10-31 12:41:44.965492: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (512): 	Total Chunks: 10, Chunks in use: 10. 5.2KiB allocated for chunks. 5.2KiB in use in bin. 5.1KiB client-requested in use in bin.
2019-10-31 12:41:44.965505: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (1024): 	Total Chunks: 14, Chunks in use: 14. 16.8KiB allocated for chunks. 16.8KiB in use in bin. 14.5KiB client-requested in use in bin.
2019-10-31 12:41:44.965517: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (2048): 	Total Chunks: 2, Chunks in use: 2. 4.0KiB allocated for chunks. 4.0KiB in use in bin. 4.0KiB client-requested in use in bin.
2019-10-31 12:41:44.965528: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (4096): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:41:44.965538: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (8192): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:41:44.965550: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (16384): 	Total Chunks: 1, Chunks in use: 1. 18.0KiB allocated for chunks. 18.0KiB in use in bin. 18.0KiB client-requested in use in bin.
2019-10-31 12:41:44.965562: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (32768): 	Total Chunks: 1, Chunks in use: 0. 35.5KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:41:44.965574: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (65536): 	Total Chunks: 6, Chunks in use: 4. 432.0KiB allocated for chunks. 288.0KiB in use in bin. 288.0KiB client-requested in use in bin.
2019-10-31 12:41:44.965587: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (131072): 	Total Chunks: 3, Chunks in use: 2. 426.2KiB allocated for chunks. 282.2KiB in use in bin. 216.0KiB client-requested in use in bin.
2019-10-31 12:41:44.965598: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (262144): 	Total Chunks: 7, Chunks in use: 5. 2.11MiB allocated for chunks. 1.41MiB in use in bin. 1.41MiB client-requested in use in bin.
2019-10-31 12:41:44.965610: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (524288): 	Total Chunks: 6, Chunks in use: 4. 3.66MiB allocated for chunks. 2.25MiB in use in bin. 2.25MiB client-requested in use in bin.
2019-10-31 12:41:44.965621: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (1048576): 	Total Chunks: 3, Chunks in use: 3. 3.38MiB allocated for chunks. 3.38MiB in use in bin. 3.38MiB client-requested in use in bin.
2019-10-31 12:41:44.965633: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (2097152): 	Total Chunks: 8, Chunks in use: 6. 19.12MiB allocated for chunks. 13.50MiB in use in bin. 13.50MiB client-requested in use in bin.
2019-10-31 12:41:44.965644: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:41:44.965654: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (8388608): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:41:44.965664: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:41:44.965676: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (33554432): 	Total Chunks: 2, Chunks in use: 1. 89.25MiB allocated for chunks. 32.00MiB in use in bin. 32.00MiB client-requested in use in bin.
2019-10-31 12:41:44.965687: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (67108864): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:41:44.965702: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:41:44.965714: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (268435456): 	Total Chunks: 1, Chunks in use: 0. 11.04GiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:41:44.965726: I tensorflow/core/common_runtime/bfc_allocator.cc:780] Bin for 15.94GiB was 256.00MiB, Chunk State: 
2019-10-31 12:41:44.965743: I tensorflow/core/common_runtime/bfc_allocator.cc:786]   Size: 11.04GiB | Requested Size: 0B | in_use: 0 | bin_num: 20, prev:   Size: 32.00MiB | Requested Size: 32.00MiB | in_use: 1 | bin_num: -1
2019-10-31 12:41:44.965753: I tensorflow/core/common_runtime/bfc_allocator.cc:793] Next region of size 11982716928
2019-10-31 12:41:44.965765: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848000000 next 1 of size 1280
2019-10-31 12:41:44.965775: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848000500 next 2 of size 256
2019-10-31 12:41:44.965784: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848000600 next 3 of size 256
2019-10-31 12:41:44.965792: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848000700 next 6 of size 256
2019-10-31 12:41:44.965802: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848000800 next 9 of size 512
2019-10-31 12:41:44.965811: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848000a00 next 4 of size 1536
2019-10-31 12:41:44.965820: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848001000 next 5 of size 1280
2019-10-31 12:41:44.965829: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848001500 next 16 of size 1024
2019-10-31 12:41:44.965838: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848001900 next 18 of size 1024
2019-10-31 12:41:44.965847: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848001d00 next 19 of size 256
2019-10-31 12:41:44.965856: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848001e00 next 24 of size 256
2019-10-31 12:41:44.965865: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848001f00 next 27 of size 512
2019-10-31 12:41:44.965873: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848002100 next 28 of size 512
2019-10-31 12:41:44.965882: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848002300 next 30 of size 512
2019-10-31 12:41:44.965891: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848002500 next 20 of size 512
2019-10-31 12:41:44.965899: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848002700 next 21 of size 1280
2019-10-31 12:41:44.965908: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848002c00 next 7 of size 141568
2019-10-31 12:41:44.965918: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848025500 next 8 of size 73728
2019-10-31 12:41:44.965927: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848037500 next 32 of size 256
2019-10-31 12:41:44.965935: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848037600 next 38 of size 256
2019-10-31 12:41:44.965944: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848037700 next 41 of size 512
2019-10-31 12:41:44.965953: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848037900 next 34 of size 1536
2019-10-31 12:41:44.965962: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848037f00 next 35 of size 1280
2019-10-31 12:41:44.965970: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848038400 next 44 of size 1024
2019-10-31 12:41:44.965984: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848038800 next 47 of size 1024
2019-10-31 12:41:44.965994: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848038c00 next 49 of size 2048
2019-10-31 12:41:44.966003: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f2848039400 next 52 of size 256
2019-10-31 12:41:44.966012: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848039500 next 55 of size 256
2019-10-31 12:41:44.966020: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848039600 next 58 of size 256
2019-10-31 12:41:44.966029: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848039700 next 60 of size 512
2019-10-31 12:41:44.966038: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848039900 next 56 of size 1536
2019-10-31 12:41:44.966047: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848039f00 next 53 of size 1280
2019-10-31 12:41:44.966055: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f284803a400 next 54 of size 2048
2019-10-31 12:41:44.966064: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f284803ac00 next 64 of size 1024
2019-10-31 12:41:44.966073: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f284803b000 next 66 of size 1024
2019-10-31 12:41:44.966082: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f284803b400 next 67 of size 256
2019-10-31 12:41:44.966090: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f284803b500 next 70 of size 256
2019-10-31 12:41:44.966099: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f284803b600 next 72 of size 256
2019-10-31 12:41:44.966108: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f284803b700 next 73 of size 256
2019-10-31 12:41:44.966116: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f284803b800 next 68 of size 512
2019-10-31 12:41:44.966125: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f284803ba00 next 69 of size 768
2019-10-31 12:41:44.966135: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f284803bd00 next 77 of size 512
2019-10-31 12:41:44.966143: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f284803bf00 next 71 of size 36352
2019-10-31 12:41:44.966152: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848044d00 next 22 of size 18432
2019-10-31 12:41:44.966162: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848049500 next 23 of size 73728
2019-10-31 12:41:44.966170: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f284805b500 next 10 of size 442368
2019-10-31 12:41:44.966179: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f28480c7500 next 11 of size 294912
2019-10-31 12:41:44.966188: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f284810f500 next 36 of size 73728
2019-10-31 12:41:44.966197: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848121500 next 37 of size 73728
2019-10-31 12:41:44.966206: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848133500 next 57 of size 73728
2019-10-31 12:41:44.966215: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f2848145500 next 25 of size 73728
2019-10-31 12:41:44.966223: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848157500 next 26 of size 294912
2019-10-31 12:41:44.966232: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f284819f500 next 39 of size 294912
2019-10-31 12:41:44.966241: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f28481e7500 next 40 of size 294912
2019-10-31 12:41:44.966250: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f284822f500 next 59 of size 294912
2019-10-31 12:41:44.966259: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848277500 next 74 of size 147456
2019-10-31 12:41:44.966272: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f284829b500 next 29 of size 147456
2019-10-31 12:41:44.966281: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f28482bf500 next 13 of size 589824
2019-10-31 12:41:44.966291: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f284834f500 next 14 of size 1179648
2019-10-31 12:41:44.966300: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f284846f500 next 31 of size 589824
2019-10-31 12:41:44.966309: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f28484ff500 next 33 of size 589824
2019-10-31 12:41:44.966317: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f284858f500 next 75 of size 294912
2019-10-31 12:41:44.966326: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f28485d7500 next 12 of size 884736
2019-10-31 12:41:44.966336: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f28486af500 next 15 of size 2359296
2019-10-31 12:41:44.966345: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f28488ef500 next 17 of size 2359296
2019-10-31 12:41:44.966353: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f2848b2f500 next 76 of size 589824
2019-10-31 12:41:44.966362: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848bbf500 next 42 of size 589824
2019-10-31 12:41:44.966371: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848c4f500 next 43 of size 1179648
2019-10-31 12:41:44.966380: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2848d6f500 next 61 of size 1179648
2019-10-31 12:41:44.966389: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f2848e8f500 next 45 of size 3538944
2019-10-31 12:41:44.966397: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f28491ef500 next 46 of size 2359296
2019-10-31 12:41:44.966406: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f284942f500 next 48 of size 2359296
2019-10-31 12:41:44.966415: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f284966f500 next 62 of size 2359296
2019-10-31 12:41:44.966424: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f28498af500 next 63 of size 2359296
2019-10-31 12:41:44.966432: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2849aef500 next 65 of size 2359296
2019-10-31 12:41:44.966441: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f2849d2f500 next 50 of size 60030976
2019-10-31 12:41:44.966450: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f284d66f500 next 51 of size 33554432
2019-10-31 12:41:44.966459: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f284f66f500 next 18446744073709551615 of size 11858529024
2019-10-31 12:41:44.966468: I tensorflow/core/common_runtime/bfc_allocator.cc:809]      Summary of in-use Chunks by size: 
2019-10-31 12:41:44.966479: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 13 Chunks of size 256 totalling 3.2KiB
2019-10-31 12:41:44.966490: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 9 Chunks of size 512 totalling 4.5KiB
2019-10-31 12:41:44.966499: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 768 totalling 768B
2019-10-31 12:41:44.966509: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 6 Chunks of size 1024 totalling 6.0KiB
2019-10-31 12:41:44.966519: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 5 Chunks of size 1280 totalling 6.2KiB
2019-10-31 12:41:44.966529: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 3 Chunks of size 1536 totalling 4.5KiB
2019-10-31 12:41:44.966539: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 2048 totalling 4.0KiB
2019-10-31 12:41:44.966549: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 18432 totalling 18.0KiB
2019-10-31 12:41:44.966559: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 4 Chunks of size 73728 totalling 288.0KiB
2019-10-31 12:41:44.966579: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 141568 totalling 138.2KiB
2019-10-31 12:41:44.966591: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 147456 totalling 144.0KiB
2019-10-31 12:41:44.966601: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 5 Chunks of size 294912 totalling 1.41MiB
2019-10-31 12:41:44.966611: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 4 Chunks of size 589824 totalling 2.25MiB
2019-10-31 12:41:44.966620: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 3 Chunks of size 1179648 totalling 3.38MiB
2019-10-31 12:41:44.966630: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 6 Chunks of size 2359296 totalling 13.50MiB
2019-10-31 12:41:44.966641: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 33554432 totalling 32.00MiB
2019-10-31 12:41:44.966651: I tensorflow/core/common_runtime/bfc_allocator.cc:816] Sum Total of in-use chunks: 53.13MiB
2019-10-31 12:41:44.966660: I tensorflow/core/common_runtime/bfc_allocator.cc:818] total_region_allocated_bytes_: 11982716928 memory_limit_: 11982716928 available bytes: 0 curr_region_allocation_bytes_: 23965433856
2019-10-31 12:41:44.966673: I tensorflow/core/common_runtime/bfc_allocator.cc:824] Stats: 
Limit:                 11982716928
InUse:                    55715328
MaxInUse:                115352320
NumAllocs:                     320
MaxAllocSize:             33554432

2019-10-31 12:41:44.966687: W tensorflow/core/common_runtime/bfc_allocator.cc:319] **__________________________________________________________________________________________________
2019-10-31 12:41:44.966718: W tensorflow/core/framework/op_kernel.cc:1546] OP_REQUIRES failed at random_op.cc:76 : Resource exhausted: OOM when allocating tensor with shape[33423488,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
[I 12:42:05.564 LabApp] Starting buffering for 98e3f4b4-ec88-46fd-a714-d558f562ab4c:dfc469f7956f4cf58329f2df4c457d97
[I 12:42:07.737 LabApp] Kernel restarted: 98e3f4b4-ec88-46fd-a714-d558f562ab4c
[I 12:42:11.259 LabApp] Adapting from protocol version 5.1 (kernel 98e3f4b4-ec88-46fd-a714-d558f562ab4c) to 5.3 (client).
[I 12:42:11.261 LabApp] Restoring connection for 98e3f4b4-ec88-46fd-a714-d558f562ab4c:dfc469f7956f4cf58329f2df4c457d97
[I 12:42:11.261 LabApp] Replaying 6 buffered messages
2019-10-31 12:42:23.994707: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-31 12:42:24.522780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-31 12:42:24.524013: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 12:42:24.526236: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-31 12:42:24.528450: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-31 12:42:24.529893: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-31 12:42:24.533537: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-31 12:42:24.536562: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-31 12:42:24.543518: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-31 12:42:24.546780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-31 12:42:24.786124: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55980eb9c870 executing computations on platform CUDA. Devices:
2019-10-31 12:42:24.786235: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-31 12:42:24.791968: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-31 12:42:24.793725: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55980ec732b0 executing computations on platform Host. Devices:
2019-10-31 12:42:24.793777: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-31 12:42:24.796219: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-31 12:42:24.796367: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 12:42:24.796447: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-31 12:42:24.796521: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-31 12:42:24.796594: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-31 12:42:24.796666: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-31 12:42:24.796738: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-31 12:42:24.796813: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-31 12:42:24.799953: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-31 12:42:24.800062: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 12:42:24.803720: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-31 12:42:24.803759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-31 12:42:24.803779: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-31 12:42:24.807306: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
[I 12:42:25.140 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAEGAN2-128.ipynb
2019-10-31 12:42:37.250173: W tensorflow/core/common_runtime/bfc_allocator.cc:314] Allocator (GPU_0_bfc) ran out of memory trying to allocate 7.97GiB (rounded to 8556412928).  Current allocation summary follows.
2019-10-31 12:42:37.250280: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (256): 	Total Chunks: 7, Chunks in use: 7. 1.8KiB allocated for chunks. 1.8KiB in use in bin. 1.1KiB client-requested in use in bin.
2019-10-31 12:42:37.250319: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (512): 	Total Chunks: 4, Chunks in use: 4. 2.2KiB allocated for chunks. 2.2KiB in use in bin. 2.1KiB client-requested in use in bin.
2019-10-31 12:42:37.250347: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (1024): 	Total Chunks: 5, Chunks in use: 5. 6.0KiB allocated for chunks. 6.0KiB in use in bin. 5.1KiB client-requested in use in bin.
2019-10-31 12:42:37.250371: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (2048): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:42:37.250395: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (4096): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:42:37.250418: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (8192): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:42:37.250472: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (16384): 	Total Chunks: 1, Chunks in use: 1. 18.0KiB allocated for chunks. 18.0KiB in use in bin. 18.0KiB client-requested in use in bin.
2019-10-31 12:42:37.250501: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (32768): 	Total Chunks: 1, Chunks in use: 0. 35.5KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:42:37.250529: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (65536): 	Total Chunks: 4, Chunks in use: 2. 301.8KiB allocated for chunks. 144.0KiB in use in bin. 144.0KiB client-requested in use in bin.
2019-10-31 12:42:37.250556: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (131072): 	Total Chunks: 1, Chunks in use: 1. 144.0KiB allocated for chunks. 144.0KiB in use in bin. 144.0KiB client-requested in use in bin.
2019-10-31 12:42:37.250583: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (262144): 	Total Chunks: 4, Chunks in use: 2. 1.12MiB allocated for chunks. 576.0KiB in use in bin. 576.0KiB client-requested in use in bin.
2019-10-31 12:42:37.250609: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (524288): 	Total Chunks: 1, Chunks in use: 1. 576.0KiB allocated for chunks. 576.0KiB in use in bin. 576.0KiB client-requested in use in bin.
2019-10-31 12:42:37.250635: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (1048576): 	Total Chunks: 2, Chunks in use: 1. 2.25MiB allocated for chunks. 1.12MiB in use in bin. 1.12MiB client-requested in use in bin.
2019-10-31 12:42:37.250659: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (2097152): 	Total Chunks: 3, Chunks in use: 2. 6.75MiB allocated for chunks. 4.50MiB in use in bin. 4.50MiB client-requested in use in bin.
2019-10-31 12:42:37.250682: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:42:37.250705: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (8388608): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:42:37.250728: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:42:37.250751: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (33554432): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:42:37.250773: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (67108864): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:42:37.250796: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:42:37.250823: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (268435456): 	Total Chunks: 2, Chunks in use: 1. 11.15GiB allocated for chunks. 7.97GiB in use in bin. 7.97GiB client-requested in use in bin.
2019-10-31 12:42:37.250847: I tensorflow/core/common_runtime/bfc_allocator.cc:780] Bin for 7.97GiB was 256.00MiB, Chunk State: 
2019-10-31 12:42:37.250880: I tensorflow/core/common_runtime/bfc_allocator.cc:786]   Size: 3.18GiB | Requested Size: 0B | in_use: 0 | bin_num: 20, prev:   Size: 7.97GiB | Requested Size: 7.97GiB | in_use: 1 | bin_num: -1
2019-10-31 12:42:37.250900: I tensorflow/core/common_runtime/bfc_allocator.cc:793] Next region of size 11982716928
2019-10-31 12:42:37.250923: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f63b8000000 next 1 of size 1280
2019-10-31 12:42:37.250943: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f63b8000500 next 2 of size 256
2019-10-31 12:42:37.250972: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f63b8000600 next 3 of size 256
2019-10-31 12:42:37.250992: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f63b8000700 next 6 of size 256
2019-10-31 12:42:37.251013: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f63b8000800 next 9 of size 512
2019-10-31 12:42:37.251032: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f63b8000a00 next 4 of size 1536
2019-10-31 12:42:37.251051: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f63b8001000 next 5 of size 1280
2019-10-31 12:42:37.251071: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f63b8001500 next 16 of size 1024
2019-10-31 12:42:37.251090: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f63b8001900 next 18 of size 1024
2019-10-31 12:42:37.251161: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f63b8001d00 next 19 of size 256
2019-10-31 12:42:37.251186: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f63b8001e00 next 22 of size 256
2019-10-31 12:42:37.251204: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f63b8001f00 next 27 of size 256
2019-10-31 12:42:37.251221: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f63b8002000 next 28 of size 256
2019-10-31 12:42:37.251238: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f63b8002100 next 20 of size 512
2019-10-31 12:42:37.251256: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f63b8002300 next 21 of size 768
2019-10-31 12:42:37.251274: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f63b8002600 next 32 of size 512
2019-10-31 12:42:37.251291: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f63b8002800 next 23 of size 36352
2019-10-31 12:42:37.251309: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f63b800b600 next 24 of size 18432
2019-10-31 12:42:37.251328: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f63b800fe00 next 7 of size 87808
2019-10-31 12:42:37.251346: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f63b8025500 next 8 of size 73728
2019-10-31 12:42:37.251364: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f63b8037500 next 25 of size 73728
2019-10-31 12:42:37.251381: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f63b8049500 next 26 of size 73728
2019-10-31 12:42:37.251399: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f63b805b500 next 29 of size 294912
2019-10-31 12:42:37.251417: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f63b80a3500 next 10 of size 147456
2019-10-31 12:42:37.251435: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f63b80c7500 next 11 of size 294912
2019-10-31 12:42:37.251453: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f63b810f500 next 30 of size 294912
2019-10-31 12:42:37.251470: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f63b8157500 next 31 of size 294912
2019-10-31 12:42:37.251488: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f63b819f500 next 33 of size 1179648
2019-10-31 12:42:37.251506: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f63b82bf500 next 13 of size 589824
2019-10-31 12:42:37.251524: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f63b834f500 next 14 of size 1179648
2019-10-31 12:42:37.251541: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f63b846f500 next 12 of size 2359296
2019-10-31 12:42:37.251559: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f63b86af500 next 15 of size 2359296
2019-10-31 12:42:37.251577: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f63b88ef500 next 17 of size 2359296
2019-10-31 12:42:37.251595: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f63b8b2f500 next 34 of size 8556412928
2019-10-31 12:42:37.251623: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f65b6b37500 next 18446744073709551615 of size 3414575872
2019-10-31 12:42:37.251641: I tensorflow/core/common_runtime/bfc_allocator.cc:809]      Summary of in-use Chunks by size: 
2019-10-31 12:42:37.251664: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 7 Chunks of size 256 totalling 1.8KiB
2019-10-31 12:42:37.251686: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 3 Chunks of size 512 totalling 1.5KiB
2019-10-31 12:42:37.251705: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 768 totalling 768B
2019-10-31 12:42:37.251725: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 1024 totalling 2.0KiB
2019-10-31 12:42:37.251745: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 1280 totalling 2.5KiB
2019-10-31 12:42:37.251765: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 1536 totalling 1.5KiB
2019-10-31 12:42:37.251786: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 18432 totalling 18.0KiB
2019-10-31 12:42:37.251807: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 73728 totalling 144.0KiB
2019-10-31 12:42:37.251828: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 147456 totalling 144.0KiB
2019-10-31 12:42:37.251849: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 294912 totalling 576.0KiB
2019-10-31 12:42:37.251869: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 589824 totalling 576.0KiB
2019-10-31 12:42:37.251890: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 1179648 totalling 1.12MiB
2019-10-31 12:42:37.251910: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 2359296 totalling 4.50MiB
2019-10-31 12:42:37.251930: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 8556412928 totalling 7.97GiB
2019-10-31 12:42:37.251949: I tensorflow/core/common_runtime/bfc_allocator.cc:816] Sum Total of in-use chunks: 7.98GiB
2019-10-31 12:42:37.251967: I tensorflow/core/common_runtime/bfc_allocator.cc:818] total_region_allocated_bytes_: 11982716928 memory_limit_: 11982716928 available bytes: 0 curr_region_allocation_bytes_: 23965433856
2019-10-31 12:42:37.251998: I tensorflow/core/common_runtime/bfc_allocator.cc:824] Stats: 
Limit:                 11982716928
InUse:                  8563814400
MaxInUse:               8563814656
NumAllocs:                     124
MaxAllocSize:           8556412928

2019-10-31 12:42:37.252024: W tensorflow/core/common_runtime/bfc_allocator.cc:319] ************************************************************************____________________________
2019-10-31 12:42:37.252081: W tensorflow/core/framework/op_kernel.cc:1546] OP_REQUIRES failed at cwise_ops_common.cc:70 : Resource exhausted: OOM when allocating tensor with shape[33423488,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
[I 12:43:21.343 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 12:44:25.338 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAEGAN2-128.ipynb
[I 12:45:21.335 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 12:47:20.891 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 12:48:25.256 LabApp] Starting buffering for 98e3f4b4-ec88-46fd-a714-d558f562ab4c:dfc469f7956f4cf58329f2df4c457d97
[I 12:48:25.260 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAEGAN2-128.ipynb
[I 12:48:27.763 LabApp] Kernel restarted: 98e3f4b4-ec88-46fd-a714-d558f562ab4c
[I 12:48:30.938 LabApp] Adapting from protocol version 5.1 (kernel 98e3f4b4-ec88-46fd-a714-d558f562ab4c) to 5.3 (client).
[I 12:48:30.939 LabApp] Restoring connection for 98e3f4b4-ec88-46fd-a714-d558f562ab4c:dfc469f7956f4cf58329f2df4c457d97
[I 12:48:30.940 LabApp] Replaying 6 buffered messages
2019-10-31 12:48:43.501822: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-31 12:48:44.018708: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-31 12:48:44.020004: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 12:48:44.023312: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-31 12:48:44.025738: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-31 12:48:44.026893: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-31 12:48:44.029634: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-31 12:48:44.031957: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-31 12:48:44.037347: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-31 12:48:44.040012: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-31 12:48:44.253958: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x557b8d40a060 executing computations on platform CUDA. Devices:
2019-10-31 12:48:44.254015: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-31 12:48:44.257469: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-31 12:48:44.258570: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x557b8d4e0b00 executing computations on platform Host. Devices:
2019-10-31 12:48:44.258602: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-31 12:48:44.259675: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-31 12:48:44.259751: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 12:48:44.259791: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-31 12:48:44.259830: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-31 12:48:44.259868: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-31 12:48:44.259905: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-31 12:48:44.259943: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-31 12:48:44.259982: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-31 12:48:44.262781: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-31 12:48:44.262904: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 12:48:44.264789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-31 12:48:44.264810: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-31 12:48:44.264821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-31 12:48:44.266754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-31 12:48:47.817418: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-31 12:48:48.710833: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
[I 12:49:21.142 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 12:49:58.279 LabApp] Starting buffering for 98e3f4b4-ec88-46fd-a714-d558f562ab4c:dfc469f7956f4cf58329f2df4c457d97
[I 12:50:00.707 LabApp] Kernel restarted: 98e3f4b4-ec88-46fd-a714-d558f562ab4c
[I 12:50:03.715 LabApp] Adapting from protocol version 5.1 (kernel 98e3f4b4-ec88-46fd-a714-d558f562ab4c) to 5.3 (client).
[I 12:50:03.716 LabApp] Restoring connection for 98e3f4b4-ec88-46fd-a714-d558f562ab4c:dfc469f7956f4cf58329f2df4c457d97
[I 12:50:03.716 LabApp] Replaying 6 buffered messages
2019-10-31 12:50:17.179881: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-31 12:50:17.738838: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-31 12:50:17.740107: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 12:50:17.742900: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-31 12:50:17.745214: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-31 12:50:17.746479: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-31 12:50:17.749598: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-31 12:50:17.752135: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-31 12:50:17.757824: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-31 12:50:17.760572: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-31 12:50:17.973452: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5584c55ee190 executing computations on platform CUDA. Devices:
2019-10-31 12:50:17.973541: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-31 12:50:17.979097: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-31 12:50:17.980582: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5584c56c4c40 executing computations on platform Host. Devices:
2019-10-31 12:50:17.980636: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-31 12:50:17.982921: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-31 12:50:17.983050: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 12:50:17.983113: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-31 12:50:17.983151: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-31 12:50:17.983185: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-31 12:50:17.983233: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-31 12:50:17.983267: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-31 12:50:17.983301: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-31 12:50:17.984983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-31 12:50:17.985047: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 12:50:17.986915: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-31 12:50:17.986934: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-31 12:50:17.986944: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-31 12:50:17.988918: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2019-10-31 12:50:21.311840: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-31 12:50:22.149778: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
[I 12:50:25.241 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAEGAN2-128.ipynb
2019-10-31 12:50:32.633341: W tensorflow/core/common_runtime/bfc_allocator.cc:314] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.98GiB (rounded to 4278206464).  Current allocation summary follows.
2019-10-31 12:50:32.633448: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (256): 	Total Chunks: 10, Chunks in use: 10. 2.5KiB allocated for chunks. 2.5KiB in use in bin. 1.4KiB client-requested in use in bin.
2019-10-31 12:50:32.633476: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (512): 	Total Chunks: 6, Chunks in use: 6. 3.5KiB allocated for chunks. 3.5KiB in use in bin. 3.1KiB client-requested in use in bin.
2019-10-31 12:50:32.633498: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (1024): 	Total Chunks: 8, Chunks in use: 8. 9.2KiB allocated for chunks. 9.2KiB in use in bin. 8.3KiB client-requested in use in bin.
2019-10-31 12:50:32.633518: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (2048): 	Total Chunks: 1, Chunks in use: 0. 2.5KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:50:32.633537: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (4096): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:50:32.633556: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (8192): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:50:32.633578: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (16384): 	Total Chunks: 11, Chunks in use: 9. 203.5KiB allocated for chunks. 156.0KiB in use in bin. 146.0KiB client-requested in use in bin.
2019-10-31 12:50:32.633600: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (32768): 	Total Chunks: 1, Chunks in use: 1. 32.0KiB allocated for chunks. 32.0KiB in use in bin. 32.0KiB client-requested in use in bin.
2019-10-31 12:50:32.633622: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (65536): 	Total Chunks: 4, Chunks in use: 3. 328.0KiB allocated for chunks. 216.0KiB in use in bin. 216.0KiB client-requested in use in bin.
2019-10-31 12:50:32.633644: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (131072): 	Total Chunks: 1, Chunks in use: 1. 144.0KiB allocated for chunks. 144.0KiB in use in bin. 144.0KiB client-requested in use in bin.
2019-10-31 12:50:32.633681: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (262144): 	Total Chunks: 6, Chunks in use: 5. 1.82MiB allocated for chunks. 1.41MiB in use in bin. 1.41MiB client-requested in use in bin.
2019-10-31 12:50:32.633702: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (524288): 	Total Chunks: 6, Chunks in use: 5. 3.47MiB allocated for chunks. 2.97MiB in use in bin. 2.62MiB client-requested in use in bin.
2019-10-31 12:50:32.633722: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (1048576): 	Total Chunks: 3, Chunks in use: 3. 3.78MiB allocated for chunks. 3.78MiB in use in bin. 3.78MiB client-requested in use in bin.
2019-10-31 12:50:32.633743: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (2097152): 	Total Chunks: 18, Chunks in use: 18. 44.04MiB allocated for chunks. 44.04MiB in use in bin. 43.07MiB client-requested in use in bin.
2019-10-31 12:50:32.633765: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (4194304): 	Total Chunks: 4, Chunks in use: 4. 30.52MiB allocated for chunks. 30.52MiB in use in bin. 30.52MiB client-requested in use in bin.
2019-10-31 12:50:32.633785: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (8388608): 	Total Chunks: 6, Chunks in use: 6. 63.01MiB allocated for chunks. 63.01MiB in use in bin. 63.01MiB client-requested in use in bin.
2019-10-31 12:50:32.633807: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (16777216): 	Total Chunks: 6, Chunks in use: 6. 126.02MiB allocated for chunks. 126.02MiB in use in bin. 126.02MiB client-requested in use in bin.
2019-10-31 12:50:32.633828: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (33554432): 	Total Chunks: 4, Chunks in use: 4. 128.00MiB allocated for chunks. 128.00MiB in use in bin. 128.00MiB client-requested in use in bin.
2019-10-31 12:50:32.633850: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (67108864): 	Total Chunks: 6, Chunks in use: 6. 508.02MiB allocated for chunks. 508.02MiB in use in bin. 508.02MiB client-requested in use in bin.
2019-10-31 12:50:32.633868: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:50:32.633888: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (268435456): 	Total Chunks: 5, Chunks in use: 4. 10.27GiB allocated for chunks. 6.96GiB in use in bin. 6.96GiB client-requested in use in bin.
2019-10-31 12:50:32.633907: I tensorflow/core/common_runtime/bfc_allocator.cc:780] Bin for 3.98GiB was 256.00MiB, Chunk State: 
2019-10-31 12:50:32.633933: I tensorflow/core/common_runtime/bfc_allocator.cc:786]   Size: 3.31GiB | Requested Size: 0B | in_use: 0 | bin_num: 20, prev:   Size: 1016.02MiB | Requested Size: 1016.02MiB | in_use: 1 | bin_num: -1
2019-10-31 12:50:32.633949: I tensorflow/core/common_runtime/bfc_allocator.cc:793] Next region of size 11982716928
2019-10-31 12:50:32.633966: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e70000000 next 1 of size 1280
2019-10-31 12:50:32.633981: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e70000500 next 2 of size 256
2019-10-31 12:50:32.633996: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e70000600 next 3 of size 256
2019-10-31 12:50:32.634011: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e70000700 next 6 of size 256
2019-10-31 12:50:32.634026: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e70000800 next 9 of size 512
2019-10-31 12:50:32.634040: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e70000a00 next 4 of size 1536
2019-10-31 12:50:32.634055: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e70001000 next 5 of size 1280
2019-10-31 12:50:32.634069: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e70001500 next 16 of size 1024
2019-10-31 12:50:32.634083: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e70001900 next 18 of size 1024
2019-10-31 12:50:32.634105: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e70001d00 next 19 of size 256
2019-10-31 12:50:32.634120: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e70001e00 next 22 of size 256
2019-10-31 12:50:32.634134: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e70001f00 next 27 of size 256
2019-10-31 12:50:32.634148: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e70002000 next 28 of size 256
2019-10-31 12:50:32.634161: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e70002100 next 20 of size 512
2019-10-31 12:50:32.634176: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e70002300 next 21 of size 768
2019-10-31 12:50:32.634190: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e70002600 next 32 of size 512
2019-10-31 12:50:32.634204: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e70002800 next 63 of size 256
2019-10-31 12:50:32.634219: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e70002900 next 35 of size 768
2019-10-31 12:50:32.634233: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e70002c00 next 36 of size 512
2019-10-31 12:50:32.634248: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e70002e00 next 46 of size 16384
2019-10-31 12:50:32.634263: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e70006e00 next 23 of size 18432
2019-10-31 12:50:32.634277: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e7000b600 next 24 of size 18432
2019-10-31 12:50:32.634291: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e7000fe00 next 49 of size 16384
2019-10-31 12:50:32.634305: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e70013e00 next 47 of size 16384
2019-10-31 12:50:32.634319: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e70017e00 next 51 of size 16384
2019-10-31 12:50:32.634333: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e7001be00 next 57 of size 1024
2019-10-31 12:50:32.634346: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e7001c200 next 61 of size 1024
2019-10-31 12:50:32.634360: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e7001c600 next 67 of size 256
2019-10-31 12:50:32.634374: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e7001c700 next 71 of size 256
2019-10-31 12:50:32.634388: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f2e7001c800 next 77 of size 2560
2019-10-31 12:50:32.634401: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e7001d200 next 78 of size 1280
2019-10-31 12:50:32.634415: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f2e7001d700 next 7 of size 32256
2019-10-31 12:50:32.634430: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e70025500 next 8 of size 73728
2019-10-31 12:50:32.634444: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e70037500 next 45 of size 32768
2019-10-31 12:50:32.634458: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e7003f500 next 48 of size 16384
2019-10-31 12:50:32.634472: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e70043500 next 25 of size 24576
2019-10-31 12:50:32.634487: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e70049500 next 26 of size 73728
2019-10-31 12:50:32.634501: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e7005b500 next 29 of size 294912
2019-10-31 12:50:32.634516: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e700a3500 next 10 of size 147456
2019-10-31 12:50:32.634530: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e700c7500 next 11 of size 294912
2019-10-31 12:50:32.634544: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e7010f500 next 30 of size 294912
2019-10-31 12:50:32.634565: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e70157500 next 31 of size 294912
2019-10-31 12:50:32.634580: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e7019f500 next 50 of size 524288
2019-10-31 12:50:32.634594: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f2e7021f500 next 79 of size 16384
2019-10-31 12:50:32.634608: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e70223500 next 80 of size 16384
2019-10-31 12:50:32.634622: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f2e70227500 next 72 of size 114688
2019-10-31 12:50:32.634636: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e70243500 next 73 of size 73728
2019-10-31 12:50:32.634650: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f2e70255500 next 33 of size 434176
2019-10-31 12:50:32.634665: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e702bf500 next 13 of size 589824
2019-10-31 12:50:32.634681: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e7034f500 next 14 of size 1179648
2019-10-31 12:50:32.634696: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e7046f500 next 12 of size 2359296
2019-10-31 12:50:32.634710: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e706af500 next 15 of size 2359296
2019-10-31 12:50:32.634724: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e708ef500 next 17 of size 2359296
2019-10-31 12:50:32.634739: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e70b2f500 next 37 of size 2097152
2019-10-31 12:50:32.634754: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e70d2f500 next 38 of size 2097152
2019-10-31 12:50:32.634769: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e70f2f500 next 34 of size 16257024
2019-10-31 12:50:32.634784: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e71eb0500 next 39 of size 16257024
2019-10-31 12:50:32.634798: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e72e31500 next 40 of size 7872512
2019-10-31 12:50:32.634812: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e735b3500 next 41 of size 7872512
2019-10-31 12:50:32.634827: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e73d35500 next 42 of size 3686400
2019-10-31 12:50:32.634841: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e740b9500 next 43 of size 3686400
2019-10-31 12:50:32.634856: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e7443d500 next 44 of size 1605632
2019-10-31 12:50:32.634870: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e745c5500 next 54 of size 2097152
2019-10-31 12:50:32.634884: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e747c5500 next 52 of size 2097152
2019-10-31 12:50:32.634898: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e749c5500 next 53 of size 2097152
2019-10-31 12:50:32.634911: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e74bc5500 next 55 of size 2359296
2019-10-31 12:50:32.634925: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e74e05500 next 56 of size 2359296
2019-10-31 12:50:32.634939: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e75045500 next 65 of size 1179648
2019-10-31 12:50:32.634953: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e75165500 next 68 of size 294912
2019-10-31 12:50:32.634968: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e751ad500 next 59 of size 884736
2019-10-31 12:50:32.634982: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e75285500 next 60 of size 2359296
2019-10-31 12:50:32.634996: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e754c5500 next 58 of size 8388608
2019-10-31 12:50:32.635017: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e75cc5500 next 62 of size 8388608
2019-10-31 12:50:32.635032: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e764c5500 next 64 of size 16777216
2019-10-31 12:50:32.635047: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e774c5500 next 66 of size 16777216
2019-10-31 12:50:32.635062: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e784c5500 next 69 of size 33554432
2019-10-31 12:50:32.635076: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e7a4c5500 next 70 of size 33554432
2019-10-31 12:50:32.635090: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e7c4c5500 next 74 of size 67108864
2019-10-31 12:50:32.635119: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e804c5500 next 75 of size 67108864
2019-10-31 12:50:32.635137: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f2e844c5500 next 76 of size 524288
2019-10-31 12:50:32.635152: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e84545500 next 81 of size 524288
2019-10-31 12:50:32.635166: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e845c5500 next 82 of size 2097152
2019-10-31 12:50:32.635180: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e847c5500 next 83 of size 2097152
2019-10-31 12:50:32.635194: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e849c5500 next 84 of size 8388608
2019-10-31 12:50:32.635208: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e851c5500 next 85 of size 8388608
2019-10-31 12:50:32.635222: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e859c5500 next 86 of size 16777216
2019-10-31 12:50:32.635236: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e869c5500 next 87 of size 16777216
2019-10-31 12:50:32.635250: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e879c5500 next 88 of size 33554432
2019-10-31 12:50:32.635264: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e899c5500 next 89 of size 33554432
2019-10-31 12:50:32.635277: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e8b9c5500 next 90 of size 67108864
2019-10-31 12:50:32.635291: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e8f9c5500 next 91 of size 67108864
2019-10-31 12:50:32.635305: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e939c5500 next 92 of size 2097152
2019-10-31 12:50:32.635320: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e93bc5500 next 93 of size 8128512
2019-10-31 12:50:32.635335: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e94385d00 next 94 of size 8128512
2019-10-31 12:50:32.635350: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e94b46500 next 95 of size 3936256
2019-10-31 12:50:32.635364: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e94f07500 next 96 of size 3936256
2019-10-31 12:50:32.635378: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e952c8500 next 97 of size 32514048
2019-10-31 12:50:32.635392: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e971ca500 next 98 of size 32514048
2019-10-31 12:50:32.635407: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2e990cc500 next 99 of size 132128768
2019-10-31 12:50:32.635422: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2ea0ece500 next 100 of size 132128768
2019-10-31 12:50:32.635438: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2ea8cd0500 next 101 of size 1065369600
2019-10-31 12:50:32.635452: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2ee84d4500 next 102 of size 1065369600
2019-10-31 12:50:32.635466: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f2f27cd8500 next 103 of size 4278206464
2019-10-31 12:50:32.635488: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f3026cdc500 next 104 of size 589824
2019-10-31 12:50:32.635503: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f3026d6c500 next 105 of size 1065369600
2019-10-31 12:50:32.635518: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f3066570500 next 18446744073709551615 of size 3554851584
2019-10-31 12:50:32.635532: I tensorflow/core/common_runtime/bfc_allocator.cc:809]      Summary of in-use Chunks by size: 
2019-10-31 12:50:32.635551: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 10 Chunks of size 256 totalling 2.5KiB
2019-10-31 12:50:32.635568: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 4 Chunks of size 512 totalling 2.0KiB
2019-10-31 12:50:32.635584: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 768 totalling 1.5KiB
2019-10-31 12:50:32.635600: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 4 Chunks of size 1024 totalling 4.0KiB
2019-10-31 12:50:32.635616: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 3 Chunks of size 1280 totalling 3.8KiB
2019-10-31 12:50:32.635633: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 1536 totalling 1.5KiB
2019-10-31 12:50:32.635649: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 6 Chunks of size 16384 totalling 96.0KiB
2019-10-31 12:50:32.635666: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 18432 totalling 36.0KiB
2019-10-31 12:50:32.635682: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 24576 totalling 24.0KiB
2019-10-31 12:50:32.635699: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 32768 totalling 32.0KiB
2019-10-31 12:50:32.635716: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 3 Chunks of size 73728 totalling 216.0KiB
2019-10-31 12:50:32.635733: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 147456 totalling 144.0KiB
2019-10-31 12:50:32.635749: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 5 Chunks of size 294912 totalling 1.41MiB
2019-10-31 12:50:32.635765: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 524288 totalling 1.00MiB
2019-10-31 12:50:32.635781: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 589824 totalling 1.12MiB
2019-10-31 12:50:32.635798: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 884736 totalling 864.0KiB
2019-10-31 12:50:32.635814: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 1179648 totalling 2.25MiB
2019-10-31 12:50:32.635831: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 1605632 totalling 1.53MiB
2019-10-31 12:50:32.635847: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 8 Chunks of size 2097152 totalling 16.00MiB
2019-10-31 12:50:32.635864: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 6 Chunks of size 2359296 totalling 13.50MiB
2019-10-31 12:50:32.635880: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 3686400 totalling 7.03MiB
2019-10-31 12:50:32.635897: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 3936256 totalling 7.51MiB
2019-10-31 12:50:32.635913: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 7872512 totalling 15.02MiB
2019-10-31 12:50:32.635930: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 8128512 totalling 15.50MiB
2019-10-31 12:50:32.635947: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 4 Chunks of size 8388608 totalling 32.00MiB
2019-10-31 12:50:32.635964: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 16257024 totalling 31.01MiB
2019-10-31 12:50:32.635980: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 4 Chunks of size 16777216 totalling 64.00MiB
2019-10-31 12:50:32.635997: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 32514048 totalling 62.02MiB
2019-10-31 12:50:32.636013: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 4 Chunks of size 33554432 totalling 128.00MiB
2019-10-31 12:50:32.636036: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 4 Chunks of size 67108864 totalling 256.00MiB
2019-10-31 12:50:32.636055: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 132128768 totalling 252.02MiB
2019-10-31 12:50:32.636072: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 3 Chunks of size 1065369600 totalling 2.98GiB
2019-10-31 12:50:32.636088: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 4278206464 totalling 3.98GiB
2019-10-31 12:50:32.636104: I tensorflow/core/common_runtime/bfc_allocator.cc:816] Sum Total of in-use chunks: 7.85GiB
2019-10-31 12:50:32.636118: I tensorflow/core/common_runtime/bfc_allocator.cc:818] total_region_allocated_bytes_: 11982716928 memory_limit_: 11982716928 available bytes: 0 curr_region_allocation_bytes_: 23965433856
2019-10-31 12:50:32.636138: I tensorflow/core/common_runtime/bfc_allocator.cc:824] Stats: 
Limit:                 11982716928
InUse:                  8426740992
MaxInUse:               8426740992
NumAllocs:                     419
MaxAllocSize:           4278206464

2019-10-31 12:50:32.636161: W tensorflow/core/common_runtime/bfc_allocator.cc:319] ***********************************************************************_____________________________
2019-10-31 12:50:32.636213: W tensorflow/core/framework/op_kernel.cc:1546] OP_REQUIRES failed at conv_grad_input_ops.cc:954 : Resource exhausted: OOM when allocating tensor with shape[32,128,511,511] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
[I 12:51:21.309 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 12:51:24.582 LabApp] KernelRestarter: restarting kernel (1/5), keep random ports
[I 12:51:32.695 LabApp] Starting buffering for 98e3f4b4-ec88-46fd-a714-d558f562ab4c:dfc469f7956f4cf58329f2df4c457d97
[I 12:51:35.050 LabApp] Kernel restarted: 98e3f4b4-ec88-46fd-a714-d558f562ab4c
[I 12:51:36.393 LabApp] Adapting from protocol version 5.1 (kernel 98e3f4b4-ec88-46fd-a714-d558f562ab4c) to 5.3 (client).
[I 12:51:36.394 LabApp] Restoring connection for 98e3f4b4-ec88-46fd-a714-d558f562ab4c:dfc469f7956f4cf58329f2df4c457d97
[I 12:51:36.394 LabApp] Replaying 7 buffered messages
2019-10-31 12:51:48.510943: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
[I 12:51:48.832 LabApp] 302 GET /notebooks/avgn_paper/notebooks/6.0-neural-networks/ (::1) 0.73ms
[I 12:51:48.859 LabApp] 302 GET /notebooks/avgn_paper/notebooks/6.0-neural-networks (::1) 1.36ms
2019-10-31 12:51:49.453256: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-31 12:51:49.454449: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 12:51:49.456496: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-31 12:51:49.458036: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-31 12:51:49.458949: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-31 12:51:49.460977: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-31 12:51:49.462684: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-31 12:51:49.466453: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-31 12:51:49.468286: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
[W 12:51:49.512 LabApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20191021134151 (::1) 2.34ms referer=http://localhost:8187/tree/avgn_paper/notebooks/6.0-neural-networks
2019-10-31 12:51:49.653961: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561c0ce05ee0 executing computations on platform CUDA. Devices:
2019-10-31 12:51:49.654020: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-31 12:51:49.658741: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-31 12:51:49.659935: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561c0cedc970 executing computations on platform Host. Devices:
2019-10-31 12:51:49.659969: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-31 12:51:49.661027: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-31 12:51:49.661105: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 12:51:49.661146: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-31 12:51:49.661183: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-31 12:51:49.661221: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-31 12:51:49.661259: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-31 12:51:49.661297: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-31 12:51:49.661335: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-31 12:51:49.663124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-31 12:51:49.663190: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 12:51:49.665305: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-31 12:51:49.665326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-31 12:51:49.665337: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-31 12:51:49.667992: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-31 12:51:52.867130: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-31 12:51:53.674630: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
[I 12:51:58.464 LabApp] Kernel started: e31889d0-de0c-4d2d-b55d-a086cc9652b5
[W 12:51:58.516 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 3.86ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 12:51:59.737 LabApp] Adapting from protocol version 5.1 (kernel e31889d0-de0c-4d2d-b55d-a086cc9652b5) to 5.3 (client).
2019-10-31 12:52:04.172729: W tensorflow/core/common_runtime/bfc_allocator.cc:314] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.98GiB (rounded to 4278206464).  Current allocation summary follows.
2019-10-31 12:52:04.172834: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (256): 	Total Chunks: 10, Chunks in use: 10. 2.5KiB allocated for chunks. 2.5KiB in use in bin. 1.4KiB client-requested in use in bin.
2019-10-31 12:52:04.172888: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (512): 	Total Chunks: 6, Chunks in use: 6. 3.5KiB allocated for chunks. 3.5KiB in use in bin. 3.1KiB client-requested in use in bin.
2019-10-31 12:52:04.172918: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (1024): 	Total Chunks: 8, Chunks in use: 8. 9.2KiB allocated for chunks. 9.2KiB in use in bin. 8.3KiB client-requested in use in bin.
2019-10-31 12:52:04.172945: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (2048): 	Total Chunks: 1, Chunks in use: 0. 2.5KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:52:04.172968: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (4096): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:52:04.172991: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (8192): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:52:04.173021: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (16384): 	Total Chunks: 11, Chunks in use: 9. 203.5KiB allocated for chunks. 156.0KiB in use in bin. 146.0KiB client-requested in use in bin.
2019-10-31 12:52:04.173048: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (32768): 	Total Chunks: 1, Chunks in use: 1. 32.0KiB allocated for chunks. 32.0KiB in use in bin. 32.0KiB client-requested in use in bin.
2019-10-31 12:52:04.173075: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (65536): 	Total Chunks: 4, Chunks in use: 3. 328.0KiB allocated for chunks. 216.0KiB in use in bin. 216.0KiB client-requested in use in bin.
2019-10-31 12:52:04.173102: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (131072): 	Total Chunks: 1, Chunks in use: 1. 144.0KiB allocated for chunks. 144.0KiB in use in bin. 144.0KiB client-requested in use in bin.
2019-10-31 12:52:04.173127: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (262144): 	Total Chunks: 6, Chunks in use: 5. 1.82MiB allocated for chunks. 1.41MiB in use in bin. 1.41MiB client-requested in use in bin.
2019-10-31 12:52:04.173152: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (524288): 	Total Chunks: 6, Chunks in use: 5. 3.47MiB allocated for chunks. 2.97MiB in use in bin. 2.62MiB client-requested in use in bin.
2019-10-31 12:52:04.173177: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (1048576): 	Total Chunks: 3, Chunks in use: 3. 3.78MiB allocated for chunks. 3.78MiB in use in bin. 3.78MiB client-requested in use in bin.
2019-10-31 12:52:04.173204: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (2097152): 	Total Chunks: 18, Chunks in use: 18. 44.04MiB allocated for chunks. 44.04MiB in use in bin. 43.07MiB client-requested in use in bin.
2019-10-31 12:52:04.173232: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (4194304): 	Total Chunks: 4, Chunks in use: 4. 30.52MiB allocated for chunks. 30.52MiB in use in bin. 30.52MiB client-requested in use in bin.
2019-10-31 12:52:04.173259: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (8388608): 	Total Chunks: 6, Chunks in use: 6. 63.01MiB allocated for chunks. 63.01MiB in use in bin. 63.01MiB client-requested in use in bin.
2019-10-31 12:52:04.173286: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (16777216): 	Total Chunks: 6, Chunks in use: 6. 126.02MiB allocated for chunks. 126.02MiB in use in bin. 126.02MiB client-requested in use in bin.
2019-10-31 12:52:04.173313: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (33554432): 	Total Chunks: 4, Chunks in use: 4. 128.00MiB allocated for chunks. 128.00MiB in use in bin. 128.00MiB client-requested in use in bin.
2019-10-31 12:52:04.173340: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (67108864): 	Total Chunks: 6, Chunks in use: 6. 508.02MiB allocated for chunks. 508.02MiB in use in bin. 508.02MiB client-requested in use in bin.
2019-10-31 12:52:04.173364: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-10-31 12:52:04.173404: I tensorflow/core/common_runtime/bfc_allocator.cc:764] Bin (268435456): 	Total Chunks: 5, Chunks in use: 4. 10.27GiB allocated for chunks. 6.96GiB in use in bin. 6.96GiB client-requested in use in bin.
2019-10-31 12:52:04.173431: I tensorflow/core/common_runtime/bfc_allocator.cc:780] Bin for 3.98GiB was 256.00MiB, Chunk State: 
2019-10-31 12:52:04.173467: I tensorflow/core/common_runtime/bfc_allocator.cc:786]   Size: 3.31GiB | Requested Size: 0B | in_use: 0 | bin_num: 20, prev:   Size: 1016.02MiB | Requested Size: 1016.02MiB | in_use: 1 | bin_num: -1
2019-10-31 12:52:04.173489: I tensorflow/core/common_runtime/bfc_allocator.cc:793] Next region of size 11981409280
2019-10-31 12:52:04.173513: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa0000000 next 1 of size 1280
2019-10-31 12:52:04.173534: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa0000500 next 2 of size 256
2019-10-31 12:52:04.173553: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa0000600 next 3 of size 256
2019-10-31 12:52:04.173571: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa0000700 next 6 of size 256
2019-10-31 12:52:04.173594: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa0000800 next 9 of size 512
2019-10-31 12:52:04.173614: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa0000a00 next 4 of size 1536
2019-10-31 12:52:04.173633: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa0001000 next 5 of size 1280
2019-10-31 12:52:04.173652: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa0001500 next 16 of size 1024
2019-10-31 12:52:04.173671: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa0001900 next 18 of size 1024
2019-10-31 12:52:04.173691: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa0001d00 next 19 of size 256
2019-10-31 12:52:04.173709: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa0001e00 next 22 of size 256
2019-10-31 12:52:04.173728: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa0001f00 next 27 of size 256
2019-10-31 12:52:04.173746: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa0002000 next 28 of size 256
2019-10-31 12:52:04.173765: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa0002100 next 20 of size 512
2019-10-31 12:52:04.173785: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa0002300 next 21 of size 768
2019-10-31 12:52:04.173804: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa0002600 next 32 of size 512
2019-10-31 12:52:04.173822: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa0002800 next 63 of size 256
2019-10-31 12:52:04.173841: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa0002900 next 35 of size 768
2019-10-31 12:52:04.173860: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa0002c00 next 36 of size 512
2019-10-31 12:52:04.173879: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa0002e00 next 46 of size 16384
2019-10-31 12:52:04.173899: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa0006e00 next 23 of size 18432
2019-10-31 12:52:04.173918: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa000b600 next 24 of size 18432
2019-10-31 12:52:04.173937: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa000fe00 next 49 of size 16384
2019-10-31 12:52:04.173955: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa0013e00 next 47 of size 16384
2019-10-31 12:52:04.173974: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa0017e00 next 51 of size 16384
2019-10-31 12:52:04.173993: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa001be00 next 57 of size 1024
2019-10-31 12:52:04.174020: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa001c200 next 61 of size 1024
2019-10-31 12:52:04.174041: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa001c600 next 67 of size 256
2019-10-31 12:52:04.174060: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa001c700 next 71 of size 256
2019-10-31 12:52:04.174078: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f8aa001c800 next 77 of size 2560
2019-10-31 12:52:04.174097: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa001d200 next 78 of size 1280
2019-10-31 12:52:04.174116: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f8aa001d700 next 7 of size 32256
2019-10-31 12:52:04.174135: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa0025500 next 8 of size 73728
2019-10-31 12:52:04.174156: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa0037500 next 45 of size 32768
2019-10-31 12:52:04.174175: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa003f500 next 48 of size 16384
2019-10-31 12:52:04.174194: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa0043500 next 25 of size 24576
2019-10-31 12:52:04.174213: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa0049500 next 26 of size 73728
2019-10-31 12:52:04.174232: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa005b500 next 29 of size 294912
2019-10-31 12:52:04.174252: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa00a3500 next 10 of size 147456
2019-10-31 12:52:04.174272: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa00c7500 next 11 of size 294912
2019-10-31 12:52:04.174291: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa010f500 next 30 of size 294912
2019-10-31 12:52:04.174310: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa0157500 next 31 of size 294912
2019-10-31 12:52:04.174329: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa019f500 next 50 of size 524288
2019-10-31 12:52:04.174349: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f8aa021f500 next 79 of size 16384
2019-10-31 12:52:04.174368: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa0223500 next 80 of size 16384
2019-10-31 12:52:04.174387: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f8aa0227500 next 72 of size 114688
2019-10-31 12:52:04.174406: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa0243500 next 73 of size 73728
2019-10-31 12:52:04.174425: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f8aa0255500 next 33 of size 434176
2019-10-31 12:52:04.174445: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa02bf500 next 13 of size 589824
2019-10-31 12:52:04.174465: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa034f500 next 14 of size 1179648
2019-10-31 12:52:04.174484: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa046f500 next 12 of size 2359296
2019-10-31 12:52:04.174504: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa06af500 next 15 of size 2359296
2019-10-31 12:52:04.174523: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa08ef500 next 17 of size 2359296
2019-10-31 12:52:04.174543: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa0b2f500 next 37 of size 2097152
2019-10-31 12:52:04.174562: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa0d2f500 next 38 of size 2097152
2019-10-31 12:52:04.174581: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa0f2f500 next 34 of size 16257024
2019-10-31 12:52:04.174601: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa1eb0500 next 39 of size 16257024
2019-10-31 12:52:04.174628: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa2e31500 next 40 of size 7872512
2019-10-31 12:52:04.174649: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa35b3500 next 41 of size 7872512
2019-10-31 12:52:04.174669: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa3d35500 next 42 of size 3686400
2019-10-31 12:52:04.174688: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa40b9500 next 43 of size 3686400
2019-10-31 12:52:04.174708: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa443d500 next 44 of size 1605632
2019-10-31 12:52:04.174727: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa45c5500 next 54 of size 2097152
2019-10-31 12:52:04.174746: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa47c5500 next 52 of size 2097152
2019-10-31 12:52:04.174765: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa49c5500 next 53 of size 2097152
2019-10-31 12:52:04.174784: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa4bc5500 next 55 of size 2359296
2019-10-31 12:52:04.174803: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa4e05500 next 56 of size 2359296
2019-10-31 12:52:04.174822: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa5045500 next 65 of size 1179648
2019-10-31 12:52:04.174840: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa5165500 next 68 of size 294912
2019-10-31 12:52:04.174859: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa51ad500 next 59 of size 884736
2019-10-31 12:52:04.174879: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa5285500 next 60 of size 2359296
2019-10-31 12:52:04.174898: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa54c5500 next 58 of size 8388608
2019-10-31 12:52:04.174917: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa5cc5500 next 62 of size 8388608
2019-10-31 12:52:04.174937: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa64c5500 next 64 of size 16777216
2019-10-31 12:52:04.174957: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa74c5500 next 66 of size 16777216
2019-10-31 12:52:04.174976: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aa84c5500 next 69 of size 33554432
2019-10-31 12:52:04.174996: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aaa4c5500 next 70 of size 33554432
2019-10-31 12:52:04.175016: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8aac4c5500 next 74 of size 67108864
2019-10-31 12:52:04.175034: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8ab04c5500 next 75 of size 67108864
2019-10-31 12:52:04.175053: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f8ab44c5500 next 76 of size 524288
2019-10-31 12:52:04.175072: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8ab4545500 next 81 of size 524288
2019-10-31 12:52:04.175091: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8ab45c5500 next 82 of size 2097152
2019-10-31 12:52:04.175136: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8ab47c5500 next 83 of size 2097152
2019-10-31 12:52:04.175158: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8ab49c5500 next 84 of size 8388608
2019-10-31 12:52:04.175177: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8ab51c5500 next 85 of size 8388608
2019-10-31 12:52:04.175196: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8ab59c5500 next 86 of size 16777216
2019-10-31 12:52:04.175215: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8ab69c5500 next 87 of size 16777216
2019-10-31 12:52:04.175234: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8ab79c5500 next 88 of size 33554432
2019-10-31 12:52:04.175252: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8ab99c5500 next 89 of size 33554432
2019-10-31 12:52:04.175281: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8abb9c5500 next 90 of size 67108864
2019-10-31 12:52:04.175301: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8abf9c5500 next 91 of size 67108864
2019-10-31 12:52:04.175319: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8ac39c5500 next 92 of size 2097152
2019-10-31 12:52:04.175339: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8ac3bc5500 next 93 of size 8128512
2019-10-31 12:52:04.175358: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8ac4385d00 next 94 of size 8128512
2019-10-31 12:52:04.175378: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8ac4b46500 next 95 of size 3936256
2019-10-31 12:52:04.175397: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8ac4f07500 next 96 of size 3936256
2019-10-31 12:52:04.175416: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8ac52c8500 next 97 of size 32514048
2019-10-31 12:52:04.175436: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8ac71ca500 next 98 of size 32514048
2019-10-31 12:52:04.175456: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8ac90cc500 next 99 of size 132128768
2019-10-31 12:52:04.175475: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8ad0ece500 next 100 of size 132128768
2019-10-31 12:52:04.175495: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8ad8cd0500 next 101 of size 1065369600
2019-10-31 12:52:04.175514: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8b184d4500 next 102 of size 1065369600
2019-10-31 12:52:04.175533: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8b57cd8500 next 103 of size 4278206464
2019-10-31 12:52:04.175553: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8c56cdc500 next 104 of size 589824
2019-10-31 12:52:04.175572: I tensorflow/core/common_runtime/bfc_allocator.cc:800] InUse at 0x7f8c56d6c500 next 105 of size 1065369600
2019-10-31 12:52:04.175591: I tensorflow/core/common_runtime/bfc_allocator.cc:800] Free  at 0x7f8c96570500 next 18446744073709551615 of size 3553543936
2019-10-31 12:52:04.175609: I tensorflow/core/common_runtime/bfc_allocator.cc:809]      Summary of in-use Chunks by size: 
2019-10-31 12:52:04.175633: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 10 Chunks of size 256 totalling 2.5KiB
2019-10-31 12:52:04.175656: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 4 Chunks of size 512 totalling 2.0KiB
2019-10-31 12:52:04.175678: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 768 totalling 1.5KiB
2019-10-31 12:52:04.175699: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 4 Chunks of size 1024 totalling 4.0KiB
2019-10-31 12:52:04.175721: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 3 Chunks of size 1280 totalling 3.8KiB
2019-10-31 12:52:04.175742: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 1536 totalling 1.5KiB
2019-10-31 12:52:04.175765: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 6 Chunks of size 16384 totalling 96.0KiB
2019-10-31 12:52:04.175787: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 18432 totalling 36.0KiB
2019-10-31 12:52:04.175808: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 24576 totalling 24.0KiB
2019-10-31 12:52:04.175830: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 32768 totalling 32.0KiB
2019-10-31 12:52:04.175852: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 3 Chunks of size 73728 totalling 216.0KiB
2019-10-31 12:52:04.175874: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 147456 totalling 144.0KiB
2019-10-31 12:52:04.175896: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 5 Chunks of size 294912 totalling 1.41MiB
2019-10-31 12:52:04.175926: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 524288 totalling 1.00MiB
2019-10-31 12:52:04.175950: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 589824 totalling 1.12MiB
2019-10-31 12:52:04.175972: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 884736 totalling 864.0KiB
2019-10-31 12:52:04.175993: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 1179648 totalling 2.25MiB
2019-10-31 12:52:04.176014: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 1605632 totalling 1.53MiB
2019-10-31 12:52:04.176036: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 8 Chunks of size 2097152 totalling 16.00MiB
2019-10-31 12:52:04.176058: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 6 Chunks of size 2359296 totalling 13.50MiB
2019-10-31 12:52:04.176080: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 3686400 totalling 7.03MiB
2019-10-31 12:52:04.176101: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 3936256 totalling 7.51MiB
2019-10-31 12:52:04.176123: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 7872512 totalling 15.02MiB
2019-10-31 12:52:04.176145: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 8128512 totalling 15.50MiB
2019-10-31 12:52:04.176167: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 4 Chunks of size 8388608 totalling 32.00MiB
2019-10-31 12:52:04.176188: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 16257024 totalling 31.01MiB
2019-10-31 12:52:04.176211: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 4 Chunks of size 16777216 totalling 64.00MiB
2019-10-31 12:52:04.176233: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 32514048 totalling 62.02MiB
2019-10-31 12:52:04.176255: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 4 Chunks of size 33554432 totalling 128.00MiB
2019-10-31 12:52:04.176277: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 4 Chunks of size 67108864 totalling 256.00MiB
2019-10-31 12:52:04.176299: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 2 Chunks of size 132128768 totalling 252.02MiB
2019-10-31 12:52:04.176320: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 3 Chunks of size 1065369600 totalling 2.98GiB
2019-10-31 12:52:04.176341: I tensorflow/core/common_runtime/bfc_allocator.cc:812] 1 Chunks of size 4278206464 totalling 3.98GiB
2019-10-31 12:52:04.176362: I tensorflow/core/common_runtime/bfc_allocator.cc:816] Sum Total of in-use chunks: 7.85GiB
2019-10-31 12:52:04.176381: I tensorflow/core/common_runtime/bfc_allocator.cc:818] total_region_allocated_bytes_: 11981409280 memory_limit_: 11981409485 available bytes: 205 curr_region_allocation_bytes_: 23962819072
2019-10-31 12:52:04.176408: I tensorflow/core/common_runtime/bfc_allocator.cc:824] Stats: 
Limit:                 11981409485
InUse:                  8426740992
MaxInUse:               8426740992
NumAllocs:                     419
MaxAllocSize:           4278206464

2019-10-31 12:52:04.176444: W tensorflow/core/common_runtime/bfc_allocator.cc:319] ***********************************************************************_____________________________
2019-10-31 12:52:04.176515: W tensorflow/core/framework/op_kernel.cc:1546] OP_REQUIRES failed at conv_grad_input_ops.cc:954 : Resource exhausted: OOM when allocating tensor with shape[32,128,511,511] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
[I 12:52:05.038 LabApp] Copying avgn_paper/notebooks/6.0-neural-networks/Starling-AE.ipynb to /avgn_paper/notebooks/6.0-neural-networks
[W 12:52:06.909 LabApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20191021134151 (::1) 4.62ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-AE-Copy1.ipynb
[I 12:52:08.133 LabApp] Kernel started: 95e67d6a-4c4a-45be-b3f6-93f8445b51d0
[W 12:52:08.203 LabApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20191021134151 (::1) 2.73ms referer=http://localhost:8187/notebooks/avgn_paper/notebooks/6.0-neural-networks/Starling-AE-Copy1.ipynb
[I 12:52:09.331 LabApp] Adapting from protocol version 5.1 (kernel 95e67d6a-4c4a-45be-b3f6-93f8445b51d0) to 5.3 (client).
[I 12:52:25.262 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAEGAN2-128.ipynb
[I 12:52:35.691 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-seq2seq-AE.ipynb
2019-10-31 12:53:11.637398: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-31 12:53:12.157431: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-31 12:53:12.164965: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 12:53:12.172654: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-31 12:53:12.176538: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-31 12:53:12.186363: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-31 12:53:12.189604: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-31 12:53:12.192214: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-31 12:53:12.198085: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-31 12:53:12.200962: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-31 12:53:12.428002: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5627b3425640 executing computations on platform CUDA. Devices:
2019-10-31 12:53:12.428094: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-31 12:53:12.434703: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-31 12:53:12.436964: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5627b34fc110 executing computations on platform Host. Devices:
2019-10-31 12:53:12.437027: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-31 12:53:12.438924: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-31 12:53:12.439069: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 12:53:12.439187: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-31 12:53:12.439270: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-31 12:53:12.439346: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-31 12:53:12.439441: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-31 12:53:12.439524: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-31 12:53:12.439618: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-31 12:53:12.442801: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-31 12:53:12.442933: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 12:53:12.446606: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-31 12:53:12.446645: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-31 12:53:12.446664: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-31 12:53:12.450188: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
[I 12:53:20.597 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 12:53:59.025 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Canary-Seq2Seq.ipynb
[I 12:54:10.097 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-seq2seq-AE.ipynb
[I 12:55:21.239 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 12:55:26.036 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-seq2seq-AE.ipynb
[I 12:56:10.269 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-seq2seq-AE.ipynb
[I 12:57:21.411 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 12:58:09.708 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-seq2seq-AE.ipynb
2019-10-31 12:58:26.199044: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-31 12:58:26.459983: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
[I 12:59:02.883 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-seq2seq-AE.ipynb
[I 12:59:21.286 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
2019-10-31 12:59:24.152361: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:502] constant folding failed: Invalid argument: Unsupported type: 21
2019-10-31 12:59:24.529549: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:502] constant folding failed: Invalid argument: Unsupported type: 21
[I 12:59:36.181 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-seq2seq-AE.ipynb
[I 12:59:41.798 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-seq2seq-AE.ipynb
[I 12:59:44.426 LabApp] Kernel interrupted: 95e67d6a-4c4a-45be-b3f6-93f8445b51d0
[I 13:00:10.465 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-seq2seq-AE.ipynb
[I 13:01:21.983 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 13:01:42.620 LabApp] Kernel interrupted: 95e67d6a-4c4a-45be-b3f6-93f8445b51d0
[I 13:01:43.350 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-seq2seq-AE.ipynb
[I 13:01:45.683 LabApp] Starting buffering for 95e67d6a-4c4a-45be-b3f6-93f8445b51d0:5657c24f825142b0a29dc07d39158348
[I 13:01:48.287 LabApp] Kernel restarted: 95e67d6a-4c4a-45be-b3f6-93f8445b51d0
[I 13:01:51.206 LabApp] Adapting from protocol version 5.1 (kernel 95e67d6a-4c4a-45be-b3f6-93f8445b51d0) to 5.3 (client).
[I 13:01:51.207 LabApp] Restoring connection for 95e67d6a-4c4a-45be-b3f6-93f8445b51d0:5657c24f825142b0a29dc07d39158348
[I 13:01:51.207 LabApp] Replaying 8 buffered messages
[I 13:02:02.406 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAEGAN2-128.ipynb
[I 13:02:04.753 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAEGAN2-128.ipynb
2019-10-31 13:02:05.394325: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-31 13:02:05.908505: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-31 13:02:05.910609: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 13:02:05.914741: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-31 13:02:05.917474: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-31 13:02:05.919289: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-31 13:02:05.922839: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-31 13:02:05.925924: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-31 13:02:05.932505: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-31 13:02:05.935668: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-31 13:02:06.184012: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5598daed1530 executing computations on platform CUDA. Devices:
2019-10-31 13:02:06.184084: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-31 13:02:06.188837: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-31 13:02:06.190682: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5598dafa7fc0 executing computations on platform Host. Devices:
2019-10-31 13:02:06.190726: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-31 13:02:06.192280: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
2019-10-31 13:02:06.192384: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 13:02:06.192445: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-31 13:02:06.192502: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-31 13:02:06.192559: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-31 13:02:06.192616: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-31 13:02:06.192673: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-31 13:02:06.192733: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-31 13:02:06.195407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-31 13:02:06.195503: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 13:02:06.198518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-31 13:02:06.198549: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-31 13:02:06.198565: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-31 13:02:06.201534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11427 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
[I 13:02:07.626 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAEGAN2-128.ipynb
[I 13:02:08.343 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-seq2seq-AE.ipynb
2019-10-31 13:02:09.576947: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-31 13:02:09.777424: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-31 13:02:18.324657: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:502] constant folding failed: Invalid argument: Unsupported type: 21
2019-10-31 13:02:18.702251: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:502] constant folding failed: Invalid argument: Unsupported type: 21
[I 13:02:19.596 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAEGAN2-128.ipynb
[I 13:02:21.882 LabApp] Starting buffering for 98e3f4b4-ec88-46fd-a714-d558f562ab4c:dfc469f7956f4cf58329f2df4c457d97
[I 13:02:24.134 LabApp] Kernel restarted: 98e3f4b4-ec88-46fd-a714-d558f562ab4c
[I 13:02:26.970 LabApp] Adapting from protocol version 5.1 (kernel 98e3f4b4-ec88-46fd-a714-d558f562ab4c) to 5.3 (client).
[I 13:02:26.971 LabApp] Restoring connection for 98e3f4b4-ec88-46fd-a714-d558f562ab4c:dfc469f7956f4cf58329f2df4c457d97
[I 13:02:26.971 LabApp] Replaying 7 buffered messages
2019-10-31 13:02:37.590067: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-31 13:02:38.110461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-31 13:02:38.111143: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 13:02:38.112787: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-31 13:02:38.114069: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-31 13:02:38.114502: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-31 13:02:38.116225: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-31 13:02:38.117568: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-31 13:02:38.120988: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-31 13:02:38.122834: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-31 13:02:38.331888: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c17a3613a0 executing computations on platform CUDA. Devices:
2019-10-31 13:02:38.331946: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-31 13:02:38.334922: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-31 13:02:38.335930: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c17a437e00 executing computations on platform Host. Devices:
2019-10-31 13:02:38.335953: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-31 13:02:38.337024: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-31 13:02:38.337094: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 13:02:38.337130: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-31 13:02:38.337164: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-31 13:02:38.337198: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-31 13:02:38.337242: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-31 13:02:38.337277: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-31 13:02:38.337311: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-31 13:02:38.339012: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-31 13:02:38.339068: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 13:02:38.340912: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-31 13:02:38.340931: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-31 13:02:38.340940: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-31 13:02:38.342937: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-31 13:02:41.410200: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-31 13:02:42.256277: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
[I 13:03:22.830 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 13:04:02.400 LabApp] Starting buffering for 98e3f4b4-ec88-46fd-a714-d558f562ab4c:dfc469f7956f4cf58329f2df4c457d97
[I 13:04:04.871 LabApp] Kernel restarted: 98e3f4b4-ec88-46fd-a714-d558f562ab4c
[I 13:04:07.868 LabApp] Adapting from protocol version 5.1 (kernel 98e3f4b4-ec88-46fd-a714-d558f562ab4c) to 5.3 (client).
[I 13:04:07.869 LabApp] Restoring connection for 98e3f4b4-ec88-46fd-a714-d558f562ab4c:dfc469f7956f4cf58329f2df4c457d97
[I 13:04:07.869 LabApp] Replaying 6 buffered messages
[I 13:04:09.609 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-seq2seq-AE.ipynb
2019-10-31 13:04:19.456951: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-31 13:04:19.950593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-31 13:04:19.951579: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 13:04:19.953420: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-31 13:04:19.954790: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-31 13:04:19.955564: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-31 13:04:19.957350: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-31 13:04:19.958902: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-31 13:04:19.962324: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-31 13:04:19.964166: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-31 13:04:20.166773: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55804d868e60 executing computations on platform CUDA. Devices:
2019-10-31 13:04:20.166825: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-31 13:04:20.170089: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-31 13:04:20.171114: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55804d93f8f0 executing computations on platform Host. Devices:
2019-10-31 13:04:20.171139: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-31 13:04:20.172266: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-31 13:04:20.172344: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 13:04:20.172383: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-31 13:04:20.172425: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-31 13:04:20.172463: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-31 13:04:20.172506: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-31 13:04:20.172545: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-31 13:04:20.172586: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-31 13:04:20.174380: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-31 13:04:20.174440: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 13:04:20.189127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-31 13:04:20.189173: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-31 13:04:20.189185: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-31 13:04:20.191091: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-31 13:04:24.016464: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-31 13:04:24.876124: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
[I 13:04:25.365 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAEGAN2-128.ipynb
[I 13:05:21.565 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 13:06:09.251 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-seq2seq-AE.ipynb
[I 13:06:25.222 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAEGAN2-128.ipynb
[I 13:06:25.436 LabApp] Kernel interrupted: 98e3f4b4-ec88-46fd-a714-d558f562ab4c
[I 13:07:22.561 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 13:08:09.207 LabApp] Kernel interrupted: 98e3f4b4-ec88-46fd-a714-d558f562ab4c
[I 13:08:09.384 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-seq2seq-AE.ipynb
[I 13:08:25.735 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAEGAN2-128.ipynb
[I 13:09:21.626 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
[I 13:09:47.442 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAEGAN2-128.ipynb
[I 13:09:48.007 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-VAEGAN2-128.ipynb
[I 13:10:09.673 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-seq2seq-AE.ipynb
[I 13:10:29.537 LabApp] Starting buffering for 98e3f4b4-ec88-46fd-a714-d558f562ab4c:dfc469f7956f4cf58329f2df4c457d97
[I 13:10:32.460 LabApp] Kernel restarted: 98e3f4b4-ec88-46fd-a714-d558f562ab4c
[I 13:10:35.234 LabApp] Adapting from protocol version 5.1 (kernel 98e3f4b4-ec88-46fd-a714-d558f562ab4c) to 5.3 (client).
[I 13:10:35.235 LabApp] Restoring connection for 98e3f4b4-ec88-46fd-a714-d558f562ab4c:dfc469f7956f4cf58329f2df4c457d97
[I 13:10:35.235 LabApp] Replaying 8 buffered messages
2019-10-31 13:10:48.796086: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-10-31 13:10:49.286745: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-31 13:10:49.288052: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 13:10:49.290192: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-31 13:10:49.291808: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-31 13:10:49.292697: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-31 13:10:49.294870: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-31 13:10:49.297196: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-31 13:10:49.301443: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-31 13:10:49.303660: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-31 13:10:49.495803: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e7ac2ba240 executing computations on platform CUDA. Devices:
2019-10-31 13:10:49.495864: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2019-10-31 13:10:49.501116: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599870000 Hz
2019-10-31 13:10:49.502573: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e7ac390cd0 executing computations on platform Host. Devices:
2019-10-31 13:10:49.502604: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-10-31 13:10:49.503638: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:83:00.0
2019-10-31 13:10:49.503739: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 13:10:49.503779: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-10-31 13:10:49.503815: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-10-31 13:10:49.503852: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-10-31 13:10:49.503888: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-10-31 13:10:49.503925: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-10-31 13:10:49.503961: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-31 13:10:49.505561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-10-31 13:10:49.505632: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-10-31 13:10:49.507477: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-31 13:10:49.507497: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-10-31 13:10:49.507507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-10-31 13:10:49.509396: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:83:00.0, compute capability: 6.1)
2019-10-31 13:10:52.718722: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-10-31 13:10:53.569137: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
[I 13:11:21.423 LabApp] Saving file at /avgn_paper/notebooks/6.0-neural-networks/Starling-128-GAN.ipynb
