{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marmoset vocalization dataset custom parsing\n",
    "- This dataset has:\n",
    "    - A number of WAVs where naming convention stores the individuals vocalizing\n",
    "    - Corresponding .mat files with the timing of each phee/call and the individual making the vocalization\n",
    "- This notebook extracts periods of vocalization into new WAV files, and creates a corresponding JSON and TextGrid for each WAV with annotation information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T04:12:50.024418Z",
     "start_time": "2019-06-18T04:12:50.021792Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_id = 'marmoset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T04:12:51.721210Z",
     "start_time": "2019-06-18T04:12:50.026312Z"
    }
   },
   "outputs": [],
   "source": [
    "from avgn.utils.general import prepare_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T04:12:51.764574Z",
     "start_time": "2019-06-18T04:12:51.726838Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=GPU\n"
     ]
    }
   ],
   "source": [
    "prepare_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T04:12:52.448385Z",
     "start_time": "2019-06-18T04:12:51.766511Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from tqdm.autonotebook import tqdm\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from datetime import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T04:12:52.478400Z",
     "start_time": "2019-06-18T04:12:52.450234Z"
    }
   },
   "outputs": [],
   "source": [
    "#import avgn_paper as avgn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T04:12:52.583071Z",
     "start_time": "2019-06-18T04:12:52.480060Z"
    }
   },
   "outputs": [],
   "source": [
    "import avgn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T04:12:52.682037Z",
     "start_time": "2019-06-18T04:12:52.584638Z"
    }
   },
   "outputs": [],
   "source": [
    "from avgn.custom_parsing.miller_marmoset import (\n",
    "    parse_marmoset_data,\n",
    "    parse_marmoset_calls,\n",
    ")\n",
    "from avgn.utils.paths import DATA_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data in original format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T04:12:52.772841Z",
     "start_time": "2019-06-18T04:12:52.685789Z"
    }
   },
   "outputs": [],
   "source": [
    "DSLOC = avgn.utils.paths.Path('/mnt/cube/Datasets/Marmosets/FromMillerLab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T04:12:52.877568Z",
     "start_time": "2019-06-18T04:12:52.776355Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(186,\n",
       " [PosixPath('/mnt/cube/Datasets/Marmosets/FromMillerLab/han.todd.170621.wav'),\n",
       "  PosixPath('/mnt/cube/Datasets/Marmosets/FromMillerLab/ares_spn_230217_203.wav'),\n",
       "  PosixPath('/mnt/cube/Datasets/Marmosets/FromMillerLab/ares_ant_010317_33.wav')])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wavs = list(DSLOC.glob('*.wav'))\n",
    "len(wavs), wavs[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T04:12:52.966220Z",
     "start_time": "2019-06-18T04:12:52.879451Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82,\n",
       " [PosixPath('/mnt/cube/Datasets/Marmosets/FromMillerLab/apollo_angel_140217.mat'),\n",
       "  PosixPath('/mnt/cube/Datasets/Marmosets/FromMillerLab/jasmine.hermes.170622.mat'),\n",
       "  PosixPath('/mnt/cube/Datasets/Marmosets/FromMillerLab/aladdin_banana_060317.mat')])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matfiles = list(DSLOC.glob(\"*.mat\"))\n",
    "len(matfiles), matfiles[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse data into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T04:12:53.057262Z",
     "start_time": "2019-06-18T04:12:52.969893Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_marmoset_data(wavs, _filetype=\"wav\"):\n",
    "    \"\"\"Parse filename of marmoset data into a pandas dataframe\n",
    "        \n",
    "    Arguments:\n",
    "        wavs {[type]} -- [description]\n",
    "    \n",
    "    Keyword Arguments:\n",
    "        _filetype {str} -- [description] (default: {\"wav\"})\n",
    "    \n",
    "    Returns:\n",
    "        [type] -- [description]\n",
    "    \"\"\"\n",
    "    wav_df = pd.DataFrame(\n",
    "        columns=[\"monkey1\", \"monkey2\", \"date\", \"date_idx\", _filetype + \"_loc\"]\n",
    "    )\n",
    "    for _wav in wavs:\n",
    "        if _wav.stem[0] == \".\":\n",
    "            continue\n",
    "        monkey1 = None\n",
    "        date = None\n",
    "        monkey2 = None\n",
    "        date_idx = None\n",
    "\n",
    "        wav_split = _wav.stem.split(\"_\")\n",
    "        if len(wav_split) == 3:\n",
    "            monkey1, monkey2, date = wav_split\n",
    "        elif len(wav_split) == 4:\n",
    "            monkey1, monkey2, date, date_idx = wav_split\n",
    "        elif len(wav_split) == 1:\n",
    "            if len(_wav.stem.split(\".\")) == 3:\n",
    "                monkey1, monkey2, date = _wav.stem.split(\".\")\n",
    "            elif len(_wav.stem.split(\".\")) == 2:\n",
    "                monkey1, date_idx = _wav.stem.split(\".\")\n",
    "            elif len(_wav.stem.split(\".\")) == 4:\n",
    "                monkey1, date_idx, date, _ = _wav.stem.split(\".\")\n",
    "            elif len(re.findall(\"[A-Z][^A-Z]*\", _wav.stem)) == 2:\n",
    "                monkey1, date_idx = re.findall(\"[A-Z][^A-Z]*\", _wav.stem)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        wav_df.loc[len(wav_df)] = [monkey1, monkey2, date, date_idx, _wav]\n",
    "    return wav_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T04:12:53.765039Z",
     "start_time": "2019-06-18T04:12:53.060529Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>monkey1</th>\n",
       "      <th>monkey2</th>\n",
       "      <th>date</th>\n",
       "      <th>date_idx</th>\n",
       "      <th>wav_loc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>han</td>\n",
       "      <td>todd</td>\n",
       "      <td>170621</td>\n",
       "      <td>None</td>\n",
       "      <td>/mnt/cube/Datasets/Marmosets/FromMillerLab/han...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ares</td>\n",
       "      <td>spn</td>\n",
       "      <td>230217</td>\n",
       "      <td>203</td>\n",
       "      <td>/mnt/cube/Datasets/Marmosets/FromMillerLab/are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ares</td>\n",
       "      <td>ant</td>\n",
       "      <td>010317</td>\n",
       "      <td>33</td>\n",
       "      <td>/mnt/cube/Datasets/Marmosets/FromMillerLab/are...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  monkey1 monkey2    date date_idx  \\\n",
       "0     han    todd  170621     None   \n",
       "1    ares     spn  230217      203   \n",
       "2    ares     ant  010317       33   \n",
       "\n",
       "                                             wav_loc  \n",
       "0  /mnt/cube/Datasets/Marmosets/FromMillerLab/han...  \n",
       "1  /mnt/cube/Datasets/Marmosets/FromMillerLab/are...  \n",
       "2  /mnt/cube/Datasets/Marmosets/FromMillerLab/are...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wav_df = parse_marmoset_data(wavs, _filetype = \"wav\")\n",
    "print(len(wav_df))\n",
    "display(wav_df[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T04:12:54.063811Z",
     "start_time": "2019-06-18T04:12:53.767670Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>monkey1</th>\n",
       "      <th>monkey2</th>\n",
       "      <th>date</th>\n",
       "      <th>date_idx</th>\n",
       "      <th>mat_loc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apollo</td>\n",
       "      <td>angel</td>\n",
       "      <td>140217</td>\n",
       "      <td>None</td>\n",
       "      <td>/mnt/cube/Datasets/Marmosets/FromMillerLab/apo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jasmine</td>\n",
       "      <td>hermes</td>\n",
       "      <td>170622</td>\n",
       "      <td>None</td>\n",
       "      <td>/mnt/cube/Datasets/Marmosets/FromMillerLab/jas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aladdin</td>\n",
       "      <td>banana</td>\n",
       "      <td>060317</td>\n",
       "      <td>None</td>\n",
       "      <td>/mnt/cube/Datasets/Marmosets/FromMillerLab/ala...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   monkey1 monkey2    date date_idx  \\\n",
       "0   apollo   angel  140217     None   \n",
       "1  jasmine  hermes  170622     None   \n",
       "2  aladdin  banana  060317     None   \n",
       "\n",
       "                                             mat_loc  \n",
       "0  /mnt/cube/Datasets/Marmosets/FromMillerLab/apo...  \n",
       "1  /mnt/cube/Datasets/Marmosets/FromMillerLab/jas...  \n",
       "2  /mnt/cube/Datasets/Marmosets/FromMillerLab/ala...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mf_df = parse_marmoset_data(matfiles, _filetype = \"mat\")\n",
    "print(len(mf_df))\n",
    "display(mf_df[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T04:12:54.117250Z",
     "start_time": "2019-06-18T04:12:54.068573Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>monkey1</th>\n",
       "      <th>monkey2</th>\n",
       "      <th>date</th>\n",
       "      <th>date_idx</th>\n",
       "      <th>mat_loc</th>\n",
       "      <th>wav_loc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apollo</td>\n",
       "      <td>angel</td>\n",
       "      <td>140217</td>\n",
       "      <td>None</td>\n",
       "      <td>/mnt/cube/Datasets/Marmosets/FromMillerLab/apo...</td>\n",
       "      <td>/mnt/cube/Datasets/Marmosets/FromMillerLab/apo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jasmine</td>\n",
       "      <td>hermes</td>\n",
       "      <td>170622</td>\n",
       "      <td>None</td>\n",
       "      <td>/mnt/cube/Datasets/Marmosets/FromMillerLab/jas...</td>\n",
       "      <td>/mnt/cube/Datasets/Marmosets/FromMillerLab/jas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aladdin</td>\n",
       "      <td>banana</td>\n",
       "      <td>060317</td>\n",
       "      <td>None</td>\n",
       "      <td>/mnt/cube/Datasets/Marmosets/FromMillerLab/ala...</td>\n",
       "      <td>/mnt/cube/Datasets/Marmosets/FromMillerLab/ala...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   monkey1 monkey2    date date_idx  \\\n",
       "0   apollo   angel  140217     None   \n",
       "1  jasmine  hermes  170622     None   \n",
       "2  aladdin  banana  060317     None   \n",
       "\n",
       "                                             mat_loc  \\\n",
       "0  /mnt/cube/Datasets/Marmosets/FromMillerLab/apo...   \n",
       "1  /mnt/cube/Datasets/Marmosets/FromMillerLab/jas...   \n",
       "2  /mnt/cube/Datasets/Marmosets/FromMillerLab/ala...   \n",
       "\n",
       "                                             wav_loc  \n",
       "0  /mnt/cube/Datasets/Marmosets/FromMillerLab/apo...  \n",
       "1  /mnt/cube/Datasets/Marmosets/FromMillerLab/jas...  \n",
       "2  /mnt/cube/Datasets/Marmosets/FromMillerLab/ala...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# merge dataframes\n",
    "mf_df = pd.merge(\n",
    "    mf_df,\n",
    "    wav_df,\n",
    "    how=\"left\",\n",
    "    left_on=[\"monkey1\", \"monkey2\", \"date\", \"date_idx\"],\n",
    "    right_on=[\"monkey1\", \"monkey2\", \"date\", \"date_idx\"],\n",
    "    suffixes=(False, False),\n",
    ")\n",
    "# remove unlabelled wavs\n",
    "mf_df = mf_df[mf_df.wav_loc.isnull() == False]\n",
    "print(len(mf_df))\n",
    "display(mf_df[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse matfiles into syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T04:12:54.206430Z",
     "start_time": "2019-06-18T04:12:54.119371Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "\n",
    "def parse_marmoset_calls(row, callers=[\"monkey1_data\", \"monkey2_data\"]):\n",
    "    \"\"\" Parses a .mat file of marmoset vocalizations into a dataframe\n",
    "        \n",
    "    Arguments:\n",
    "        row {[type]} -- [description]\n",
    "    \n",
    "    Keyword Arguments:\n",
    "        callers {list} -- [description] (default: {[\"monkey1_data\", \"monkey2_data\"]})\n",
    "    \n",
    "    Returns:\n",
    "        [type] -- [description]\n",
    "    \"\"\"\n",
    "    # load the annotations\n",
    "    annotations = loadmat(row.mat_loc.as_posix())\n",
    "    # create syllable_df\n",
    "    syllable_df = pd.DataFrame(\n",
    "        columns=[\n",
    "            \"indv\",\n",
    "            \"partner\",\n",
    "            \"date\",\n",
    "            \"call_type\",\n",
    "            \"wav_loc\",\n",
    "            \"call_num\",\n",
    "            \"pulse_n\",\n",
    "            \"pulse_start\",\n",
    "            \"pulse_end\",\n",
    "        ]\n",
    "    )\n",
    "    for caller in callers:\n",
    "        # determine partner vs indv.\n",
    "        indv = row.monkey1 if caller == \"monkey1_data\" else row.monkey2\n",
    "        partner = row.monkey2 if caller == \"monkey1_data\" else row.monkey1\n",
    "        for call_ix, call in enumerate(annotations[caller]):\n",
    "            # this list goes [start1, end1, start2, end2]\n",
    "            n_subcalls = int(len(call[1]) / 2)\n",
    "            call_name = call[0][0]  # e.g. \"phee\"\n",
    "            for call_sub in range(n_subcalls):\n",
    "                subcall_start = call[1][call_sub * 2]\n",
    "                subcall_end = call[1][(call_sub * 2) + 1]\n",
    "                # if this call is too long, its probably a mistake\n",
    "                if ((subcall_end - subcall_start) > 5) or (\n",
    "                    (subcall_end - subcall_start) <= 0\n",
    "                ):\n",
    "                    continue\n",
    "                syllable_df.loc[len(syllable_df)] = [\n",
    "                    indv,\n",
    "                    partner,\n",
    "                    row.date,\n",
    "                    call_name,\n",
    "                    row.wav_loc,\n",
    "                    call_ix,\n",
    "                    call_sub,\n",
    "                    subcall_start[0],\n",
    "                    subcall_end[0],\n",
    "                ]\n",
    "    return syllable_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T04:13:02.055820Z",
     "start_time": "2019-06-18T04:12:54.208384Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e01bcd0fec0e4bf9909c2b6ff0ef0389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=80), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    3.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 out of  80 | elapsed:    4.3s remaining:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done  51 out of  80 | elapsed:    4.9s remaining:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  80 | elapsed:    5.3s remaining:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  69 out of  80 | elapsed:    5.8s remaining:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  78 out of  80 | elapsed:    7.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:    7.6s finished\n"
     ]
    }
   ],
   "source": [
    "syllable_df = pd.concat(\n",
    "    Parallel(n_jobs=-1, verbose=10)(\n",
    "        delayed(parse_marmoset_calls)(row)\n",
    "        for idx, row in tqdm(mf_df.iterrows(), total=len(mf_df))\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T04:13:02.112424Z",
     "start_time": "2019-06-18T04:13:02.058617Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14295\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indv</th>\n",
       "      <th>partner</th>\n",
       "      <th>date</th>\n",
       "      <th>call_type</th>\n",
       "      <th>wav_loc</th>\n",
       "      <th>call_num</th>\n",
       "      <th>pulse_n</th>\n",
       "      <th>pulse_start</th>\n",
       "      <th>pulse_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apollo</td>\n",
       "      <td>angel</td>\n",
       "      <td>140217</td>\n",
       "      <td>phee</td>\n",
       "      <td>/mnt/cube/Datasets/Marmosets/FromMillerLab/apo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14.038007</td>\n",
       "      <td>16.171723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apollo</td>\n",
       "      <td>angel</td>\n",
       "      <td>140217</td>\n",
       "      <td>phee</td>\n",
       "      <td>/mnt/cube/Datasets/Marmosets/FromMillerLab/apo...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>107.359792</td>\n",
       "      <td>108.729595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apollo</td>\n",
       "      <td>angel</td>\n",
       "      <td>140217</td>\n",
       "      <td>phee</td>\n",
       "      <td>/mnt/cube/Datasets/Marmosets/FromMillerLab/apo...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>109.060383</td>\n",
       "      <td>110.417463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     indv partner    date call_type  \\\n",
       "0  apollo   angel  140217      phee   \n",
       "1  apollo   angel  140217      phee   \n",
       "2  apollo   angel  140217      phee   \n",
       "\n",
       "                                             wav_loc call_num pulse_n  \\\n",
       "0  /mnt/cube/Datasets/Marmosets/FromMillerLab/apo...        0       0   \n",
       "1  /mnt/cube/Datasets/Marmosets/FromMillerLab/apo...        1       0   \n",
       "2  /mnt/cube/Datasets/Marmosets/FromMillerLab/apo...        1       1   \n",
       "\n",
       "   pulse_start   pulse_end  \n",
       "0    14.038007   16.171723  \n",
       "1   107.359792  108.729595  \n",
       "2   109.060383  110.417463  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(len(syllable_df))\n",
    "display(syllable_df[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### segment WAVs into 'bouts'\n",
    "- There are a lot of periods of time in the original datasets that are not occupied by any vocalizations. Here, we segment out those time periods and create new sub-WAVs. For each sub-WAV, we generate a JSON with metadata and segment information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T04:13:02.207699Z",
     "start_time": "2019-06-18T04:13:02.114284Z"
    }
   },
   "outputs": [],
   "source": [
    "from avgn.utils.json import NoIndent, NoIndentEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T04:13:02.299923Z",
     "start_time": "2019-06-18T04:13:02.209771Z"
    }
   },
   "outputs": [],
   "source": [
    "def segment_wav_into_bouts(wav_df, hparams):\n",
    "    \"\"\" Segments the wav_df full of segmental information into individual bouts\n",
    "    \"\"\"\n",
    "    # populate a list of dataframes corresponding to each bout\n",
    "    bout_dfs = []\n",
    "    # first bout starts at first voc\n",
    "    bout_start = wav_df.iloc[0].pulse_start\n",
    "    for ri, (idx, row) in enumerate(wav_df.iterrows()):\n",
    "\n",
    "        # if this is the last voc, it should be the end of the bout\n",
    "        if ri == len(wav_df) - 1:\n",
    "            bout_end = row.pulse_end\n",
    "        # if there is not a gap greater than bout_segmentation_min_s after this voc its part of the same voc\n",
    "        if ri == len(wav_df) - 1:\n",
    "            bout_end = row.pulse_end\n",
    "        else:\n",
    "            if (\n",
    "                wav_df.iloc[ri + 1].pulse_start - row.pulse_end\n",
    "                > hparams.bout_segmentation_min_s\n",
    "            ):\n",
    "                bout_end = row.pulse_end\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        # create a dataframe of only the bout\n",
    "        bout_df = wav_df[\n",
    "            (wav_df.pulse_start >= bout_start) & (wav_df.pulse_end <= bout_end)\n",
    "        ]\n",
    "        bout_dfs.append(bout_df)\n",
    "        \n",
    "        # set next bout start\n",
    "        if ri < len(wav_df)-1:\n",
    "            bout_start = wav_df.iloc[ri + 1].pulse_start\n",
    "        \n",
    "    return bout_dfs\n",
    "\n",
    "\n",
    "def load_bout_data(bout_df, wav_df, hparams):\n",
    "    \"\"\" Loads data for marmoset bout given a bout dataframe\n",
    "    \"\"\"\n",
    "    bout_start = bout_df.pulse_start.values[0]\n",
    "    bout_end = bout_df.pulse_end.values[-1]\n",
    "    # Ensure padding does not start before WAV starts\n",
    "    bout_pad_start = hparams.bout_pad_s\n",
    "    if bout_start - hparams.bout_pad_s < 0:\n",
    "        bout_pad_start = hparams.bout_pad_s - bout_start\n",
    "\n",
    "    # load the wav at the relevant times + padding if possible\n",
    "    clip_duration = (bout_end + hparams.bout_pad_s) - (bout_start - bout_pad_start)\n",
    "    bout_wav, sr = librosa.load(\n",
    "        bout_df.iloc[0].wav_loc,\n",
    "        mono=True,\n",
    "        sr=None,\n",
    "        offset=bout_start - bout_pad_start,\n",
    "        duration=clip_duration,\n",
    "    )\n",
    "    # extract a noise clip\n",
    "    if hparams.get_noise_clip:\n",
    "        bout_noise, noise_sr = avgn.custom_parsing.general.extract_noise_clip(\n",
    "            bout_df.iloc[0].wav_loc,\n",
    "            bout_start,\n",
    "            bout_end,\n",
    "            wav_df.pulse_start.values,\n",
    "            wav_df.pulse_end.values,\n",
    "            hparams.min_noise_clip_size_s,\n",
    "            hparams.max_noise_clip_size_s,\n",
    "        )\n",
    "    else:\n",
    "        bout_noise = None\n",
    "        noise_sr = None\n",
    "    return bout_wav, sr, bout_noise, noise_sr, bout_start, bout_pad_start\n",
    "\n",
    "\n",
    "def generate_json(bout_df, bout_number, bout_len, sr, bout_start, bout_pad_start):\n",
    "    \"\"\" Generates a json from \n",
    "    \"\"\"\n",
    "    wavdate = datetime.strptime(bout_df.date.values[0], \"%d%m%y\")\n",
    "    wav_date = wavdate.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "    # wav general information\n",
    "    json_dict = {}\n",
    "    json_dict[\"bout_number\"] = bout_number\n",
    "    json_dict[\"datetime\"] = wav_date\n",
    "    json_dict[\"samplerate_hz\"] = sr\n",
    "    json_dict[\"original_wav\"] = bout_df.wav_loc.values[0].as_posix()\n",
    "    json_dict[\"length_s\"] = bout_len\n",
    "    json_dict[\"time_relative_to_original_wav\"] = bout_start - bout_pad_start\n",
    "    json_dict[\"indvs\"] = {}\n",
    "    json_dict\n",
    "\n",
    "    # individual specific information\n",
    "    for indv in bout_df.indv.unique():\n",
    "        json_dict[\"indvs\"][indv] = {}\n",
    "        indv_df = bout_df[bout_df.indv == indv].sort_values(by=\"pulse_start\")\n",
    "        json_dict[\"indvs\"][indv][\"partner\"] = indv_df.partner.values[0]\n",
    "        json_dict[\"indvs\"][indv][\"calls\"] = {\n",
    "            \"start_times\": NoIndent(\n",
    "                list(indv_df.pulse_start.values - bout_start + bout_pad_start)\n",
    "            ),\n",
    "            \"end_times\": NoIndent(\n",
    "                list(indv_df.pulse_end.values - bout_start + bout_pad_start)\n",
    "            ),\n",
    "            \"labels\": NoIndent(list(indv_df.call_type.values)),\n",
    "            \"call_num\": NoIndent(list(indv_df.call_num.values)),\n",
    "            \"pulse_num\": NoIndent(list(indv_df.pulse_n.values)),\n",
    "        }\n",
    "\n",
    "    json_txt = json.dumps(json_dict, cls=NoIndentEncoder, indent=2)\n",
    "    return json_txt\n",
    "\n",
    "\n",
    "def save_bout_data(DATA_DIR, json_txt, bout_wav, sr, bout_noise, noise_sr, dataset_id, DT_ID, wav_stem, bout_start, bout_pad_start):\n",
    "\n",
    "    # get time of bout relative to wav\n",
    "    time_in_wav = bout_start - bout_pad_start\n",
    "    bout_start_string = avgn.utils.general.seconds_to_str(time_in_wav)\n",
    "\n",
    "    # output locations\n",
    "    wav_out = (\n",
    "        DATA_DIR\n",
    "        / \"processed\"\n",
    "        / dataset_id\n",
    "        / DT_ID\n",
    "        / \"WAV\"\n",
    "        / (wav_stem + \"__\" + bout_start_string + \".WAV\")\n",
    "    )\n",
    "    json_out = (\n",
    "        DATA_DIR\n",
    "        / \"processed\"\n",
    "        / dataset_id\n",
    "        / DT_ID\n",
    "        / \"JSON\"\n",
    "        / (wav_stem + \"__\" + bout_start_string + \".JSON\")\n",
    "    )\n",
    "\n",
    "    # save wav file\n",
    "    avgn.utils.paths.ensure_dir(wav_out)\n",
    "    librosa.output.write_wav(wav_out, y=bout_wav, sr=sr, norm=True)\n",
    "\n",
    "    # save json\n",
    "    avgn.utils.paths.ensure_dir(json_out.as_posix())\n",
    "    print(json_txt, file=open(json_out.as_posix(), \"w\"))\n",
    "    \n",
    "    # save noise file\n",
    "    if hparams.get_noise_clip:\n",
    "        noise_out = (\n",
    "            DATA_DIR\n",
    "            / \"processed\"\n",
    "            / dataset_id\n",
    "            / DT_ID\n",
    "            / \"NOISE\"\n",
    "            / (wav_stem + \"__\" + bout_start_string + \".WAV\")\n",
    "        )\n",
    "        avgn.utils.paths.ensure_dir(noise_out)\n",
    "        if bout_noise is not None:\n",
    "            librosa.output.write_wav(noise_out, y=bout_noise, sr=noise_sr, norm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T04:13:02.417204Z",
     "start_time": "2019-06-18T04:13:02.302561Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019-06-17_21-13-02'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a unique datetime identifier for the files output by this notebook\n",
    "DT_ID = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "DT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T04:13:02.505578Z",
     "start_time": "2019-06-18T04:13:02.420993Z"
    }
   },
   "outputs": [],
   "source": [
    "# HParams is just a python object storing a set of hyperparameters.\n",
    "hparams = avgn.utils.general.HParams(\n",
    "    bout_segmentation_min_s = 30,  # Minimum amount of seconds between vocal activity required to split a wavfile\n",
    "    bout_pad_s = 5, # how much time to pad this bout with on either side\n",
    "    # noise clip\n",
    "    get_noise_clip = True, # if a noise clip preceding the vocalization should be grabbed to help reduce noise in analysis\n",
    "    max_noise_clip_size_s = 10, # how large the noise clip can be\n",
    "    min_noise_clip_size_s = 1, # how small the noise clip can be\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T04:13:05.969402Z",
     "start_time": "2019-06-18T04:13:02.509046Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29e62da870624e6187839bb0ca9a7b15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=78), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    2.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  39 out of  78 | elapsed:    3.0s remaining:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  78 | elapsed:    3.0s remaining:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  78 | elapsed:    3.1s remaining:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  63 out of  78 | elapsed:    3.2s remaining:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  71 out of  78 | elapsed:    3.2s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  78 out of  78 | elapsed:    3.3s finished\n"
     ]
    }
   ],
   "source": [
    "bout_dfs =  Parallel(n_jobs=-1, verbose=10)(\n",
    "        delayed(segment_wav_into_bouts)(\n",
    "            (\n",
    "                syllable_df[syllable_df.wav_loc == wav_loc]\n",
    "                .sort_values(by=[\"pulse_start\"])\n",
    "                .reset_index()\n",
    "            ),\n",
    "            hparams,\n",
    "        )\n",
    "        for wav_loc in tqdm(syllable_df.wav_loc.unique())\n",
    "    )\n",
    "bout_dfs = [item for sublist in bout_dfs for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T04:13:06.019751Z",
     "start_time": "2019-06-18T04:13:05.972325Z"
    }
   },
   "outputs": [],
   "source": [
    "def segment_and_annotate_bouts(bout_number, wav_df, bout_df, hparams):\n",
    "    \"\"\" segments parsed bouts and annotates as json\n",
    "    \"\"\"\n",
    "    bout_wav, sr, bout_noise, noise_sr, bout_start, bout_pad_start = load_bout_data(bout_df, wav_df, hparams)\n",
    "    bout_duration = len(bout_wav) / sr\n",
    "    # generate the json for the bout\n",
    "    json_txt = generate_json(bout_df, bout_number, bout_duration, sr, bout_start, bout_pad_start)\n",
    "    # save bout WAV, Noise, and JSON\n",
    "    wav_stem = bout_df.iloc[0].wav_loc.stem\n",
    "    save_bout_data(DATA_DIR, json_txt, bout_wav, sr, bout_noise, noise_sr, dataset_id, DT_ID, wav_stem, bout_start, bout_pad_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T04:17:56.933244Z",
     "start_time": "2019-06-18T04:13:23.365718Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aef6db42df134b509cd039ef0736ed19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=769), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=-1)]: Done  50 tasks      | elapsed:   15.1s\n",
      "[Parallel(n_jobs=-1)]: Done  65 tasks      | elapsed:   16.5s\n",
      "[Parallel(n_jobs=-1)]: Done  80 tasks      | elapsed:   21.7s\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed:   24.7s\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:   30.2s\n",
      "[Parallel(n_jobs=-1)]: Done 133 tasks      | elapsed:   38.1s\n",
      "/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done 152 tasks      | elapsed:   41.1s\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:   51.5s\n",
      "[Parallel(n_jobs=-1)]: Done 194 tasks      | elapsed:   57.3s\n",
      "[Parallel(n_jobs=-1)]: Done 217 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 240 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 265 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 290 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 344 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 373 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 402 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 433 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 464 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 497 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 530 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 565 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 600 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 637 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 674 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 713 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 769 out of 769 | elapsed:  4.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Parallel(n_jobs=-1, verbose=10)(\n",
    "    delayed(segment_and_annotate_bouts)(\n",
    "        bout_number,\n",
    "        syllable_df[syllable_df.wav_loc == bout_df.iloc[0].wav_loc]\n",
    "        .sort_values(by=[\"pulse_start\"])\n",
    "        .reset_index(),\n",
    "        bout_df,\n",
    "        hparams,\n",
    "    )\n",
    "    for bout_number, bout_df in tqdm(enumerate(bout_dfs), total=len(bout_dfs))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
