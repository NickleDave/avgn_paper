{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-25T15:10:32.972Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=2\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-25T15:10:32.974Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/cube/tsainbur/conda_envs/tpy3/lib/python3.6/site-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "from avgn.utils.paths import DATA_DIR, most_recent_subdirectory, ensure_dir\n",
    "from avgn.tensorflow.data import _parse_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-25T15:10:32.976Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.autonotebook import tqdm\n",
    "%matplotlib inline\n",
    "from IPython import display\n",
    "import pandas as pd\n",
    "\n",
    "# the nightly build of tensorflow_probability is required as of the time of writing this \n",
    "import tensorflow_probability as tfp\n",
    "ds = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-25T15:10:32.978Z"
    }
   },
   "outputs": [],
   "source": [
    "print(tf.__version__, tfp.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-25T15:10:32.979Z"
    }
   },
   "outputs": [],
   "source": [
    "TRAIN_SIZE=482608\n",
    "BATCH_SIZE=512\n",
    "TEST_SIZE=10000\n",
    "DIMS = (32, 24, 1)\n",
    "N_TRAIN_BATCHES =int((TRAIN_SIZE-TEST_SIZE)/BATCH_SIZE)\n",
    "N_TEST_BATCHES = int(TEST_SIZE/BATCH_SIZE)\n",
    "TRAIN_BUF = 1000\n",
    "TEST_BUF = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-25T15:10:32.981Z"
    }
   },
   "outputs": [],
   "source": [
    "network_type = 'AE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-25T15:10:32.982Z"
    }
   },
   "outputs": [],
   "source": [
    "DATASET_ID = 'canary_segmented'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-25T15:10:32.983Z"
    }
   },
   "outputs": [],
   "source": [
    "record_loc = DATA_DIR / 'tfrecords' / \"canary_32x24.tfrecord\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-25T15:10:32.985Z"
    }
   },
   "outputs": [],
   "source": [
    "# read the dataset\n",
    "raw_dataset = tf.data.TFRecordDataset([record_loc.as_posix()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-25T15:10:32.986Z"
    }
   },
   "outputs": [],
   "source": [
    "data_types = {\n",
    "    \"spectrogram\": tf.uint8,\n",
    "    \"index\": tf.int64,\n",
    "    \"phrase\": tf.int64,\n",
    "    \"indv\": tf.string,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-25T15:10:32.987Z"
    }
   },
   "outputs": [],
   "source": [
    "# parse each data type to the raw dataset\n",
    "dataset = raw_dataset.map(lambda x: _parse_function(x, data_types=data_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-25T15:10:32.988Z"
    }
   },
   "outputs": [],
   "source": [
    "spec, index, phrase, indv  = next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-25T15:10:32.990Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.matshow(spec.numpy().reshape(DIMS).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-25T15:10:32.992Z"
    }
   },
   "outputs": [],
   "source": [
    "test_dataset = dataset.take(TEST_SIZE).shuffle(TEST_BUF).batch(BATCH_SIZE)\n",
    "train_dataset = dataset.skip(TEST_SIZE).take(TRAIN_SIZE-TEST_SIZE).shuffle(TEST_BUF).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-25T15:10:32.993Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (\n",
    "    Conv2D,\n",
    "    Reshape,\n",
    "    Bidirectional,\n",
    "    Dense,\n",
    "    RepeatVector,\n",
    "    TimeDistributed,\n",
    "    LSTM\n",
    ")\n",
    "\n",
    "N_Z = 128\n",
    "shape_final = (8,6,64) # x channel will be the sequence length\n",
    "\n",
    "enc = [\n",
    "    Conv2D(\n",
    "        filters=32, kernel_size=3, strides=(2, 2), activation=tf.nn.leaky_relu, padding=\"same\"\n",
    "    ),\n",
    "    Conv2D(\n",
    "        filters=shape_final[2], kernel_size=3, strides=(2, 2), activation=tf.nn.leaky_relu, padding=\"same\"\n",
    "    ),\n",
    "    Reshape(target_shape=(shape_final[0], np.prod(shape_final[1:]))),\n",
    "    Bidirectional(LSTM(units=100, activation=\"relu\")),\n",
    "    Dense(units=512),\n",
    "    Dense(units=N_Z),\n",
    "]\n",
    "\n",
    "dec = [\n",
    "    Dense(units=512),\n",
    "    RepeatVector(shape_final[0]),\n",
    "    Bidirectional(LSTM(units=100, activation=\"relu\", return_sequences=True)),\n",
    "    TimeDistributed(Dense(np.prod(shape_final[1:]))),\n",
    "    Reshape(target_shape=(shape_final[0], shape_final[1], shape_final[2])),\n",
    "    tf.keras.layers.Conv2DTranspose(\n",
    "        filters=64, kernel_size=3, strides=(2, 2), padding=\"SAME\", activation=tf.nn.leaky_relu\n",
    "    ),\n",
    "    tf.keras.layers.Conv2DTranspose(\n",
    "        filters=32, kernel_size=3, strides=(2, 2), padding=\"SAME\", activation=tf.nn.leaky_relu\n",
    "    ),\n",
    "    tf.keras.layers.Conv2DTranspose(\n",
    "        filters=1, kernel_size=3, strides=(1, 1), padding=\"SAME\", activation=\"tanh\"\n",
    "    ),\n",
    "    Reshape(target_shape=(32, 24, 1)),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-25T15:10:32.994Z"
    }
   },
   "outputs": [],
   "source": [
    "from avgn.tensorflow.AE import AE, plot_reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-25T15:10:32.995Z"
    }
   },
   "outputs": [],
   "source": [
    "# the optimizer for the model\n",
    "optimizer = tf.keras.optimizers.Adam(1e-4\n",
    "# train the model\n",
    "model = AE(\n",
    "    enc = enc,\n",
    "    dec = dec,\n",
    "    optimizer = optimizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-25T15:10:32.997Z"
    }
   },
   "outputs": [],
   "source": [
    "# exampled data for plotting results\n",
    "example_data = next(iter(test_dataset))\n",
    "example_data = (\n",
    "        tf.cast(tf.reshape(example_data[0], [BATCH_SIZE] + list(DIMS)), tf.float32)\n",
    "        / 255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-25T15:10:32.998Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_reconstruction(model, example_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-25T15:10:32.999Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-25T15:10:33.000Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.__path__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-25T15:10:33.001Z"
    }
   },
   "outputs": [],
   "source": [
    "# a pandas dataframe to save the loss information to\n",
    "losses = pd.DataFrame(columns = ['recon_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-25T15:10:33.003Z"
    }
   },
   "outputs": [],
   "source": [
    "N_TRAIN_BATCHES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-25T15:10:33.005Z"
    }
   },
   "outputs": [],
   "source": [
    "n_epochs = 500\n",
    "for epoch in range(n_epochs):\n",
    "    # train\n",
    "    for batch, train_x in tqdm(\n",
    "        zip(range(N_TRAIN_BATCHES), train_dataset), total=N_TRAIN_BATCHES\n",
    "    ):\n",
    "        #print(train_x[-1].numpy()[:4])\n",
    "        x = tf.cast(tf.reshape(train_x[0], [BATCH_SIZE] + list(DIMS)), tf.float32) / 255\n",
    "        model.train_net(x)\n",
    "    # test on holdout\n",
    "    loss = []\n",
    "    for batch, test_x in tqdm(\n",
    "        zip(range(N_TEST_BATCHES), test_dataset), total=N_TEST_BATCHES\n",
    "    ):\n",
    "        x = tf.cast(tf.reshape(test_x[0], [BATCH_SIZE] + list(DIMS)), tf.float32) / 255\n",
    "        loss.append(model.compute_loss(x))\n",
    "    losses.loc[len(losses)] = np.mean(loss, axis=0)\n",
    "    # plot results\n",
    "    display.clear_output()\n",
    "    print(\n",
    "        \"Epoch: {} | recon_loss: {}\".format(\n",
    "            epoch, losses.recon_loss.values[-1]\n",
    "        )\n",
    "    )\n",
    "    plot_reconstruction(model, example_data)\n",
    "    plt.plot(losses.recon_loss.values)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-25T15:10:33.006Z"
    }
   },
   "outputs": [],
   "source": [
    "#save_loc = DATA_DIR / 'models' / network_type / DATASET_ID\n",
    "#ensure_dir(save_loc)\n",
    "\n",
    "# Save the entire model to a HDF5 file.\n",
    "# The '.h5' extension indicates that the model shuold be saved to HDF5.\n",
    "#model.save_weights((save_loc / (str(epoch).zfill(4))).as_posix()) \n",
    "\n",
    "# Recreate the exact same model, including its weights and the optimizer\n",
    "#new_model = tf.keras.models.load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot samples from latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-25T15:10:33.008Z"
    }
   },
   "outputs": [],
   "source": [
    "z = model.encode(example_data).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-25T15:10:33.009Z"
    }
   },
   "outputs": [],
   "source": [
    "xmax, ymax = np.max(z, axis=0)\n",
    "xmin, ymin = np.min(z, axis=0)\n",
    "print(xmax, ymax, xmin, ymin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-25T15:10:33.010Z"
    }
   },
   "outputs": [],
   "source": [
    "# sample from grid\n",
    "nx = ny= 30\n",
    "meshgrid = np.meshgrid(np.linspace(xmin, xmax, nx), np.linspace(ymin, ymax, ny))\n",
    "meshgrid = np.array(meshgrid).reshape(2, nx*ny).T\n",
    "x_grid = model.decode(meshgrid)\n",
    "x_grid = x_grid.numpy().reshape(nx, ny, DIMS[0], DIMS[1], DIMS[2])\n",
    "# fill canvas\n",
    "canvas = np.zeros((nx*DIMS[0], ny*DIMS[1]))\n",
    "for xi in range(nx):\n",
    "    for yi in range(ny):\n",
    "        canvas[xi*DIMS[0]:xi*DIMS[0]+DIMS[0], yi*DIMS[1]:yi*DIMS[1]+DIMS[1]] = x_grid[xi, yi,:,:,:].squeeze()\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "ax.matshow(canvas, vmin = 0, cmap=plt.cm.Greys, origin = 'lower')\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  plot dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-25T15:10:33.012Z"
    }
   },
   "outputs": [],
   "source": [
    "all_x = []\n",
    "all_z = []\n",
    "all_indv = []\n",
    "all_labels = []\n",
    "for batch, train_x in tqdm(\n",
    "    zip(range(N_TRAIN_BATCHES), train_dataset), total=N_TRAIN_BATCHES\n",
    "):\n",
    "    x = train_x[0]\n",
    "    all_x.append(x)\n",
    "    x = tf.cast(tf.reshape(x, [BATCH_SIZE] + list(DIMS)), tf.float32) / 255\n",
    "    #model.train_net(x)\n",
    "    all_z.append(model.encode(x).numpy())\n",
    "    all_indv.append(train_x[3].numpy())\n",
    "    all_labels.append(train_x[2].numpy())\n",
    "\n",
    "all_z = np.vstack(all_z)\n",
    "all_indv = np.concatenate(all_indv)\n",
    "all_labels = np.concatenate(all_labels)\n",
    "all_x = np.concatenate(all_x)\n",
    "all_x = np.reshape(all_x, [len(all_x)] + list(DIMS[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-25T15:10:33.013Z"
    }
   },
   "outputs": [],
   "source": [
    "from avgn.visualization.projections import scatter_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-25T15:10:33.014Z"
    }
   },
   "outputs": [],
   "source": [
    "np.shape(all_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-25T15:10:33.017Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(all_z[:,0], all_z[:,1], s=1, c='k', alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-25T15:10:33.018Z"
    }
   },
   "outputs": [],
   "source": [
    "scatter_spec(\n",
    "        np.vstack(all_z),\n",
    "        all_x,\n",
    "        column_size=15,\n",
    "        x_range = [-4,4],\n",
    "        y_range = [-4,4],\n",
    "        pal_color=\"hls\",\n",
    "        color_points=False,\n",
    "        enlarge_points=20,\n",
    "        figsize=(10, 10),\n",
    "        scatter_kwargs = {\n",
    "            'labels': list(all_labels),\n",
    "            'alpha':0.25,\n",
    "            's': 1,\n",
    "            'show_legend': False\n",
    "        },\n",
    "        matshow_kwargs = {\n",
    "            'cmap': plt.cm.Greys\n",
    "        },\n",
    "        line_kwargs = {\n",
    "            'lw':1,\n",
    "            'ls':\"solid\",\n",
    "            'alpha':0.25,\n",
    "        },\n",
    "        draw_lines=True\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
